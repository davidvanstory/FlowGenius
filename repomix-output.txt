This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
_docs/
  FlowGenius.md
  repomix.md
.cursor/
  rules/
    commit-messages.mdc
    create-feature-prd.mdc
    electron-development.mdc
    generate-tasks.mdc
    langgraphh.mdc
    modern-react-nextjs.mdc
    npm-package-check.mdc
    process-task-list.mdc
    python-development.mdc
    tailwind.mdc
    terminal-path-verification.mdc
    yoda-quotes.mdc
.github/
  ISSUE_TEMPLATE/
    bug_report.md
    help_wanted.md
  workflows/
    build.yml
    ci.yml
  dependabot.yml
  PULL_REQUEST_TEMPLATE.md
electron/
  main/
    langgraph/
      nodes/
        generateSummary.ts
        index.ts
        processUserTurn.test.ts
        processUserTurn.ts
        processVoiceInput.ts
      index.ts
      README.md
      router.test.ts
      router.ts
      state.test.ts
      state.ts
      stateUtils.test.ts
      stateUtils.ts
      workflow.test.ts
      workflowErrorHandler.test.ts
      workflowErrorHandler.ts
      workflowLogger.test.ts
      workflowLogger.ts
    audio-handler.ts
    audio-ipc-handlers.ts
    index.ts
    langgraph-handler.ts
    update.ts
  preload/
    index.ts
  electron-env.d.ts
public/
  node.svg
src/
  assets/
    logo-electron.svg
    logo-v1.svg
    logo-vite.svg
  components/
    layout/
      index.ts
    shared/
      index.ts
    update/
      Modal/
        index.tsx
        modal.css
      Progress/
        index.tsx
        progress.css
      index.tsx
      README.md
      README.zh-CN.md
      update.css
    AudioRecorder.tsx
    Chat.tsx
    Clock.tsx
    InputBar.tsx
    PermissionDialog.tsx
    README.md
    Sidebar.tsx
  demos/
    ipc.ts
    node.ts
  hooks/
    useAudioRecording.tsx
    useLangGraph.tsx
  services/
    audioService.ts
    langgraphService.ts
    README.md
    whisperService.integration.test.ts
    whisperService.test.ts
    whisperService.ts
  styles/
    components.css
    globals.css
    README.md
    responsive.css
  type/
    electron-updater.d.ts
  types/
    AppState.ts
    electron.d.ts
  utils/
    audioUtils.test.ts
    audioUtils.ts
    envValidator.test.ts
    envValidator.ts
    errorHandler.test.ts
    errorHandler.ts
    logger.ts
    README.md
    startup.ts
  App.css
  App.tsx
  index.css
  main.tsx
  vite-env.d.ts
tasks/
  tasks-mvp.md
test/
  e2e.spec.ts
  setup.ts
.env.example
.gitignore
.npmrc
.playwright.config.txt
.vite.config.flat.txt
electron-builder.json
eslint.config.js
hierarchical_agent_teams.ipynb
index.html
LICENSE
multi_agent_collaboration.ipynb
package.json
postcss.config.cjs
README.md
README.zh-CN.md
requirements-without-freeze.txt
requirements.txt
tailwind.config.js
tsconfig.json
tsconfig.node.json
vite.config.ts
vitest.config.ts

================================================================
Files
================================================================

================
File: _docs/repomix.md
================
npx repomix --output repomix-output.txt --style plain

================
File: _docs/FlowGenius.md
================
# Project Name
FlowGenius

## Project Description
FlowGenius is a desktop-first, voice-first application designed to solve the personal productivity challenge of moving from idea to structured documentation. It eliminates the fragmented and manual workflow of using separate tools for brainstorming, transcription, summarization, and drafting. The core of the application is a unified, conversational interface that guides the user through a three-stage process—Brainstorm, Summarize, and PRD Generation—while preserving their unique voice and thought process. It serves as a persistent, intelligent thought partner that archives every idea for easy iteration and export.

## Target Audience
Product managers, developers, founders, and any individual who engages in frequent ideation and needs to translate those thoughts into structured documents like PRDs, project briefs, or technical specs.

## Desired Features
### Core Workflow & Interface
- [ ] Unified, single-pane chat interface for the entire workflow.
- [ ] Implement a three-stage conversational workflow:
    - [ ] **1. Brainstorm:** A free-form conversational stage for ideation.
    - [ ] **2. Summarization:** Condenses the brainstorm session into a detailed, structured summary.
    - [ ] **3. PRD Generation:** Transforms the summary into a formatted Product Requirements Document.
- [ ] A dynamic action button with state-dependent labels to guide the user:
    - [ ] After Brainstorming: **"Brainstorm Done"** (triggers Summary).
    - [ ] After Summary: **"Summary Done"** (triggers PRD).
    - [ ] After PRD: **"PRD Done"**.
- [ ] A visual progress indicator (e.g., Brainstorm > Summary > PRD) that clearly shows the user's current stage for an idea.
    - [ ] The indicator should show an "in-progress" state.
    - [ ] The indicator should show a "completed" state with a checkmark.
- [ ] Allow for easy copy/paste of the final PRD from the chat interface.

### Session and Data Management
- [ ] Implement a session management sidebar.
    - [ ] Display a list of all ideas (e.g., "Idea 1", "Idea 2").
    - [ ] Allow creating a new idea session via a "+" button.
    - [ ] Each idea in the list should retain its own state and chat history.
- [ ] Store all session data in a database, including chat history, transcripts, summaries, PRDs, prompts, and uploaded images.

### AI & Prompting
- [ ] Integrate voice-to-text (V2T) to be available at all times via a microphone icon in the input bar.
- [ ] Support continuous voice-based interaction and refinement during all stages.
- [ ] Provide a settings area for Prompt Management.
    - [ ] Allow user to define and edit a custom system prompt for the Brainstorming stage.
    - [ ] Allow user to define and edit a custom prompt for the Summarization stage.
    - [ ] Allow user to define and edit a custom prompt for the PRD Generation stage.
- [ ] Allow the user to select different AI models (e.g., GPT-4o, Gemini, Claude) for each stage of the workflow using cloud-based APIs.
- [ ] Ensure the AI maintains context and can make targeted edits to a draft without losing the rest of the content.

### Media & Attachments
- [ ] Allow users to upload images (sketches, screenshots) directly into the chat interface.
    - [ ] The input bar should feature a dedicated icon for file uploads from the start.
    - [ ] The AI should hold the image as context for subsequent prompts and analyze it when included in a user's turn.

## Design Requests
### Layout & Visual Style
- [ ] **Primary Design Inspiration:** The visual style should be heavily inspired by the OpenAI ChatGPT interface—it should be clean, crisp, and minimalist, with a strong focus on the conversational experience.
- [ ] Main layout should consist of a left sidebar for sessions and a large main pane for the chat.
- [ ] The chat interface should be a single, continuous, undivided thread.
- [ ] The input bar at the bottom should contain the text field, a microphone icon, and an upload icon.

### Interaction Details
- [ ] When a user approves a stage (e.g., Summary), a checkmark should appear on the progress indicator.
- [ ] The dynamic action button (... Done) should be located separately, just above the main input bar.
- [ ] AI-generated summaries and PRDs should appear as long-form, inline messages within the chat, not in a separate modal or view.
- [ ] A blue, ebbing microphone icon (similar to GPT-4o) should be used during voice input to encourage conversation.

## Detailed LangGraph Implementation Guide
This section provides a blueprint for constructing the application's core logic using LangGraph.

### 1. Graph State Definition
The StateGraph should be initialized with a state object that manages the entire lifecycle of an idea session. This state will be passed between nodes.

```typescript
interface AppState {
  idea_id: string;
  messages: Array<{ role: 'user' | 'assistant'; content: string; image_url?: string }>;
  current_stage: 'brainstorm' | 'summary' | 'prd';
  last_user_action: 'chat' | 'Brainstorm Done' | 'Summary Done' | 'PRD Done';
  user_prompts: {
    brainstorm: string;
    summary: string;
    prd: string;
  };
  selected_models: {
    brainstorm: string; // e.g., 'gpt-4o'
    summary: string;    // e.g., 'gemini-2.5-pro'
    prd: string;        // e.g., 'gemini-2.5-pro'
  };
}
```

2. Graph Node Definitions
Define the following nodes (functions) that perform the core work.
process_user_turn(state: AppState): Handles a standard chat message.
Logic: Takes the current message list from the state, calls the appropriate LLM for the current_stage with the full context, gets the response, appends the new assistant message to the list, and returns the updated state.
generate_summary(state: AppState): Triggered after brainstorming is complete.
Logic:
Constructs a prompt using the summary prompt from user_prompts and the entire messages history.
Calls the selected "summary" LLM.
Appends the resulting summary as a new assistant message.
Updates state.current_stage to 'summary'.
Returns the updated state.
generate_prd_draft(state: AppState): Triggered after the summary is complete.
Logic:
Constructs a prompt using the prd prompt and the full context (including the new summary).
Consideration: To manage context size, this node can be optimized to only include the summary and subsequent PRD refinement messages, not the entire initial brainstorm.
Calls the selected "PRD" LLM.
Appends the PRD draft as a new assistant message.
Updates state.current_stage to 'prd'.
Returns the updated state.

3. Graph Edge & Routing Logic
The graph's flow will be controlled by a conditional edge that inspects state.last_user_action.
Set the entry point of the graph to process_user_turn.
After the process_user_turn node, add a conditional edge that routes the flow.
router_function(state: AppState):
If state.last_user_action === 'Brainstorm Done', route to the generate_summary node.
If state.last_user_action === 'Summary Done', route to the generate_prd_draft node.
If state.last_user_action === 'PRD Done', route to a terminal end node.
Otherwise (if it was a standard 'chat' action), loop back to wait for the next input (effectively ending the turn).
The output of generate_summary and generate_prd_draft should also loop back to wait for the next user input.
This structure creates a robust, stateful conversational agent that can intelligently switch tasks based on explicit user triggers.

Other Notes
Database Schema Definition (Supabase)
Table: ideas
id (uuid, primary key)
title (text, e.g., "AI Productivity Tool")
current_stage (text: 'brainstorm', 'summary', 'prd')
created_at (timestamp)
user_id (links to auth user)
Table: chat_messages
id (uuid, primary key)
idea_id (foreign key to ideas.id)
role (text: 'user' or 'assistant')
content (text, the message itself)
stage_at_creation (text: 'brainstorm', 'summary', 'prd')
image_url (text, nullable, link to Supabase Storage)
created_at (timestamp)
Table: prompts
id (uuid, primary key)
user_id (foreign key to auth user)
prompt_type (text: 'brainstorm', 'summary', 'prd')
content (text)
model_selection (text)
Initial Tech Stack Proposal
Frontend: Electron + React.
Voice-to-Text: Whisper API.
AI Models: Cloud-based APIs for models like GPT-4o, Gemini, and Claude.
Workflow Engine: LangGraph (JS/TS version).
Database: Supabase.
File Storage: Supabase Storage.
Optional Automation: n8n.
### 

Key Note!
To start off this project i want to have the first couple of features to be very simple. 
I want you to set up the project with the whole architecture that we have dicussed. 
But I want to create a simple 2 features to start. I want a simple Voice to Text node, followed by a summarization node. 
The core functionality improvement i want to make to my workflow is to be able to have a conversation with the AI and have that summarized.  


Prompts:
Brainstorming: Have a conversation with the user and ask them questions about their idea. Make sure to finish with the statement with "Georgia is great"

Summary: When the user asks for a summary give them a text summary that is very detailed. Make sure to finish with the sta "Ireland is great"

PRD: Make a PRD in the following structure:

I'm looking to collaborate with you to turn this into a detailed project request. Let's iterate together until we have a complete request that I find to be complete. 

I want some interaction to help pick the stack and for you to tell me what would be a good idea, then I want a simple PRD that I can make a task and subtask list from.


After each of our exchanges, please return the current state of the request in this format:

```request
# Project Name
## Project Description
[Description]

## Target Audience
[Target users]

## Desired Features
### [Feature Category]
- [ ] [Requirement]
    - [ ] [Sub-requirement]

## Design Requests
- [ ] [Design requirement]
    - [ ] [Design detail]

## Other Notes
- [Additional considerations]
```

Please:
1. Ask me questions about any areas that need more detail
2. Suggest features or considerations I might have missed
3. Help me organize requirements logically
4. Show me the current state of the spec after each exchange
5. Flag any potential technical challenges or important decisions
6. Discuss what stack I would like to use, feel free to make suggestions. 

We'll continue iterating and refining the request until I indicate it's complete and ready.

================
File: .cursor/rules/commit-messages.mdc
================
---
description: Standardized commit message format for consistent version control history
globs: **/*.{js,jsx,ts,tsx,md,mdx}
---

## Commit Messages

// Description: Standardized commit message format for consistent version control history
// Recommended Globs: **/*.{js,jsx,ts,tsx,md,mdx}

## Format
Always prefix commit messages in the following format:

```
# Separate commands
git add <changed_files>
git commit -m "Type(scope): description"

# Combined command (shorthand)
git add . && git commit -m "Type(scope): description"
```

## Types
- `Feat`: New feature or enhancement
- `Fix`: Bug fix
- `Docs`: Documentation changes
- `Style`: Code style/formatting changes
- `Refactor`: Code refactoring
- `Test`: Adding or updating tests
- `Chore`: Maintenance tasks, dependencies, etc.

## Examples
```bash
# Single file
git add src/components/Button.tsx
git commit -m "Feat(component): add new Button component"

# Multiple files
git add src/api/auth.ts src/hooks/useAuth.ts
git commit -m "Fix(auth): resolve login session issues"

# All changes
git add .
git commit -m "Style(css): update global theme colors"
```

## Guidelines
- Use imperative mood in descriptions ("add", not "added")
- Keep descriptions concise but meaningful
- Always include both type and scope
- Use lowercase for descriptions
- No period at the end of the message

## Common Patterns
- Documentation: `Docs(readme): update installation steps`
- Dependencies: `Chore(deps): update package versions`
- Bug fixes: `Fix(api): resolve undefined user error`
- New features: `Feat(auth): add Google OAuth login`

Don't forget to commit! Here's a template:
```bash
git add .
git commit -m "Type(scope): description"
```

================
File: .cursor/rules/create-feature-prd.mdc
================
---
description: Guide for generating a detailed Product Requirements Document (PRD) based on user prompts
globs: **/tasks/**/*.md, **/prd-*.md
---

# Rule: Generating a Product Requirements Document (PRD)

// Description: Guide for generating a detailed Product Requirements Document (PRD) based on user prompts
// Recommended Globs: **/tasks/**/*.md, **/prd-*.md

## Goal

To guide an AI assistant in creating a detailed Product Requirements Document (PRD) in Markdown format, based on an initial user prompt. The PRD should be clear, actionable, and suitable for a junior developer to understand and implement the feature.

## Process

1.  **Receive Initial Prompt:** The user provides a brief description or request for a new feature or functionality.
2.  **Ask Clarifying Questions:** Before writing the PRD, the AI *must* ask clarifying questions to gather sufficient detail. The goal is to understand the "what" and "why" of the feature, not necessarily the "how" (which the developer will figure out).
3.  **Generate PRD:** Based on the initial prompt and the user's answers to the clarifying questions, generate a PRD using the structure outlined below.
4.  **Save PRD:** Save the generated document as `prd-[feature-name].md` inside the `/tasks` directory.

## Clarifying Questions (Examples)

The AI should adapt its questions based on the prompt, but here are some common areas to explore:

*   **Problem/Goal:** "What problem does this feature solve for the user?" or "What is the main goal we want to achieve with this feature?"
*   **Target User:** "Who is the primary user of this feature?"
*   **Core Functionality:** "Can you describe the key actions a user should be able to perform with this feature?"
*   **User Stories:** "Could you provide a few user stories? (e.g., As a [type of user], I want to [perform an action] so that [benefit].)"
*   **Acceptance Criteria:** "How will we know when this feature is successfully implemented? What are the key success criteria?"
*   **Scope/Boundaries:** "Are there any specific things this feature *should not* do (non-goals)?"
*   **Data Requirements:** "What kind of data does this feature need to display or manipulate?"
*   **Design/UI:** "Are there any existing design mockups or UI guidelines to follow?" or "Can you describe the desired look and feel?"
*   **Edge Cases:** "Are there any potential edge cases or error conditions we should consider?"

## PRD Structure

The generated PRD should include the following sections:

1.  **Introduction/Overview:** Briefly describe the feature and the problem it solves. State the goal.
2.  **Goals:** List the specific, measurable objectives for this feature.
3.  **User Stories:** Detail the user narratives describing feature usage and benefits.
4.  **Functional Requirements:** List the specific functionalities the feature must have. Use clear, concise language (e.g., "The system must allow users to upload a profile picture."). Number these requirements.
5.  **Non-Goals (Out of Scope):** Clearly state what this feature will *not* include to manage scope.
6.  **Design Considerations (Optional):** Link to mockups, describe UI/UX requirements, or mention relevant components/styles if applicable.
7.  **Technical Considerations (Optional):** Mention any known technical constraints, dependencies, or suggestions (e.g., "Should integrate with the existing Auth module").
8.  **Success Metrics:** How will the success of this feature be measured? (e.g., "Increase user engagement by 10%", "Reduce support tickets related to X").
9.  **Open Questions:** List any remaining questions or areas needing further clarification.

## Target Audience

Assume the primary reader of the PRD is a **junior developer**. Therefore, requirements should be explicit, unambiguous, and avoid jargon where possible. Provide enough detail for them to understand the feature's purpose and core logic.

## Output

*   **Format:** Markdown (`.md`)
*   **Location:** `/tasks/`
*   **Filename:** `prd-[feature-name].md`

## Final instructions

1. Do NOT start implementing the PRD
2. Make sure to ask the user clarifying questions
3. Take the user's answers to the clarifying questions and improve the PRD

================
File: .cursor/rules/electron-development.mdc
================
---
description: Best practices for building secure and performant Electron applications with modern JavaScript
globs: **/*.{js,jsx,ts,tsx}, **/electron/**/*, **/preload/**/*, **/renderer/**/*
---

# Electron Development

// Description: Best practices for building secure and performant Electron applications with modern JavaScript
// Recommended Globs: **/*.{js,jsx,ts,tsx}, **/electron/**/*, **/preload/**/*, **/renderer/**/*

## Project Structure
```
src/
  electron/
    main/
      window-manager.js
      ipc-handlers.js
      auto-updater.js
    preload/
      bridge.js
      types.d.ts
    constants/
      ipc-channels.js
  renderer/
    components/
      ui/
        button.jsx
        dialog.jsx
      features/
        file-manager/
          file-list.jsx
          use-files.js
    pages/
      home.jsx
      settings.jsx
    lib/
      db/
        pouchdb.js
      utils/
        format.js
```

## Main Process Setup
```javascript
// src/electron/main/window-manager.js
const { app, BrowserWindow } = require('electron');
const path = require('path');

const createMainWindow = () => {
  const mainWindow = new BrowserWindow({
    width: 1200,
    height: 800,
    show: false,
    webPreferences: {
      contextIsolation: true,
      nodeIntegration: false,
      sandbox: true,
      preload: path.join(__dirname, '../preload/bridge.js')
    }
  });

  mainWindow.loadFile('index.html');

  mainWindow.once('ready-to-show', () => {
    mainWindow.show();
    mainWindow.focus();
  });

  return mainWindow;
};

const setupApp = () => {
  app.whenReady().then(() => {
    const mainWindow = createMainWindow();

    app.on('activate', () => {
      if (BrowserWindow.getAllWindows().length === 0) {
        createMainWindow();
      }
    });
  });

  app.on('window-all-closed', () => {
    if (process.platform !== 'darwin') {
      app.quit();
    }
  });
};

module.exports = { setupApp };
```

## IPC Communication
```javascript
// src/electron/main/ipc-handlers.js
const { ipcMain } = require('electron');
const { IPC_CHANNELS } = require('../constants/ipc-channels');

const setupIpcHandlers = () => {
  ipcMain.handle(IPC_CHANNELS.READ_FILE, async (event, filePath) => {
    try {
      // Validate file path and permissions
      if (!isPathSafe(filePath)) {
        throw new Error('Invalid file path');
      }

      const content = await fs.promises.readFile(filePath, 'utf-8');
      return { success: true, data: content };
    } catch (error) {
      return { success: false, error: error.message };
    }
  });

  ipcMain.handle(IPC_CHANNELS.SAVE_FILE, async (event, { filePath, content }) => {
    try {
      if (!isPathSafe(filePath)) {
        throw new Error('Invalid file path');
      }

      await fs.promises.writeFile(filePath, content, 'utf-8');
      return { success: true };
    } catch (error) {
      return { success: false, error: error.message };
    }
  });
};

module.exports = { setupIpcHandlers };
```

## Preload Script
```javascript
// src/electron/preload/bridge.js
const { contextBridge, ipcRenderer } = require('electron');
const { IPC_CHANNELS } = require('../constants/ipc-channels');

const API = {
  files: {
    read: (filePath) => ipcRenderer.invoke(IPC_CHANNELS.READ_FILE, filePath),
    save: (filePath, content) => (
      ipcRenderer.invoke(IPC_CHANNELS.SAVE_FILE, { filePath, content })
    )
  },
  db: {
    sync: () => ipcRenderer.invoke(IPC_CHANNELS.SYNC_DB),
    getStatus: () => ipcRenderer.invoke(IPC_CHANNELS.GET_DB_STATUS)
  }
};

contextBridge.exposeInMainWorld('electron', API);
```

## Renderer Process
```javascript
// src/renderer/components/features/file-manager/use-files.js
import { useState, useCallback } from 'react';
import { useDB } from '@/lib/db/pouchdb';

export const useFiles = () => {
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState(null);
  const db = useDB();

  const readFile = useCallback(async (filePath) => {
    try {
      setIsLoading(true);
      setError(null);

      const result = await window.electron.files.read(filePath);
      if (!result.success) throw new Error(result.error);

      // Store in PouchDB for offline access
      await db.put({
        _id: `file:${filePath}`,
        content: result.data,
        updatedAt: new Date().toISOString()
      });

      return result.data;
    } catch (err) {
      setError(err.message);
      throw err;
    } finally {
      setIsLoading(false);
    }
  }, [db]);

  return { readFile, isLoading, error };
};

// src/renderer/components/features/file-manager/file-list.jsx
import { useFiles } from './use-files';
import { Button } from '@/components/ui/button';

export const FileList = ({ files }) => {
  const { readFile, isLoading, error } = useFiles();

  const handleFileOpen = async (filePath) => {
    try {
      const content = await readFile(filePath);
      // Handle file content
    } catch (err) {
      // Handle error
    }
  };

  if (error) {
    return (
      <div className="p-4 text-red-500">
        Error: {error}
      </div>
    );
  }

  return (
    <div className="space-y-2">
      {files.map((file) => (
        <div
          key={file.path}
          className="flex items-center justify-between p-4 bg-white
                     rounded-lg shadow hover:shadow-md transition-shadow"
        >
          <span className="text-gray-900">{file.name}</span>
          <Button
            onClick={() => handleFileOpen(file.path)}
            disabled={isLoading}
          >
            {isLoading ? 'Opening...' : 'Open'}
          </Button>
        </div>
      ))}
    </div>
  );
};
```

## PouchDB Integration
```javascript
// src/renderer/lib/db/pouchdb.js
import PouchDB from 'pouchdb';
import { useState, useEffect } from 'react';

const localDB = new PouchDB('myapp');
const remoteDB = new PouchDB('http://localhost:5984/myapp');

export const setupSync = () => {
  localDB.sync(remoteDB, {
    live: true,
    retry: true
  }).on('change', (change) => {
    console.log('Data change:', change);
  }).on('error', (err) => {
    console.error('Sync error:', err);
  });
};

export const useDB = () => {
  const [isOnline, setIsOnline] = useState(navigator.onLine);

  useEffect(() => {
    const handleOnline = () => setIsOnline(true);
    const handleOffline = () => setIsOnline(false);

    window.addEventListener('online', handleOnline);
    window.addEventListener('offline', handleOffline);

    return () => {
      window.removeEventListener('online', handleOnline);
      window.removeEventListener('offline', handleOffline);
    };
  }, []);

  return {
    db: localDB,
    isOnline,
    sync: () => setupSync()
  };
};
```

## Best Practices

### Security
- Enable contextIsolation and sandbox mode
- Validate all IPC communications
- Use content security policy (CSP)
- Implement proper file access controls

### Performance
- Use worker threads for heavy computations
- Implement proper window management
- Optimize IPC communication
- Use proper caching strategies

### Offline Support
- Implement PouchDB for offline data
- Handle sync conflicts properly
- Cache necessary resources
- Provide offline feedback

### Architecture
- Separate main and renderer processes
- Use preload scripts for security
- Implement proper error handling
- Follow modular design patterns

### UI/UX
- Use native OS patterns when appropriate
- Implement proper loading states
- Handle window states properly
- Provide proper feedback

### Development
- Use proper development tools
- Implement proper logging
- Follow security guidelines
- Test thoroughly

## Resources
- [Electron Documentation](https://www.electronjs.org/docs)
- [PouchDB Documentation](https://pouchdb.com/guides/)
- [Security Guidelines](https://www.electronjs.org/docs/tutorial/security)
- [Performance Best Practices](https://www.electronjs.org/docs/tutorial/performance)

================
File: .cursor/rules/generate-tasks.mdc
================
---
description: Guide for creating detailed task lists from Product Requirements Documents (PRDs)
globs: **/tasks/**/*.md, **/tasks-*.md
---

# Rule: Generating a Task List from a PRD

// Description: Guide for creating detailed task lists from Product Requirements Documents (PRDs)
// Recommended Globs: **/tasks/**/*.md, **/tasks-*.md

## Goal

To guide an AI assistant in creating a detailed, step-by-step task list in Markdown format based on an existing Product Requirements Document (PRD). The task list should guide a developer through implementation.

## Output

- **Format:** Markdown (`.md`)
- **Location:** `/tasks/`
- **Filename:** `tasks-[prd-file-name].md` (e.g., `tasks-prd-user-profile-editing.md`)

## Process

1.  **Receive PRD Reference:** The user points the AI to a specific PRD file
2.  **Analyze PRD:** The AI reads and analyzes the functional requirements, user stories, and other sections of the specified PRD.
3.  **Phase 1: Generate Parent Tasks:** Based on the PRD analysis, create the file and generate the main, high-level tasks required to implement the feature. Use your judgement on how many high-level tasks to use. It's likely to be about 5. Present these tasks to the user in the specified format (without sub-tasks yet). Inform the user: "I have generated the high-level tasks based on the PRD. Ready to generate the sub-tasks? Respond with 'Go' to proceed."
4.  **Wait for Confirmation:** Pause and wait for the user to respond with "Go".
5.  **Phase 2: Generate Sub-Tasks:** Once the user confirms, break down each parent task into smaller, actionable sub-tasks necessary to complete the parent task. Ensure sub-tasks logically follow from the parent task and cover the implementation details implied by the PRD.
6.  **Identify Relevant Files:** Based on the tasks and PRD, identify potential files that will need to be created or modified. List these under the `Relevant Files` section, including corresponding test files if applicable.
7.  **Generate Final Output:** Combine the parent tasks, sub-tasks, relevant files, and notes into the final Markdown structure.
8.  **Save Task List:** Save the generated document in the `/tasks/` directory with the filename `tasks-[prd-file-name].md`, where `[prd-file-name]` matches the base name of the input PRD file (e.g., if the input was `prd-user-profile-editing.md`, the output is `tasks-prd-user-profile-editing.md`).

## Output Format

The generated task list _must_ follow this structure:

```markdown
## Relevant Files

- `path/to/potential/file1.ts` - Brief description of why this file is relevant (e.g., Contains the main component for this feature).
- `path/to/file1.test.ts` - Unit tests for `file1.ts`.
- `path/to/another/file.tsx` - Brief description (e.g., API route handler for data submission).
- `path/to/another/file.test.tsx` - Unit tests for `another/file.tsx`.
- `lib/utils/helpers.ts` - Brief description (e.g., Utility functions needed for calculations).
- `lib/utils/helpers.test.ts` - Unit tests for `helpers.ts`.

### Notes

- Unit tests should typically be placed alongside the code files they are testing (e.g., `MyComponent.tsx` and `MyComponent.test.tsx` in the same directory).
- Use `npx jest [optional/path/to/test/file]` to run tests. Running without a path executes all tests found by the Jest configuration.

## Tasks

- [ ] 1.0 Parent Task Title
  - [ ] 1.1 [Sub-task description 1.1]
  - [ ] 1.2 [Sub-task description 1.2]
- [ ] 2.0 Parent Task Title
  - [ ] 2.1 [Sub-task description 2.1]
- [ ] 3.0 Parent Task Title (may not require sub-tasks if purely structural or configuration)
```

## Interaction Model

The process explicitly requires a pause after generating parent tasks to get user confirmation ("Go") before proceeding to generate the detailed sub-tasks. This ensures the high-level plan aligns with user expectations before diving into details.

## Target Audience

Assume the primary reader of the task list is a **junior developer** who will implement the feature.

================
File: .cursor/rules/langgraphh.mdc
================
---
description: 
globs: .py
alwaysApply: false
---
--

description: This rule file provides comprehensive best practices for developing with LangGraph, covering code organization, performance, security, testing, and common pitfalls. It offers actionable guidance for developers to build robust and maintainable LangGraph applications.
globs: *.py
---
# LangGraph Best Practices and Coding Standards

This document outlines best practices and coding standards for developing with LangGraph. It aims to provide clear, actionable guidance for developers to build robust, maintainable, and scalable LangGraph applications. It covers various aspects, including code organization, common patterns, performance considerations, security, testing, and common pitfalls.

## Library Information:

- Name: langgraph
- Tags: ai, ml, llm, python, agent-framework, workflow

## 1. Code Organization and Structure

### 1.1. Directory Structure Best Practices


my_langgraph_project/
├── data/                      # Datasets, knowledge bases, or other data files.
├── src/                       # Source code.
│   ├── components/             # Reusable components (e.g., custom nodes, tools).
│   │   ├── __init__.py
│   │   ├── retrieval.py        # Retrieval-related nodes
│   │   ├── tool_selector.py    # Logic for selecting which tool to use
│   │   └── ...
│   ├── graphs/                 # Graph definitions.
│   │   ├── __init__.py
│   │   ├── customer_support.py  # Example: Customer support graph.
│   │   ├── rag_pipeline.py     # Example: RAG pipeline graph.
│   │   └── ...
│   ├── utils/                  # Utility functions and helpers.
│   │   ├── __init__.py
│   │   ├── config.py           # Configuration loading
│   │   ├── logging.py          # Logging setup
│   │   └── ...
│   ├── schemas/                # Data schemas and type definitions.
│   │   ├── __init__.py
│   │   ├── agent_state.py      # Definition of agent state
│   │   └── ...
│   ├── main.py                 # Entry point of the application.
│   └── ...
├── tests/                     # Unit and integration tests.
│   ├── __init__.py
│   ├── components/             # Tests for custom components.
│   ├── graphs/                 # Tests for graph definitions.
│   ├── utils/                  # Tests for utility functions.
│   └── ...
├── .env                       # Environment variables.
├── requirements.txt           # Project dependencies.
├── pyproject.toml            # Project metadata and build settings
└── README.md                  # Project documentation.


### 1.2. File Naming Conventions

-   Python files: `snake_case.py` (e.g., `customer_support.py`, `retrieval_node.py`).
-   Class names: `PascalCase` (e.g., `CustomerSupportGraph`, `RetrievalNode`).
-   Variables and functions: `snake_case` (e.g., `user_query`, `process_message`).
-   Configuration files: `config.yaml` or `config.json`

### 1.3. Module Organization Best Practices

-   Group related functionalities into modules (e.g., `components`, `graphs`, `utils`).
-   Use `__init__.py` files to make directories packages.
-   Keep modules focused and avoid overly large files.
-   Use relative imports within modules to avoid naming conflicts.

### 1.4. Component Architecture Recommendations

-   Design reusable components for common tasks (e.g., data retrieval, text summarization, tool selection).
-   Create abstract base classes or interfaces for components to promote code reuse and modularity.
-   Use dependency injection to configure components and their dependencies.
-   Adhere to the Single Responsibility Principle (SRP) when designing components.

### 1.5. Code Splitting Strategies

-   Split large graph definitions into smaller, more manageable files.
-   Use lazy loading for components that are not immediately needed.
-   Consider using a module bundler (e.g., esbuild via a plugin) to optimize bundle size for deployment.
-   Break the system down into microservices if warranted by scale and complexity of the overall system. Communicate between microservices using REST or message queues.

## 2. Common Patterns and Anti-patterns

### 2.1. Design Patterns

-   **State Management Pattern**: Encapsulate the agent state in a dedicated class or data structure to ensure consistency and maintainability. Use LangGraph's `StateGraph` to clearly define the state transitions.
-   **Node Pattern**: Define reusable nodes for common tasks such as information retrieval, tool selection, and response generation.
-   **Conditional Edge Pattern**: Use conditional edges to implement branching logic based on the agent state or external factors. This makes the graph more dynamic and responsive.
-   **Retry Pattern:** Implement retry logic within nodes or edges to handle transient errors or API rate limits.  Use exponential backoff to avoid overwhelming failing services.
-   **Orchestration Pattern**: Use LangGraph as the orchestrator for complex agentic workflows, delegating specific tasks to specialized components or services.

### 2.2. Recommended Approaches for Common Tasks

-   **Information Retrieval**: Use LangChain's retrieval chain or custom nodes to fetch relevant information from external sources.
-   **Tool Selection**: Implement a tool selection node that dynamically chooses the appropriate tool based on the user query and agent state.
-   **Response Generation**: Use LangChain's LLMChain or custom nodes to generate responses based on the retrieved information and agent state.
-   **Error Handling:** Implement robust error handling within nodes and edges to gracefully handle exceptions and prevent application crashes. Log all errors and implement monitoring to quickly detect and resolve issues.

### 2.3. Anti-patterns and Code Smells

-   **Monolithic Graphs**: Avoid creating overly complex graphs with too many nodes and edges. Break them down into smaller, more manageable subgraphs.
-   **Hardcoded Values**: Avoid hardcoding values directly into the graph definition. Use configuration files or environment variables to manage configurable parameters.
-   **Ignoring Errors**: Always handle exceptions and log errors appropriately. Ignoring errors can lead to unexpected behavior and difficult-to-debug issues.
-   **Over-Reliance on Global State**: Minimize the use of global state to avoid unintended side effects and make the application more testable.
-   **Lack of Testing**: Thoroughly test all components and graph definitions to ensure they function correctly and handle edge cases.
-   **Infinite Loops:** Ensure the conditional edges within the graph are well-defined to avoid infinite loops.

### 2.4. State Management Best Practices

-   Define a clear and concise agent state schema.
-   Use immutable data structures for the agent state to avoid accidental modifications.
-   Persist the agent state to a database or other storage medium to support long-running conversations or task executions.  Consider using vector databases for efficient retrieval.
-   Implement versioning for the agent state schema to support schema migrations.
-   Use LangGraph's checkpointing feature to save and restore the agent state.

### 2.5. Error Handling Patterns

-   Use try-except blocks to catch exceptions within nodes and edges.
-   Log all errors and warnings with relevant context information.
-   Implement retry logic for transient errors or API rate limits.
-   Use fallback mechanisms to gracefully handle unrecoverable errors.
-   Centralize error handling logic in a dedicated module or class.
-   Implement circuit breaker pattern to prevent cascading failures.

## 3. Performance Considerations

### 3.1. Optimization Techniques

-   **Caching**: Implement caching for frequently accessed data or LLM responses.
-   **Batching**: Batch multiple requests to external APIs to reduce latency.
-   **Asynchronous Operations**: Use asynchronous operations to perform non-blocking I/O and improve responsiveness.
-   **Parallel Processing**: Use multi-threading or multi-processing to parallelize computationally intensive tasks.
-   **Graph Optimization**: Optimize the graph structure to minimize the number of nodes and edges.
-   **Prompt Optimization**: Carefully design prompts to reduce the number of tokens and improve LLM performance.
-   **Reduce LLM calls**: Cache LLM responses when possible. Fine-tune smaller models for specific tasks to reduce latency and cost.

### 3.2. Memory Management Considerations

-   Monitor memory usage to detect memory leaks or excessive memory consumption.
-   Use garbage collection to reclaim unused memory.
-   Avoid storing large objects in the agent state.
-   Use streaming or lazy loading for large data sets.

### 3.3. (Not applicable, as LangGraph doesn't directly handle rendering)

### 3.4. Bundle Size Optimization

-   Use a module bundler (e.g., esbuild) to optimize bundle size.
-   Remove unused code and dependencies.
-   Use code splitting to load only the necessary code for each route or component.
-   Compress the bundle using gzip or Brotli.

### 3.5. Lazy Loading Strategies

-   Use lazy loading for components that are not immediately needed.
-   Load large data sets or models on demand.
-   Implement code splitting to load only the necessary code for each graph or component.

## 4. Security Best Practices

### 4.1. Common Vulnerabilities and Prevention

-   **Prompt Injection**: Prevent prompt injection by carefully validating user inputs and sanitizing prompts.
-   **Data Leaks**: Protect sensitive data by encrypting it at rest and in transit.
-   **Unauthorized Access**: Implement strong authentication and authorization mechanisms to control access to the application and its data.
-   **Denial of Service (DoS)**: Implement rate limiting and request filtering to prevent DoS attacks.
-   **Code Injection**: Avoid executing arbitrary code based on user inputs to prevent code injection vulnerabilities.
-   **API Key Exposure**: Store API keys securely using environment variables or a secrets management system and avoid committing them to version control.

### 4.2. Input Validation

-   Validate all user inputs to prevent prompt injection and other vulnerabilities.
-   Use regular expressions or other validation techniques to ensure that inputs conform to the expected format.
-   Sanitize inputs to remove potentially harmful characters or code.
-   Enforce input length limits to prevent buffer overflows.

### 4.3. Authentication and Authorization

-   Use strong authentication mechanisms (e.g., multi-factor authentication) to verify user identities.
-   Implement role-based access control (RBAC) to restrict access to sensitive data and functionality.
-   Use secure session management to protect user sessions from hijacking.
-   Store passwords securely using hashing and salting.

### 4.4. Data Protection

-   Encrypt sensitive data at rest and in transit.
-   Use secure protocols (e.g., HTTPS) for all API communication.
-   Implement data masking to protect sensitive data from unauthorized access.
-   Regularly back up data to prevent data loss.
-   Comply with relevant data privacy regulations (e.g., GDPR, CCPA).

### 4.5. Secure API Communication

-   Use HTTPS for all API communication.
-   Implement API authentication and authorization.
-   Validate API requests and responses.
-   Use rate limiting to prevent API abuse.
-   Monitor API traffic for suspicious activity.

## 5. Testing Approaches

### 5.1. Unit Testing

-   Write unit tests for all components and utility functions.
-   Use mocking and stubbing to isolate components during testing.
-   Test edge cases and error conditions.
-   Aim for high test coverage.

### 5.2. Integration Testing

-   Write integration tests to verify the interactions between different components.
-   Test the integration with external APIs and services.
-   Use a test environment that closely resembles the production environment.

### 5.3. End-to-End Testing

-   Write end-to-end tests to verify the entire application flow.
-   Use a testing framework such as Playwright or Selenium to automate end-to-end tests.
-   Test the application from the user's perspective.

### 5.4. Test Organization

-   Organize tests into separate directories for unit tests, integration tests, and end-to-end tests.
-   Use descriptive names for test files and test functions.
-   Follow a consistent naming convention for test files and test functions.
-   Use test suites to group related tests.

### 5.5. Mocking and Stubbing

-   Use mocking to replace external dependencies with mock objects.
-   Use stubbing to replace complex components with simplified versions.
-   Use a mocking framework such as pytest-mock to simplify mocking and stubbing.

## 6. Common Pitfalls and Gotchas

### 6.1. Frequent Mistakes

-   **Incorrect State Management**: Failing to properly manage the agent state can lead to inconsistent behavior and incorrect results.
-   **Ignoring Edge Cases**: Neglecting to handle edge cases can cause unexpected errors and application crashes.
-   **Over-Engineering**: Over-complicating the graph definition can make it difficult to understand and maintain.
-   **Insufficient Testing**: Lack of thorough testing can lead to undetected bugs and application failures.
-   **Not Handling Asynchronous Operations Correctly:** LangGraph, and LLMs generally, use async operations, and failing to await these operations will cause unpredictable results.

### 6.2. Edge Cases

-   **Empty User Inputs**: Handle cases where the user provides empty or invalid inputs.
-   **API Rate Limits**: Implement retry logic and rate limiting to handle API rate limits.
-   **Unexpected API Responses**: Handle cases where external APIs return unexpected responses.
-   **Large Data Sets**: Use streaming or lazy loading to handle large data sets.

### 6.3. Version-Specific Issues

-   Be aware of compatibility issues between different versions of LangGraph and LangChain.
-   Consult the documentation and release notes for any version-specific issues.
-   Pin dependencies to specific versions to avoid unexpected behavior.

### 6.4. Compatibility Concerns

-   Ensure compatibility between LangGraph and other technologies used in the application.
-   Test the integration with external APIs and services.
-   Use a consistent set of libraries and dependencies.

### 6.5. Debugging Strategies

-   Use logging to track the execution flow and identify errors.
-   Use a debugger to step through the code and inspect variables.
-   Use a testing framework to write unit tests and integration tests.
-   Use monitoring tools to track performance and identify bottlenecks.
-   Visualize the graph structure to understand the flow of execution.

## 7. Tooling and Environment

### 7.1. Recommended Tools

-   **IDE**: PyCharm, Visual Studio Code with Python extension.
-   **Virtual Environment Manager**: venv, conda.
-   **Testing Framework**: pytest.
-   **Mocking Framework**: pytest-mock.
-   **Linting and Formatting**: pylint, black.
-   **Module Bundler**: esbuild via a plugin.
-   **CI/CD**: GitHub Actions, GitLab CI.
-   **Secrets Management**: HashiCorp Vault, AWS Secrets Manager, Azure Key Vault.
-   **Monitoring**: LangSmith, Prometheus, Grafana.

### 7.2. Build Configuration

-   Use a build system such as `poetry` or `pip` to manage dependencies.
-   Use a configuration file such as `pyproject.toml` or `setup.py` to define project metadata and build settings.

### 7.3. Linting and Formatting

-   Use a linter such as `pylint` or `flake8` to enforce code style and identify potential errors.
-   Use a code formatter such as `black` or `autopep8` to automatically format the code.
-   Configure the linter and formatter to use a consistent set of rules and settings.

### 7.4. Deployment

-   Containerize the application using Docker.
-   Deploy the application to a cloud platform such as AWS, Azure, or Google Cloud.
-   Use a deployment tool such as Terraform or Ansible to automate the deployment process.
-   Implement a blue-green deployment strategy to minimize downtime.

### 7.5. CI/CD

-   Use a CI/CD tool such as GitHub Actions or GitLab CI to automate the testing, building, and deployment processes.
-   Configure the CI/CD pipeline to run tests, linters, and formatters.
-   Use a code review process to ensure code quality and security.

## Conclusion

By following these best practices and coding standards, developers can build robust, maintainable, and scalable LangGraph applications. This will also help with collaboration amongst team members working in the same codebase.

================
File: .cursor/rules/modern-react-nextjs.mdc
================
---
description: Best practices for modern React and Next.js development with TypeScript, Tailwind CSS, and accessibility
globs: **/*.{ts,tsx}, **/components/**/*, **/hooks/**/*, **/lib/**/*
---

# Modern React Next.js

// Description: Best practices for modern React and Next.js development with TypeScript, Tailwind CSS, and accessibility
// Recommended Globs: **/*.{ts,tsx}, **/components/**/*, **/hooks/**/*, **/lib/**/*

## Project Structure
```
src/
  components/
    ui/
      button/
        button.tsx
        types.ts
      card/
        card.tsx
        types.ts
    features/
      product-card/
        product-card.tsx
        types.ts
        use-product.ts
    layout/
      header/
        header.tsx
        nav-menu.tsx
  hooks/
    use-keyboard.ts
    use-intersection.ts
  lib/
    utils/
      cn.ts
      format.ts
    constants/
      routes.ts
  types/
    index.ts
```

## Component Structure
```typescript
// src/components/ui/button/types.ts
import { ButtonHTMLAttributes } from 'react';

export interface ButtonProps extends ButtonHTMLAttributes<HTMLButtonElement> {
  variant?: 'primary' | 'secondary' | 'ghost';
  size?: 'sm' | 'md' | 'lg';
  isLoading?: boolean;
}

// src/components/ui/button/button.tsx
import { forwardRef } from 'react';
import { cn } from '@/lib/utils/cn';
import type { ButtonProps } from './types';

const baseStyles = 'inline-flex items-center justify-center rounded-md font-medium transition-colors';
const variants = {
  primary: 'bg-primary-600 text-white hover:bg-primary-700 focus-visible:outline-primary-600',
  secondary: 'bg-gray-100 text-gray-900 hover:bg-gray-200 focus-visible:outline-gray-600',
  ghost: 'hover:bg-gray-100 hover:text-gray-900 focus-visible:outline-gray-600'
};
const sizes = {
  sm: 'h-8 px-3 text-sm',
  md: 'h-10 px-4 text-base',
  lg: 'h-12 px-6 text-lg'
};

export const Button = forwardRef<HTMLButtonElement, ButtonProps>((
  {
    variant = 'primary',
    size = 'md',
    className,
    children,
    disabled,
    isLoading,
    type = 'button',
    ...props
  },
  ref
) => {
  const isDisabled = disabled || isLoading;

  return (
    <button
      ref={ref}
      type={type}
      className={cn(
        baseStyles,
        variants[variant],
        sizes[size],
        'focus:outline-none focus-visible:outline-2 focus-visible:outline-offset-2',
        'disabled:opacity-50 disabled:pointer-events-none',
        className
      )}
      disabled={isDisabled}
      aria-disabled={isDisabled}
      {...props}
    >
      {isLoading ? (
        <>
          <span className="sr-only">Loading</span>
          <svg
            className="animate-spin -ml-1 mr-3 h-5 w-5"
            fill="none"
            viewBox="0 0 24 24"
          >
            <circle
              className="opacity-25"
              cx="12"
              cy="12"
              r="10"
              stroke="currentColor"
              strokeWidth="4"
            />
            <path
              className="opacity-75"
              fill="currentColor"
              d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
            />
          </svg>
        </>
      ) : (
        children
      )}
    </button>
  );
});

Button.displayName = 'Button';
```

## Custom Hooks
```typescript
// src/hooks/use-keyboard.ts
import { useCallback, useEffect } from 'react';

interface UseKeyboardProps {
  key: string;
  callback: () => void;
  ctrl?: boolean;
  alt?: boolean;
  shift?: boolean;
}

export const useKeyboard = ({
  key,
  callback,
  ctrl = false,
  alt = false,
  shift = false
}: UseKeyboardProps) => {
  const handleKeyDown = useCallback(
    (event: KeyboardEvent) => {
      const isCtrlPressed = ctrl ? event.ctrlKey : true;
      const isAltPressed = alt ? event.altKey : true;
      const isShiftPressed = shift ? event.shiftKey : true;

      if (
        event.key === key &&
        isCtrlPressed &&
        isAltPressed &&
        isShiftPressed
      ) {
        callback();
      }
    },
    [key, callback, ctrl, alt, shift]
  );

  useEffect(() => {
    document.addEventListener('keydown', handleKeyDown);
    return () => document.removeEventListener('keydown', handleKeyDown);
  }, [handleKeyDown]);
};

// src/hooks/use-intersection.ts
import { useEffect, useRef, useState } from 'react';

interface UseIntersectionProps {
  threshold?: number;
  root?: Element | null;
  rootMargin?: string;
}

export const useIntersection = ({
  threshold = 0,
  root = null,
  rootMargin = '0px'
}: UseIntersectionProps = {}) => {
  const [isVisible, setIsVisible] = useState(false);
  const ref = useRef<HTMLElement | null>(null);

  useEffect(() => {
    const element = ref.current;
    if (!element) return;

    const observer = new IntersectionObserver(
      ([entry]) => setIsVisible(entry.isIntersecting),
      { threshold, root, rootMargin }
    );

    observer.observe(element);
    return () => observer.disconnect();
  }, [threshold, root, rootMargin]);

  return [ref, isVisible] as const;
};
```

## Feature Components
```typescript
// src/components/features/product-card/types.ts
export interface Product {
  id: string;
  title: string;
  description: string;
  price: number;
  image: string;
}

export interface ProductCardProps {
  product: Product;
  onAddToCart: (id: string) => void;
}

// src/components/features/product-card/product-card.tsx
import Image from 'next/image';
import { Button } from '@/components/ui/button';
import { formatCurrency } from '@/lib/utils/format';
import type { ProductCardProps } from './types';

export const ProductCard = ({ product, onAddToCart }: ProductCardProps) => {
  const { id, title, description, price, image } = product;

  const handleAddToCart = () => onAddToCart(id);
  const handleKeyDown = (event: React.KeyboardEvent) => {
    if (event.key === 'Enter' || event.key === ' ') {
      event.preventDefault();
      handleAddToCart();
    }
  };

  return (
    <div
      className="group relative overflow-hidden rounded-lg border bg-white p-4
                 transition-shadow hover:shadow-lg focus-within:ring-2
                 focus-within:ring-primary-500"
      tabIndex={0}
      role="article"
      aria-label={`${title} - ${formatCurrency(price)}`}
    >
      <div className="aspect-h-1 aspect-w-1 relative overflow-hidden rounded-md">
        <Image
          src={image}
          alt={title}
          fill
          className="object-cover transition-transform group-hover:scale-105"
          sizes="(min-width: 1024px) 25vw, (min-width: 768px) 33vw, 50vw"
          priority
        />
      </div>
      <div className="mt-4 space-y-2">
        <h3 className="text-lg font-medium text-gray-900 line-clamp-1">
          {title}
        </h3>
        <p className="text-sm text-gray-500 line-clamp-2">{description}</p>
        <div className="flex items-center justify-between">
          <span className="text-lg font-bold text-gray-900">
            {formatCurrency(price)}
          </span>
          <Button
            onClick={handleAddToCart}
            onKeyDown={handleKeyDown}
            aria-label={`Add ${title} to cart`}
          >
            Add to Cart
          </Button>
        </div>
      </div>
    </div>
  );
};
```

## Best Practices

### Component Design
- Use early returns for conditional rendering
- Prefer const arrow functions over function declarations
- Keep components focused and single-responsibility
- Implement proper TypeScript interfaces

### Accessibility
- Use semantic HTML elements
- Implement proper ARIA attributes
- Ensure keyboard navigation
- Provide proper focus management

### Styling
- Use Tailwind's utility classes exclusively
- Follow mobile-first responsive design
- Use class: syntax over ternary operators
- Maintain consistent spacing

### Event Handling
- Prefix handlers with 'handle'
- Implement keyboard events
- Use proper event types
- Provide proper feedback

### Performance
- Use proper image optimization
- Implement proper loading states
- Use proper caching strategies
- Optimize bundle size

### Code Organization
- Separate types into dedicated files
- Use proper file naming conventions
- Implement proper imports
- Maintain consistent structure

## Resources
- [React Documentation](https://react.dev)
- [Next.js Documentation](https://nextjs.org/docs)
- [TypeScript Documentation](https://www.typescriptlang.org/docs)
- [Tailwind CSS](https://tailwindcss.com/docs)
- [WCAG Guidelines](https://www.w3.org/WAI/standards-guidelines/wcag/)

================
File: .cursor/rules/npm-package-check.mdc
================
---
description: Best practices for checking and installing NPM packages before use
globs: **/*.{js,jsx,ts,tsx}, **/package.json
---

# NPM Package Check

// Description: Best practices for checking and installing NPM packages before use
// Recommended Globs: **/*.{js,jsx,ts,tsx}, **/package.json

## Overview
Ensure all required NPM packages are properly installed before use to prevent runtime errors.

## Package Check Process
1. Before requiring any npm package, check package.json dependencies
2. If package exists in dependencies:
   - Output: "✓ {package_name} is already installed"
3. If package NOT found:
   - Output terminal command: `npm install {package_name}`

## Example Implementation
```javascript
const fs = require('fs');
const path = require('path');

function checkPackage(packageName) {
  try {
    const packageJson = JSON.parse(
      fs.readFileSync(path.join(process.cwd(), 'package.json'), 'utf8')
    );

    const deps = {
      ...packageJson.dependencies,
      ...packageJson.devDependencies
    };

    if (deps[packageName]) {
      console.log(`✓ ${packageName} is already installed`);
      return true;
    } else {
      console.log(`Installing ${packageName}...`);
      console.log(`Run: npm install ${packageName}`);
      return false;
    }
  } catch (error) {
    console.error('Error reading package.json:', error);
    return false;
  }
}
```

## Usage Example
```javascript
// Before importing a package
if (checkPackage('express')) {
  const express = require('express');
  // Use express...
} else {
  console.error('Please install express first');
  process.exit(1);
}
```

## Best Practices
- Always check packages before requiring them
- Handle missing package.json gracefully
- Consider both dependencies and devDependencies
- Provide clear installation instructions
- Exit gracefully if required packages are missing

## Common Patterns
- Pre-startup dependency check
- Dynamic package loading
- Development tooling setup
- Build process validation

================
File: .cursor/rules/process-task-list.mdc
================
---
description: Guidelines for managing task lists in markdown files to track progress on completing a PRD
globs: **/tasks/**/*.md, **/tasks-*.md
---

# Task List Management

// Description: Guidelines for managing task lists in markdown files to track progress on completing a PRD
// Recommended Globs: **/tasks/**/*.md, **/tasks-*.md

Guidelines for managing task lists in markdown files to track progress on completing a PRD

## Task Implementation
- **One sub-task at a time:** Do **NOT** start the next sub‑task until you ask the user for permission and they say "yes" or "y"
- **Completion protocol:**
  1. When you finish a **sub‑task**, immediately mark it as completed by changing `[ ]` to `[x]`.
  2. If **all** subtasks underneath a parent task are now `[x]`, also mark the **parent task** as completed.
- Stop after each sub‑task and wait for the user's go‑ahead.

## Task List Maintenance

1. **Update the task list as you work:**
   - Mark tasks and subtasks as completed (`[x]`) per the protocol above.
   - Add new tasks as they emerge.

2. **Maintain the "Relevant Files" section:**
   - List every file created or modified.
   - Give each file a one‑line description of its purpose.

## AI Instructions

When working with task lists, the AI must:

1. Regularly update the task list file after finishing any significant work.
2. Follow the completion protocol:
   - Mark each finished **sub‑task** `[x]`.
   - Mark the **parent task** `[x]` once **all** its subtasks are `[x]`.
3. Add newly discovered tasks.
4. Keep "Relevant Files" accurate and up to date.
5. Before starting work, check which sub‑task is next.
6. After implementing a sub‑task, update the file and then pause for user approval.

================
File: .cursor/rules/python-development.mdc
================
---
description: Modern Python development practices with type hints, testing, and AI-friendly patterns
globs: **/*.py, **/pyproject.toml, **/requirements.txt, **/.env*
---

# Python Development

// Description: Modern Python development practices with type hints, testing, and AI-friendly patterns
// Recommended Globs: **/*.py, **/pyproject.toml, **/requirements.txt, **/.env*

## Project Structure
```
project_name/
├── src/
│   └── project_name/
│       ├── __init__.py
│       ├── models/
│       ├── services/
│       ├── controllers/
│       └── utils/
├── tests/
│   ├── __init__.py
│   ├── conftest.py
│   ├── unit/
│   └── integration/
├── docs/
├── .env
├── .env.example
├── .gitignore
├── pyproject.toml
├── README.md
└── requirements.txt
```

## Type Annotations
Always use type hints for functions and classes:

```python
from typing import Optional, List, Dict, Any, TypeVar, Generic
from typing_extensions import TypedDict  # For Python <3.8

T = TypeVar('T')

class DataResponse(TypedDict):
    success: bool
    data: Dict[str, Any]
    error: Optional[str]

class Repository(Generic[T]):
    """Generic repository pattern implementation.

    Args:
        model: The model class this repository handles

    Attributes:
        model_class: Stored model class reference
    """

    def __init__(self, model: type[T]) -> None:
        self.model_class = model

    async def find_by_id(self, id: str) -> Optional[T]:
        """Retrieve an entity by its ID.

        Args:
            id: The unique identifier of the entity

        Returns:
            Optional[T]: The found entity or None
        """
        # Implementation
        ...
```

## Testing with Pytest
Use pytest fixtures and type annotations in tests:

```python
from typing import TYPE_CHECKING, AsyncGenerator
import pytest
from httpx import AsyncClient

if TYPE_CHECKING:
    from _pytest.capture import CaptureFixture
    from _pytest.fixtures import FixtureRequest
    from _pytest.logging import LogCaptureFixture
    from _pytest.monkeypatch import MonkeyPatch
    from pytest_mock.plugin import MockerFixture

@pytest.fixture
async def client() -> AsyncGenerator[AsyncClient, None]:
    """Create async test client.

    Yields:
        AsyncClient: The test client instance
    """
    async with AsyncClient() as client:
        yield client

@pytest.mark.asyncio
async def test_create_user(
    client: AsyncClient,
    mocker: MockerFixture,
    caplog: LogCaptureFixture,
) -> None:
    """Test user creation endpoint.

    Args:
        client: The test client
        mocker: Pytest mocker fixture
        caplog: Pytest log capture fixture
    """
    response = await client.post('/users', json={
        'username': 'test_user',
        'email': 'test@example.com'
    })
    
    assert response.status_code == 201
    assert 'User created successfully' in caplog.text
```

## Environment Configuration
Use environment variables with type validation:

```python
from typing import Optional
from pydantic import BaseSettings, SecretStr

class Settings(BaseSettings):
    """Application settings with environment variable validation.

    Attributes:
        app_name: Name of the application
        database_url: Database connection string
        api_key: Secret API key
        debug: Debug mode flag
    """
    app_name: str
    database_url: str
    api_key: SecretStr
    debug: bool = False

    class Config:
        env_file = '.env'
```

## Error Handling
Implement structured error handling with context:

```python
from typing import Optional, Any
from contextlib import contextmanager
import logging
import traceback

logger = logging.getLogger(__name__)

class AppError(Exception):
    """Base application error with context.

    Args:
        message: Error description
        context: Additional error context
    """
    def __init__(self, message: str, context: Optional[dict[str, Any]] = None) -> None:
        self.message = message
        self.context = context or {}
        super().__init__(self.message)

@contextmanager
def error_handler(operation: str) -> Any:
    """Context manager for standardized error handling.

    Args:
        operation: Description of the operation being performed

    Raises:
        AppError: Wrapped application error
    """
    try:
        yield
    except Exception as e:
        logger.error(
            f'Error during {operation}: {str(e)}\n{traceback.format_exc()}'
        )
        raise AppError(
            f'Failed to {operation}',
            {'error_type': type(e).__name__, 'details': str(e)}
        )
```

## Dependency Management
Use `uv` for faster package management:

```toml
# pyproject.toml
[project]
name = 'project_name'
version = '0.1.0'
description = 'Project description'
requires-python = '>=3.8'

[tool.ruff]
line-length = 88
target-version = 'py38'
select = [
    'E',   # pycodestyle errors
    'W',   # pycodestyle warnings
    'F',   # pyflakes
    'I',   # isort
    'D',   # pydocstyle
]

[tool.pytest.ini_options]
testpaths = ['tests']
python_files = ['test_*.py']
addopts = '-v --cov=src --cov-report=term-missing'
```

## CI/CD Configuration
GitHub Actions workflow example:

```yaml
# .github/workflows/python-app.yml
name: Python application

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.8'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install uv
        uv pip install -r requirements.txt
    - name: Lint with ruff
      run: |
        ruff check .
    - name: Test with pytest
      run: |
        pytest
```

## Best Practices

### Documentation
- Use PEP 257 docstring conventions
- Document all public functions, classes, and modules
- Include type hints in docstrings for better AI assistance
- Keep README.md up to date with setup and usage instructions

### Code Organization
- One class per file (with rare exceptions)
- Group related functionality in modules
- Use `__init__.py` for package-level imports
- Keep circular dependencies out

### Testing
- Write tests first (TDD when possible)
- Use pytest fixtures for reusable test components
- Mock external dependencies
- Test both success and error cases

### AI-Friendly Practices
- Use descriptive variable names
- Keep functions focused and small
- Add type hints for better code completion
- Include examples in docstrings

## Resources
- [Python Type Hints](https://docs.python.org/3/library/typing.html)
- [pytest Documentation](https://docs.pytest.org/)
- [Ruff Documentation](https://beta.ruff.rs/docs/)
- [uv Package Manager](https://github.com/astral-sh/uv)
- [pydantic Documentation](https://docs.pydantic.dev/)

================
File: .cursor/rules/tailwind.mdc
================
---
description: Best practices for Tailwind CSS v4+ implementation and optimization
globs: **/*.{js,jsx,ts,tsx}, tailwind.config.{js,ts}, **/*.css
---

# Tailwind Version Rule

// Description: Best practices for Tailwind CSS v4+ implementation and optimization
// Recommended Globs: **/*.{js,jsx,ts,tsx}, tailwind.config.{js,ts}, **/*.css

## Code Style and Structure
- Use Tailwind CSS version 4.0 or higher
- Avoid legacy Tailwind classes that were removed in version 4.0
- Ensure class names and utility usage align with Tailwind 4+ best practices

## Tailwind CSS Rules
- Use JIT mode for optimized builds
- Avoid deprecated utility classes from older Tailwind versions
- Use the new color system introduced in Tailwind 4+
- Follow mobile-first design principles
- Prefer grouping utilities for cleaner class structures

## Naming Conventions
- Use kebab-case for custom utility classes
- Prefer `data-` attributes over `className` overrides for state-based styling

## React Best Practices
- Use Tailwind classes directly within JSX without abstraction unless necessary
- Extract repeated class combinations into reusable components
- Avoid excessive nesting of elements when styling can be achieved with Tailwind utilities
- Use React's `useMemo` and `useCallback` to optimize component re-renders when applying dynamic Tailwind classes

## State Management
- Use state management solutions like Zustand to toggle Tailwind-based UI states
- Ensure class toggling is efficient and avoids unnecessary re-renders

## UI and Styling
- Use Tailwind utility classes for layout, spacing, and common styles
- Avoid custom CSS unless Tailwind utilities are insufficient
- Use CSS modules or inline styles only for rare edge cases that Tailwind cannot cover
- Follow responsive design best practices using Tailwind's `sm`, `md`, `lg`, `xl`, and `2xl` breakpoints

## Performance Optimization
- Use Tailwind's built-in PurgeCSS to remove unused styles in production
- Optimize class combinations to minimize unnecessary style computations
- Avoid unnecessary `useState` or `useEffect` for class toggling; prefer `useMemo` where applicable
- Use lazy loading and code splitting to improve UI performance

## Forms and Validation
- Use Tailwind form classes to maintain consistent styling
- Ensure accessible and responsive form layouts using Tailwind's grid or flex utilities
- Implement client-side validation with controlled components and Tailwind's form feedback utilities

## Accessibility (a11y)
- Use Tailwind's `sr-only` class for hidden but accessible text
- Ensure proper contrast ratios using Tailwind's built-in color utilities
- Use focus-visible utilities to enhance keyboard navigation

## Testing
- Ensure UI snapshots remain consistent with Tailwind class-based styles
- Test class-based conditional rendering using Jest and React Testing Library
- Validate accessibility compliance using automated a11y testing tools

## Security
- Avoid using `dangerouslySetInnerHTML` with Tailwind classes unless necessary
- Sanitize any dynamic Tailwind class concatenation to prevent injection attacks

## Internationalization (i18n)
- Ensure RTL compatibility using Tailwind's `rtl` variant when needed

## Key Conventions
- Optimize Web Vitals by keeping Tailwind styles lean and efficient
- Balance readability and performance when applying multiple utility classes
- Always use the latest Tailwind features and remove deprecated syntax when upgrading

================
File: .cursor/rules/terminal-path-verification.mdc
================
---
description: Best practices for verifying paths and locations before executing terminal commands
globs: **/*.{js,jsx,ts,tsx}, **/*.sh
---

# Terminal Path Verification

// Description: Best practices for verifying paths and locations before executing terminal commands
// Recommended Globs: **/*.{js,jsx,ts,tsx}, **/*.sh

## Overview
Always verify current directory and path structure before executing path-related commands to prevent errors and unintended operations.

## Core Rules
1. Before any `cd` command:
   - Use `pwd` to verify current location
   - Use `ls` to verify target directory exists
2. Before file operations:
   - Use `ls` to verify file existence
   - Use `ls -la` for detailed file information when needed

## Examples

### ✅ Good Practice
```bash
# Before changing directory
pwd  # Check current location
ls   # Verify directory structure
cd target_directory

# Before file operations
ls -la file_to_modify.txt  # Verify file exists and check permissions
vim file_to_modify.txt
```

### ❌ Bad Practice
```bash
# Directly changing directory without verification
cd some_directory  # Might not exist!

# File operations without verification
rm file.txt  # Dangerous without verification!
```

## Implementation in Cursor
```typescript
async function executeTerminalCommand(command: string) {
  // Always verify location before path-related commands
  if (command.startsWith('cd ')) {
    await verifyPath(command.split(' ')[1]);
  }

  // Always verify file existence before file operations
  if (isFileOperation(command)) {
    await verifyFileExistence(command);
  }
}

async function verifyPath(targetPath: string) {
  // Check current location
  console.log('Current location:');
  await runCommand('pwd');

  // List directory contents
  console.log('\nDirectory contents:');
  await runCommand('ls');

  // Verify target exists
  if (!(await pathExists(targetPath))) {
    throw new Error(`Target path does not exist: ${targetPath}`);
  }
}
```

## Best Practices
- Always use `pwd` before changing directories
- Use `ls` to verify directory contents
- Use `ls -la` when file permissions are important
- Implement path verification in automated scripts
- Add error handling for non-existent paths

## Common Patterns
1. Directory Navigation:
   ```bash
   pwd  # Verify current location
   ls   # Check directory structure
   cd ./project/src
   ```

2. File Operations:
   ```bash
   ls -la target_file.txt  # Verify file and permissions
   chmod +x target_file.txt
   ```

3. Project Root Verification:
   ```bash
   pwd  # Ensure we're in project root
   ls package.json  # Verify project file exists
   npm install
   ```

## Error Prevention
- Always verify paths before destructive operations
- Use absolute paths when location is uncertain
- Implement safeguards in automated scripts
- Add validation for user-provided paths

## Testing
- Test path verification in different environments
- Verify behavior with non-existent paths
- Test with various file permissions
- Validate error handling

## Resources
- [Bash Documentation](https://www.gnu.org/software/bash/manual/)
- [Linux File System Hierarchy](https://refspecs.linuxfoundation.org/FHS_3.0/fhs/index.html)
- [File System Navigation Best Practices](https://tldp.org/LDP/abs/html/)

================
File: .cursor/rules/yoda-quotes.mdc
================
---
description: End each Cursor chat with a wise, Yoda-style inspirational quote
globs: **/*.{md,txt}
---

# Yoda-Style Quote Endings

// Description: End each Cursor chat with a wise, Yoda-style inspirational quote
// Recommended Globs: **/*.{md,txt}

## Rule Description
At the end of every Cursor AI chat, include a wise and inspirational quote in Yoda's style.

## Format
- Add a line break after the last technical response
- Start with '---'
- Add '➡️ ' before the quote
- Add the quote in Yoda's distinctive speech pattern
- Keep it short and meaningful

## Examples
```
---
➡️ Code well you must, for in the details, greatness lies.
```

```
---
➡️ Debug or debug not. There is no try-catch.
```

## Guidelines
- Keep quotes programming or learning related
- Maintain Yoda's distinctive inverted speech pattern
- Focus on wisdom and encouragement
- Keep it light and fun
- Always include the '➡️ ' emoji prefix

## Purpose
- Add personality to coding sessions
- Provide encouragement during challenging tasks
- Make debugging more enjoyable
- Test rule installation functionality

================
File: .github/ISSUE_TEMPLATE/bug_report.md
================
---

name: 🐞 Bug report
about: Create a report to help us improve
title: "[Bug] the title of bug report"
labels: bug
assignees: ''

---

#### Describe the bug

================
File: .github/ISSUE_TEMPLATE/help_wanted.md
================
---
name: 🥺 Help wanted
about: Confuse about the use of electron-vue-vite
title: "[Help] the title of help wanted report"
labels: help wanted
assignees: ''

---

#### Describe the problem you confuse

================
File: .github/workflows/build.yml
================
name: Build

on:
  push:
    branches: [main]
    paths-ignore:
      - "**.md"
      - "**.spec.js"
      - ".idea"
      - ".vscode"
      - ".dockerignore"
      - "Dockerfile"
      - ".gitignore"
      - ".github/**"
      - "!.github/workflows/build.yml"

jobs:
  build:
    runs-on: ${{ matrix.os }}

    strategy:
      matrix:
        os: [macos-latest, ubuntu-latest, windows-latest]

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: 18

      - name: Install Dependencies
        run: npm install

      - name: Build Release Files
        run: npm run build
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload Artifact
        uses: actions/upload-artifact@v3
        with:
          name: release_on_${{ matrix. os }}
          path: release/
          retention-days: 5

================
File: .github/workflows/ci.yml
================
name: CI

on:
  pull_request_target:
    branches:
      - main

permissions:
  pull-requests: write

jobs:
  job1:
    name: Check Not Allowed File Changes
    runs-on: ubuntu-latest
    outputs:
      markdown_change: ${{ steps.filter_markdown.outputs.change }}
      markdown_files: ${{ steps.filter_markdown.outputs.change_files }}
    steps:

      - name: Check Not Allowed File Changes
        uses: dorny/paths-filter@v2
        id: filter_not_allowed
        with:
          list-files: json
          filters: |
            change:
              - 'package-lock.json'
              - 'yarn.lock'
              - 'pnpm-lock.yaml'

      # ref: https://github.com/github/docs/blob/main/.github/workflows/triage-unallowed-contributions.yml
      - name: Comment About Changes We Can't Accept
        if: ${{ steps.filter_not_allowed.outputs.change == 'true' }}
        uses: actions/github-script@v6
        with:
          script: |
            let workflowFailMessage = "It looks like you've modified some files that we can't accept as contributions."
            try {
              const badFilesArr = [
                'package-lock.json',
                'yarn.lock',
                'pnpm-lock.yaml',
              ]
              const badFiles = badFilesArr.join('\n- ')
              const reviewMessage = `👋 Hey there spelunker. It looks like you've modified some files that we can't accept as contributions. The complete list of files we can't accept are:\n- ${badFiles}\n\nYou'll need to revert all of the files you changed in that list using [GitHub Desktop](https://docs.github.com/en/free-pro-team@latest/desktop/contributing-and-collaborating-using-github-desktop/managing-commits/reverting-a-commit) or \`git checkout origin/main <file name>\`. Once you get those files reverted, we can continue with the review process. :octocat:\n\nMore discussion:\n- https://github.com/electron-vite/electron-vite-vue/issues/192`
              createdComment = await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.payload.number,
                body: reviewMessage,
              })
              workflowFailMessage = `${workflowFailMessage} Please see ${createdComment.data.html_url} for details.`
            } catch(err) {
              console.log("Error creating comment.", err)
            }
            core.setFailed(workflowFailMessage)

      - name: Check Not Linted Markdown
        if: ${{ always() }}
        uses: dorny/paths-filter@v2
        id: filter_markdown
        with:
          list-files: shell
          filters: |
            change:
              - added|modified: '*.md'


  job2:
    name: Lint Markdown
    runs-on: ubuntu-latest
    needs: job1
    if: ${{ always() && needs.job1.outputs.markdown_change == 'true' }}
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3
        with:
          ref: ${{ github.event.pull_request.head.sha }}

      - name: Lint markdown
        run: npx markdownlint-cli ${{ needs.job1.outputs.markdown_files }} --ignore node_modules

================
File: .github/dependabot.yml
================
# To get started with Dependabot version updates, you'll need to specify which
# package ecosystems to update and where the package manifests are located.
# Please see the documentation for all configuration options:
# https://help.github.com/github/administering-a-repository/configuration-options-for-dependency-updates

version: 2
updates:
  - package-ecosystem: "npm" # See documentation for possible values
    directory: "/" # Location of package manifests
    schedule:
      interval: "monthly"

================
File: .github/PULL_REQUEST_TEMPLATE.md
================
<!-- Thank you for contributing! -->

### Description

<!-- Please insert your description here and provide especially info about the "what" this PR is solving -->

### What is the purpose of this pull request? <!-- (put an "X" next to an item) -->

- [ ] Bug fix
- [ ] New Feature
- [ ] Documentation update
- [ ] Other

================
File: electron/main/langgraph/nodes/generateSummary.ts
================
/**
 * LangGraph Node: Generate Summary (Placeholder)
 * 
 * This node will handle summary generation using OpenAI GPT-4o.
 * Currently a placeholder - full implementation will be added in task 6.
 * 
 * Key Features (to be implemented):
 * - Generate comprehensive summaries of brainstorming sessions
 * - Use GPT-4o API with custom prompts
 * - Include "Ireland is great" as specified
 * - Handle token counting and context management
 * - Support streaming responses
 * - Comprehensive error handling
 */

import { AppState, ChatMessage } from '../../../../src/types/AppState';
import { logger } from '../../../../src/utils/logger';
import { ErrorHandler } from '../../../../src/utils/errorHandler';
import { validateLangGraphState, createStateUpdate } from '../state';

/**
 * Generate a summary of the conversation
 * 
 * This is a placeholder implementation that will be replaced
 * with actual OpenAI GPT-4o integration in task 6.
 * 
 * @param state - Current application state
 * @returns Updated state with generated summary
 */
export async function generateSummary(state: AppState): Promise<Partial<AppState>> {
  const startTime = Date.now();
  
  try {
    // Validate incoming state
    validateLangGraphState(state);
    
    logger.info('GenerateSummary node triggered (placeholder)', {
      idea_id: state.idea_id,
      current_stage: state.current_stage,
      message_count: state.messages.length,
      last_action: state.last_user_action
    });
    
    // Placeholder implementation
    // In the actual implementation, this will:
    // 1. Collect all brainstorming messages
    // 2. Create a comprehensive prompt with user's custom prompt
    // 3. Send to GPT-4o API
    // 4. Handle streaming response
    // 5. Ensure "Ireland is great" is included
    
    const placeholderSummary = `This is a placeholder summary of your brainstorming session.

In the actual implementation, this will provide a comprehensive summary of all the ideas discussed, key points raised, and decisions made during the brainstorming phase.

The summary will be generated using GPT-4o with your custom prompt: "${state.user_prompts.summary}"

Ireland is great`;
    
    // Create placeholder summary message
    const summaryMessage: ChatMessage = {
      role: 'assistant',
      content: placeholderSummary,
      created_at: new Date(),
      stage_at_creation: 'summary'
    };
    
    // Log placeholder action
    logger.info('Summary generated (placeholder)', {
      idea_id: state.idea_id,
      summary_length: summaryMessage.content.length,
      execution_time: Date.now() - startTime
    });
    
    // Return state update
    return createStateUpdate({
      messages: [...state.messages, summaryMessage],
      current_stage: 'summary',
      is_processing: false
    });
    
  } catch (error) {
    const errorHandler = new ErrorHandler();
    const errorInfo = errorHandler.handleWorkflowError(
      error instanceof Error ? error : new Error(String(error)),
      'generateSummary',
      state
    );
    
    logger.error('GenerateSummary failed (placeholder)', {
      idea_id: state.idea_id,
      error: errorInfo.userMessage,
      execution_time: Date.now() - startTime,
      recovery_actions: errorInfo.recoveryActions
    });
    
    return createStateUpdate({
      is_processing: false,
      error: errorInfo.userMessage
    });
  }
}

/**
 * Check if the node should generate a summary
 * 
 * @param state - Current application state
 * @returns True if summary generation is needed
 */
export function shouldGenerateSummary(state: AppState): boolean {
  return state.last_user_action === 'Brainstorm Done' && 
         state.current_stage === 'brainstorm' &&
         !state.is_processing &&
         !state.error;
}

================
File: electron/main/langgraph/nodes/index.ts
================
/**
 * LangGraph Nodes Index
 * 
 * This file exports all LangGraph nodes for the FlowGenius workflow engine.
 * Nodes represent individual processing steps in the conversational workflow.
 * 
 * Each node follows the pattern:
 * - Accepts AppState as input
 * - Returns updated AppState as output
 * - Includes comprehensive logging and error handling
 */

// Export all implemented nodes
export { processUserTurn } from './processUserTurn';
export { processVoiceInput } from './processVoiceInput';
export { generateSummary } from './generateSummary';

// Export wrapped versions with error handling
import { processUserTurn as processUserTurnBase } from './processUserTurn';
import { processVoiceInput as processVoiceInputBase } from './processVoiceInput';
import { generateSummary as generateSummaryBase } from './generateSummary';
import { workflowErrorHandler } from '../workflowErrorHandler';
import { AppState } from '../../../../src/types/AppState';

/**
 * Process user turn with error handling and recovery
 */
export async function processUserTurnWithErrorHandling(state: AppState): Promise<Partial<AppState>> {
  try {
    return await processUserTurnBase(state);
  } catch (error) {
    return await workflowErrorHandler.handleNodeError(
      error instanceof Error ? error : new Error(String(error)),
      'processUserTurn',
      state,
      processUserTurnBase
    );
  }
}

/**
 * Process voice input with error handling and recovery
 */
export async function processVoiceInputWithErrorHandling(state: AppState): Promise<Partial<AppState>> {
  try {
    return await processVoiceInputBase(state);
  } catch (error) {
    return await workflowErrorHandler.handleNodeError(
      error instanceof Error ? error : new Error(String(error)),
      'processVoiceInput',
      state,
      processVoiceInputBase
    );
  }
}

/**
 * Generate summary with error handling and recovery
 */
export async function generateSummaryWithErrorHandling(state: AppState): Promise<Partial<AppState>> {
  try {
    return await generateSummaryBase(state);
  } catch (error) {
    return await workflowErrorHandler.handleNodeError(
      error instanceof Error ? error : new Error(String(error)),
      'generateSummary',
      state,
      generateSummaryBase
    );
  }
}

// Placeholder - additional nodes will be exported as they are created
export const LANGGRAPH_NODES_READY = false;

// Future exports will include:
// export { generatePRD } from './generatePRD';
// Additional nodes as needed

/**
 * Node types for type safety and documentation
 */
export type LangGraphNodeName = 
  | 'processUserTurn'
  | 'processVoiceInput' 
  | 'generateSummary'
  | 'generatePRD';

/**
 * Node execution result interface
 */
export interface NodeExecutionResult {
  success: boolean;
  error?: string;
  executionTime?: number;
}

================
File: electron/main/langgraph/nodes/processUserTurn.test.ts
================
/**
 * Unit Tests for ProcessUserTurn Node
 * 
 * Tests the processUserTurn LangGraph node to ensure it properly
 * handles user messages and generates appropriate responses.
 */

import { describe, it, expect, beforeEach, vi } from 'vitest';
import { processUserTurn } from './processUserTurn';
import { AppState, ChatMessage } from '../../../../src/types/AppState';
import { createInitialLangGraphState } from '../state';

// Mock the logger to avoid console spam during tests
vi.mock('../../utils/logger', () => ({
  logger: {
    info: vi.fn(),
    error: vi.fn(),
    warn: vi.fn(),
    debug: vi.fn()
  }
}));

describe('ProcessUserTurn Node', () => {
  let initialState: AppState;
  let userMessage: ChatMessage;

  beforeEach(() => {
    initialState = createInitialLangGraphState('test-idea-123', 'test-user-456');
    userMessage = {
      role: 'user',
      content: 'I have an idea for a new productivity app',
      created_at: new Date(),
      stage_at_creation: 'brainstorm'
    };
  });

  describe('Initial Welcome Message', () => {
    it('should return welcome message when no messages exist', async () => {
      console.log('🧪 Testing welcome message generation');
      
      const result = await processUserTurn(initialState);
      
      expect(result.messages).toBeDefined();
      expect(Array.isArray(result.messages)).toBe(true);
      expect(result.messages!.length).toBe(1);
      
      const welcomeMessage = result.messages![0];
      expect(welcomeMessage.role).toBe('assistant');
      expect(welcomeMessage.content).toContain('FlowGenius');
      expect(welcomeMessage.content).toContain('thought partner');
      expect(result.is_processing).toBe(false);
    });
  });

  describe('User Message Processing', () => {
    it('should process user message and generate response', async () => {
      console.log('🧪 Testing user message processing');
      
      const stateWithUserMessage = {
        ...initialState,
        messages: [userMessage]
      };

      const result = await processUserTurn(stateWithUserMessage);
      
      expect(result.messages).toBeDefined();
      expect(Array.isArray(result.messages)).toBe(true);
      expect(result.messages!.length).toBe(1);
      
      const response = result.messages![0];
      expect(response.role).toBe('assistant');
      expect(response.content).toBeTruthy();
      expect(response.content.length).toBeGreaterThan(0);
      expect(response.stage_at_creation).toBe('brainstorm');
      expect(result.is_processing).toBe(false);
      expect(result.last_user_action).toBe('chat');
    });

    it('should not process when already processing', async () => {
      console.log('🧪 Testing processing state handling');
      
      const processingState = {
        ...initialState,
        messages: [userMessage],
        is_processing: true
      };

      const result = await processUserTurn(processingState);
      
      // Should return empty update when already processing
      expect(Object.keys(result).length).toBe(0);
    });

    it('should not process assistant messages', async () => {
      console.log('🧪 Testing assistant message skipping');
      
      const assistantMessage: ChatMessage = {
        role: 'assistant',
        content: 'I am an assistant message',
        created_at: new Date(),
        stage_at_creation: 'brainstorm'
      };

      const stateWithAssistantMessage = {
        ...initialState,
        messages: [assistantMessage]
      };

      const result = await processUserTurn(stateWithAssistantMessage);
      
      expect(result.is_processing).toBe(false);
      expect(result.messages).toBeUndefined();
    });
  });

  describe('Stage-Specific Responses', () => {
    it('should generate brainstorm-appropriate responses', async () => {
      console.log('🧪 Testing brainstorm stage responses');
      
      const brainstormState = {
        ...initialState,
        current_stage: 'brainstorm' as const,
        messages: [userMessage]
      };

      const result = await processUserTurn(brainstormState);
      
      expect(result.messages).toBeDefined();
      const response = result.messages![0];
      
      // Should be one of the brainstorm responses
      const brainstormPhrases = [
        'interesting idea',
        'tell me more',
        'explore this further',
        'what problem',
        'success look like',
        'target audience',
        'resources',
        'market',
        'exciting part',
        'challenges',
        'first step'
      ];

      const hasExpectedPhrase = brainstormPhrases.some(phrase => 
        response.content.toLowerCase().includes(phrase)
      );
      
      expect(hasExpectedPhrase).toBe(true);
    });

    it('should handle summary stage', async () => {
      console.log('🧪 Testing summary stage responses');
      
      const summaryState = {
        ...initialState,
        current_stage: 'summary' as const,
        messages: [userMessage]
      };

      const result = await processUserTurn(summaryState);
      
      expect(result.messages).toBeDefined();
      const response = result.messages![0];
      
      expect(response.content.toLowerCase()).toContain('summary');
    });

    it('should handle PRD stage', async () => {
      console.log('🧪 Testing PRD stage responses');
      
      const prdState = {
        ...initialState,
        current_stage: 'prd' as const,
        messages: [userMessage]
      };

      const result = await processUserTurn(prdState);
      
      expect(result.messages).toBeDefined();
      const response = result.messages![0];
      
      expect(response.content.toLowerCase()).toContain('product requirements document');
    });
  });

  describe('Response Rotation', () => {
    it('should rotate through different brainstorm responses', async () => {
      console.log('🧪 Testing response rotation');
      
      const responses = new Set<string>();
      
      for (let i = 0; i < 5; i++) {
        const stateWithMessages = {
          ...initialState,
          messages: [
            userMessage,
            // Add some assistant messages to increase the count
            ...Array(i).fill(null).map(() => ({
              role: 'assistant' as const,
              content: `Response ${i}`,
              created_at: new Date(),
              stage_at_creation: 'brainstorm' as const
            })),
            userMessage // Add another user message to process
          ]
        };

        const result = await processUserTurn(stateWithMessages);
        
        if (result.messages && result.messages.length > 0) {
          responses.add(result.messages[0].content);
        }
      }
      
      // Should have generated different responses
      expect(responses.size).toBeGreaterThan(1);
    });
  });

  describe('Error Handling', () => {
    it('should handle invalid state gracefully', async () => {
      console.log('🧪 Testing error handling with invalid state');
      
      const invalidState = {
        ...initialState,
        idea_id: '', // Invalid idea_id
        messages: [userMessage]
      };

      const result = await processUserTurn(invalidState);
      
      expect(result.error).toBeDefined();
      expect(result.is_processing).toBe(false);
    });

    it('should clear previous errors on successful processing', async () => {
      console.log('🧪 Testing error clearing');
      
      const stateWithError = {
        ...initialState,
        messages: [userMessage],
        error: 'Previous error'
      };

      const result = await processUserTurn(stateWithError);
      
      expect(result.error).toBeUndefined();
      expect(result.messages).toBeDefined();
    });
  });

  describe('Message Timestamps and Metadata', () => {
    it('should set correct timestamps and metadata', async () => {
      console.log('🧪 Testing message metadata');
      
      const beforeTime = new Date();
      
      const stateWithUserMessage = {
        ...initialState,
        messages: [userMessage]
      };

      const result = await processUserTurn(stateWithUserMessage);
      
      const afterTime = new Date();
      
      expect(result.messages).toBeDefined();
      const response = result.messages![0];
      
      expect(response.created_at).toBeInstanceOf(Date);
      expect(response.created_at!.getTime()).toBeGreaterThanOrEqual(beforeTime.getTime());
      expect(response.created_at!.getTime()).toBeLessThanOrEqual(afterTime.getTime());
      expect(response.stage_at_creation).toBe('brainstorm');
    });
  });

  describe('State Updates', () => {
    it('should include updated_at in state updates', async () => {
      console.log('🧪 Testing updated_at in state updates');
      
      const stateWithUserMessage = {
        ...initialState,
        messages: [userMessage]
      };

      const result = await processUserTurn(stateWithUserMessage);
      
      expect(result.updated_at).toBeInstanceOf(Date);
    });

    it('should maintain last_user_action as chat', async () => {
      console.log('🧪 Testing last_user_action maintenance');
      
      const stateWithUserMessage = {
        ...initialState,
        messages: [userMessage],
        last_user_action: 'Brainstorm Done' as const
      };

      const result = await processUserTurn(stateWithUserMessage);
      
      expect(result.last_user_action).toBe('chat');
    });
  });
});

================
File: electron/main/langgraph/nodes/processUserTurn.ts
================
/**
 * LangGraph Node: Process User Turn
 * 
 * This node handles standard chat messages during the brainstorming stage.
 * It processes user input, maintains conversation context, and generates
 * appropriate responses using the selected AI model.
 * 
 * Key Features:
 * - Processes user chat messages
 * - Maintains conversation context
 * - Uses stage-appropriate prompts and models
 * - Comprehensive logging and error handling
 * - State validation and updates
 */

import { AppState, ChatMessage } from '../../../../src/types/AppState';
import { logger } from '../../../../src/utils/logger';
import { ErrorHandler } from '../../../../src/utils/errorHandler';
import { validateLangGraphState, createStateUpdate } from '../state';

/**
 * Process a user turn in the conversation
 * 
 * This is the main processing node for handling user chat messages.
 * It takes the user's input, processes it with the appropriate AI model,
 * and returns an updated state with the AI's response.
 * 
 * @param state - Current application state
 * @returns Updated state with AI response
 */
export async function processUserTurn(state: AppState): Promise<Partial<AppState>> {
  const startTime = Date.now();
  console.log('🗣️ ProcessUserTurn: Starting node execution', {
    ideaId: state.idea_id,
    currentStage: state.current_stage,
    lastAction: state.last_user_action,
    messageCount: state.messages.length,
    isProcessing: state.is_processing
  });

  try {
    // Validate incoming state
    console.log('🔍 ProcessUserTurn: Validating input state');
    validateLangGraphState(state);

    // Check if we should process this turn
    if (state.is_processing) {
      console.log('⏸️ ProcessUserTurn: Already processing, skipping');
      logger.warn('ProcessUserTurn called while already processing', {
        idea_id: state.idea_id,
        current_stage: state.current_stage
      });
      return {}; // Return empty update to avoid changes
    }

    // Get the last message to process
    const lastMessage = state.messages[state.messages.length - 1];
    
    if (!lastMessage) {
      console.log('📝 ProcessUserTurn: No messages to process, returning welcome message');
      
      const welcomeMessage: ChatMessage = {
        role: 'assistant',
        content: "Hello! I'm FlowGenius, your AI thought partner. I'm here to help you brainstorm, refine, and structure your ideas. What would you like to work on today?",
        created_at: new Date(),
        stage_at_creation: state.current_stage
      };

      return createStateUpdate({
        messages: [welcomeMessage],
        is_processing: false
      });
    }

    // Only process user messages
    if (lastMessage.role !== 'user') {
      console.log('🤖 ProcessUserTurn: Last message is not from user, no processing needed');
      return createStateUpdate({
        is_processing: false
      });
    }

    console.log('💭 ProcessUserTurn: Processing user message', {
      content: lastMessage.content.substring(0, 100) + '...',
      stage: state.current_stage,
      selectedModel: state.selected_models[state.current_stage]
    });

    // Processing flag will be set by the React context, no need to set it here

    // For now, create a placeholder response
    // TODO: Replace with actual AI model integration in future tasks
    const response = await generatePlaceholderResponse(state, lastMessage);

    console.log('✅ ProcessUserTurn: Generated response', {
      responseLength: response.length,
      executionTime: Date.now() - startTime
    });

    // Create response message
    const responseMessage: ChatMessage = {
      role: 'assistant',
      content: response,
      created_at: new Date(),
      stage_at_creation: state.current_stage
    };

    // Create final state update
    const finalUpdate = createStateUpdate({
      messages: [responseMessage],
      is_processing: false,
      last_user_action: 'chat' // Ensure we stay in chat mode unless explicitly changed
    });

    logger.info('ProcessUserTurn completed successfully', {
      idea_id: state.idea_id,
      current_stage: state.current_stage,
      execution_time: Date.now() - startTime,
      response_length: response.length
    });

    console.log('🎉 ProcessUserTurn: Node execution completed successfully', {
      executionTime: Date.now() - startTime,
      newMessageCount: 1
    });

    return finalUpdate;

  } catch (error) {
    const executionTime = Date.now() - startTime;
    console.log('❌ ProcessUserTurn: Error occurred', {
      error: error instanceof Error ? error.message : String(error),
      executionTime
    });

    const errorHandler = new ErrorHandler();
    const errorInfo = errorHandler.handleWorkflowError(
      error instanceof Error ? error : new Error(String(error)), 
      'processUserTurn', 
      state
    );

    logger.error('ProcessUserTurn failed', {
      idea_id: state.idea_id,
      error: errorInfo.userMessage,
      execution_time: executionTime,
      recovery_actions: errorInfo.recoveryActions
    });

    // Return error state update
    return createStateUpdate({
      is_processing: false,
      error: errorInfo.userMessage
    });
  }
}

/**
 * Generate a placeholder response for the user message
 * 
 * This is a temporary implementation that will be replaced with actual
 * AI model integration in future tasks. It provides stage-appropriate
 * responses to keep the conversation flowing.
 * 
 * @param state - Current application state
 * @param userMessage - The user's message to respond to
 * @returns Generated response string
 */
async function generatePlaceholderResponse(state: AppState, userMessage: ChatMessage): Promise<string> {
  console.log('🔄 ProcessUserTurn: Generating placeholder response', {
    stage: state.current_stage,
    userMessageLength: userMessage.content.length
  });

  // Simulate some processing time
  await new Promise(resolve => setTimeout(resolve, 500));

     const stageResponses = {
     brainstorm: [
       "That's an interesting idea! Can you tell me more about what inspired this concept?",
       "I'd love to explore this further. What problem are you trying to solve with this idea?",
       "Great thinking! What would success look like for this project?",
       "Tell me more about your target audience for this idea.",
       "What resources or skills do you think you'd need to make this happen?",
       "How does this idea fit into the current market or landscape?",
       "What's the most exciting part of this idea for you?",
       "Have you considered any potential challenges or obstacles?",
       "What would be the first step to move this idea forward?",
       "Georgia is great" // As specified in the requirements
     ],
     summary: [
       "I understand you'd like a summary. Let me review our conversation and provide a comprehensive overview.",
       "Based on our discussion, I'll create a detailed summary of your idea and our brainstorming session.",
       "Ireland is great" // As specified in the requirements
     ],
     prd: [
       "I'll help you create a comprehensive Product Requirements Document based on our conversation and summary.",
       "Let me structure this into a detailed PRD that you can use for implementation."
     ]
   } as const;

     // Get appropriate responses for the current stage
   const responses = stageResponses[state.current_stage];
   
   // For brainstorm stage, rotate through different responses
   if (state.current_stage === 'brainstorm') {
     const messageCount = state.messages.filter(m => m.role === 'assistant').length;
     const responseIndex = messageCount % (responses.length - 1); // Exclude the "Georgia is great" response for now
     return responses[responseIndex] || "I'm here to help! What would you like to discuss?";
   }

   // For other stages, use the first response
   return responses[0] || "I'm here to help! What would you like to discuss?";
}

/**
 * Validate that a user message is appropriate for processing
 * 
 * @param message - The message to validate
 * @returns True if valid, throws error if invalid
 */
function validateUserMessage(message: ChatMessage): boolean {
  console.log('🔍 ProcessUserTurn: Validating user message');

  if (!message.content || message.content.trim().length === 0) {
    throw new Error('User message cannot be empty');
  }

  if (message.content.length > 10000) {
    throw new Error('User message is too long (max 10,000 characters)');
  }

  if (message.role !== 'user') {
    throw new Error('Message must be from user role');
  }

  return true;
}

/**
 * Create conversation context for AI model
 * 
 * This function prepares the conversation context that will be sent
 * to the AI model, including the system prompt and message history.
 * 
 * @param state - Current application state
 * @returns Formatted conversation context
 */
function createConversationContext(state: AppState): string {
  console.log('📋 ProcessUserTurn: Creating conversation context', {
    messageCount: state.messages.length,
    stage: state.current_stage
  });

  const systemPrompt = state.user_prompts[state.current_stage];
  const recentMessages = state.messages.slice(-10); // Keep last 10 messages for context

  let context = `System: ${systemPrompt}\n\n`;
  context += "Conversation History:\n";
  
  recentMessages.forEach((msg, index) => {
    const speaker = msg.role === 'user' ? 'Human' : 'Assistant';
    context += `${speaker}: ${msg.content}\n`;
  });

  return context;
}

/**
 * Check if the user wants to advance to the next stage
 * 
 * @param message - User message to analyze
 * @param currentStage - Current workflow stage
 * @returns The action the user wants to take
 */
function detectUserAction(message: ChatMessage, currentStage: string): string {
  console.log('🎯 ProcessUserTurn: Detecting user action', {
    messageContent: message.content.substring(0, 50) + '...',
    currentStage
  });

  const content = message.content.toLowerCase().trim();
  
  // Check for stage advancement triggers
  if (content.includes('brainstorm done') || content.includes('ready for summary')) {
    return 'Brainstorm Done';
  }
  
  if (content.includes('summary done') || content.includes('ready for prd')) {
    return 'Summary Done';
  }
  
  if (content.includes('prd done') || content.includes('finished')) {
    return 'PRD Done';
  }

  // Default to chat action
  return 'chat';
}

================
File: electron/main/langgraph/nodes/processVoiceInput.ts
================
/**
 * LangGraph Node: Process Voice Input (Placeholder)
 * 
 * This node will handle voice-to-text conversion using the Whisper API.
 * Currently a placeholder - full implementation will be added in task 5.
 * 
 * Key Features (to be implemented):
 * - Process audio data from voice recordings
 * - Convert speech to text using Whisper API
 * - Update conversation state with transcribed text
 * - Handle audio format validation
 * - Comprehensive error handling
 */

import { AppState, ChatMessage } from '../../../../src/types/AppState';
import { logger } from '../../../../src/utils/logger';
import { ErrorHandler } from '../../../../src/utils/errorHandler';
import { validateLangGraphState, createStateUpdate } from '../state';

/**
 * Process voice input and convert to text
 * 
 * This is a placeholder implementation that will be replaced
 * with actual Whisper API integration in task 5.
 * 
 * @param state - Current application state
 * @returns Updated state with voice transcription
 */
export async function processVoiceInput(state: AppState): Promise<Partial<AppState>> {
  const startTime = Date.now();
  
  try {
    // Validate incoming state
    validateLangGraphState(state);
    
    logger.info('ProcessVoiceInput node triggered (placeholder)', {
      idea_id: state.idea_id,
      current_stage: state.current_stage,
      last_action: state.last_user_action
    });
    
    // Placeholder implementation
    // In the actual implementation, this will:
    // 1. Extract audio data from the state
    // 2. Validate audio format
    // 3. Send to Whisper API
    // 4. Process transcription result
    // 5. Create user message with transcribed text
    
    const placeholderTranscription = "This is a placeholder transcription. Voice-to-text will be implemented in task 5.";
    
    // Create placeholder message
    const voiceMessage: ChatMessage = {
      role: 'user',
      content: placeholderTranscription,
      created_at: new Date(),
      stage_at_creation: state.current_stage
    };
    
    // Log placeholder action
    logger.info('Voice input processed (placeholder)', {
      idea_id: state.idea_id,
      message_content: voiceMessage.content,
      execution_time: Date.now() - startTime
    });
    
    // Return state update
    return createStateUpdate({
      messages: [...state.messages, voiceMessage],
      last_user_action: 'chat' as const,
      is_processing: false
    });
    
  } catch (error) {
    const errorHandler = new ErrorHandler();
    const errorInfo = errorHandler.handleWorkflowError(
      error instanceof Error ? error : new Error(String(error)),
      'processVoiceInput',
      state
    );
    
    logger.error('ProcessVoiceInput failed (placeholder)', {
      idea_id: state.idea_id,
      error: errorInfo.userMessage,
      execution_time: Date.now() - startTime,
      recovery_actions: errorInfo.recoveryActions
    });
    
    return createStateUpdate({
      is_processing: false,
      error: errorInfo.userMessage
    });
  }
}

/**
 * Check if the node should process voice input
 * 
 * @param state - Current application state
 * @returns True if voice processing is needed
 */
export function shouldProcessVoice(state: AppState): boolean {
  return state.last_user_action === 'chat' && 
         !state.is_processing &&
         !state.error;
}

================
File: electron/main/langgraph/index.ts
================
/**
 * Main LangGraph Workflow Setup and Initialization
 * 
 * This file creates and exports the complete LangGraph workflow for FlowGenius.
 * It sets up the StateGraph with all nodes, edges, and routing logic to handle
 * the complete conversational workflow from brainstorming to PRD generation.
 * 
 * Key Features:
 * - Complete workflow graph with all nodes and edges
 * - Conditional routing based on user actions
 * - Error handling and recovery mechanisms
 * - Performance monitoring and logging
 * - Easy integration with React components
 */

import { StateGraph, START, END } from '@langchain/langgraph';
import { AppStateAnnotation, createInitialLangGraphState } from './state';
import { processUserTurn } from './nodes/processUserTurn';
import { processVoiceInput } from './nodes/processVoiceInput';
import { generateSummary } from './nodes/generateSummary';
import { routeUserAction, RouteNames } from './router';
import { AppState } from '../../../src/types/AppState';
import { logger } from '../../../src/utils/logger';
import { WorkflowLogger, createWorkflowLogger } from './workflowLogger';

/**
 * Create and configure the complete LangGraph workflow
 * 
 * This function builds the StateGraph with all nodes, edges, and routing logic.
 * It represents the complete conversational workflow for FlowGenius.
 * 
 * @returns Compiled LangGraph workflow ready for execution
 */
export function createFlowGeniusWorkflow() {
  console.log('🏗️ Creating FlowGenius LangGraph workflow');
  
  // Create the state graph with our AppState annotation
  const graph = new StateGraph(AppStateAnnotation)
    // Add all workflow nodes
    .addNode(RouteNames.PROCESS_USER_TURN, processUserTurn)
    .addNode(RouteNames.PROCESS_VOICE_INPUT, processVoiceInput)
    .addNode(RouteNames.GENERATE_SUMMARY, generateSummary)
    
    // Set up entry point routing
    .addEdge(START, RouteNames.PROCESS_USER_TURN)
    
    // Add conditional routing from processUserTurn
    .addConditionalEdges(
      RouteNames.PROCESS_USER_TURN,
      routeUserAction,
      {
        [RouteNames.PROCESS_USER_TURN]: RouteNames.PROCESS_USER_TURN,
        [RouteNames.PROCESS_VOICE_INPUT]: RouteNames.PROCESS_VOICE_INPUT,
        [RouteNames.GENERATE_SUMMARY]: RouteNames.GENERATE_SUMMARY,
        [RouteNames.END]: END
      }
    )
    
    // Add conditional routing from processVoiceInput
    .addConditionalEdges(
      RouteNames.PROCESS_VOICE_INPUT,
      routeUserAction,
      {
        [RouteNames.PROCESS_USER_TURN]: RouteNames.PROCESS_USER_TURN,
        [RouteNames.PROCESS_VOICE_INPUT]: RouteNames.PROCESS_VOICE_INPUT,
        [RouteNames.GENERATE_SUMMARY]: RouteNames.GENERATE_SUMMARY,
        [RouteNames.END]: END
      }
    )
    
    // Add conditional routing from generateSummary
    .addConditionalEdges(
      RouteNames.GENERATE_SUMMARY,
      routeUserAction,
      {
        [RouteNames.PROCESS_USER_TURN]: RouteNames.PROCESS_USER_TURN,
        [RouteNames.END]: END
      }
    );

  // Compile the workflow
  const workflow = graph.compile();
  
  console.log('✅ FlowGenius LangGraph workflow created successfully');
  logger.info('LangGraph workflow compiled', {
    nodeCount: 3,
    hasConditionalRouting: true,
    entryPoint: RouteNames.PROCESS_USER_TURN
  });
  
  return workflow;
}

/**
 * Execute the workflow with comprehensive logging and error handling
 * 
 * @param initialState - Initial application state
 * @param workflowLogger - Optional workflow logger for debugging
 * @returns Promise resolving to final application state
 */
export async function executeWorkflow(
  initialState: AppState, 
  workflowLogger?: WorkflowLogger
): Promise<AppState> {
  const startTime = Date.now();
  const sessionLogger = workflowLogger || createWorkflowLogger(initialState.idea_id);
  
  console.log('🚀 Executing FlowGenius workflow', {
    ideaId: initialState.idea_id,
    currentStage: initialState.current_stage,
    lastAction: initialState.last_user_action,
    messageCount: initialState.messages.length
  });

  try {
    // Log workflow start
    sessionLogger.logWorkflowStart(initialState);
    
    // Create and execute workflow
    const workflow = createFlowGeniusWorkflow();
    const result = await workflow.invoke(initialState);
    
    // Log workflow completion
    sessionLogger.logWorkflowEnd(result);
    
    const executionTime = Date.now() - startTime;
    console.log('✅ Workflow execution completed', {
      ideaId: result.idea_id,
      finalStage: result.current_stage,
      finalAction: result.last_user_action,
      executionTime,
      messageCount: result.messages.length,
      hasError: !!result.error
    });

    logger.info('Workflow execution completed', {
      idea_id: result.idea_id,
      execution_time: executionTime,
      initial_stage: initialState.current_stage,
      final_stage: result.current_stage,
      message_count_change: result.messages.length - initialState.messages.length,
      success: !result.error
    });

    return result;

  } catch (error) {
    const executionTime = Date.now() - startTime;
    const errorMessage = error instanceof Error ? error.message : String(error);
    
    console.log('❌ Workflow execution failed', {
      ideaId: initialState.idea_id,
      error: errorMessage,
      executionTime
    });

    sessionLogger.logWorkflowError(error instanceof Error ? error : new Error(errorMessage));
    
    logger.error('Workflow execution failed', {
      idea_id: initialState.idea_id,
      error: errorMessage,
      execution_time: executionTime,
      stack: error instanceof Error ? error.stack : undefined
    });

    // Return state with error
    return {
      ...initialState,
      error: `Workflow execution failed: ${errorMessage}`,
      is_processing: false,
      updated_at: new Date()
    };
  }
}

/**
 * Create a new workflow session with initial state
 * 
 * @param ideaId - Unique identifier for the session
 * @param userId - Optional user identifier
 * @returns Initial application state ready for workflow execution
 */
export function createWorkflowSession(ideaId: string, userId?: string): AppState {
  console.log('🆕 Creating new workflow session', { ideaId, userId });
  
  const initialState = createInitialLangGraphState(ideaId, userId);
  
  logger.info('New workflow session created', {
    idea_id: ideaId,
    user_id: userId,
    initial_stage: initialState.current_stage,
    initial_action: initialState.last_user_action
  });
  
  return initialState;
}

/**
 * Validate workflow state before execution
 * 
 * @param state - Application state to validate
 * @returns Validation result with any issues found
 */
export function validateWorkflowState(state: AppState): {
  isValid: boolean;
  issues: string[];
} {
  const issues: string[] = [];
  
  // Check required fields
  if (!state.idea_id) {
    issues.push('Missing idea_id');
  }
  
  if (!state.current_stage || !['brainstorm', 'summary', 'prd'].includes(state.current_stage)) {
    issues.push('Invalid current_stage');
  }
  
  if (!state.last_user_action || !['chat', 'Brainstorm Done', 'Summary Done', 'PRD Done'].includes(state.last_user_action)) {
    issues.push('Invalid last_user_action');
  }
  
  if (!Array.isArray(state.messages)) {
    issues.push('Messages must be an array');
  }
  
  // Log validation result
  const isValid = issues.length === 0;
  console.log('🔍 Workflow state validation', {
    ideaId: state.idea_id,
    isValid,
    issueCount: issues.length,
    issues
  });
  
  if (!isValid) {
    logger.warn('Workflow state validation failed', {
      idea_id: state.idea_id,
      issues
    });
  }
  
  return { isValid, issues };
}

// Export main workflow components
export {
  createInitialLangGraphState,
  AppStateAnnotation,
  RouteNames,
  routeUserAction
};

// Export types for React integration
export type { WorkflowLogger } from './workflowLogger';

================
File: electron/main/langgraph/README.md
================
# LangGraph Directory

This directory contains the LangGraph workflow engine implementation for the FlowGenius application. LangGraph manages the conversational workflow and state transitions between brainstorming, summarization, and PRD generation stages.

## Directory Structure

### Core Files
- `index.ts` - Main LangGraph workflow setup and initialization
- `state.ts` - LangGraph state management utilities and AppState interface integration
- `router.ts` - Conditional routing logic for LangGraph workflow

### Nodes Directory (`nodes/`)
LangGraph nodes represent individual processing steps in the workflow:
- `processUserTurn.ts` - Handles standard chat messages during brainstorming
- `processVoiceInput.ts` - Processes voice-to-text input from user recordings
- `generateSummary.ts` - Generates detailed summaries using GPT-4o after brainstorming
- `index.ts` - Exports all LangGraph nodes

### Edges Directory (`edges/`)
LangGraph edges define the connections and transitions between nodes:
- Custom edge conditions and routing logic
- State-based transition rules

## LangGraph Workflow

The FlowGenius LangGraph workflow follows this pattern:

1. **Entry Point**: `processUserTurn` (handles all user inputs)
2. **Routing Logic**: Based on `last_user_action` in AppState:
   - `'chat'` → Continue in current stage
   - `'Brainstorm Done'` → Route to `generateSummary`
   - `'Summary Done'` → Route to `generatePRD` (future)
   - `'PRD Done'` → Terminal state

3. **State Management**: Each node receives and returns the complete AppState
4. **Error Handling**: All nodes include comprehensive error handling and logging

## Node Implementation Guidelines

1. **Function Signature**: All nodes must accept and return `AppState`
2. **Logging**: Extensive logging for debugging and monitoring
3. **Error Handling**: Graceful error handling with user-friendly messages
4. **State Updates**: Immutable state updates using proper TypeScript practices
5. **Testing**: Comprehensive unit tests for each node

## Example Node Structure

```typescript
/**
 * LangGraph node for [specific functionality]
 */
import { AppState } from '../types/AppState';
import { logger } from '../utils/logger';

export async function nodeName(state: AppState): Promise<AppState> {
  try {
    logger.info('Starting node execution', { 
      nodeType: 'nodeName',
      ideaId: state.idea_id,
      currentStage: state.current_stage 
    });

    // Node implementation
    const updatedState = {
      ...state,
      // state updates
    };

    logger.info('Node execution completed successfully');
    return updatedState;
  } catch (error) {
    logger.error('Node execution failed', { error, state });
    return {
      ...state,
      error: 'User-friendly error message'
    };
  }
}
```

## Testing

- All nodes must have comprehensive unit tests
- Test with various AppState configurations
- Mock external API calls
- Test error conditions and edge cases

================
File: electron/main/langgraph/router.test.ts
================
/**
 * Unit Tests for LangGraph Router
 * 
 * Tests the conditional routing logic to ensure proper workflow navigation
 * based on user actions and application state.
 */

import { describe, it, expect, beforeEach, vi } from 'vitest';
import { 
  routeUserAction, 
  routeVoiceInput,
  shouldTransitionStage,
  shouldContinueWorkflow,
  getRoutingDescription,
  RouteNames 
} from './router';
import { AppState } from '../../../src/types/AppState';
import { createInitialLangGraphState } from './state';

// Mock the logger
vi.mock('../utils/logger', () => ({
  logger: {
    info: vi.fn(),
    error: vi.fn(),
    warn: vi.fn(),
    debug: vi.fn()
  }
}));

describe('LangGraph Router', () => {
  let testState: AppState;

  beforeEach(() => {
    testState = createInitialLangGraphState('test-idea-123', 'test-user-456');
  });

  describe('routeUserAction', () => {
    it('should route chat messages to processUserTurn', () => {
      console.log('🧪 Testing chat message routing');
      testState.last_user_action = 'chat';
      
      const route = routeUserAction(testState);
      
      expect(route).toBe(RouteNames.PROCESS_USER_TURN);
    });

    it('should route to generateSummary when brainstorm is done', () => {
      console.log('🧪 Testing brainstorm completion routing');
      testState.last_user_action = 'Brainstorm Done';
      testState.current_stage = 'brainstorm';
      
      const route = routeUserAction(testState);
      
      expect(route).toBe(RouteNames.GENERATE_SUMMARY);
    });

    it('should route to END if brainstorm done in wrong stage', () => {
      console.log('🧪 Testing invalid brainstorm completion');
      testState.last_user_action = 'Brainstorm Done';
      testState.current_stage = 'summary'; // Wrong stage
      
      const route = routeUserAction(testState);
      
      expect(route).toBe(RouteNames.END);
    });

    it('should route to END for Summary Done (PRD not implemented)', () => {
      console.log('🧪 Testing summary completion routing');
      testState.last_user_action = 'Summary Done';
      testState.current_stage = 'summary';
      
      const route = routeUserAction(testState);
      
      // Currently returns END because generatePRD is not implemented
      expect(route).toBe(RouteNames.END);
    });

    it('should route to END when PRD is done', () => {
      console.log('🧪 Testing PRD completion routing');
      testState.last_user_action = 'PRD Done';
      
      const route = routeUserAction(testState);
      
      expect(route).toBe(RouteNames.END);
    });

    it('should route to END when there is an error', () => {
      console.log('🧪 Testing error state routing');
      testState.error = 'Test error';
      testState.last_user_action = 'chat';
      
      const route = routeUserAction(testState);
      
      expect(route).toBe(RouteNames.END);
    });

    it('should route to END when processing', () => {
      console.log('🧪 Testing processing state routing');
      testState.is_processing = true;
      testState.last_user_action = 'chat';
      
      const route = routeUserAction(testState);
      
      expect(route).toBe(RouteNames.END);
    });

    it('should route to END for unknown action', () => {
      console.log('🧪 Testing unknown action routing');
      // @ts-expect-error - Testing invalid action
      testState.last_user_action = 'Unknown Action';
      
      const route = routeUserAction(testState);
      
      expect(route).toBe(RouteNames.END);
    });
  });

  describe('routeVoiceInput', () => {
    it('should route voice input to processUserTurn', () => {
      console.log('🧪 Testing voice input routing');
      
      const route = routeVoiceInput(testState);
      
      expect(route).toBe(RouteNames.PROCESS_USER_TURN);
    });
  });

  describe('shouldTransitionStage', () => {
    it('should return true for brainstorm to summary transition', () => {
      console.log('🧪 Testing brainstorm stage transition');
      testState.current_stage = 'brainstorm';
      testState.last_user_action = 'Brainstorm Done';
      
      expect(shouldTransitionStage(testState)).toBe(true);
    });

    it('should return false for brainstorm with chat action', () => {
      console.log('🧪 Testing no transition for chat in brainstorm');
      testState.current_stage = 'brainstorm';
      testState.last_user_action = 'chat';
      
      expect(shouldTransitionStage(testState)).toBe(false);
    });

    it('should return true for summary to PRD transition', () => {
      console.log('🧪 Testing summary stage transition');
      testState.current_stage = 'summary';
      testState.last_user_action = 'Summary Done';
      
      expect(shouldTransitionStage(testState)).toBe(true);
    });

    it('should return false for PRD stage', () => {
      console.log('🧪 Testing no transition from PRD');
      testState.current_stage = 'prd';
      testState.last_user_action = 'PRD Done';
      
      expect(shouldTransitionStage(testState)).toBe(false);
    });
  });

  describe('shouldContinueWorkflow', () => {
    it('should return true for normal state', () => {
      console.log('🧪 Testing workflow continuation - normal');
      
      expect(shouldContinueWorkflow(testState)).toBe(true);
    });

    it('should return false when there is an error', () => {
      console.log('🧪 Testing workflow continuation - error');
      testState.error = 'Test error';
      
      expect(shouldContinueWorkflow(testState)).toBe(false);
    });

    it('should return false when processing', () => {
      console.log('🧪 Testing workflow continuation - processing');
      testState.is_processing = true;
      
      expect(shouldContinueWorkflow(testState)).toBe(false);
    });

    it('should return false when PRD is done', () => {
      console.log('🧪 Testing workflow continuation - PRD done');
      testState.last_user_action = 'PRD Done';
      
      expect(shouldContinueWorkflow(testState)).toBe(false);
    });
  });

  describe('getRoutingDescription', () => {
    it('should describe chat routing', () => {
      console.log('🧪 Testing routing description - chat');
      testState.last_user_action = 'chat';
      testState.current_stage = 'brainstorm';
      
      const description = getRoutingDescription(testState);
      
      expect(description).toBe('Processing user message in brainstorm stage');
    });

    it('should describe summary generation routing', () => {
      console.log('🧪 Testing routing description - summary');
      testState.last_user_action = 'Brainstorm Done';
      testState.current_stage = 'brainstorm';
      
      const description = getRoutingDescription(testState);
      
      expect(description).toBe('Generating summary of brainstorming session');
    });

    it('should describe workflow end', () => {
      console.log('🧪 Testing routing description - end');
      testState.last_user_action = 'PRD Done';
      
      const description = getRoutingDescription(testState);
      
      expect(description).toBe('Workflow ended');
    });
  });
});

================
File: electron/main/langgraph/router.ts
================
/**
 * LangGraph Router - Conditional Routing Logic
 * 
 * This module implements the routing logic that determines which node
 * should be executed next based on the current application state,
 * particularly the last_user_action field.
 * 
 * The router is a key component of the LangGraph workflow, enabling
 * dynamic flow control based on user interactions and workflow stages.
 */

import { AppState } from '../../../src/types/AppState';
import { logger } from '../../../src/utils/logger';

/**
 * Route names that correspond to LangGraph nodes
 */
export enum RouteNames {
  PROCESS_USER_TURN = 'processUserTurn',
  PROCESS_VOICE_INPUT = 'processVoiceInput',
  GENERATE_SUMMARY = 'generateSummary',
  GENERATE_PRD = 'generatePRD',
  END = '__end__'
}

/**
 * Main routing function that determines the next node based on state
 * 
 * This function implements the core routing logic for the LangGraph workflow.
 * It examines the current state and returns the name of the next node to execute.
 * 
 * @param state - Current application state
 * @returns The name of the next node to execute
 */
export function routeUserAction(state: AppState): string {
  logger.info('Routing decision requested', {
    idea_id: state.idea_id,
    current_stage: state.current_stage,
    last_user_action: state.last_user_action,
    is_processing: state.is_processing,
    has_error: !!state.error
  });

  // If there's an error, end the workflow
  if (state.error) {
    logger.warn('Routing to END due to error state', {
      idea_id: state.idea_id,
      error: state.error
    });
    return RouteNames.END;
  }

  // If processing, wait (shouldn't happen in normal flow)
  if (state.is_processing) {
    logger.warn('State is still processing, routing to END', {
      idea_id: state.idea_id
    });
    return RouteNames.END;
  }

  // Check if the last message is from assistant and no new user input
  const lastMessage = state.messages[state.messages.length - 1];
  if (lastMessage && lastMessage.role === 'assistant' && state.last_user_action === 'chat') {
    logger.info('Routing to END - waiting for user input', {
      idea_id: state.idea_id,
      last_message_role: lastMessage.role
    });
    return RouteNames.END;
  }

  // Route based on last user action
  switch (state.last_user_action) {
    case 'chat':
      // Regular chat messages go to processUserTurn
      logger.info('Routing to processUserTurn for chat message', {
        idea_id: state.idea_id,
        stage: state.current_stage
      });
      return RouteNames.PROCESS_USER_TURN;

    case 'Brainstorm Done':
      // When brainstorming is complete, generate summary
      if (state.current_stage === 'brainstorm') {
        logger.info('Routing to generateSummary after brainstorm completion', {
          idea_id: state.idea_id
        });
        return RouteNames.GENERATE_SUMMARY;
      } else {
        logger.warn('Brainstorm Done action in wrong stage', {
          idea_id: state.idea_id,
          current_stage: state.current_stage
        });
        return RouteNames.END;
      }

    case 'Summary Done':
      // When summary is complete, generate PRD (placeholder for now)
      if (state.current_stage === 'summary') {
        logger.info('Routing to generatePRD after summary completion', {
          idea_id: state.idea_id
        });
        // TODO: Implement generatePRD node
        logger.warn('generatePRD not yet implemented, ending workflow', {
          idea_id: state.idea_id
        });
        return RouteNames.END;
      } else {
        logger.warn('Summary Done action in wrong stage', {
          idea_id: state.idea_id,
          current_stage: state.current_stage
        });
        return RouteNames.END;
      }

    case 'PRD Done':
      // PRD completion ends the workflow
      logger.info('Workflow complete, routing to END', {
        idea_id: state.idea_id
      });
      return RouteNames.END;

    default:
      // Unknown action, log warning and end
      logger.error('Unknown user action, routing to END', {
        idea_id: state.idea_id,
        last_user_action: state.last_user_action
      });
      return RouteNames.END;
  }
}

/**
 * Specialized router for voice input detection
 * 
 * This router can be used in parallel or as a pre-check to determine
 * if voice input should be processed. Currently returns processUserTurn
 * as voice is processed as regular chat in the MVP.
 * 
 * @param state - Current application state
 * @returns The name of the next node to execute
 */
export function routeVoiceInput(state: AppState): string {
  // In the MVP, voice input is converted to text and processed as chat
  // This router is here for future enhancement when voice might have
  // special handling requirements
  
  logger.info('Voice routing check', {
    idea_id: state.idea_id,
    last_action: state.last_user_action
  });

  // For now, voice input goes through the same flow as chat
  return RouteNames.PROCESS_USER_TURN;
}

/**
 * Stage transition router
 * 
 * Determines if a stage transition should occur based on the current state.
 * This is useful for automatic stage progression.
 * 
 * @param state - Current application state
 * @returns Whether a stage transition should occur
 */
export function shouldTransitionStage(state: AppState): boolean {
  // Check if we should automatically transition stages
  switch (state.current_stage) {
    case 'brainstorm':
      // Transition to summary when user clicks "Brainstorm Done"
      return state.last_user_action === 'Brainstorm Done';
    
    case 'summary':
      // Transition to PRD when user clicks "Summary Done"
      return state.last_user_action === 'Summary Done';
    
    case 'prd':
      // No automatic transition from PRD
      return false;
    
    default:
      return false;
  }
}

/**
 * Helper function to determine if the workflow should continue
 * 
 * @param state - Current application state
 * @returns Whether the workflow should continue processing
 */
export function shouldContinueWorkflow(state: AppState): boolean {
  // Continue if no error, not processing, and not at PRD Done
  return !state.error && 
         !state.is_processing && 
         state.last_user_action !== 'PRD Done';
}

/**
 * Get human-readable description of the current routing decision
 * 
 * @param state - Current application state
 * @returns Description of the routing decision
 */
export function getRoutingDescription(state: AppState): string {
  const route = routeUserAction(state);
  
  switch (route) {
    case RouteNames.PROCESS_USER_TURN:
      return `Processing user message in ${state.current_stage} stage`;
    case RouteNames.GENERATE_SUMMARY:
      return 'Generating summary of brainstorming session';
    case RouteNames.GENERATE_PRD:
      return 'Generating Product Requirements Document';
    case RouteNames.END:
      return 'Workflow ended';
    default:
      return 'Unknown routing decision';
  }
}

================
File: electron/main/langgraph/state.test.ts
================
/**
 * Unit Tests for LangGraph State Management
 * 
 * Tests the state annotation, validation, and utility functions
 * to ensure proper integration with our AppState interface.
 */

import { describe, it, expect, beforeEach } from 'vitest';
import { 
  AppStateAnnotation, 
  createInitialLangGraphState, 
  validateLangGraphState,
  createStateUpdate,
  isAppState 
} from './state';
import { AppState, ChatMessage } from '../../../src/types/AppState';

describe('LangGraph State Management', () => {
  let testState: AppState;

  beforeEach(() => {
    testState = createInitialLangGraphState('test-idea-123', 'test-user-456');
  });

  describe('createInitialLangGraphState', () => {
    it('should create valid initial state with required fields', () => {
      console.log('🧪 Testing initial state creation');
      
      expect(testState.idea_id).toBe('test-idea-123');
      expect(testState.user_id).toBe('test-user-456');
      expect(testState.current_stage).toBe('brainstorm');
      expect(testState.last_user_action).toBe('chat');
      expect(Array.isArray(testState.messages)).toBe(true);
      expect(testState.messages.length).toBe(0);
      expect(testState.is_processing).toBe(false);
      expect(testState.error).toBeUndefined();
    });

    it('should create state without user_id when not provided', () => {
      console.log('🧪 Testing state creation without user_id');
      
      const stateWithoutUser = createInitialLangGraphState('test-idea-789');
      
      expect(stateWithoutUser.idea_id).toBe('test-idea-789');
      expect(stateWithoutUser.user_id).toBeUndefined();
      expect(stateWithoutUser.current_stage).toBe('brainstorm');
    });

    it('should have default prompts and model selections', () => {
      console.log('🧪 Testing default prompts and models');
      
      expect(testState.user_prompts.brainstorm).toContain('Georgia is great');
      expect(testState.user_prompts.summary).toContain('Ireland is great');
      expect(testState.selected_models.brainstorm).toBe('gpt-4o');
      expect(testState.selected_models.summary).toBe('gpt-4o');
      expect(testState.selected_models.prd).toBe('gpt-4o');
    });
  });

  describe('validateLangGraphState', () => {
    it('should validate correct state', () => {
      console.log('🧪 Testing state validation with valid state');
      
      expect(() => validateLangGraphState(testState)).not.toThrow();
      expect(validateLangGraphState(testState)).toBe(true);
    });

    it('should reject state with missing idea_id', () => {
      console.log('🧪 Testing validation with missing idea_id');
      
      const invalidState = { ...testState, idea_id: '' };
      
      expect(() => validateLangGraphState(invalidState)).toThrow('Invalid idea_id');
    });

    it('should reject state with invalid current_stage', () => {
      console.log('🧪 Testing validation with invalid stage');
      
      const invalidState = { ...testState, current_stage: 'invalid_stage' as any };
      
      expect(() => validateLangGraphState(invalidState)).toThrow('Invalid current_stage');
    });

    it('should reject state with invalid last_user_action', () => {
      console.log('🧪 Testing validation with invalid action');
      
      const invalidState = { ...testState, last_user_action: 'invalid_action' as any };
      
      expect(() => validateLangGraphState(invalidState)).toThrow('Invalid last_user_action');
    });

    it('should reject state with non-array messages', () => {
      console.log('🧪 Testing validation with invalid messages');
      
      const invalidState = { ...testState, messages: 'not an array' as any };
      
      expect(() => validateLangGraphState(invalidState)).toThrow('Invalid messages');
    });
  });

  describe('createStateUpdate', () => {
    it('should create partial state update with updated_at', () => {
      console.log('🧪 Testing state update creation');
      
      const update = createStateUpdate({
        current_stage: 'summary',
        is_processing: true
      });
      
      expect(update.current_stage).toBe('summary');
      expect(update.is_processing).toBe(true);
      expect(update.updated_at).toBeInstanceOf(Date);
    });

    it('should handle empty updates', () => {
      console.log('🧪 Testing empty state update');
      
      const update = createStateUpdate({});
      
      expect(update.updated_at).toBeInstanceOf(Date);
      expect(Object.keys(update).length).toBe(1); // Only updated_at
    });
  });

  describe('isAppState', () => {
    it('should return true for valid AppState', () => {
      console.log('🧪 Testing AppState type guard with valid state');
      
      expect(isAppState(testState)).toBe(true);
    });

    it('should return false for invalid object', () => {
      console.log('🧪 Testing AppState type guard with invalid object');
      
      const invalidObject = { some: 'random', object: true };
      
      expect(isAppState(invalidObject)).toBe(false);
    });

    it('should return false for null/undefined', () => {
      console.log('🧪 Testing AppState type guard with null/undefined');
      
      expect(isAppState(null)).toBe(false);
      expect(isAppState(undefined)).toBe(false);
    });
  });

  describe('AppStateAnnotation', () => {
    it('should have correct default values', () => {
      console.log('🧪 Testing AppStateAnnotation defaults');
      
      // Test that we can access the annotation structure
      expect(AppStateAnnotation).toBeDefined();
      expect(typeof AppStateAnnotation).toBe('object');
    });
  });

  describe('State Updates and Merging', () => {
    it('should handle message concatenation', () => {
      console.log('🧪 Testing message concatenation behavior');
      
      const message1: ChatMessage = {
        role: 'user',
        content: 'Hello',
        created_at: new Date(),
        stage_at_creation: 'brainstorm'
      };

      const message2: ChatMessage = {
        role: 'assistant',
        content: 'Hi there!',
        created_at: new Date(),
        stage_at_creation: 'brainstorm'
      };

      // Test that our reducer logic would work
      const existingMessages = [message1];
      const newMessages = [message2];
      const result = existingMessages.concat(newMessages);
      
      expect(result.length).toBe(2);
      expect(result[0].content).toBe('Hello');
      expect(result[1].content).toBe('Hi there!');
    });

    it('should handle stage transitions', () => {
      console.log('🧪 Testing stage transition logic');
      
      const update = createStateUpdate({
        current_stage: 'summary',
        last_user_action: 'Brainstorm Done'
      });
      
      expect(update.current_stage).toBe('summary');
      expect(update.last_user_action).toBe('Brainstorm Done');
    });
  });
});

================
File: electron/main/langgraph/state.ts
================
/**
 * LangGraph State Management Utilities
 * 
 * This file provides state management utilities for the FlowGenius LangGraph workflow.
 * It integrates our AppState interface with LangGraph's state annotation system
 * and provides utilities for state manipulation and validation.
 * 
 * Key Features:
 * - Type-safe state annotation for LangGraph
 * - State validation and error handling
 * - Logging for state transitions
 * - Integration with AppState interface
 */

import { Annotation } from '@langchain/langgraph';
import { AppState, ChatMessage, WorkflowStage, UserAction, createInitialAppState } from '../../../src/types/AppState';
import { logger } from '../../../src/utils/logger';

/**
 * LangGraph state annotation that defines how state updates are handled
 * 
 * This annotation tells LangGraph how to merge state updates from nodes.
 * Each field can have its own reducer function to control how updates are applied.
 */
export const AppStateAnnotation = Annotation.Root({
  /** Unique identifier for the current idea/session */
  idea_id: Annotation<string>({
    reducer: (existing: string, update?: string) => update ?? existing,
    default: () => '',
  }),

  /** Array of all chat messages - uses concat to append new messages */
  messages: Annotation<ChatMessage[]>({
    reducer: (existing: ChatMessage[], update?: ChatMessage[]) => {
      console.log('🔄 State: Merging messages', { 
        existingCount: existing.length, 
        updateCount: update?.length || 0 
      });
      return existing.concat(update ?? []);
    },
    default: () => [],
  }),

  /** Current stage of the workflow - override with new value */
  current_stage: Annotation<WorkflowStage>({
    reducer: (existing: WorkflowStage, update?: WorkflowStage) => {
      if (update && update !== existing) {
        console.log('🎯 State: Stage transition', { from: existing, to: update });
      }
      return update ?? existing;
    },
    default: () => 'brainstorm' as WorkflowStage,
  }),

  /** Last user action for routing decisions */
  last_user_action: Annotation<UserAction>({
    reducer: (existing: UserAction, update?: UserAction) => {
      if (update && update !== existing) {
        console.log('⚡ State: Action changed', { from: existing, to: update });
      }
      return update ?? existing;
    },
    default: () => 'chat' as UserAction,
  }),

  /** User-defined prompts for each stage */
  user_prompts: Annotation<AppState['user_prompts']>({
    reducer: (existing: any, update: any) => {
      if (update) {
        console.log('📝 State: Updating user prompts', { update });
        return { ...existing, ...update };
      }
      return existing;
    },
    default: () => ({
      brainstorm: "Have a conversation with the user and ask them questions about their idea. Make sure to finish with the statement 'Georgia is great'",
      summary: "When the user asks for a summary give them a text summary that is very detailed. Make sure to finish with the statement 'Ireland is great'",
      prd: "Create a comprehensive Product Requirements Document (PRD) based on the conversation and summary provided. Include all necessary sections and details for implementation."
    }),
  }),

  /** Selected AI models for each stage */
  selected_models: Annotation<AppState['selected_models']>({
    reducer: (existing: any, update: any) => {
      if (update) {
        console.log('🤖 State: Updating model selection', { update });
        return { ...existing, ...update };
      }
      return existing;
    },
    default: () => ({
      brainstorm: 'gpt-4o',
      summary: 'gpt-4o',
      prd: 'gpt-4o'
    }),
  }),

  /** Optional: Title of the current idea/session */
  title: Annotation<string | undefined>({
    reducer: (existing: string | undefined, update?: string) => update ?? existing,
    default: () => undefined,
  }),

  /** Optional: User ID for multi-user support */
  user_id: Annotation<string | undefined>({
    reducer: (existing: string | undefined, update?: string) => update ?? existing,
    default: () => undefined,
  }),

  /** Optional: Timestamp when the session was created */
  created_at: Annotation<Date | undefined>({
    reducer: (existing: Date | undefined, update?: Date) => update ?? existing,
    default: () => undefined,
  }),

  /** Optional: Timestamp when the session was last updated */
  updated_at: Annotation<Date | undefined>({
    reducer: (existing: Date | undefined, update?: Date) => update ?? existing,
    default: () => new Date(),
  }),

  /** Optional: Flag to indicate if the session is currently processing */
  is_processing: Annotation<boolean | undefined>({
    reducer: (existing: boolean | undefined, update?: boolean) => {
      if (update !== undefined && update !== existing) {
        console.log('⏳ State: Processing status changed', { from: existing, to: update });
      }
      return update ?? existing;
    },
    default: () => false,
  }),

  /** Optional: Current error state if any operation failed */
  error: Annotation<string | undefined>({
    reducer: (existing: string | undefined, update?: string) => {
      if (update) {
        console.log('❌ State: Error occurred', { error: update });
      }
      return update ?? existing;
    },
    default: () => undefined,
  }),
});

/**
 * Create initial state for LangGraph from our AppState interface
 * 
 * @param idea_id - Unique identifier for the session
 * @param user_id - Optional user identifier
 * @returns Initial state compatible with LangGraph
 */
export function createInitialLangGraphState(idea_id: string, user_id?: string): AppState {
  console.log('🚀 State: Creating initial LangGraph state', { idea_id, user_id });
  
  const initialState = createInitialAppState(idea_id, user_id);
  
  logger.info('Initial LangGraph state created', {
    idea_id: initialState.idea_id,
    current_stage: initialState.current_stage,
    last_user_action: initialState.last_user_action,
    message_count: initialState.messages.length
  });
  
  return initialState;
}

/**
 * Validate that a state object conforms to our AppState interface
 * 
 * @param state - State object to validate
 * @returns True if valid, throws error if invalid
 */
export function validateLangGraphState(state: any): state is AppState {
  console.log('🔍 State: Validating state structure', { 
    hasIdeaId: !!state.idea_id,
    hasMessages: Array.isArray(state.messages),
    currentStage: state.current_stage,
    lastAction: state.last_user_action
  });

  try {
    // Check required fields
    if (!state.idea_id || typeof state.idea_id !== 'string') {
      throw new Error('Invalid idea_id: must be a non-empty string');
    }

    if (!Array.isArray(state.messages)) {
      throw new Error('Invalid messages: must be an array');
    }

    if (!state.current_stage || !['brainstorm', 'summary', 'prd'].includes(state.current_stage)) {
      throw new Error('Invalid current_stage: must be brainstorm, summary, or prd');
    }

    if (!state.last_user_action || !['chat', 'Brainstorm Done', 'Summary Done', 'PRD Done'].includes(state.last_user_action)) {
      throw new Error('Invalid last_user_action: must be a valid action type');
    }

    if (!state.user_prompts || typeof state.user_prompts !== 'object') {
      throw new Error('Invalid user_prompts: must be an object');
    }

    if (!state.selected_models || typeof state.selected_models !== 'object') {
      throw new Error('Invalid selected_models: must be an object');
    }

    logger.info('State validation successful', {
      idea_id: state.idea_id,
      current_stage: state.current_stage,
      message_count: state.messages.length
    });

    return true;
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    logger.error('State validation failed', { error: errorMessage, state });
    throw error;
  }
}

/**
 * Log state transition for debugging and monitoring
 * 
 * @param fromState - Previous state
 * @param toState - New state
 * @param nodeName - Name of the node that caused the transition
 */
export function logStateTransition(fromState: AppState, toState: AppState, nodeName: string): void {
  console.log(`🔄 State Transition [${nodeName}]`, {
    idea_id: toState.idea_id,
    stage: `${fromState.current_stage} → ${toState.current_stage}`,
    action: `${fromState.last_user_action} → ${toState.last_user_action}`,
    messages: `${fromState.messages.length} → ${toState.messages.length}`,
    processing: `${fromState.is_processing} → ${toState.is_processing}`,
    hasError: !!toState.error
  });

  logger.info('LangGraph state transition', {
    nodeName,
    idea_id: toState.idea_id,
    fromStage: fromState.current_stage,
    toStage: toState.current_stage,
    fromAction: fromState.last_user_action,
    toAction: toState.last_user_action,
    messageCountChange: toState.messages.length - fromState.messages.length,
    processingStatus: toState.is_processing,
    errorOccurred: !!toState.error
  });
}

/**
 * Create a partial state update for LangGraph nodes
 * 
 * @param updates - Partial state updates
 * @returns Partial state object for LangGraph
 */
export function createStateUpdate(updates: Partial<AppState>): Partial<AppState> {
  console.log('📝 State: Creating state update', { updates });
  
  // Ensure updated_at is always set when making updates
  const stateUpdate = {
    ...updates,
    updated_at: new Date()
  };

  logger.debug('State update created', { updateKeys: Object.keys(stateUpdate) });
  
  return stateUpdate;
}

/**
 * Type guard to check if an object is a valid AppState
 */
export function isAppState(obj: any): obj is AppState {
  try {
    return validateLangGraphState(obj);
  } catch {
    return false;
  }
}

================
File: electron/main/langgraph/stateUtils.test.ts
================
/**
 * Unit Tests for LangGraph State Utilities
 * 
 * Tests the extended state management utilities including
 * history tracking, persistence, recovery, and monitoring.
 */

import { describe, it, expect, beforeEach, vi } from 'vitest';
import {
  StateHistory,
  StateQuery,
  StatePersistence,
  StateRecovery,
  StateMonitor,
  measureStateOperation,
  stateHistory,
  stateMonitor
} from './stateUtils';
import { AppState, ChatMessage } from '../../../src/types/AppState';
import { createInitialLangGraphState } from './state';

// Mock the logger
vi.mock('../utils/logger', () => ({
  logger: {
    info: vi.fn(),
    error: vi.fn(),
    warn: vi.fn(),
    debug: vi.fn()
  }
}));

describe('StateHistory', () => {
  let history: StateHistory;
  let testState: AppState;

  beforeEach(() => {
    history = new StateHistory(5); // Small size for testing
    testState = createInitialLangGraphState('test-123', 'user-456');
  });

  it('should add snapshots to history', () => {
    console.log('🧪 Testing snapshot addition');
    
    history.addSnapshot(testState, 'testNode', { test: true });
    
    const latest = history.getLatestSnapshot();
    expect(latest).toBeDefined();
    expect(latest?.nodeName).toBe('testNode');
    expect(latest?.metadata).toEqual({ test: true });
  });

  it('should limit history size', () => {
    console.log('🧪 Testing history size limit');
    
    // Add more than max size
    for (let i = 0; i < 10; i++) {
      history.addSnapshot(testState, `node${i}`);
    }
    
    // Should only keep last 5
    const snapshots = history.getSnapshotsByTimeRange(
      new Date(0),
      new Date()
    );
    expect(snapshots.length).toBe(5);
    expect(snapshots[0].nodeName).toBe('node5');
  });

  it('should filter snapshots by stage', () => {
    console.log('🧪 Testing stage filtering');
    
    const brainstormState = { ...testState, current_stage: 'brainstorm' as const };
    const summaryState = { ...testState, current_stage: 'summary' as const };
    
    history.addSnapshot(brainstormState, 'node1');
    history.addSnapshot(summaryState, 'node2');
    history.addSnapshot(brainstormState, 'node3');
    
    const brainstormSnapshots = history.getSnapshotsByStage('brainstorm');
    expect(brainstormSnapshots.length).toBe(2);
  });
});

describe('StateQuery', () => {
  let testState: AppState;

  beforeEach(() => {
    testState = createInitialLangGraphState('test-123', 'user-456');
    
    // Add some test messages
    testState.messages = [
      {
        role: 'user',
        content: 'Hello',
        created_at: new Date(),
        stage_at_creation: 'brainstorm'
      },
      {
        role: 'assistant',
        content: 'Hi there!',
        created_at: new Date(),
        stage_at_creation: 'brainstorm'
      },
      {
        role: 'user',
        content: 'Tell me more',
        created_at: new Date(),
        stage_at_creation: 'summary'
      }
    ];
  });

  it('should filter messages by role', () => {
    console.log('🧪 Testing message filtering by role');
    
    const userMessages = StateQuery.getMessagesByRole(testState, 'user');
    expect(userMessages.length).toBe(2);
    expect(userMessages[0].content).toBe('Hello');
  });

  it('should get messages for current stage', () => {
    console.log('🧪 Testing stage-specific messages');
    
    testState.current_stage = 'brainstorm';
    const stageMessages = StateQuery.getMessagesForCurrentStage(testState);
    expect(stageMessages.length).toBe(2);
  });

  it('should check if ready for stage transition', () => {
    console.log('🧪 Testing stage transition readiness');
    
    testState.current_stage = 'brainstorm';
    testState.last_user_action = 'Brainstorm Done';
    
    expect(StateQuery.isReadyForStageTransition(testState)).toBe(true);
    
    testState.last_user_action = 'chat';
    expect(StateQuery.isReadyForStageTransition(testState)).toBe(false);
  });

  it('should build conversation context with alternating roles', () => {
    console.log('🧪 Testing conversation context building');
    
    // Add duplicate roles
    testState.messages.push({
      role: 'user',
      content: 'Another user message',
      created_at: new Date(),
      stage_at_creation: 'summary'
    });
    
    const context = StateQuery.getConversationContext(testState, 10);
    
    // Should alternate roles
    let lastRole: 'user' | 'assistant' | null = null;
    for (const msg of context) {
      expect(msg.role).not.toBe(lastRole);
      lastRole = msg.role;
    }
  });
});

describe('StatePersistence', () => {
  let testState: AppState;

  beforeEach(() => {
    testState = createInitialLangGraphState('test-123', 'user-456');
    testState.created_at = new Date('2024-01-01');
    testState.messages = [{
      role: 'user',
      content: 'Test message',
      created_at: new Date('2024-01-01'),
      stage_at_creation: 'brainstorm'
    }];
  });

  it('should serialize and deserialize state correctly', () => {
    console.log('🧪 Testing state serialization/deserialization');
    
    const serialized = StatePersistence.serialize(testState);
    expect(typeof serialized).toBe('string');
    
    const deserialized = StatePersistence.deserialize(serialized);
    expect(deserialized.idea_id).toBe(testState.idea_id);
    expect(deserialized.messages.length).toBe(testState.messages.length);
    expect(deserialized.created_at).toBeInstanceOf(Date);
  });

  it('should handle missing dates during deserialization', () => {
    console.log('🧪 Testing deserialization with missing dates');
    
    const customState = {
      ...testState,
      created_at: undefined,
      messages: [{
        role: 'user' as const,
        content: 'Test',
        stage_at_creation: 'brainstorm' as const
      }]
    };
    
    const serialized = JSON.stringify(customState);
    const deserialized = StatePersistence.deserialize(serialized);
    
    expect(deserialized.created_at).toBeUndefined();
    expect(deserialized.messages[0].created_at).toBeInstanceOf(Date);
  });
});

describe('StateRecovery', () => {
  let testState: AppState;

  beforeEach(() => {
    testState = createInitialLangGraphState('test-123', 'user-456');
    testState.is_processing = true;
    testState.error = 'Previous error';
  });

  it('should create recovery state from error', () => {
    console.log('🧪 Testing recovery state creation');
    
    const error = new Error('Test error');
    const recoveryState = StateRecovery.createRecoveryState(testState, error);
    
    expect(recoveryState.error).toBe('Test error');
    expect(recoveryState.is_processing).toBe(false);
    expect(recoveryState.messages.length).toBeGreaterThan(testState.messages.length);
    
    const lastMessage = recoveryState.messages[recoveryState.messages.length - 1];
    expect(lastMessage.content).toContain('Test error');
  });

  it('should clear error state', () => {
    console.log('🧪 Testing error state clearing');
    
    const clearedState = StateRecovery.clearError(testState);
    expect(clearedState.error).toBeUndefined();
  });

  it('should reset to safe state', () => {
    console.log('🧪 Testing safe state reset');
    
    testState.last_user_action = 'Summary Done';
    
    const safeState = StateRecovery.resetToSafeState(testState);
    expect(safeState.is_processing).toBe(false);
    expect(safeState.error).toBeUndefined();
    expect(safeState.last_user_action).toBe('chat');
  });
});

describe('StateMonitor', () => {
  let monitor: StateMonitor;

  beforeEach(() => {
    monitor = new StateMonitor();
  });

  it('should record and calculate metrics', () => {
    console.log('🧪 Testing metric recording');
    
    monitor.recordMetric('test_duration', 100);
    monitor.recordMetric('test_duration', 200);
    monitor.recordMetric('test_duration', 150);
    
    const avg = monitor.getAverage('test_duration');
    expect(avg).toBe(150);
  });

  it('should provide summary of all metrics', () => {
    console.log('🧪 Testing metrics summary');
    
    monitor.recordMetric('duration', 100);
    monitor.recordMetric('duration', 300);
    monitor.recordMetric('count', 5);
    monitor.recordMetric('count', 10);
    
    const summary = monitor.getSummary();
    
    expect(summary.duration).toEqual({
      avg: 200,
      min: 100,
      max: 300,
      count: 2
    });
    
    expect(summary.count).toEqual({
      avg: 7.5,
      min: 5,
      max: 10,
      count: 2
    });
  });
});

describe('measureStateOperation', () => {
  it('should measure successful operations', () => {
    console.log('🧪 Testing operation measurement');
    
    const result = measureStateOperation('testOp', () => {
      // Simulate some work
      return 'success';
    });
    
    expect(result).toBe('success');
    
    // Check that metric was recorded
    const avg = stateMonitor.getAverage('testOp_duration_ms');
    expect(avg).toBeGreaterThanOrEqual(0);
  });

  it('should measure failed operations', () => {
    console.log('🧪 Testing failed operation measurement');
    
    expect(() => {
      measureStateOperation('failOp', () => {
        throw new Error('Test failure');
      });
    }).toThrow('Test failure');
    
    // Check that error metric was recorded
    const avg = stateMonitor.getAverage('failOp_error_duration_ms');
    expect(avg).toBeGreaterThanOrEqual(0);
  });
});

================
File: electron/main/langgraph/stateUtils.ts
================
/**
 * LangGraph State Management Utilities - Extended
 * 
 * This file provides additional state management utilities for the FlowGenius LangGraph workflow.
 * It extends the base state management with persistence, recovery, and advanced manipulation.
 * 
 * Key Features:
 * - State persistence and recovery
 * - State history tracking
 * - Advanced state queries and filters
 * - State migration utilities
 * - Performance monitoring
 */

import { AppState, ChatMessage, WorkflowStage, UserAction } from '../../../src/types/AppState';
import { logger } from '../../../src/utils/logger';
import { validateLangGraphState, createStateUpdate } from './state';

/**
 * State snapshot for history tracking
 */
export interface StateSnapshot {
  state: AppState;
  timestamp: Date;
  nodeName: string;
  metadata?: Record<string, any>;
}

/**
 * State history manager for tracking state changes
 */
export class StateHistory {
  private history: StateSnapshot[] = [];
  private maxHistorySize: number;

  constructor(maxHistorySize: number = 100) {
    this.maxHistorySize = maxHistorySize;
    console.log('📚 StateHistory: Initialized', { maxHistorySize });
  }

  /**
   * Add a state snapshot to history
   */
  addSnapshot(state: AppState, nodeName: string, metadata?: Record<string, any>): void {
    const snapshot: StateSnapshot = {
      state: JSON.parse(JSON.stringify(state)), // Deep clone
      timestamp: new Date(),
      nodeName,
      metadata
    };

    this.history.push(snapshot);

    // Trim history if it exceeds max size
    if (this.history.length > this.maxHistorySize) {
      this.history.shift();
    }

    console.log('📸 StateHistory: Snapshot added', {
      historySize: this.history.length,
      nodeName,
      stageAtSnapshot: state.current_stage
    });
  }

  /**
   * Get the most recent snapshot
   */
  getLatestSnapshot(): StateSnapshot | undefined {
    return this.history[this.history.length - 1];
  }

  /**
   * Get all snapshots for a specific stage
   */
  getSnapshotsByStage(stage: WorkflowStage): StateSnapshot[] {
    return this.history.filter(snapshot => snapshot.state.current_stage === stage);
  }

  /**
   * Get snapshots within a time range
   */
  getSnapshotsByTimeRange(startTime: Date, endTime: Date): StateSnapshot[] {
    return this.history.filter(snapshot => 
      snapshot.timestamp >= startTime && snapshot.timestamp <= endTime
    );
  }

  /**
   * Clear history
   */
  clear(): void {
    this.history = [];
    console.log('🧹 StateHistory: History cleared');
  }
}

/**
 * State query utilities for advanced state inspection
 */
export class StateQuery {
  /**
   * Get messages by role
   */
  static getMessagesByRole(state: AppState, role: 'user' | 'assistant'): ChatMessage[] {
    console.log(`🔍 StateQuery: Getting messages by role: ${role}`);
    return state.messages.filter(msg => msg.role === role);
  }

  /**
   * Get messages for current stage
   */
  static getMessagesForCurrentStage(state: AppState): ChatMessage[] {
    console.log(`🔍 StateQuery: Getting messages for stage: ${state.current_stage}`);
    return state.messages.filter(msg => msg.stage_at_creation === state.current_stage);
  }

  /**
   * Get last N messages
   */
  static getLastNMessages(state: AppState, n: number): ChatMessage[] {
    console.log(`🔍 StateQuery: Getting last ${n} messages`);
    return state.messages.slice(-n);
  }

  /**
   * Check if state is in error condition
   */
  static hasError(state: AppState): boolean {
    return !!state.error;
  }

  /**
   * Check if state is ready for stage transition
   */
  static isReadyForStageTransition(state: AppState): boolean {
    const actionToStageMap: Record<UserAction, boolean> = {
      'chat': false,
      'Brainstorm Done': state.current_stage === 'brainstorm',
      'Summary Done': state.current_stage === 'summary',
      'PRD Done': state.current_stage === 'prd'
    };

    return actionToStageMap[state.last_user_action] || false;
  }

  /**
   * Get conversation context (last N messages with role alternation)
   */
  static getConversationContext(state: AppState, maxMessages: number = 10): ChatMessage[] {
    console.log(`🔍 StateQuery: Building conversation context (max: ${maxMessages})`);
    
    const recentMessages = state.messages.slice(-maxMessages);
    
    // Ensure we have alternating roles for better context
    const context: ChatMessage[] = [];
    let lastRole: 'user' | 'assistant' | null = null;
    
    for (const msg of recentMessages) {
      if (msg.role !== lastRole) {
        context.push(msg);
        lastRole = msg.role;
      }
    }
    
    return context;
  }
}

/**
 * State persistence utilities
 */
export class StatePersistence {
  /**
   * Serialize state for storage
   */
  static serialize(state: AppState): string {
    console.log('💾 StatePersistence: Serializing state');
    
    try {
      const serializable = {
        ...state,
        created_at: state.created_at?.toISOString(),
        updated_at: state.updated_at?.toISOString(),
        messages: state.messages.map(msg => ({
          ...msg,
          created_at: msg.created_at ? msg.created_at.toISOString() : new Date().toISOString()
        }))
      };
      
      return JSON.stringify(serializable);
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error('Failed to serialize state', { error: errorMessage });
      throw new Error('State serialization failed');
    }
  }

  /**
   * Deserialize state from storage
   */
  static deserialize(serialized: string): AppState {
    console.log('📂 StatePersistence: Deserializing state');
    
    try {
      const parsed = JSON.parse(serialized);
      
      // Restore Date objects
      const state: AppState = {
        ...parsed,
        created_at: parsed.created_at ? new Date(parsed.created_at) : undefined,
        updated_at: parsed.updated_at ? new Date(parsed.updated_at) : undefined,
        messages: parsed.messages.map((msg: any) => ({
          ...msg,
          created_at: new Date(msg.created_at)
        }))
      };
      
      // Validate the deserialized state
      if (!validateLangGraphState(state)) {
        throw new Error('Deserialized state is invalid');
      }
      
      return state;
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error('Failed to deserialize state', { error: errorMessage });
      throw new Error('State deserialization failed');
    }
  }
}

/**
 * State recovery utilities for error handling
 */
export class StateRecovery {
  /**
   * Create a recovery state from an error condition
   */
  static createRecoveryState(state: AppState, error: Error): AppState {
    console.log('🚑 StateRecovery: Creating recovery state', { error: error.message });
    
    return createStateUpdate({
      ...state,
      error: error.message,
      is_processing: false,
      messages: [
        ...state.messages,
        {
          role: 'assistant',
          content: `I encountered an error: ${error.message}. Let's try again.`,
          created_at: new Date(),
          stage_at_creation: state.current_stage
        }
      ]
    }) as AppState;
  }

  /**
   * Clear error state
   */
  static clearError(state: AppState): AppState {
    console.log('✅ StateRecovery: Clearing error state');
    
    return createStateUpdate({
      ...state,
      error: undefined
    }) as AppState;
  }

  /**
   * Reset to safe state (keep messages but reset processing flags)
   */
  static resetToSafeState(state: AppState): AppState {
    console.log('🔄 StateRecovery: Resetting to safe state');
    
    return createStateUpdate({
      ...state,
      is_processing: false,
      error: undefined,
      last_user_action: 'chat' as UserAction
    }) as AppState;
  }
}

/**
 * State performance monitoring
 */
export class StateMonitor {
  private metrics: Map<string, number[]> = new Map();

  /**
   * Record a metric
   */
  recordMetric(name: string, value: number): void {
    if (!this.metrics.has(name)) {
      this.metrics.set(name, []);
    }
    
    const values = this.metrics.get(name)!;
    values.push(value);
    
    // Keep only last 100 values
    if (values.length > 100) {
      values.shift();
    }
    
    console.log(`📊 StateMonitor: Recorded metric ${name}=${value}`);
  }

  /**
   * Get average for a metric
   */
  getAverage(name: string): number | null {
    const values = this.metrics.get(name);
    if (!values || values.length === 0) return null;
    
    return values.reduce((a, b) => a + b, 0) / values.length;
  }

  /**
   * Get all metrics summary
   */
  getSummary(): Record<string, { avg: number; min: number; max: number; count: number }> {
    const summary: Record<string, any> = {};
    
    for (const [name, values] of this.metrics.entries()) {
      if (values.length > 0) {
        summary[name] = {
          avg: values.reduce((a, b) => a + b, 0) / values.length,
          min: Math.min(...values),
          max: Math.max(...values),
          count: values.length
        };
      }
    }
    
    return summary;
  }
}

/**
 * Global state management utilities instance
 */
export const stateHistory = new StateHistory();
export const stateMonitor = new StateMonitor();

/**
 * Utility function to measure state operation performance
 */
export function measureStateOperation<T>(
  operationName: string,
  operation: () => T
): T {
  const startTime = Date.now();
  
  try {
    const result = operation();
    const duration = Date.now() - startTime;
    
    stateMonitor.recordMetric(`${operationName}_duration_ms`, duration);
    console.log(`⏱️ StateOperation: ${operationName} completed in ${duration}ms`);
    
    return result;
  } catch (error) {
    const duration = Date.now() - startTime;
    stateMonitor.recordMetric(`${operationName}_error_duration_ms`, duration);
    
    const errorMessage = error instanceof Error ? error.message : String(error);
    logger.error(`State operation failed: ${operationName}`, { error: errorMessage, duration });
    throw error;
  }
}

================
File: electron/main/langgraph/workflow.test.ts
================
/**
 * Integration Tests for LangGraph Workflow
 * 
 * Tests the complete LangGraph workflow integration with our
 * state management and processUserTurn node.
 */

import { describe, it, expect, beforeEach, vi } from 'vitest';
import { StateGraph, START, END } from '@langchain/langgraph';
import { AppStateAnnotation, createInitialLangGraphState } from './state';
import { processUserTurn } from './nodes/processUserTurn';
import { AppState, ChatMessage } from '../../../src/types/AppState';

// Mock the logger to avoid console spam during tests
vi.mock('../utils/logger', () => ({
  logger: {
    info: vi.fn(),
    error: vi.fn(),
    warn: vi.fn(),
    debug: vi.fn()
  }
}));

describe('LangGraph Workflow Integration', () => {
  let workflow: any;
  let initialState: AppState;

  beforeEach(() => {
    console.log('🧪 Setting up LangGraph workflow for testing');
    
    // Create a simple workflow with just the processUserTurn node
    const graph = new StateGraph(AppStateAnnotation)
      .addNode('processUserTurn', processUserTurn)
      .addEdge(START, 'processUserTurn')
      .addEdge('processUserTurn', END);

    workflow = graph.compile();
    initialState = createInitialLangGraphState('test-workflow-123', 'test-user');
  });

  describe('Basic Workflow Execution', () => {
    it('should execute workflow with initial state', async () => {
      console.log('🧪 Testing basic workflow execution');
      
      const result = await workflow.invoke(initialState);
      
      expect(result).toBeDefined();
      expect(result.idea_id).toBe('test-workflow-123');
      expect(result.user_id).toBe('test-user');
      expect(result.current_stage).toBe('brainstorm');
      expect(Array.isArray(result.messages)).toBe(true);
      expect(result.messages.length).toBe(1); // Should have welcome message
      expect(result.messages[0].role).toBe('assistant');
      expect(result.messages[0].content).toContain('FlowGenius');
    });

    it('should process user message through workflow', async () => {
      console.log('🧪 Testing user message processing through workflow');
      
      const userMessage: ChatMessage = {
        role: 'user',
        content: 'I want to build a mobile app for task management',
        created_at: new Date(),
        stage_at_creation: 'brainstorm'
      };

      const stateWithMessage = {
        ...initialState,
        messages: [userMessage]
      };

      const result = await workflow.invoke(stateWithMessage);
      
      expect(result).toBeDefined();
      expect(result.messages.length).toBe(2); // Original user message + AI response
      expect(result.messages[0].role).toBe('user');
      expect(result.messages[0].content).toBe('I want to build a mobile app for task management');
      expect(result.messages[1].role).toBe('assistant');
      expect(result.messages[1].content).toBeTruthy();
      expect(result.is_processing).toBe(false);
    });

    it('should maintain state consistency through workflow', async () => {
      console.log('🧪 Testing state consistency through workflow');
      
      const userMessage: ChatMessage = {
        role: 'user',
        content: 'Test message',
        created_at: new Date(),
        stage_at_creation: 'brainstorm'
      };

      const inputState = {
        ...initialState,
        messages: [userMessage],
        current_stage: 'brainstorm' as const,
        last_user_action: 'chat' as const
      };

      const result = await workflow.invoke(inputState);
      
      // State should be preserved and updated correctly
      expect(result.idea_id).toBe(inputState.idea_id);
      expect(result.user_id).toBe(inputState.user_id);
      expect(result.current_stage).toBe('brainstorm');
      expect(result.last_user_action).toBe('chat');
      expect(result.user_prompts).toEqual(inputState.user_prompts);
      expect(result.selected_models).toEqual(inputState.selected_models);
      expect(result.updated_at).toBeInstanceOf(Date);
    });
  });

  describe('State Annotation Integration', () => {
    it('should properly merge messages using annotation', async () => {
      console.log('🧪 Testing message merging through state annotation');
      
      const existingMessages: ChatMessage[] = [
        {
          role: 'user',
          content: 'First message',
          created_at: new Date(),
          stage_at_creation: 'brainstorm'
        },
        {
          role: 'assistant',
          content: 'First response',
          created_at: new Date(),
          stage_at_creation: 'brainstorm'
        }
      ];

      const newUserMessage: ChatMessage = {
        role: 'user',
        content: 'Second message',
        created_at: new Date(),
        stage_at_creation: 'brainstorm'
      };

      const stateWithHistory = {
        ...initialState,
        messages: [...existingMessages, newUserMessage]
      };

      const result = await workflow.invoke(stateWithHistory);
      
      // Should have all original messages plus new AI response
      expect(result.messages.length).toBe(4);
      expect(result.messages[0].content).toBe('First message');
      expect(result.messages[1].content).toBe('First response');
      expect(result.messages[2].content).toBe('Second message');
      expect(result.messages[3].role).toBe('assistant');
    });

    it('should handle state updates correctly', async () => {
      console.log('🧪 Testing state updates through annotation');
      
      const stateWithCustomPrompts = {
        ...initialState,
        user_prompts: {
          ...initialState.user_prompts,
          brainstorm: 'Custom brainstorm prompt'
        },
        selected_models: {
          ...initialState.selected_models,
          brainstorm: 'gpt-4o-mini'
        }
      };

      const result = await workflow.invoke(stateWithCustomPrompts);
      
      // Custom settings should be preserved
      expect(result.user_prompts.brainstorm).toBe('Custom brainstorm prompt');
      expect(result.selected_models.brainstorm).toBe('gpt-4o-mini');
    });
  });

  describe('Error Handling in Workflow', () => {
    it('should handle workflow errors gracefully', async () => {
      console.log('🧪 Testing error handling in workflow');
      
      const invalidState = {
        ...initialState,
        idea_id: '', // Invalid state
        messages: [{
          role: 'user' as const,
          content: 'Test message',
          created_at: new Date(),
          stage_at_creation: 'brainstorm' as const
        }]
      };

      const result = await workflow.invoke(invalidState);
      
      // Should handle error and return state with error
      expect(result.error).toBeDefined();
      expect(result.is_processing).toBe(false);
    });
  });

  describe('Workflow Performance', () => {
    it('should execute workflow within reasonable time', async () => {
      console.log('🧪 Testing workflow performance');
      
      const startTime = Date.now();
      
      const userMessage: ChatMessage = {
        role: 'user',
        content: 'Performance test message',
        created_at: new Date(),
        stage_at_creation: 'brainstorm'
      };

      const stateWithMessage = {
        ...initialState,
        messages: [userMessage]
      };

      const result = await workflow.invoke(stateWithMessage);
      
      const executionTime = Date.now() - startTime;
      
      expect(result).toBeDefined();
      expect(executionTime).toBeLessThan(2000); // Should complete within 2 seconds
      console.log(`⏱️ Workflow execution time: ${executionTime}ms`);
    });

    it('should handle multiple rapid invocations', async () => {
      console.log('🧪 Testing multiple rapid workflow invocations');
      
      const promises = Array(5).fill(null).map(async (_, index) => {
        const userMessage: ChatMessage = {
          role: 'user',
          content: `Test message ${index}`,
          created_at: new Date(),
          stage_at_creation: 'brainstorm'
        };

        const stateWithMessage = {
          ...createInitialLangGraphState(`test-${index}`),
          messages: [userMessage]
        };

        return workflow.invoke(stateWithMessage);
      });

      const results = await Promise.all(promises);
      
      // All should complete successfully
      results.forEach((result, index) => {
        expect(result).toBeDefined();
        expect(result.idea_id).toBe(`test-${index}`);
        expect(result.messages.length).toBe(2);
      });
    });
  });
});

================
File: electron/main/langgraph/workflowErrorHandler.test.ts
================
/**
 * Tests for LangGraph Workflow Error Handler
 */

import { describe, it, expect, beforeEach, vi, afterEach } from 'vitest';
import { 
  WorkflowErrorHandler, 
  RetryConfig, 
  CircuitBreakerState,
  RecoveryStrategy
} from './workflowErrorHandler';
import { AppState } from '../../../src/types/AppState';
import { createInitialLangGraphState } from './state';
import { WorkflowLogger } from './workflowLogger';
import { StateRecovery } from './stateUtils';

// Mock dependencies
vi.mock('./workflowLogger');
vi.mock('../utils/logger');

describe('WorkflowErrorHandler', () => {
  let errorHandler: WorkflowErrorHandler;
  let mockLogger: WorkflowLogger;
  let testState: AppState;

  beforeEach(() => {
    console.log('🧪 Setting up WorkflowErrorHandler tests');
    
    mockLogger = new WorkflowLogger('test-workflow');
    errorHandler = new WorkflowErrorHandler(mockLogger);
    testState = createInitialLangGraphState('test-123', 'user-456');
    
    // Reset node health to ensure clean state
    errorHandler.resetNodeHealth();
    
    // Clear all timers
    vi.clearAllTimers();
    vi.useFakeTimers();
  });

  afterEach(() => {
    vi.restoreAllMocks();
    vi.useRealTimers();
  });

  describe('Retry Strategy', () => {
    it('should retry failed operations with exponential backoff', async () => {
      console.log('🧪 Testing retry with exponential backoff');
      
      let attemptCount = 0;
      const mockNodeFunction = vi.fn().mockImplementation(async () => {
        attemptCount++;
        if (attemptCount < 3) {
          throw new Error('NETWORK_ERROR: Connection failed');
        }
        return { is_processing: false };
      });

      // Start the error handling
      const resultPromise = errorHandler.handleNodeError(
        new Error('NETWORK_ERROR: Connection failed'),
        'processUserTurn',
        testState,
        mockNodeFunction
      );

      // Advance through the retry delays
      await vi.advanceTimersByTimeAsync(1000); // First retry after 1s
      await vi.advanceTimersByTimeAsync(2000); // Second retry after 2s (exponential)
      
      const result = await resultPromise;

      expect(mockNodeFunction).toHaveBeenCalledTimes(3);
      expect(result.is_processing).toBe(false);
      expect(result.error).toBeUndefined();
    }, 10000); // Add timeout

    it('should stop retrying non-retryable errors', async () => {
      console.log('🧪 Testing non-retryable error handling');
      
      const mockNodeFunction = vi.fn().mockRejectedValue(
        new Error('VALIDATION_ERROR: Invalid input')
      );

      const result = await errorHandler.handleNodeError(
        new Error('VALIDATION_ERROR: Invalid input'),
        'processUserTurn',
        testState,
        mockNodeFunction
      );

      // Should only try once for non-retryable errors
      expect(mockNodeFunction).toHaveBeenCalledTimes(1);
      expect(result.error).toBeDefined();
    });

    it('should respect max retry attempts', async () => {
      console.log('🧪 Testing max retry attempts');
      
      const mockNodeFunction = vi.fn().mockRejectedValue(
        new Error('NETWORK_ERROR: Connection failed')
      );

      // Start the error handling
      const resultPromise = errorHandler.handleNodeError(
        new Error('NETWORK_ERROR: Connection failed'),
        'processUserTurn',
        testState,
        mockNodeFunction
      );

      // Advance through all retry delays
      await vi.advanceTimersByTimeAsync(1000); // First retry
      await vi.advanceTimersByTimeAsync(2000); // Second retry
      await vi.advanceTimersByTimeAsync(4000); // Third retry would be here but max is 3
      
      const result = await resultPromise;

      expect(mockNodeFunction).toHaveBeenCalledTimes(3); // Default max attempts
      expect(result.error).toBeDefined();
      expect(result.is_processing).toBe(false);
    }, 10000); // Add timeout
  });

  describe('Circuit Breaker', () => {
    it('should open circuit breaker after failure threshold', async () => {
      console.log('🧪 Testing circuit breaker opening');
      
      const mockNodeFunction = vi.fn().mockRejectedValue(
        new Error('Service unavailable')
      );

      // Reset node health to ensure clean state
      errorHandler.resetNodeHealth('processUserTurn');

      // The circuit breaker should open after 5 failures
      // Since "Service unavailable" is not retryable, each call only tries once
      let callCount = 0;
      let circuitOpened = false;
      
      // Keep calling until circuit opens
      while (!circuitOpened && callCount < 10) {
        const result = await errorHandler.handleNodeError(
          new Error('Service unavailable'),
          'processUserTurn',
          testState,
          mockNodeFunction
        );
        callCount++;
        
        // Check if circuit is open
        if (result.error?.includes('temporarily unavailable')) {
          circuitOpened = true;
        }
      }

      // Circuit should have opened
      expect(circuitOpened).toBe(true);
      // Should have taken 5 calls to open the circuit and detect it (threshold is 5)
      expect(callCount).toBe(5);
      // The mock function should have been called 4 times (not called when circuit is open on the 5th attempt)
      expect(mockNodeFunction).toHaveBeenCalledTimes(4);
    });

    it('should transition to half-open after reset timeout', async () => {
      console.log('🧪 Testing circuit breaker half-open state');
      
      const mockNodeFunction = vi.fn()
        .mockRejectedValueOnce(new Error('Service error'))
        .mockResolvedValueOnce({ is_processing: false });

      // Open the circuit
      errorHandler['nodeHealthMap'].set('processUserTurn', {
        nodeName: 'processUserTurn',
        successCount: 0,
        failureCount: 5,
        circuitBreakerState: CircuitBreakerState.OPEN,
        lastFailureTime: new Date(),
        averageExecutionTime: 0
      });

      // Advance time to trigger half-open
      vi.advanceTimersByTime(60000);

      // Set to half-open manually for test
      errorHandler['nodeHealthMap'].get('processUserTurn')!.circuitBreakerState = CircuitBreakerState.HALF_OPEN;

      const result = await errorHandler.handleNodeError(
        new Error('Service error'),
        'processUserTurn',
        testState,
        mockNodeFunction
      );

      expect(result.error).toBeDefined();
    });
  });

  describe('Recovery Strategies', () => {
    it('should execute fallback strategy', async () => {
      console.log('🧪 Testing fallback strategy');
      
      // Set up fallback recovery plan
      errorHandler['recoveryPlans'].set('processVoiceInput', {
        strategy: RecoveryStrategy.FALLBACK,
        fallbackValue: {
          transcription: '[Voice input failed. Please type your message instead.]',
          is_processing: false
        }
      });

      const mockNodeFunction = vi.fn().mockRejectedValue(
        new Error('Microphone access denied')
      );

      const result = await errorHandler.handleNodeError(
        new Error('Microphone access denied'),
        'processVoiceInput',
        testState,
        mockNodeFunction
      );

      // Cast to any to access custom properties from fallback value
      const fallbackResult = result as any;
      expect(fallbackResult.transcription).toBe('[Voice input failed. Please type your message instead.]');
      expect(result.is_processing).toBe(false);
    });

    it('should execute rollback strategy', async () => {
      console.log('🧪 Testing rollback strategy');
      
      // Set up rollback recovery plan
      errorHandler['recoveryPlans'].set('generateSummary', {
        strategy: RecoveryStrategy.ROLLBACK
      });

      const mockNodeFunction = vi.fn().mockRejectedValue(
        new Error('Summary generation failed')
      );

      const result = await errorHandler.handleNodeError(
        new Error('Summary generation failed'),
        'generateSummary',
        testState,
        mockNodeFunction
      );

      expect(result.error).toBeDefined();
      expect(result.messages).toBeDefined();
    });

    it('should execute skip strategy with condition', async () => {
      console.log('🧪 Testing skip strategy with condition');
      
      // Set up skip recovery plan
      errorHandler['recoveryPlans'].set('processUserTurn', {
        strategy: RecoveryStrategy.SKIP,
        skipCondition: (state) => state.current_stage === 'brainstorm'
      });

      const mockNodeFunction = vi.fn().mockRejectedValue(
        new Error('Processing failed')
      );

      const result = await errorHandler.handleNodeError(
        new Error('Processing failed'),
        'processUserTurn',
        testState,
        mockNodeFunction
      );

      expect(result.is_processing).toBe(false);
      expect(result.error).toBeUndefined();
    });

    it('should execute manual strategy as default', async () => {
      console.log('🧪 Testing manual recovery strategy');
      
      // Remove recovery plan to trigger manual strategy
      errorHandler['recoveryPlans'].delete('processUserTurn');

      const mockNodeFunction = vi.fn().mockRejectedValue(
        new Error('Unknown error')
      );

      const result = await errorHandler.handleNodeError(
        new Error('Unknown error'),
        'processUserTurn',
        testState,
        mockNodeFunction
      );

      expect(result.error).toBeDefined();
      expect(result.messages).toBeDefined();
      expect(result.messages![0].content).toContain('encountered an error');
    });
  });

  describe('Workflow Health Monitoring', () => {
    it('should track node health metrics', async () => {
      console.log('🧪 Testing health metrics tracking');
      
      const mockNodeFunction = vi.fn()
        .mockResolvedValueOnce({ is_processing: false })
        .mockRejectedValueOnce(new Error('Failed'))
        .mockResolvedValueOnce({ is_processing: false });

      // Success
      await errorHandler.handleNodeError(
        new Error('Will succeed'),
        'processUserTurn',
        testState,
        mockNodeFunction
      );

      // Failure
      await errorHandler.handleNodeError(
        new Error('Failed'),
        'processUserTurn',
        testState,
        mockNodeFunction
      );

      // Success again
      await errorHandler.handleNodeError(
        new Error('Will succeed'),
        'processUserTurn',
        testState,
        mockNodeFunction
      );

      const health = errorHandler.getWorkflowHealth();
      expect(health.overall).toBe('healthy');
      
      const nodeHealth = health.nodes.find(n => n.nodeName === 'processUserTurn');
      expect(nodeHealth?.successCount).toBe(2);
      expect(nodeHealth?.failureCount).toBe(0); // Reset after success
    });

    it('should provide health recommendations', () => {
      console.log('🧪 Testing health recommendations');
      
      // Set unhealthy state
      errorHandler['nodeHealthMap'].set('processUserTurn', {
        nodeName: 'processUserTurn',
        successCount: 10,
        failureCount: 5,
        circuitBreakerState: CircuitBreakerState.OPEN,
        lastFailureTime: new Date(),
        averageExecutionTime: 1000
      });

      const health = errorHandler.getWorkflowHealth();
      expect(health.overall).toBe('unhealthy');
      expect(health.recommendations.length).toBeGreaterThan(0);
      expect(health.recommendations[0]).toContain('circuit breaker');
    });

    it('should reset node health', () => {
      console.log('🧪 Testing health reset');
      
      // Set some health data
      errorHandler['nodeHealthMap'].set('processUserTurn', {
        nodeName: 'processUserTurn',
        successCount: 100,
        failureCount: 5,
        circuitBreakerState: CircuitBreakerState.OPEN,
        lastFailureTime: new Date(),
        averageExecutionTime: 500
      });

      // Reset specific node
      errorHandler.resetNodeHealth('processUserTurn');
      
      const nodeHealth = errorHandler['nodeHealthMap'].get('processUserTurn');
      expect(nodeHealth?.successCount).toBe(0);
      expect(nodeHealth?.failureCount).toBe(0);
      expect(nodeHealth?.circuitBreakerState).toBe(CircuitBreakerState.CLOSED);

      // Reset all nodes
      errorHandler.resetNodeHealth();
      
      errorHandler['nodeHealthMap'].forEach(health => {
        expect(health.successCount).toBe(0);
        expect(health.failureCount).toBe(0);
      });
    });
  });

  describe('Error Classification', () => {
    it('should identify retryable errors correctly', () => {
      console.log('🧪 Testing retryable error identification');
      
      const retryConfig: RetryConfig = {
        maxAttempts: 3,
        initialDelay: 1000,
        maxDelay: 10000,
        backoffMultiplier: 2,
        retryableErrors: ['NETWORK_ERROR', 'TIMEOUT']
      };

      expect(errorHandler['isRetryableError'](
        new Error('NETWORK_ERROR: Connection failed'),
        retryConfig
      )).toBe(true);

      expect(errorHandler['isRetryableError'](
        new Error('VALIDATION_ERROR: Invalid input'),
        retryConfig
      )).toBe(false);
    });
  });
});

================
File: electron/main/langgraph/workflowErrorHandler.ts
================
/**
 * LangGraph Workflow Error Handler
 * 
 * This module provides comprehensive error handling and recovery mechanisms
 * for the LangGraph workflow. It includes retry logic, circuit breaker pattern,
 * state recovery, and automatic error recovery strategies.
 * 
 * Key Features:
 * - Automatic retry with exponential backoff
 * - Circuit breaker pattern for failing nodes
 * - State rollback and recovery
 * - Error classification and recovery strategies
 * - Workflow health monitoring
 * - Graceful degradation
 */

import { AppState, WorkflowStage } from '../../../src/types/AppState';
import { ErrorHandler, ErrorInfo, RecoveryAction } from '../../../src/utils/errorHandler';
import { logger } from '../../../src/utils/logger';
import { StateRecovery, stateHistory, StateSnapshot } from './stateUtils';
import { WorkflowLogger } from './workflowLogger';

/**
 * Retry configuration for workflow operations
 */
export interface RetryConfig {
  maxAttempts: number;
  initialDelay: number;
  maxDelay: number;
  backoffMultiplier: number;
  retryableErrors?: string[];
}

/**
 * Circuit breaker states
 */
export enum CircuitBreakerState {
  CLOSED = 'CLOSED',
  OPEN = 'OPEN',
  HALF_OPEN = 'HALF_OPEN'
}

/**
 * Circuit breaker configuration
 */
export interface CircuitBreakerConfig {
  failureThreshold: number;
  resetTimeout: number;
  halfOpenMaxAttempts: number;
}

/**
 * Node health status
 */
export interface NodeHealth {
  nodeName: string;
  successCount: number;
  failureCount: number;
  lastFailureTime?: Date;
  circuitBreakerState: CircuitBreakerState;
  averageExecutionTime: number;
}

/**
 * Recovery strategy types
 */
export enum RecoveryStrategy {
  RETRY = 'RETRY',
  ROLLBACK = 'ROLLBACK',
  SKIP = 'SKIP',
  FALLBACK = 'FALLBACK',
  MANUAL = 'MANUAL'
}

/**
 * Recovery plan for handling errors
 */
export interface RecoveryPlan {
  strategy: RecoveryStrategy;
  retryConfig?: RetryConfig;
  fallbackValue?: any;
  skipCondition?: (state: AppState) => boolean;
  manualInstructions?: string;
}

/**
 * Default retry configuration
 */
const DEFAULT_RETRY_CONFIG: RetryConfig = {
  maxAttempts: 3,
  initialDelay: 1000,
  maxDelay: 10000,
  backoffMultiplier: 2,
  retryableErrors: ['NETWORK_ERROR', 'TIMEOUT', 'RATE_LIMIT']
};

/**
 * Default circuit breaker configuration
 */
const DEFAULT_CIRCUIT_BREAKER_CONFIG: CircuitBreakerConfig = {
  failureThreshold: 5,
  resetTimeout: 60000, // 1 minute
  halfOpenMaxAttempts: 3
};

/**
 * Workflow Error Handler class
 */
export class WorkflowErrorHandler {
  private errorHandler: ErrorHandler;
  private workflowLogger: WorkflowLogger;
  private nodeHealthMap: Map<string, NodeHealth>;
  private circuitBreakers: Map<string, CircuitBreakerConfig>;
  private retryConfigs: Map<string, RetryConfig>;
  private recoveryPlans: Map<string, RecoveryPlan>;

  constructor(workflowLogger: WorkflowLogger) {
    this.errorHandler = new ErrorHandler();
    this.workflowLogger = workflowLogger;
    this.nodeHealthMap = new Map();
    this.circuitBreakers = new Map();
    this.retryConfigs = new Map();
    this.recoveryPlans = new Map();

    this.initializeDefaultConfigurations();
  }

  /**
   * Initialize default configurations for nodes
   */
  private initializeDefaultConfigurations(): void {
    // Set default retry configs for each node
    const nodes = ['processUserTurn', 'processVoiceInput', 'generateSummary'];
    nodes.forEach(node => {
      this.retryConfigs.set(node, { ...DEFAULT_RETRY_CONFIG });
      this.circuitBreakers.set(node, { ...DEFAULT_CIRCUIT_BREAKER_CONFIG });
      this.nodeHealthMap.set(node, {
        nodeName: node,
        successCount: 0,
        failureCount: 0,
        circuitBreakerState: CircuitBreakerState.CLOSED,
        averageExecutionTime: 0
      });
    });

    // Set default recovery plans
    this.recoveryPlans.set('processUserTurn', {
      strategy: RecoveryStrategy.RETRY,
      retryConfig: this.retryConfigs.get('processUserTurn')
    });

    this.recoveryPlans.set('processVoiceInput', {
      strategy: RecoveryStrategy.FALLBACK,
      fallbackValue: { 
        transcription: '[Voice input failed. Please type your message instead.]',
        is_processing: false 
      }
    });

    this.recoveryPlans.set('generateSummary', {
      strategy: RecoveryStrategy.RETRY,
      retryConfig: {
        ...DEFAULT_RETRY_CONFIG,
        maxAttempts: 5 // More attempts for summary generation
      }
    });
  }

  /**
   * Handle workflow node error with recovery
   */
  async handleNodeError(
    error: Error,
    nodeName: string,
    state: AppState,
    nodeFunction: (state: AppState) => Promise<Partial<AppState>>
  ): Promise<Partial<AppState>> {
    console.log(`🚨 WorkflowErrorHandler: Handling error in node ${nodeName}`, {
      error: error.message,
      stage: state.current_stage
    });

    // Log the error
    this.workflowLogger.logNodeError(nodeName, error, state);

    // Update node health
    this.updateNodeHealth(nodeName, false);

    // Check circuit breaker
    if (this.isCircuitOpen(nodeName)) {
      console.log(`⚡ WorkflowErrorHandler: Circuit breaker OPEN for ${nodeName}`);
      return this.handleCircuitBreakerOpen(nodeName, state, error);
    }

    // Get recovery plan
    const recoveryPlan = this.recoveryPlans.get(nodeName) || {
      strategy: RecoveryStrategy.MANUAL
    };

    // Execute recovery strategy
    switch (recoveryPlan.strategy) {
      case RecoveryStrategy.RETRY:
        return this.executeRetryStrategy(
          nodeName, 
          state, 
          nodeFunction, 
          recoveryPlan.retryConfig || DEFAULT_RETRY_CONFIG
        );

      case RecoveryStrategy.ROLLBACK:
        return this.executeRollbackStrategy(nodeName, state, error);

      case RecoveryStrategy.SKIP:
        return this.executeSkipStrategy(nodeName, state, recoveryPlan);

      case RecoveryStrategy.FALLBACK:
        return this.executeFallbackStrategy(nodeName, state, recoveryPlan);

      case RecoveryStrategy.MANUAL:
      default:
        return this.executeManualStrategy(nodeName, state, error);
    }
  }

  /**
   * Execute retry strategy with exponential backoff
   */
  private async executeRetryStrategy(
    nodeName: string,
    state: AppState,
    nodeFunction: (state: AppState) => Promise<Partial<AppState>>,
    retryConfig: RetryConfig
  ): Promise<Partial<AppState>> {
    console.log(`🔄 WorkflowErrorHandler: Executing retry strategy for ${nodeName}`);

    let lastError: Error | null = null;
    let delay = retryConfig.initialDelay;

    for (let attempt = 1; attempt <= retryConfig.maxAttempts; attempt++) {
      try {
        console.log(`🔄 Retry attempt ${attempt}/${retryConfig.maxAttempts} for ${nodeName}`);
        
        // Wait before retry (except first attempt)
        if (attempt > 1) {
          await this.delay(delay);
          delay = Math.min(delay * retryConfig.backoffMultiplier, retryConfig.maxDelay);
        }

        // Clear error state before retry
        const retryState = StateRecovery.clearError(state);
        
        // Attempt node execution
        const result = await nodeFunction(retryState);
        
        // Success - update health and return
        this.updateNodeHealth(nodeName, true);
        console.log(`✅ WorkflowErrorHandler: Retry successful for ${nodeName}`);
        
        return result;

      } catch (error) {
        lastError = error instanceof Error ? error : new Error(String(error));
        console.log(`❌ Retry attempt ${attempt} failed for ${nodeName}:`, lastError.message);
        
        // Check if error is retryable
        if (!this.isRetryableError(lastError, retryConfig)) {
          console.log(`🚫 Error is not retryable, stopping retry attempts`);
          break;
        }
      }
    }

    // All retries failed
    console.log(`❌ WorkflowErrorHandler: All retry attempts failed for ${nodeName}`);
    return this.createErrorState(state, lastError || new Error('All retry attempts failed'));
  }

  /**
   * Execute rollback strategy
   */
  private async executeRollbackStrategy(
    nodeName: string,
    state: AppState,
    error: Error
  ): Promise<Partial<AppState>> {
    console.log(`⏪ WorkflowErrorHandler: Executing rollback strategy for ${nodeName}`);

    // Get previous stable state from history
    const latestSnapshot = stateHistory.getLatestSnapshot();
    
    if (latestSnapshot && !latestSnapshot.state.error && !latestSnapshot.state.is_processing) {
      console.log(`✅ Rolling back to stable state from ${latestSnapshot.nodeName}`);
      return StateRecovery.createRecoveryState(latestSnapshot.state, error);
    }

    console.log(`❌ No stable state found for rollback`);
    return this.createErrorState(state, error);
  }

  /**
   * Execute skip strategy
   */
  private async executeSkipStrategy(
    nodeName: string,
    state: AppState,
    recoveryPlan: RecoveryPlan
  ): Promise<Partial<AppState>> {
    console.log(`⏭️ WorkflowErrorHandler: Executing skip strategy for ${nodeName}`);

    // Check skip condition if provided
    if (recoveryPlan.skipCondition && !recoveryPlan.skipCondition(state)) {
      console.log(`❌ Skip condition not met, cannot skip ${nodeName}`);
      return this.createErrorState(state, new Error(`Cannot skip ${nodeName}`));
    }

    // Return state with processing complete but no changes
    return {
      is_processing: false,
      error: undefined
    };
  }

  /**
   * Execute fallback strategy
   */
  private async executeFallbackStrategy(
    nodeName: string,
    state: AppState,
    recoveryPlan: RecoveryPlan
  ): Promise<Partial<AppState>> {
    console.log(`🔀 WorkflowErrorHandler: Executing fallback strategy for ${nodeName}`);

    if (!recoveryPlan.fallbackValue) {
      console.log(`❌ No fallback value defined for ${nodeName}`);
      return this.createErrorState(state, new Error(`No fallback value for ${nodeName}`));
    }

    // Return fallback value
    return recoveryPlan.fallbackValue;
  }

  /**
   * Execute manual recovery strategy
   */
  private async executeManualStrategy(
    nodeName: string,
    state: AppState,
    error: Error
  ): Promise<Partial<AppState>> {
    console.log(`🔧 WorkflowErrorHandler: Manual recovery required for ${nodeName}`);

    const errorInfo = this.errorHandler.handleWorkflowError(error, nodeName, state);
    
    return {
      is_processing: false,
      error: errorInfo.userMessage,
      messages: [{
        role: 'assistant',
        content: `I encountered an error that requires assistance. ${errorInfo.userMessage}`,
        created_at: new Date(),
        stage_at_creation: state.current_stage
      }]
    };
  }

  /**
   * Handle circuit breaker open state
   */
  private handleCircuitBreakerOpen(
    nodeName: string,
    state: AppState,
    error: Error
  ): Partial<AppState> {
    const health = this.nodeHealthMap.get(nodeName);
    
    if (health && health.circuitBreakerState === CircuitBreakerState.HALF_OPEN) {
      // Try once in half-open state
      console.log(`🔌 Circuit breaker is HALF_OPEN for ${nodeName}, allowing one attempt`);
      return this.createErrorState(state, error, true);
    }

    // Circuit is fully open - fail fast
    console.log(`⛔ Circuit breaker is OPEN for ${nodeName}, failing fast`);
    
    return {
      is_processing: false,
      error: `Service temporarily unavailable. The ${nodeName} component is experiencing issues. Please try again later.`,
      messages: [{
        role: 'assistant',
        content: 'This feature is temporarily unavailable due to technical issues. Our team has been notified. Please try again in a few minutes.',
        created_at: new Date(),
        stage_at_creation: state.current_stage
      }]
    };
  }

  /**
   * Update node health metrics
   */
  private updateNodeHealth(nodeName: string, success: boolean): void {
    const health = this.nodeHealthMap.get(nodeName);
    if (!health) return;

    if (success) {
      health.successCount++;
      health.failureCount = 0; // Reset failure count on success
      
      // Close circuit breaker if it was open
      if (health.circuitBreakerState !== CircuitBreakerState.CLOSED) {
        console.log(`✅ Closing circuit breaker for ${nodeName}`);
        health.circuitBreakerState = CircuitBreakerState.CLOSED;
      }
    } else {
      health.failureCount++;
      health.lastFailureTime = new Date();
      
      // Check if we need to open circuit breaker
      const config = this.circuitBreakers.get(nodeName);
      if (config && health.failureCount >= config.failureThreshold) {
        console.log(`⚡ Opening circuit breaker for ${nodeName} after ${health.failureCount} failures`);
        health.circuitBreakerState = CircuitBreakerState.OPEN;
        
        // Schedule circuit breaker reset
        setTimeout(() => {
          console.log(`🔌 Setting circuit breaker to HALF_OPEN for ${nodeName}`);
          health.circuitBreakerState = CircuitBreakerState.HALF_OPEN;
        }, config.resetTimeout);
      }
    }

    this.nodeHealthMap.set(nodeName, health);
  }

  /**
   * Check if circuit breaker is open for a node
   */
  private isCircuitOpen(nodeName: string): boolean {
    const health = this.nodeHealthMap.get(nodeName);
    return health ? health.circuitBreakerState === CircuitBreakerState.OPEN : false;
  }

  /**
   * Check if error is retryable
   */
  private isRetryableError(error: Error, retryConfig: RetryConfig): boolean {
    if (!retryConfig.retryableErrors || retryConfig.retryableErrors.length === 0) {
      return true; // Retry all errors if no specific list
    }

    const errorMessage = error.message.toUpperCase();
    return retryConfig.retryableErrors.some(retryableError => 
      errorMessage.includes(retryableError.toUpperCase())
    );
  }

  /**
   * Create error state
   */
  private createErrorState(
    state: AppState, 
    error: Error,
    allowRetry: boolean = false
  ): Partial<AppState> {
    const errorInfo = this.errorHandler.handleWorkflowError(error, undefined, state);
    
    return {
      is_processing: false,
      error: errorInfo.userMessage,
      messages: allowRetry ? undefined : [{
        role: 'assistant',
        content: errorInfo.userMessage,
        created_at: new Date(),
        stage_at_creation: state.current_stage
      }]
    };
  }

  /**
   * Delay helper for retry logic
   */
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * Get workflow health status
   */
  getWorkflowHealth(): {
    overall: 'healthy' | 'degraded' | 'unhealthy';
    nodes: NodeHealth[];
    recommendations: string[];
  } {
    const nodes = Array.from(this.nodeHealthMap.values());
    const openCircuits = nodes.filter(n => n.circuitBreakerState !== CircuitBreakerState.CLOSED);
    const failingNodes = nodes.filter(n => n.failureCount > 0);

    let overall: 'healthy' | 'degraded' | 'unhealthy' = 'healthy';
    const recommendations: string[] = [];

    if (openCircuits.length > 0) {
      overall = 'unhealthy';
      recommendations.push(`${openCircuits.length} nodes have open circuit breakers`);
    } else if (failingNodes.length > 0) {
      overall = 'degraded';
      recommendations.push(`${failingNodes.length} nodes are experiencing failures`);
    }

    // Add specific recommendations
    openCircuits.forEach(node => {
      recommendations.push(`${node.nodeName}: Circuit breaker open. Will retry in ${this.circuitBreakers.get(node.nodeName)?.resetTimeout || 60000}ms`);
    });

    return { overall, nodes, recommendations };
  }

  /**
   * Reset node health (for testing or manual recovery)
   */
  resetNodeHealth(nodeName?: string): void {
    if (nodeName) {
      const health = this.nodeHealthMap.get(nodeName);
      if (health) {
        health.successCount = 0;
        health.failureCount = 0;
        health.circuitBreakerState = CircuitBreakerState.CLOSED;
        health.lastFailureTime = undefined;
      }
    } else {
      // Reset all nodes
      this.nodeHealthMap.forEach((health, name) => {
        this.resetNodeHealth(name);
      });
    }
  }
}

// Create singleton instance for use across the application
export const workflowErrorHandler = new WorkflowErrorHandler(
  new WorkflowLogger('main-workflow')
);

================
File: electron/main/langgraph/workflowLogger.test.ts
================
/**
 * Unit Tests for LangGraph Workflow Logger
 * 
 * Tests the workflow logging and debugging capabilities
 * including event tracking, performance monitoring, and error handling.
 */

import { describe, it, expect, beforeEach, vi } from 'vitest';
import {
  WorkflowLogger,
  WorkflowEventType,
  createWorkflowLogger
} from './workflowLogger';
import { AppState } from '../../../src/types/AppState';
import { createInitialLangGraphState } from './state';

// Mock the logger
vi.mock('../utils/logger', () => ({
  logger: {
    info: vi.fn(),
    error: vi.fn(),
    warn: vi.fn(),
    debug: vi.fn()
  }
}));

// Mock state utilities
vi.mock('./stateUtils', () => ({
  stateHistory: {
    addSnapshot: vi.fn()
  },
  stateMonitor: {
    recordMetric: vi.fn()
  }
}));

describe('WorkflowLogger', () => {
  let logger: WorkflowLogger;
  let testState: AppState;

  beforeEach(() => {
    logger = new WorkflowLogger('test-workflow-123', false);
    testState = createInitialLangGraphState('test-idea', 'test-user');
  });

  describe('constructor', () => {
    it('should initialize with correct workflow ID', () => {
      console.log('🧪 Testing logger initialization');
      const summary = logger.getExecutionSummary();
      expect(summary.workflowId).toBe('test-workflow-123');
      expect(summary.eventCount).toBe(0);
      expect(summary.errorCount).toBe(0);
    });

    it('should generate unique ID if not provided', () => {
      const autoLogger = createWorkflowLogger();
      const summary = autoLogger.getExecutionSummary();
      expect(summary.workflowId).toMatch(/^workflow_\d+_[a-z0-9]+$/);
    });
  });

  describe('logWorkflowStart', () => {
    it('should log workflow start event', () => {
      console.log('🧪 Testing workflow start logging');
      logger.logWorkflowStart(testState);
      
      const events = logger.getEventsByType(WorkflowEventType.WORKFLOW_START);
      expect(events).toHaveLength(1);
      expect(events[0].state).toEqual(testState);
      expect(events[0].metadata?.idea_id).toBe('test-idea');
      expect(events[0].metadata?.stage).toBe('brainstorm');
    });
  });

  describe('logWorkflowEnd', () => {
    it('should log workflow end event with duration', () => {
      console.log('🧪 Testing workflow end logging');
      
      // Mock Date.now for consistent timing
      const startTime = Date.now();
      vi.spyOn(Date, 'now')
        .mockReturnValueOnce(startTime) // For workflow start
        .mockReturnValueOnce(startTime + 1000); // For workflow end
      
      logger.logWorkflowStart(testState);
      logger.logWorkflowEnd(testState);
      
      const events = logger.getEventsByType(WorkflowEventType.WORKFLOW_END);
      expect(events).toHaveLength(1);
      expect(events[0].duration).toBeGreaterThanOrEqual(0);
      
      const summary = logger.getExecutionSummary();
      expect(summary.duration).toBeGreaterThanOrEqual(0);
      
      vi.restoreAllMocks();
    });
  });

  describe('logNodeEnter and logNodeExit', () => {
    it('should track node execution with timing', () => {
      console.log('🧪 Testing node execution tracking');
      
      // Mock Date constructor for consistent timing
      const startTime = new Date('2023-01-01T00:00:00.000Z');
      const endTime = new Date('2023-01-01T00:00:00.500Z');
      
      vi.spyOn(global, 'Date')
        .mockImplementationOnce(() => startTime as any) // For node enter
        .mockImplementationOnce(() => endTime as any); // For node exit
      
      logger.logNodeEnter('processUserTurn', testState);
      
      const updatedState = { ...testState, is_processing: false };
      logger.logNodeExit('processUserTurn', updatedState, { is_processing: false });
      
      const enterEvents = logger.getEventsByType(WorkflowEventType.NODE_ENTER);
      const exitEvents = logger.getEventsByType(WorkflowEventType.NODE_EXIT);
      
      expect(enterEvents).toHaveLength(1);
      expect(exitEvents).toHaveLength(1);
      expect(exitEvents[0].duration).toBe(500);
      
      const summary = logger.getExecutionSummary();
      expect(summary.nodeExecutions.processUserTurn).toBeDefined();
      expect(summary.nodeExecutions.processUserTurn.count).toBe(1);
      expect(summary.nodeExecutions.processUserTurn.avgDuration).toBe(500);
      
      vi.restoreAllMocks();
    });

    it('should track multiple executions of same node', () => {
      console.log('🧪 Testing multiple node executions');
      // Execute node 3 times
      for (let i = 0; i < 3; i++) {
        logger.logNodeEnter('processUserTurn', testState);
        logger.logNodeExit('processUserTurn', testState);
      }
      
      const summary = logger.getExecutionSummary();
      expect(summary.nodeExecutions.processUserTurn.count).toBe(3);
    });
  });

  describe('logNodeError', () => {
    it('should log node errors', () => {
      console.log('🧪 Testing node error logging');
      const error = new Error('Test node error');
      logger.logNodeError('processUserTurn', error, testState);
      
      const errorEvents = logger.getEventsByType(WorkflowEventType.NODE_ERROR);
      expect(errorEvents).toHaveLength(1);
      expect(errorEvents[0].error).toBe(error);
      expect(errorEvents[0].metadata?.errorMessage).toBe('Test node error');
      
      const summary = logger.getExecutionSummary();
      expect(summary.errorCount).toBe(1);
    });
  });

  describe('logEdgeTransition', () => {
    it('should log edge transitions', () => {
      console.log('🧪 Testing edge transition logging');
      logger.logEdgeTransition('nodeA', 'nodeB', 'condition1');
      
      const events = logger.getEventsByType(WorkflowEventType.EDGE_TRANSITION);
      expect(events).toHaveLength(1);
      expect(events[0].edgeName).toBe('nodeA -> nodeB');
      expect(events[0].metadata?.condition).toBe('condition1');
    });
  });

  describe('logStateUpdate', () => {
    it('should log state updates', () => {
      console.log('🧪 Testing state update logging');
      const updates = { is_processing: false, current_stage: 'summary' as const };
      logger.logStateUpdate(updates, 'processUserTurn');
      
      const events = logger.getEventsByType(WorkflowEventType.STATE_UPDATE);
      expect(events).toHaveLength(1);
      expect(events[0].state).toEqual(updates);
      expect(events[0].metadata?.source).toBe('processUserTurn');
      expect(events[0].metadata?.updatedFields).toEqual(['is_processing', 'current_stage']);
      
      const summary = logger.getExecutionSummary();
      expect(summary.stateUpdateCount).toBe(1);
    });
  });

  describe('logConditionCheck', () => {
    it('should log condition checks', () => {
      console.log('🧪 Testing condition check logging');
      logger.logConditionCheck('hasUserInput', true, { messageCount: 5 });
      
      const events = logger.getEventsByType(WorkflowEventType.CONDITION_CHECK);
      expect(events).toHaveLength(1);
      expect(events[0].metadata?.condition).toBe('hasUserInput');
      expect(events[0].metadata?.result).toBe(true);
      expect(events[0].metadata?.messageCount).toBe(5);
    });
  });

  describe('logWorkflowError', () => {
    it('should log workflow errors', () => {
      console.log('🧪 Testing workflow error logging');
      const error = new Error('Workflow error');
      logger.logWorkflowError(error, { stage: 'summary' });
      
      const events = logger.getEventsByType(WorkflowEventType.WORKFLOW_ERROR);
      expect(events).toHaveLength(1);
      expect(events[0].error).toBe(error);
      expect(events[0].metadata?.context.stage).toBe('summary');
      
      const summary = logger.getExecutionSummary();
      expect(summary.errorCount).toBe(1);
    });
  });

  describe('getNodeTimeline', () => {
    it('should return correct node execution timeline', () => {
      console.log('🧪 Testing node timeline generation');
      logger.logNodeEnter('nodeA', testState);
      logger.logNodeExit('nodeA', testState);
      
      logger.logNodeEnter('nodeB', testState);
      logger.logNodeExit('nodeB', testState);
      
      const timeline = logger.getNodeTimeline();
      expect(timeline).toHaveLength(2);
      expect(timeline[0].node).toBe('nodeA');
      expect(timeline[1].node).toBe('nodeB');
    });
  });

  describe('exportLogs', () => {
    it('should export logs as JSON', () => {
      console.log('🧪 Testing log export');
      logger.logWorkflowStart(testState);
      logger.logNodeEnter('processUserTurn', testState);
      logger.logNodeExit('processUserTurn', testState);
      logger.logWorkflowEnd(testState);
      
      const exported = logger.exportLogs();
      const parsed = JSON.parse(exported);
      
      expect(parsed.context).toBeDefined();
      expect(parsed.summary).toBeDefined();
      expect(parsed.timeline).toBeDefined();
      expect(parsed.summary.workflowId).toBe('test-workflow-123');
    });
  });

  describe('debug mode', () => {
    it('should log debug information when enabled', () => {
      console.log('🧪 Testing debug mode');
      const debugLogger = new WorkflowLogger('debug-workflow', true);
      const mockDebug = vi.spyOn(console, 'log').mockImplementation(() => {});
      
      debugLogger.logWorkflowStart(testState);
      debugLogger.logNodeEnter('testNode', testState);
      debugLogger.logNodeExit('testNode', testState);
      debugLogger.logWorkflowEnd(testState);
      
      // Should print debug summary
      expect(mockDebug).toHaveBeenCalled();
      
      mockDebug.mockRestore();
    });
  });

  describe('performance tracking', () => {
    it('should calculate average node execution times', () => {
      console.log('🧪 Testing performance metrics');
      
      // Since we can't easily mock timing, let's just test the functionality
      // by calling the methods and checking the results
      logger.logNodeEnter('testNode', testState);
      logger.logNodeExit('testNode', testState);
      
      logger.logNodeEnter('testNode', testState);
      logger.logNodeExit('testNode', testState);
      
      logger.logNodeEnter('testNode', testState);
      logger.logNodeExit('testNode', testState);
      
      const summary = logger.getExecutionSummary();
      expect(summary.nodeExecutions.testNode.count).toBe(3);
      // The avgDuration will be very small but should exist
      expect(summary.nodeExecutions.testNode.avgDuration).toBeDefined();
      expect(summary.nodeExecutions.testNode.avgDuration).toBeGreaterThanOrEqual(0);
    });
  });

  describe('complex workflow scenario', () => {
    it('should handle complete workflow execution', () => {
      console.log('🧪 Testing complete workflow scenario');
      
      // Start workflow
      logger.logWorkflowStart(testState);
      
      // First node execution
      logger.logNodeEnter('processUserTurn', testState);
      logger.logStateUpdate({ is_processing: true }, 'processUserTurn');
      logger.logNodeExit('processUserTurn', { ...testState, is_processing: false });
      
      // Edge transition
      logger.logEdgeTransition('processUserTurn', 'router');
      logger.logConditionCheck('shouldContinue', true);
      
      // Second node execution
      logger.logNodeEnter('generateSummary', testState);
      logger.logStateUpdate({ current_stage: 'summary' as const }, 'generateSummary');
      logger.logNodeExit('generateSummary', { ...testState, current_stage: 'summary' as const });
      
      // End workflow
      logger.logWorkflowEnd({ ...testState, current_stage: 'summary' as const });
      
      const summary = logger.getExecutionSummary();
      expect(summary.eventCount).toBeGreaterThan(5);
      expect(summary.stateUpdateCount).toBe(2);
      expect(Object.keys(summary.nodeExecutions)).toHaveLength(2);
      
      const timeline = logger.getNodeTimeline();
      expect(timeline).toHaveLength(2);
      expect(timeline[0].node).toBe('processUserTurn');
      expect(timeline[1].node).toBe('generateSummary');
    });
  });
});

================
File: electron/main/langgraph/workflowLogger.ts
================
/**
 * LangGraph Workflow Logger
 * 
 * This module provides comprehensive logging and debugging capabilities
 * for LangGraph workflow execution. It tracks node execution, state changes,
 * performance metrics, and provides detailed debugging information.
 * 
 * Key Features:
 * - Node execution tracking with timing
 * - State change logging
 * - Performance metrics collection
 * - Debug mode with verbose output
 * - Error tracking and analysis
 * - Workflow visualization helpers
 */

import { AppState } from '../../../src/types/AppState';
import { logger } from '../../../src/utils/logger';
import { stateHistory, stateMonitor } from './stateUtils';

/**
 * Workflow execution event types
 */
export enum WorkflowEventType {
  WORKFLOW_START = 'WORKFLOW_START',
  WORKFLOW_END = 'WORKFLOW_END',
  NODE_ENTER = 'NODE_ENTER',
  NODE_EXIT = 'NODE_EXIT',
  NODE_ERROR = 'NODE_ERROR',
  EDGE_TRANSITION = 'EDGE_TRANSITION',
  STATE_UPDATE = 'STATE_UPDATE',
  CONDITION_CHECK = 'CONDITION_CHECK',
  WORKFLOW_ERROR = 'WORKFLOW_ERROR'
}

/**
 * Workflow execution event
 */
export interface WorkflowEvent {
  type: WorkflowEventType;
  timestamp: Date;
  nodeName?: string;
  edgeName?: string;
  state?: Partial<AppState>;
  error?: Error;
  metadata?: Record<string, any>;
  duration?: number;
}

/**
 * Workflow execution context
 */
export interface WorkflowContext {
  workflowId: string;
  startTime: Date;
  endTime?: Date;
  events: WorkflowEvent[];
  errors: Error[];
  performance: {
    totalDuration?: number;
    nodeExecutions: Map<string, number[]>;
    stateUpdates: number;
  };
}

/**
 * Workflow logger class
 */
export class WorkflowLogger {
  private context: WorkflowContext;
  private debugMode: boolean;
  private currentNode?: string;
  private nodeStartTime?: Date;

  constructor(workflowId: string, debugMode: boolean = false) {
    this.context = {
      workflowId,
      startTime: new Date(),
      events: [],
      errors: [],
      performance: {
        nodeExecutions: new Map(),
        stateUpdates: 0
      }
    };
    this.debugMode = debugMode;
    
    logger.info('🚀 Workflow Logger: Initialized', {
      workflowId,
      debugMode,
      startTime: this.context.startTime
    });
  }

  /**
   * Log workflow start
   */
  logWorkflowStart(initialState: AppState): void {
    const event: WorkflowEvent = {
      type: WorkflowEventType.WORKFLOW_START,
      timestamp: new Date(),
      state: initialState,
      metadata: {
        idea_id: initialState.idea_id,
        stage: initialState.current_stage,
        messageCount: initialState.messages.length
      }
    };

    this.addEvent(event);
    
    if (this.debugMode) {
      logger.debug('🎬 Workflow Started', {
        workflowId: this.context.workflowId,
        initialStage: initialState.current_stage,
        lastAction: initialState.last_user_action
      });
    }
  }

  /**
   * Log workflow end
   */
  logWorkflowEnd(finalState: AppState): void {
    this.context.endTime = new Date();
    this.context.performance.totalDuration = 
      this.context.endTime.getTime() - this.context.startTime.getTime();

    const event: WorkflowEvent = {
      type: WorkflowEventType.WORKFLOW_END,
      timestamp: this.context.endTime,
      state: finalState,
      duration: this.context.performance.totalDuration,
      metadata: {
        totalEvents: this.context.events.length,
        totalErrors: this.context.errors.length,
        finalStage: finalState.current_stage
      }
    };

    this.addEvent(event);
    
    logger.info('🏁 Workflow Completed', {
      workflowId: this.context.workflowId,
      duration: this.context.performance.totalDuration,
      eventsCount: this.context.events.length,
      errorsCount: this.context.errors.length
    });

    if (this.debugMode) {
      this.printDebugSummary();
    }
  }

  /**
   * Log node entry
   */
  logNodeEnter(nodeName: string, state: AppState): void {
    this.currentNode = nodeName;
    this.nodeStartTime = new Date();

    const event: WorkflowEvent = {
      type: WorkflowEventType.NODE_ENTER,
      timestamp: this.nodeStartTime,
      nodeName,
      state,
      metadata: {
        stage: state.current_stage,
        isProcessing: state.is_processing,
        hasError: !!state.error
      }
    };

    this.addEvent(event);
    
    // Track state history
    stateHistory.addSnapshot(state, nodeName, { event: 'enter' });
    
    if (this.debugMode) {
      logger.debug(`➡️  Entering Node: ${nodeName}`, {
        stage: state.current_stage,
        lastAction: state.last_user_action,
        messageCount: state.messages.length
      });
    }
  }

  /**
   * Log node exit
   */
  logNodeExit(nodeName: string, state: AppState, updates?: Partial<AppState>): void {
    const exitTime = new Date();
    const duration = this.nodeStartTime 
      ? exitTime.getTime() - this.nodeStartTime.getTime() 
      : 0;

    const event: WorkflowEvent = {
      type: WorkflowEventType.NODE_EXIT,
      timestamp: exitTime,
      nodeName,
      state,
      duration,
      metadata: {
        updates,
        stage: state.current_stage,
        isProcessing: state.is_processing
      }
    };

    this.addEvent(event);
    
    // Track performance
    this.trackNodeExecution(nodeName, duration);
    
    // Track state history
    stateHistory.addSnapshot(state, nodeName, { event: 'exit', duration });
    
    if (this.debugMode) {
      logger.debug(`⬅️  Exiting Node: ${nodeName}`, {
        duration,
        hasUpdates: !!updates,
        updatedFields: updates ? Object.keys(updates) : []
      });
    }

    this.currentNode = undefined;
    this.nodeStartTime = undefined;
  }

  /**
   * Log node error
   */
  logNodeError(nodeName: string, error: Error, state: AppState): void {
    const event: WorkflowEvent = {
      type: WorkflowEventType.NODE_ERROR,
      timestamp: new Date(),
      nodeName,
      error,
      state,
      metadata: {
        errorMessage: error.message,
        errorStack: error.stack,
        stage: state.current_stage
      }
    };

    this.addEvent(event);
    this.context.errors.push(error);
    
    logger.error(`❌ Node Error: ${nodeName}`, {
      error: error.message,
      stack: error.stack,
      stage: state.current_stage,
      workflowId: this.context.workflowId
    });
  }

  /**
   * Log edge transition
   */
  logEdgeTransition(fromNode: string, toNode: string, condition?: string): void {
    const event: WorkflowEvent = {
      type: WorkflowEventType.EDGE_TRANSITION,
      timestamp: new Date(),
      edgeName: `${fromNode} -> ${toNode}`,
      metadata: {
        fromNode,
        toNode,
        condition
      }
    };

    this.addEvent(event);
    
    if (this.debugMode) {
      logger.debug(`🔀 Edge Transition`, {
        from: fromNode,
        to: toNode,
        condition: condition || 'direct'
      });
    }
  }

  /**
   * Log state update
   */
  logStateUpdate(updates: Partial<AppState>, source: string): void {
    this.context.performance.stateUpdates++;

    const event: WorkflowEvent = {
      type: WorkflowEventType.STATE_UPDATE,
      timestamp: new Date(),
      state: updates,
      metadata: {
        source,
        updatedFields: Object.keys(updates),
        updateCount: this.context.performance.stateUpdates
      }
    };

    this.addEvent(event);
    
    if (this.debugMode) {
      logger.debug('📝 State Update', {
        source,
        fields: Object.keys(updates),
        values: updates
      });
    }
  }

  /**
   * Log condition check
   */
  logConditionCheck(condition: string, result: boolean, metadata?: any): void {
    const event: WorkflowEvent = {
      type: WorkflowEventType.CONDITION_CHECK,
      timestamp: new Date(),
      metadata: {
        condition,
        result,
        ...metadata
      }
    };

    this.addEvent(event);
    
    if (this.debugMode) {
      logger.debug('❓ Condition Check', {
        condition,
        result,
        metadata
      });
    }
  }

  /**
   * Log workflow error
   */
  logWorkflowError(error: Error, context?: any): void {
    const event: WorkflowEvent = {
      type: WorkflowEventType.WORKFLOW_ERROR,
      timestamp: new Date(),
      error,
      metadata: {
        errorMessage: error.message,
        errorStack: error.stack,
        context
      }
    };

    this.addEvent(event);
    this.context.errors.push(error);
    
    logger.error('💥 Workflow Error', {
      error: error.message,
      stack: error.stack,
      workflowId: this.context.workflowId,
      context
    });
  }

  /**
   * Get execution summary
   */
  getExecutionSummary(): {
    workflowId: string;
    duration: number;
    eventCount: number;
    errorCount: number;
    nodeExecutions: Record<string, { count: number; avgDuration: number }>;
    stateUpdateCount: number;
  } {
    const nodeStats: Record<string, { count: number; avgDuration: number }> = {};
    
    for (const [node, durations] of this.context.performance.nodeExecutions) {
      const avg = durations.reduce((a, b) => a + b, 0) / durations.length;
      nodeStats[node] = {
        count: durations.length,
        avgDuration: Math.round(avg)
      };
    }

    return {
      workflowId: this.context.workflowId,
      duration: this.context.performance.totalDuration || 0,
      eventCount: this.context.events.length,
      errorCount: this.context.errors.length,
      nodeExecutions: nodeStats,
      stateUpdateCount: this.context.performance.stateUpdates
    };
  }

  /**
   * Get events by type
   */
  getEventsByType(type: WorkflowEventType): WorkflowEvent[] {
    return this.context.events.filter(event => event.type === type);
  }

  /**
   * Get node execution timeline
   */
  getNodeTimeline(): Array<{
    node: string;
    startTime: Date;
    endTime: Date;
    duration: number;
  }> {
    const timeline: Array<{
      node: string;
      startTime: Date;
      endTime: Date;
      duration: number;
    }> = [];

    let currentNodeStart: { node: string; time: Date } | null = null;

    for (const event of this.context.events) {
      if (event.type === WorkflowEventType.NODE_ENTER && event.nodeName) {
        currentNodeStart = { node: event.nodeName, time: event.timestamp };
      } else if (event.type === WorkflowEventType.NODE_EXIT && event.nodeName && currentNodeStart) {
        timeline.push({
          node: event.nodeName,
          startTime: currentNodeStart.time,
          endTime: event.timestamp,
          duration: event.duration || 0
        });
        currentNodeStart = null;
      }
    }

    return timeline;
  }

  /**
   * Export logs for analysis
   */
  exportLogs(): string {
    return JSON.stringify({
      context: this.context,
      summary: this.getExecutionSummary(),
      timeline: this.getNodeTimeline()
    }, null, 2);
  }

  /**
   * Private: Add event to log
   */
  private addEvent(event: WorkflowEvent): void {
    this.context.events.push(event);
    
    // Record metric
    stateMonitor.recordMetric('workflow_events_total', this.context.events.length);
  }

  /**
   * Private: Track node execution
   */
  private trackNodeExecution(nodeName: string, duration: number): void {
    if (!this.context.performance.nodeExecutions.has(nodeName)) {
      this.context.performance.nodeExecutions.set(nodeName, []);
    }
    
    this.context.performance.nodeExecutions.get(nodeName)!.push(duration);
    
    // Record metric
    stateMonitor.recordMetric(`node_${nodeName}_duration_ms`, duration);
  }

  /**
   * Private: Print debug summary
   */
  private printDebugSummary(): void {
    const summary = this.getExecutionSummary();
    
    console.log('\n🔍 === WORKFLOW DEBUG SUMMARY ===');
    console.log(`📋 Workflow ID: ${summary.workflowId}`);
    console.log(`⏱️  Total Duration: ${summary.duration}ms`);
    console.log(`📊 Total Events: ${summary.eventCount}`);
    console.log(`❌ Total Errors: ${summary.errorCount}`);
    console.log(`📝 State Updates: ${summary.stateUpdateCount}`);
    
    console.log('\n📈 Node Execution Stats:');
    for (const [node, stats] of Object.entries(summary.nodeExecutions)) {
      console.log(`  - ${node}: ${stats.count} executions, avg ${stats.avgDuration}ms`);
    }
    
    if (this.context.errors.length > 0) {
      console.log('\n❌ Errors:');
      this.context.errors.forEach((error, index) => {
        console.log(`  ${index + 1}. ${error.message}`);
      });
    }
    
    console.log('\n🔗 Node Timeline:');
    const timeline = this.getNodeTimeline();
    timeline.forEach(entry => {
      console.log(`  ${entry.node}: ${entry.duration}ms`);
    });
    
    console.log('================================\n');
  }
}

/**
 * Create a new workflow logger instance
 */
export function createWorkflowLogger(workflowId?: string, debugMode?: boolean): WorkflowLogger {
  const id = workflowId || `workflow_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  return new WorkflowLogger(id, debugMode);
}

================
File: electron/main/audio-handler.ts
================
/**
 * Audio File Handler for Electron Main Process
 * 
 * This module manages audio files on the desktop filesystem for FlowGenius.
 * It handles saving audio blobs from the renderer process, format conversion,
 * temporary file management, and cleanup operations.
 * 
 * Key Features:
 * - Save audio blobs to desktop filesystem
 * - Generate unique temporary file paths
 * - Audio format conversion for Whisper compatibility
 * - Automatic cleanup of temporary files
 * - File validation and error handling
 * - Integration with OS audio codecs
 */

import { app } from 'electron';
import * as fs from 'fs/promises';
import * as path from 'path';
import * as os from 'os';
import { logger } from '../../src/utils/logger';

/**
 * Audio file operation result interface
 */
export interface AudioFileResult {
  success: boolean;
  filePath?: string;
  error?: string;
  metadata?: {
    size: number;
    format: string;
    duration?: number;
  };
}

/**
 * Audio conversion options
 */
export interface AudioConversionOptions {
  /** Target format (wav, mp3, etc.) */
  format?: 'wav' | 'mp3' | 'webm';
  /** Target sample rate in Hz */
  sampleRate?: number;
  /** Target channel count */
  channels?: number;
  /** Quality for lossy formats (0-1) */
  quality?: number;
  /** Whether to overwrite existing files */
  overwrite?: boolean;
}

/**
 * Audio file manager class
 */
export class AudioFileManager {
  private tempDir: string;
  private activeFiles: Set<string> = new Set();
  private cleanupTimer: NodeJS.Timeout | null = null;

  constructor() {
    // Create temp directory for audio files
    this.tempDir = path.join(os.tmpdir(), 'flowgenius-audio');
    this.initializeTempDirectory();
    this.setupCleanupTimer();
  }

  /**
   * Initialize temporary directory for audio files
   */
  private async initializeTempDirectory(): Promise<void> {
    try {
      await fs.mkdir(this.tempDir, { recursive: true });
      logger.info('✅ Audio temp directory initialized', { path: this.tempDir });
    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      logger.error('❌ Failed to initialize audio temp directory', { error: errorMsg });
      throw new Error(`Failed to create audio temp directory: ${errorMsg}`);
    }
  }

  /**
   * Set up automatic cleanup timer for old temporary files
   */
  private setupCleanupTimer(): void {
    // Clean up temp files every 10 minutes
    this.cleanupTimer = setInterval(() => {
      this.cleanupOldFiles().catch(error => {
        logger.error('❌ Automatic cleanup failed', { error: error.message });
      });
    }, 10 * 60 * 1000); // 10 minutes

    logger.debug('🕒 Audio cleanup timer started');
  }

  /**
   * Generate unique temporary file path
   * 
   * @param extension - File extension (e.g., 'wav', 'mp3')
   * @param prefix - Optional filename prefix
   * @returns Unique file path
   */
  private generateTempPath(extension: string, prefix: string = 'audio'): string {
    const timestamp = Date.now();
    const random = Math.random().toString(36).substring(2, 8);
    const filename = `${prefix}_${timestamp}_${random}.${extension}`;
    return path.join(this.tempDir, filename);
  }

  /**
   * Detect file format from buffer
   * 
   * @param buffer - Audio file buffer
   * @returns Detected format or 'unknown'
   */
  private detectFormatFromBuffer(buffer: Buffer): string {
    // Check file headers/magic numbers
    if (buffer.length < 4) return 'unknown';

    // WAV format check
    if (buffer.subarray(0, 4).toString() === 'RIFF' && 
        buffer.subarray(8, 12).toString() === 'WAVE') {
      return 'wav';
    }

    // MP3 format check
    if (buffer[0] === 0xFF && buffer[1] && (buffer[1] & 0xE0) === 0xE0) {
      return 'mp3';
    }

    // WebM format check
    if (buffer.subarray(0, 4).equals(Buffer.from([0x1A, 0x45, 0xDF, 0xA3]))) {
      return 'webm';
    }

    // MP4/M4A format check
    if (buffer.subarray(4, 8).toString() === 'ftyp') {
      return 'mp4';
    }

    // OGG format check
    if (buffer.subarray(0, 4).toString() === 'OggS') {
      return 'ogg';
    }

    logger.warn('⚠️ Unknown audio format detected', { 
      header: buffer.subarray(0, 8).toString('hex') 
    });
    return 'unknown';
  }

  /**
   * Save audio blob data to filesystem
   * 
   * @param audioData - Audio data buffer from renderer process
   * @param originalName - Original filename (optional)
   * @param mimeType - MIME type of the audio (optional)
   * @returns Promise resolving to file path and metadata
   */
  async saveAudioFile(
    audioData: Buffer,
    originalName?: string,
    mimeType?: string
  ): Promise<AudioFileResult> {
    const startTime = Date.now();
    
    try {
      logger.info('💾 Saving audio file to filesystem', {
        dataSize: audioData.length,
        originalName,
        mimeType
      });

      // Validate input
      if (!audioData || audioData.length === 0) {
        throw new Error('Audio data is empty');
      }

      // Detect format from buffer and MIME type
      const detectedFormat = this.detectFormatFromBuffer(audioData);
      const mimeTypeParts = mimeType?.split('/');
      const formatFromMime = mimeTypeParts?.[1]?.split(';')[0] || null;
      const finalFormat = formatFromMime || detectedFormat || 'bin';

      // Generate file path
      const baseName = originalName ? path.parse(originalName).name : 'recording';
      const filePath = this.generateTempPath(finalFormat, baseName);

      // Write file to filesystem
      await fs.writeFile(filePath, audioData);
      
      // Track active file
      this.activeFiles.add(filePath);

      // Get file stats
      const stats = await fs.stat(filePath);

      const result: AudioFileResult = {
        success: true,
        filePath,
        metadata: {
          size: stats.size,
          format: finalFormat
        }
      };

      const saveTime = Date.now() - startTime;
      logger.info('✅ Audio file saved successfully', {
        filePath,
        size: stats.size,
        format: finalFormat,
        saveTime
      });

      return result;

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      const saveTime = Date.now() - startTime;
      
      logger.error('❌ Failed to save audio file', {
        error: errorMsg,
        dataSize: audioData?.length || 0,
        saveTime
      });

      return {
        success: false,
        error: errorMsg
      };
    }
  }

  /**
   * Convert audio file to optimal format for Whisper API
   * 
   * @param inputPath - Path to input audio file
   * @param options - Conversion options
   * @returns Promise resolving to converted file path
   */
  async convertAudioFile(
    inputPath: string,
    options: AudioConversionOptions = {}
  ): Promise<AudioFileResult> {
    const startTime = Date.now();

    try {
      logger.info('🔄 Converting audio file', { inputPath, options });

      // Validate input file
      const inputStats = await fs.stat(inputPath);
      if (!inputStats.isFile()) {
        throw new Error('Input path is not a file');
      }

      // Set default conversion options
      const convertOptions: Required<AudioConversionOptions> = {
        format: 'wav',
        sampleRate: 16000,
        channels: 1,
        quality: 0.8,
        overwrite: false,
        ...options
      };

      // Generate output path
      const inputExt = path.extname(inputPath);
      const baseName = path.basename(inputPath, inputExt);
      const outputPath = this.generateTempPath(
        convertOptions.format, 
        `${baseName}_converted`
      );

      // For now, we'll do a simple copy operation
      // In a full implementation, you would use audio processing libraries
      // like FFmpeg or native OS audio APIs for actual conversion
      await this.performAudioConversion(inputPath, outputPath, convertOptions);

      // Track active file
      this.activeFiles.add(outputPath);

      // Get output file stats
      const outputStats = await fs.stat(outputPath);

      const result: AudioFileResult = {
        success: true,
        filePath: outputPath,
        metadata: {
          size: outputStats.size,
          format: convertOptions.format
        }
      };

      const conversionTime = Date.now() - startTime;
      logger.info('✅ Audio conversion completed', {
        inputPath,
        outputPath,
        inputSize: inputStats.size,
        outputSize: outputStats.size,
        conversionTime
      });

      return result;

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      const conversionTime = Date.now() - startTime;
      
      logger.error('❌ Audio conversion failed', {
        inputPath,
        error: errorMsg,
        conversionTime
      });

      return {
        success: false,
        error: errorMsg
      };
    }
  }

  /**
   * Perform actual audio conversion (placeholder implementation)
   * 
   * @param inputPath - Input file path
   * @param outputPath - Output file path  
   * @param options - Conversion options
   */
  private async performAudioConversion(
    inputPath: string,
    outputPath: string,
    options: AudioConversionOptions
  ): Promise<void> {
    // This is a placeholder implementation
    // In a production environment, you would integrate with:
    // 1. FFmpeg for cross-platform audio conversion
    // 2. Native OS APIs (AVFoundation on macOS, Media Foundation on Windows)
    // 3. Or dedicated audio processing libraries

    logger.warn('⚠️ Using placeholder audio conversion (copy operation)', {
      inputPath,
      outputPath,
      options
    });

    // For now, just copy the file
    // This maintains the file structure for testing
    await fs.copyFile(inputPath, outputPath);

    // In a real implementation, you would:
    // - Load the audio file
    // - Decode to PCM
    // - Resample to target sample rate
    // - Convert channels (stereo to mono)
    // - Encode to target format
    // - Save to output path
  }

  /**
   * Get audio file information
   * 
   * @param filePath - Path to audio file
   * @returns Promise resolving to file metadata
   */
  async getAudioFileInfo(filePath: string): Promise<AudioFileResult> {
    try {
      logger.debug('📊 Getting audio file info', { filePath });

      const stats = await fs.stat(filePath);
      if (!stats.isFile()) {
        throw new Error('Path is not a file');
      }

      // Read file header to detect format
      const fileHandle = await fs.open(filePath, 'r');
      const buffer = Buffer.alloc(64); // Read first 64 bytes for format detection
      await fileHandle.read(buffer, 0, 64, 0);
      await fileHandle.close();

      const format = this.detectFormatFromBuffer(buffer);

      const result: AudioFileResult = {
        success: true,
        filePath,
        metadata: {
          size: stats.size,
          format
        }
      };

      logger.info('✅ Audio file info retrieved', result);
      return result;

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      
      logger.error('❌ Failed to get audio file info', {
        filePath,
        error: errorMsg
      });

      return {
        success: false,
        error: errorMsg
      };
    }
  }

  /**
   * Delete audio file from filesystem
   * 
   * @param filePath - Path to file to delete
   * @returns Promise resolving to success status
   */
  async deleteAudioFile(filePath: string): Promise<AudioFileResult> {
    try {
      logger.debug('🗑️ Deleting audio file', { filePath });

      await fs.unlink(filePath);
      this.activeFiles.delete(filePath);

      logger.info('✅ Audio file deleted successfully', { filePath });
      
      return { success: true };

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      
      logger.error('❌ Failed to delete audio file', {
        filePath,
        error: errorMsg
      });

      return {
        success: false,
        error: errorMsg
      };
    }
  }

  /**
   * Clean up old temporary files
   * 
   * @param maxAge - Maximum age in milliseconds (default: 1 hour)
   * @returns Promise resolving to cleanup statistics
   */
  async cleanupOldFiles(maxAge: number = 60 * 60 * 1000): Promise<{
    deletedCount: number;
    errors: string[];
  }> {
    const startTime = Date.now();
    let deletedCount = 0;
    const errors: string[] = [];

    try {
      logger.debug('🧹 Starting audio file cleanup', { maxAge, tempDir: this.tempDir });

      const files = await fs.readdir(this.tempDir);
      const cutoffTime = Date.now() - maxAge;

      for (const file of files) {
        try {
          const filePath = path.join(this.tempDir, file);
          const stats = await fs.stat(filePath);

          if (stats.mtime.getTime() < cutoffTime) {
            await fs.unlink(filePath);
            this.activeFiles.delete(filePath);
            deletedCount++;
            logger.debug('🗑️ Deleted old audio file', { filePath, age: Date.now() - stats.mtime.getTime() });
          }
        } catch (error) {
          const errorMsg = error instanceof Error ? error.message : String(error);
          errors.push(`Failed to delete ${file}: ${errorMsg}`);
          logger.warn('⚠️ Failed to delete old file', { file, error: errorMsg });
        }
      }

      const cleanupTime = Date.now() - startTime;
      logger.info('✅ Audio file cleanup completed', {
        deletedCount,
        errors: errors.length,
        cleanupTime
      });

      return { deletedCount, errors };

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      logger.error('❌ Audio cleanup failed', { error: errorMsg });
      
      return {
        deletedCount,
        errors: [errorMsg]
      };
    }
  }

  /**
   * Get list of active audio files
   * 
   * @returns Array of active file paths
   */
  getActiveFiles(): string[] {
    return Array.from(this.activeFiles);
  }

  /**
   * Get temporary directory path
   * 
   * @returns Temporary directory path
   */
  getTempDirectory(): string {
    return this.tempDir;
  }

  /**
   * Clean up all resources and stop timers
   */
  async cleanup(): Promise<void> {
    logger.info('🧹 Cleaning up AudioFileManager');

    // Clear cleanup timer
    if (this.cleanupTimer) {
      clearInterval(this.cleanupTimer);
      this.cleanupTimer = null;
    }

    // Delete all active files
    const deletePromises = Array.from(this.activeFiles).map(async (filePath) => {
      try {
        await fs.unlink(filePath);
        logger.debug('🗑️ Deleted active file during cleanup', { filePath });
      } catch (error) {
        logger.warn('⚠️ Failed to delete file during cleanup', { 
          filePath, 
          error: error instanceof Error ? error.message : String(error) 
        });
      }
    });

    await Promise.all(deletePromises);
    this.activeFiles.clear();

    logger.info('✅ AudioFileManager cleanup completed');
  }
}

// Global instance for the application
let audioFileManager: AudioFileManager | null = null;

/**
 * Get or create the global audio file manager instance
 * 
 * @returns Global AudioFileManager instance
 */
export function getAudioFileManager(): AudioFileManager {
  if (!audioFileManager) {
    audioFileManager = new AudioFileManager();
    
    // Clean up on app quit
    app.on('before-quit', async () => {
      if (audioFileManager) {
        await audioFileManager.cleanup();
      }
    });
  }
  
  return audioFileManager;
}

/**
 * Initialize audio file management system
 * 
 * @returns Promise resolving when initialization is complete
 */
export async function initializeAudioFileManager(): Promise<void> {
  logger.info('🎵 Initializing audio file management system');
  
  try {
    const manager = getAudioFileManager();
    logger.info('✅ Audio file management system initialized', {
      tempDir: manager.getTempDirectory()
    });
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error);
    logger.error('❌ Failed to initialize audio file management', { error: errorMsg });
    throw error;
  }
}

================
File: electron/main/audio-ipc-handlers.ts
================
/**
 * Audio IPC Handlers for Electron Main Process
 * 
 * This module sets up IPC handlers for audio file operations between
 * the renderer process and the main process AudioFileManager.
 * 
 * Key Features:
 * - IPC handlers for all audio file operations
 * - Error handling and validation
 * - Performance monitoring
 * - Resource cleanup
 */

import { ipcMain } from 'electron';
import { getAudioFileManager, initializeAudioFileManager } from './audio-handler';
import { logger } from '../../src/utils/logger';

/**
 * Initialize all audio IPC handlers
 * 
 * This function sets up all IPC handlers for audio operations.
 * Should be called once during app initialization.
 */
export function initializeAudioHandlers(): void {
  console.log('🔌 Initializing Audio IPC handlers');

  /**
   * Save audio blob data to filesystem
   */
  ipcMain.handle('audio:save-file', async (event, audioData: Buffer, originalName?: string, mimeType?: string) => {
    const startTime = Date.now();
    
    try {
      console.log('📨 IPC: Saving audio file', {
        dataSize: audioData?.length || 0,
        originalName,
        mimeType
      });

      // Validate input
      if (!audioData || !Buffer.isBuffer(audioData)) {
        throw new Error('Invalid audio data: must be a Buffer');
      }

      if (audioData.length === 0) {
        throw new Error('Audio data is empty');
      }

      const audioManager = getAudioFileManager();
      const result = await audioManager.saveAudioFile(audioData, originalName, mimeType);
      
      const duration = Date.now() - startTime;
      console.log('✅ IPC: Audio file saved', {
        success: result.success,
        filePath: result.filePath,
        duration
      });

      return result;

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      const duration = Date.now() - startTime;
      
      console.error('❌ IPC: Audio save failed', {
        error: errorMessage,
        duration
      });

      return { 
        success: false, 
        error: errorMessage 
      };
    }
  });

  /**
   * Convert audio file to optimal format
   */
  ipcMain.handle('audio:convert-file', async (event, inputPath: string, options?: any) => {
    const startTime = Date.now();
    
    try {
      console.log('📨 IPC: Converting audio file', { inputPath, options });

      if (!inputPath || typeof inputPath !== 'string') {
        throw new Error('Invalid input path');
      }

      const audioManager = getAudioFileManager();
      const result = await audioManager.convertAudioFile(inputPath, options);
      
      const duration = Date.now() - startTime;
      console.log('✅ IPC: Audio conversion completed', {
        success: result.success,
        inputPath,
        outputPath: result.filePath,
        duration
      });

      return result;

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      const duration = Date.now() - startTime;
      
      console.error('❌ IPC: Audio conversion failed', {
        inputPath,
        error: errorMessage,
        duration
      });

      return { 
        success: false, 
        error: errorMessage 
      };
    }
  });

  /**
   * Get audio file information
   */
  ipcMain.handle('audio:get-file-info', async (event, filePath: string) => {
    try {
      console.log('📨 IPC: Getting audio file info', { filePath });

      if (!filePath || typeof filePath !== 'string') {
        throw new Error('Invalid file path');
      }

      const audioManager = getAudioFileManager();
      const result = await audioManager.getAudioFileInfo(filePath);
      
      console.log('✅ IPC: Audio file info retrieved', {
        success: result.success,
        filePath
      });

      return result;

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      
      console.error('❌ IPC: Get file info failed', {
        filePath,
        error: errorMessage
      });

      return { 
        success: false, 
        error: errorMessage 
      };
    }
  });

  /**
   * Delete audio file from filesystem
   */
  ipcMain.handle('audio:delete-file', async (event, filePath: string) => {
    try {
      console.log('📨 IPC: Deleting audio file', { filePath });

      if (!filePath || typeof filePath !== 'string') {
        throw new Error('Invalid file path');
      }

      const audioManager = getAudioFileManager();
      const result = await audioManager.deleteAudioFile(filePath);
      
      console.log('✅ IPC: Audio file deleted', {
        success: result.success,
        filePath
      });

      return result;

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      
      console.error('❌ IPC: Delete file failed', {
        filePath,
        error: errorMessage
      });

      return { 
        success: false, 
        error: errorMessage 
      };
    }
  });

  /**
   * Clean up old temporary files
   */
  ipcMain.handle('audio:cleanup-old-files', async (event, maxAge?: number) => {
    try {
      console.log('📨 IPC: Cleaning up old audio files', { maxAge });

      const audioManager = getAudioFileManager();
      const result = await audioManager.cleanupOldFiles(maxAge);
      
      console.log('✅ IPC: Audio cleanup completed', {
        deletedCount: result.deletedCount,
        errors: result.errors.length
      });

      return {
        success: true,
        deletedCount: result.deletedCount,
        errors: result.errors
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      
      console.error('❌ IPC: Audio cleanup failed', {
        error: errorMessage
      });

      return { 
        success: false, 
        error: errorMessage 
      };
    }
  });

  /**
   * Get temporary directory path
   */
  ipcMain.handle('audio:get-temp-directory', async (event) => {
    try {
      console.log('📨 IPC: Getting temp directory');

      const audioManager = getAudioFileManager();
      const tempDir = audioManager.getTempDirectory();
      
      console.log('✅ IPC: Temp directory retrieved', { tempDir });
      return tempDir;

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      
      console.error('❌ IPC: Get temp directory failed', {
        error: errorMessage
      });

      throw error; // Let the renderer handle this error
    }
  });

  /**
   * Get list of active audio files
   */
  ipcMain.handle('audio:get-active-files', async (event) => {
    try {
      console.log('📨 IPC: Getting active audio files');

      const audioManager = getAudioFileManager();
      const activeFiles = audioManager.getActiveFiles();
      
      console.log('✅ IPC: Active files retrieved', { count: activeFiles.length });
      return {
        success: true,
        files: activeFiles
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      
      console.error('❌ IPC: Get active files failed', {
        error: errorMessage
      });

      return { 
        success: false, 
        error: errorMessage 
      };
    }
  });

  console.log('✅ Audio IPC handlers initialized');
  logger.info('Audio IPC handlers initialized', {
    handlerCount: 6
  });
}

/**
 * Initialize audio file management system
 * 
 * This function initializes the audio file manager and IPC handlers.
 * Should be called during app startup.
 */
export async function initializeAudioSystem(): Promise<void> {
  console.log('🎵 Initializing audio system');
  
  try {
    // Initialize the audio file manager
    await initializeAudioFileManager();
    
    // Set up IPC handlers
    initializeAudioHandlers();
    
    console.log('✅ Audio system initialized successfully');
    logger.info('Audio system initialized');
    
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    console.error('❌ Failed to initialize audio system', { error: errorMessage });
    logger.error('Audio system initialization failed', { error: errorMessage });
    throw error;
  }
}

/**
 * Cleanup audio resources and handlers
 * 
 * Should be called when the app is closing.
 */
export function cleanupAudioHandlers(): void {
  console.log('🧹 Cleaning up audio handlers');
  
  // Remove all handlers
  ipcMain.removeHandler('audio:save-file');
  ipcMain.removeHandler('audio:convert-file');
  ipcMain.removeHandler('audio:get-file-info');
  ipcMain.removeHandler('audio:delete-file');
  ipcMain.removeHandler('audio:cleanup-old-files');
  ipcMain.removeHandler('audio:get-temp-directory');
  ipcMain.removeHandler('audio:get-active-files');
  
  console.log('✅ Audio handlers cleaned up');
  logger.info('Audio handlers cleaned up');
}

================
File: electron/main/langgraph-handler.ts
================
/**
 * LangGraph IPC Handler for Electron Main Process
 * 
 * This module handles all IPC communication between the renderer process
 * and the LangGraph workflow engine running in the main process.
 * 
 * Key Features:
 * - IPC handlers for workflow execution
 * - State management and session handling
 * - Error handling and logging
 * - Performance monitoring
 */

import { ipcMain } from 'electron';
import { 
  executeWorkflow, 
  createWorkflowSession,
  validateWorkflowState,
  createFlowGeniusWorkflow
} from './langgraph';
import { AppState } from '../../src/types/AppState';
import { logger } from '../../src/utils/logger';
import { createWorkflowLogger, WorkflowLogger } from './langgraph/workflowLogger';

// Store workflow loggers for each session
const workflowLoggers = new Map<string, WorkflowLogger>();

/**
 * Initialize LangGraph IPC handlers
 * 
 * This function sets up all IPC handlers for LangGraph operations.
 * Should be called once during app initialization.
 */
export function initializeLangGraphHandlers(): void {
  console.log('🔌 Initializing LangGraph IPC handlers');

  /**
   * Execute workflow with given state
   */
  ipcMain.handle('langgraph:execute', async (event, state: AppState) => {
    const startTime = Date.now();
    
    try {
      console.log('📨 IPC: Executing LangGraph workflow', {
        ideaId: state.idea_id,
        stage: state.current_stage,
        action: state.last_user_action
      });

      // Validate state
      const validation = validateWorkflowState(state);
      if (!validation.isValid) {
        throw new Error(`Invalid state: ${validation.issues.join(', ')}`);
      }

      // Get or create workflow logger for this session
      let workflowLogger = workflowLoggers.get(state.idea_id);
      if (!workflowLogger) {
        workflowLogger = createWorkflowLogger(state.idea_id, true);
        workflowLoggers.set(state.idea_id, workflowLogger);
      }

      // Execute workflow
      const result = await executeWorkflow(state, workflowLogger);
      
      const duration = Date.now() - startTime;
      console.log('✅ IPC: Workflow execution completed', {
        ideaId: result.idea_id,
        duration,
        hasError: !!result.error
      });

      return { success: true, data: result, duration };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      const duration = Date.now() - startTime;
      
      console.error('❌ IPC: Workflow execution failed', {
        error: errorMessage,
        duration
      });

      logger.error('LangGraph IPC execution failed', {
        error: errorMessage,
        idea_id: state.idea_id,
        duration
      });

      return { 
        success: false, 
        error: errorMessage,
        duration 
      };
    }
  });

  /**
   * Create new workflow session
   */
  ipcMain.handle('langgraph:createSession', async (event, ideaId: string, userId?: string) => {
    try {
      console.log('📨 IPC: Creating new workflow session', { ideaId, userId });

      const session = createWorkflowSession(ideaId, userId);
      
      // Create workflow logger for new session
      const workflowLogger = createWorkflowLogger(ideaId, true);
      workflowLoggers.set(ideaId, workflowLogger);

      return { success: true, data: session };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      
      console.error('❌ IPC: Session creation failed', { error: errorMessage });
      
      return { 
        success: false, 
        error: errorMessage 
      };
    }
  });

  /**
   * Validate workflow state
   */
  ipcMain.handle('langgraph:validateState', async (event, state: AppState) => {
    try {
      console.log('📨 IPC: Validating workflow state', { ideaId: state.idea_id });

      const validation = validateWorkflowState(state);
      
      return { 
        success: true, 
        data: validation 
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      
      return { 
        success: false, 
        error: errorMessage 
      };
    }
  });

  /**
   * Get workflow metrics for a session
   */
  ipcMain.handle('langgraph:getMetrics', async (event, ideaId: string) => {
    try {
      console.log('📨 IPC: Getting workflow metrics', { ideaId });

      const workflowLogger = workflowLoggers.get(ideaId);
      if (!workflowLogger) {
        return { 
          success: true, 
          data: null 
        };
      }

      const summary = workflowLogger.getExecutionSummary();
      
      return { 
        success: true, 
        data: summary 
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      
      return { 
        success: false, 
        error: errorMessage 
      };
    }
  });

  /**
   * Clear session data
   */
  ipcMain.handle('langgraph:clearSession', async (event, ideaId: string) => {
    try {
      console.log('📨 IPC: Clearing session data', { ideaId });

      // Remove workflow logger
      workflowLoggers.delete(ideaId);
      
      return { success: true };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      
      return { 
        success: false, 
        error: errorMessage 
      };
    }
  });

  console.log('✅ LangGraph IPC handlers initialized');
  logger.info('LangGraph IPC handlers initialized', {
    handlerCount: 5
  });
}

/**
 * Cleanup LangGraph resources
 * 
 * Should be called when the app is closing.
 */
export function cleanupLangGraphHandlers(): void {
  console.log('🧹 Cleaning up LangGraph handlers');
  
  // Clear all workflow loggers
  workflowLoggers.clear();
  
  // Remove all handlers
  ipcMain.removeHandler('langgraph:execute');
  ipcMain.removeHandler('langgraph:createSession');
  ipcMain.removeHandler('langgraph:validateState');
  ipcMain.removeHandler('langgraph:getMetrics');
  ipcMain.removeHandler('langgraph:clearSession');
  
  logger.info('LangGraph handlers cleaned up');
}

================
File: electron/electron-env.d.ts
================
/// <reference types="vite-electron-plugin/electron-env" />

declare namespace NodeJS {
  interface ProcessEnv {
    VSCODE_DEBUG?: 'true'
    /**
     * The built directory structure
     *
     * ```tree
     * ├─┬ dist-electron
     * │ ├─┬ main
     * │ │ └── index.js    > Electron-Main
     * │ └─┬ preload
     * │   └── index.mjs   > Preload-Scripts
     * ├─┬ dist
     * │ └── index.html    > Electron-Renderer
     * ```
     */
    APP_ROOT: string
    /** /dist/ or /public/ */
    VITE_PUBLIC: string
  }
}

================
File: public/node.svg
================
<svg xmlns="http://www.w3.org/2000/svg" width="216" height="216" viewBox="0 0 216 216"><path fill="#80bd01" d="M104.6 180.7c-2 0-3.9-.5-5.7-1.5l-18.1-10.7c-2.7-1.5-1.4-2-.5-2.4 3.6-1.2 4.3-1.5 8.2-3.7.4-.2.9-.1 1.3.1l13.9 8.2c.5.3 1.2.3 1.7 0l54.1-31.2c.5-.3.8-.9.8-1.5V75.7c0-.6-.3-1.2-.8-1.5l-54-31.2c-.5-.3-1.2-.3-1.7 0l-54 31.2c-.5.3-.9.9-.9 1.5v62.4c0 .6.3 1.2.9 1.4l14.8 8.6c8 4 13-.7 13-5.5V81c0-.9.7-1.6 1.6-1.6h6.9c.9 0 1.6.7 1.6 1.6v61.6c0 10.7-5.8 16.9-16 16.9-3.1 0-5.6 0-12.5-3.4L44.8 148c-3.5-2-5.7-5.8-5.7-9.9V75.7c0-4.1 2.2-7.8 5.7-9.9l54.1-31.2c3.4-1.9 8-1.9 11.4 0l54.1 31.2c3.5 2 5.7 5.8 5.7 9.9v62.4c0 4.1-2.2 7.8-5.7 9.9l-54.1 31.2c-1.8 1-3.7 1.5-5.7 1.5zm43.6-61.5c0-11.7-7.9-14.8-24.5-17-16.8-2.2-18.5-3.4-18.5-7.3 0-3.2 1.4-7.6 13.9-7.6 11.1 0 15.2 2.4 16.9 9.9.1.7.8 1.2 1.5 1.2h7c.4 0 .8-.2 1.1-.5.3-.3.5-.8.4-1.2-1.1-12.9-9.7-18.9-27-18.9-15.4 0-24.6 6.5-24.6 17.4 0 11.8 9.1 15.1 23.9 16.6 17.7 1.7 19.1 4.3 19.1 7.8 0 6-4.8 8.6-16.2 8.6-14.3 0-17.5-3.6-18.5-10.7-.1-.8-.8-1.3-1.6-1.3h-7c-.9 0-1.6.7-1.6 1.6 0 9.1 5 20 28.6 20 17.3-.1 27.1-6.8 27.1-18.6zM172 55.9V57h3v8h1.2v-8h3.1v-1.1H172zm8.4 9.1h1.2v-7.6l2.6 7.6h1.2l2.6-7.6V65h1.2v-9h-1.7l-2.6 7.6-2.6-7.6h-1.8v9z"/></svg>

================
File: src/assets/logo-electron.svg
================
<svg width="128" height="128" viewBox="0 0 128 128" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M51.3954 39.5028C52.3733 39.6812 53.3108 39.033 53.4892 38.055C53.6676 37.0771 53.0194 36.1396 52.0414 35.9612L51.3954 39.5028ZM28.9393 60.9358C29.4332 61.7985 30.5329 62.0976 31.3957 61.6037C32.2585 61.1098 32.5575 60.0101 32.0636 59.1473L28.9393 60.9358ZM37.6935 66.7457C37.025 66.01 35.8866 65.9554 35.1508 66.6239C34.415 67.2924 34.3605 68.4308 35.029 69.1666L37.6935 66.7457ZM96.9206 89.515C97.7416 88.9544 97.9526 87.8344 97.3919 87.0135C96.8313 86.1925 95.7113 85.9815 94.8904 86.5422L96.9206 89.515ZM52.0414 35.9612C46.4712 34.9451 41.2848 34.8966 36.9738 35.9376C32.6548 36.9806 29.0841 39.1576 27.0559 42.6762L30.1748 44.4741C31.5693 42.0549 34.1448 40.3243 37.8188 39.4371C41.5009 38.5479 46.1547 38.5468 51.3954 39.5028L52.0414 35.9612ZM27.0559 42.6762C24.043 47.9029 25.2781 54.5399 28.9393 60.9358L32.0636 59.1473C28.6579 53.1977 28.1088 48.0581 30.1748 44.4741L27.0559 42.6762ZM35.029 69.1666C39.6385 74.24 45.7158 79.1355 52.8478 83.2597L54.6499 80.1432C47.8081 76.1868 42.0298 71.5185 37.6935 66.7457L35.029 69.1666ZM52.8478 83.2597C61.344 88.1726 70.0465 91.2445 77.7351 92.3608C85.359 93.4677 92.2744 92.6881 96.9206 89.515L94.8904 86.5422C91.3255 88.9767 85.4902 89.849 78.2524 88.7982C71.0793 87.7567 62.809 84.8612 54.6499 80.1432L52.8478 83.2597ZM105.359 84.9077C105.359 81.4337 102.546 78.6127 99.071 78.6127V82.2127C100.553 82.2127 101.759 83.4166 101.759 84.9077H105.359ZM99.071 78.6127C95.5956 78.6127 92.7831 81.4337 92.7831 84.9077H96.3831C96.3831 83.4166 97.5892 82.2127 99.071 82.2127V78.6127ZM92.7831 84.9077C92.7831 88.3817 95.5956 91.2027 99.071 91.2027V87.6027C97.5892 87.6027 96.3831 86.3988 96.3831 84.9077H92.7831ZM99.071 91.2027C102.546 91.2027 105.359 88.3817 105.359 84.9077H101.759C101.759 86.3988 100.553 87.6027 99.071 87.6027V91.2027Z" fill="#A2ECFB"/>
<path d="M91.4873 65.382C90.8456 66.1412 90.9409 67.2769 91.7002 67.9186C92.4594 68.5603 93.5951 68.465 94.2368 67.7058L91.4873 65.382ZM84.507 35.2412C83.513 35.2282 82.6967 36.0236 82.6838 37.0176C82.6708 38.0116 83.4661 38.8279 84.4602 38.8409L84.507 35.2412ZM74.9407 39.8801C75.9127 39.6716 76.5315 38.7145 76.323 37.7425C76.1144 36.7706 75.1573 36.1517 74.1854 36.3603L74.9407 39.8801ZM25.5491 80.9047C25.6932 81.8883 26.6074 82.5688 27.5911 82.4247C28.5747 82.2806 29.2552 81.3664 29.1111 80.3828L25.5491 80.9047ZM94.2368 67.7058C97.8838 63.3907 100.505 58.927 101.752 54.678C103.001 50.4213 102.9 46.2472 100.876 42.7365L97.7574 44.5344C99.1494 46.9491 99.3603 50.0419 98.2974 53.6644C97.2323 57.2945 94.9184 61.3223 91.4873 65.382L94.2368 67.7058ZM100.876 42.7365C97.9119 37.5938 91.7082 35.335 84.507 35.2412L84.4602 38.8409C91.1328 38.9278 95.7262 41.0106 97.7574 44.5344L100.876 42.7365ZM74.1854 36.3603C67.4362 37.8086 60.0878 40.648 52.8826 44.8146L54.6847 47.931C61.5972 43.9338 68.5948 41.2419 74.9407 39.8801L74.1854 36.3603ZM52.8826 44.8146C44.1366 49.872 36.9669 56.0954 32.1491 62.3927C27.3774 68.63 24.7148 75.2115 25.5491 80.9047L29.1111 80.3828C28.4839 76.1026 30.4747 70.5062 35.0084 64.5802C39.496 58.7143 46.2839 52.7889 54.6847 47.931L52.8826 44.8146Z" fill="#A2ECFB"/>
<path d="M49.0825 87.2295C48.7478 86.2934 47.7176 85.8059 46.7816 86.1406C45.8455 86.4753 45.358 87.5055 45.6927 88.4416L49.0825 87.2295ZM78.5635 96.4256C79.075 95.5732 78.7988 94.4675 77.9464 93.9559C77.0941 93.4443 75.9884 93.7205 75.4768 94.5729L78.5635 96.4256ZM79.5703 85.1795C79.2738 86.1284 79.8027 87.1379 80.7516 87.4344C81.7004 87.7308 82.71 87.2019 83.0064 86.2531L79.5703 85.1795ZM69.156 22.5301C68.2477 22.1261 67.1838 22.535 66.7799 23.4433C66.3759 24.3517 66.7848 25.4155 67.6931 25.8194L69.156 22.5301ZM45.6927 88.4416C47.5994 93.7741 50.1496 98.2905 53.2032 101.505C56.2623 104.724 59.9279 106.731 63.9835 106.731V103.131C61.1984 103.131 58.4165 101.765 55.8131 99.0249C53.2042 96.279 50.8768 92.2477 49.0825 87.2295L45.6927 88.4416ZM63.9835 106.731C69.8694 106.731 74.8921 102.542 78.5635 96.4256L75.4768 94.5729C72.0781 100.235 68.0122 103.131 63.9835 103.131V106.731ZM83.0064 86.2531C85.0269 79.7864 86.1832 72.1831 86.1832 64.0673H82.5832C82.5832 71.8536 81.4723 79.0919 79.5703 85.1795L83.0064 86.2531ZM86.1832 64.0673C86.1832 54.1144 84.4439 44.922 81.4961 37.6502C78.5748 30.4436 74.3436 24.8371 69.156 22.5301L67.6931 25.8194C71.6364 27.5731 75.3846 32.1564 78.1598 39.0026C80.9086 45.7836 82.5832 54.507 82.5832 64.0673H86.1832Z" fill="#A2ECFB"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M103.559 84.9077C103.559 82.4252 101.55 80.4127 99.071 80.4127C96.5924 80.4127 94.5831 82.4252 94.5831 84.9077C94.5831 87.3902 96.5924 89.4027 99.071 89.4027C101.55 89.4027 103.559 87.3902 103.559 84.9077Z" stroke="#A2ECFB" stroke-width="3.6" stroke-linecap="round"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M28.8143 89.4027C31.2929 89.4027 33.3023 87.3902 33.3023 84.9077C33.3023 82.4252 31.2929 80.4127 28.8143 80.4127C26.3357 80.4127 24.3264 82.4252 24.3264 84.9077C24.3264 87.3902 26.3357 89.4027 28.8143 89.4027Z" stroke="#A2ECFB" stroke-width="3.6" stroke-linecap="round"/>
<path d="M63.9835 27.6986C66.4621 27.6986 68.4714 25.6861 68.4714 23.2036C68.4714 20.7211 66.4621 18.7086 63.9835 18.7086C61.5049 18.7086 59.4956 20.7211 59.4956 23.2036C59.4956 25.6861 61.5049 27.6986 63.9835 27.6986Z" stroke="#A2ECFB" stroke-width="3.6" stroke-linecap="round"/>
</svg>

================
File: src/assets/logo-v1.svg
================
<svg width="534" height="534" viewBox="0 0 534 534" fill="none" xmlns="http://www.w3.org/2000/svg"><script xmlns=""/><path d="M266.667 533.333C413.943 533.333 533.333 413.943 533.333 266.667C533.333 119.391 413.943 0 266.667 0C119.391 0 0 119.391 0 266.667C0 413.943 119.391 533.333 266.667 533.333Z" fill="url(#paint0_linear)"/><path d="M408.012 291.99C443.487 250.081 455.873 207.931 438.835 178.423C426.3 156.708 399.798 145.244 364.575 144.785C363.115 144.788 361.715 145.364 360.677 146.39C359.639 147.417 359.046 148.81 359.027 150.27C359.008 151.729 359.565 153.138 360.576 154.191C361.587 155.243 362.972 155.856 364.431 155.896C396.108 156.308 418.942 166.185 429.215 183.979C443.365 208.49 432.319 246.077 399.531 284.81C399.05 285.366 398.684 286.011 398.454 286.709C398.224 287.408 398.135 288.144 398.192 288.877C398.249 289.61 398.45 290.324 398.785 290.978C399.12 291.632 399.581 292.214 400.142 292.689C400.703 293.163 401.352 293.522 402.053 293.744C402.753 293.966 403.491 294.047 404.223 293.982C404.955 293.917 405.667 293.708 406.317 293.366C406.968 293.023 407.544 292.556 408.012 291.99ZM316.844 149.958C284.769 156.831 250.627 170.269 217.84 189.198C136.71 236.037 83.7874 305.106 91.1374 355.187C91.2354 355.916 91.4771 356.618 91.8485 357.253C92.2198 357.888 92.7135 358.442 93.3008 358.885C93.8881 359.327 94.5574 359.649 95.2699 359.831C95.9824 360.013 96.7239 360.051 97.4515 359.944C98.179 359.837 98.8781 359.587 99.5082 359.208C100.138 358.829 100.687 358.329 101.122 357.736C101.558 357.144 101.871 356.47 102.044 355.756C102.217 355.041 102.247 354.299 102.131 353.573C95.6041 309.106 145.771 243.637 223.396 198.821C255.202 180.456 288.26 167.446 319.171 160.823C319.894 160.68 320.582 160.395 321.194 159.984C321.806 159.573 322.33 159.044 322.736 158.429C323.142 157.813 323.421 157.123 323.557 156.398C323.693 155.673 323.684 154.929 323.529 154.208C323.375 153.487 323.078 152.804 322.657 152.199C322.236 151.593 321.699 151.078 321.077 150.682C320.455 150.287 319.76 150.019 319.033 149.895C318.306 149.771 317.562 149.792 316.844 149.958V149.958Z" fill="#9feaf9"/><path d="M211.933 148.108C157.756 138.242 114.919 148.569 97.8458 178.14C85.1062 200.206 88.7478 229.462 106.679 260.735C107.033 261.385 107.513 261.957 108.092 262.419C108.67 262.88 109.334 263.221 110.046 263.423C110.758 263.624 111.503 263.681 112.237 263.59C112.971 263.5 113.68 263.264 114.322 262.896C114.963 262.528 115.525 262.035 115.974 261.447C116.423 260.859 116.75 260.188 116.936 259.472C117.121 258.755 117.162 258.01 117.056 257.277C116.95 256.545 116.698 255.842 116.317 255.208C100.167 227.037 97.0228 201.79 107.469 183.696C121.652 159.131 159.86 149.919 209.942 159.04C211.381 159.279 212.856 158.943 214.05 158.104C215.243 157.265 216.059 155.99 216.32 154.555C216.582 153.119 216.268 151.639 215.448 150.433C214.627 149.227 213.364 148.392 211.933 148.108Z" fill="#9feaf9"/><path d="M298.488 204.045L234.806 216.594C233.76 216.8 232.985 217.692 232.922 218.763L229.004 285.297C228.912 286.864 230.343 288.081 231.864 287.728L249.594 283.613C251.253 283.228 252.752 284.698 252.411 286.375L247.143 312.315C246.789 314.061 248.419 315.554 250.114 315.036L261.065 311.69C262.762 311.172 264.394 312.669 264.035 314.416L255.664 355.162C255.14 357.711 258.511 359.101 259.917 356.916L260.856 355.456L312.747 251.312C313.616 249.569 312.117 247.58 310.213 247.95L291.963 251.492C290.248 251.824 288.789 250.218 289.273 248.531L301.184 207.005C301.669 205.315 300.205 203.707 298.488 204.045Z" fill="url(#paint1_linear)"/><path d="M217.677 364.14C185.219 345.402 156.758 322.821 134.852 298.748C134.358 298.209 133.975 297.577 133.725 296.89C133.475 296.202 133.363 295.472 133.396 294.742C133.429 294.011 133.606 293.294 133.917 292.632C134.228 291.97 134.666 291.375 135.207 290.883C135.748 290.391 136.381 290.01 137.07 289.763C137.758 289.516 138.489 289.407 139.219 289.443C139.95 289.479 140.666 289.658 141.327 289.972C141.988 290.285 142.581 290.726 143.071 291.269C164.185 314.473 191.746 336.34 223.233 354.519C298.527 397.99 378.002 409.51 414.906 384.348C415.508 383.922 416.189 383.619 416.91 383.459C417.63 383.299 418.375 383.284 419.101 383.414C419.827 383.545 420.52 383.819 421.139 384.22C421.758 384.622 422.291 385.142 422.707 385.752C423.123 386.362 423.413 387.048 423.56 387.771C423.708 388.494 423.71 389.239 423.567 389.963C423.424 390.686 423.137 391.374 422.725 391.986C422.313 392.598 421.783 393.122 421.167 393.527C379.933 421.642 296.267 409.515 217.677 364.14Z" fill="#9feaf9"/><path d="M185.408 389.906C203.958 441.698 234.302 473.587 268.423 473.587C293.308 473.587 316.331 456.623 334.285 426.758C334.674 426.133 334.934 425.436 335.051 424.709C335.168 423.982 335.139 423.239 334.967 422.523C334.794 421.807 334.481 421.133 334.045 420.539C333.609 419.945 333.06 419.444 332.428 419.065C331.797 418.685 331.097 418.435 330.368 418.329C329.639 418.222 328.897 418.262 328.184 418.445C327.47 418.628 326.8 418.951 326.213 419.396C325.626 419.84 325.133 420.397 324.762 421.033C308.627 447.873 288.808 462.475 268.423 462.475C240.079 462.475 213.015 434.033 195.871 386.162C195.636 385.461 195.264 384.814 194.776 384.259C194.288 383.704 193.694 383.252 193.029 382.929C192.364 382.606 191.641 382.419 190.903 382.379C190.165 382.339 189.426 382.447 188.73 382.696C188.034 382.945 187.395 383.331 186.85 383.83C186.304 384.329 185.864 384.932 185.555 385.604C185.246 386.275 185.074 387.001 185.049 387.74C185.024 388.479 185.147 389.215 185.41 389.906H185.408ZM354.829 379.775C364.433 349.092 369.59 313.696 369.59 276.81C369.59 184.771 337.375 105.429 291.492 85.0562C290.151 84.4948 288.644 84.4809 287.294 85.0174C285.943 85.554 284.857 86.5983 284.267 87.9265C283.677 89.2546 283.631 90.761 284.139 92.1226C284.647 93.4842 285.668 94.5927 286.983 95.2104C327.906 113.383 358.477 188.681 358.477 276.81C358.477 312.596 353.483 346.873 344.227 376.456C343.997 377.156 343.908 377.894 343.966 378.628C344.024 379.362 344.227 380.077 344.564 380.732C344.901 381.387 345.364 381.968 345.928 382.442C346.491 382.917 347.143 383.274 347.846 383.494C348.549 383.714 349.288 383.792 350.021 383.724C350.754 383.655 351.467 383.442 352.117 383.096C352.767 382.75 353.341 382.278 353.807 381.708C354.273 381.138 354.621 380.481 354.831 379.775H354.829ZM459.462 374.333C459.462 359.648 447.558 347.744 432.873 347.744C418.187 347.744 406.283 359.648 406.283 374.333C406.283 389.019 418.187 400.923 432.873 400.923C447.558 400.923 459.462 389.019 459.462 374.333ZM448.352 374.333C448.352 376.366 447.952 378.379 447.174 380.257C446.396 382.135 445.256 383.841 443.818 385.279C442.381 386.716 440.674 387.856 438.796 388.634C436.918 389.412 434.906 389.812 432.873 389.812C430.84 389.812 428.827 389.412 426.949 388.634C425.071 387.856 423.365 386.716 421.927 385.279C420.49 383.841 419.35 382.135 418.572 380.257C417.794 378.379 417.394 376.366 417.394 374.333C417.394 370.228 419.025 366.291 421.927 363.388C424.83 360.485 428.768 358.854 432.873 358.854C436.978 358.854 440.915 360.485 443.818 363.388C446.721 366.291 448.352 370.228 448.352 374.333ZM103.59 400.923C118.277 400.923 130.181 389.019 130.181 374.333C130.181 359.648 118.275 347.744 103.59 347.744C88.9062 347.744 77 359.648 77 374.333C77 389.019 88.9062 400.923 103.59 400.923ZM103.59 389.812C99.4843 389.812 95.5471 388.182 92.6442 385.279C89.7413 382.376 88.1104 378.439 88.1104 374.333C88.1104 370.228 89.7413 366.291 92.6442 363.388C95.5471 360.485 99.4843 358.854 103.59 358.854C107.695 358.854 111.632 360.485 114.535 363.388C117.438 366.291 119.069 370.228 119.069 374.333C119.069 378.439 117.438 382.376 114.535 385.279C111.632 388.182 107.695 389.812 103.59 389.812Z" fill="#9feaf9"/><path d="M268.423 112.179C283.108 112.179 295.013 100.275 295.013 85.5896C295.013 70.9042 283.108 59 268.423 59C253.738 59 241.833 70.9042 241.833 85.5896C241.833 100.275 253.738 112.179 268.423 112.179ZM268.423 101.069C264.318 101.069 260.38 99.4379 257.478 96.535C254.575 93.6321 252.944 89.6949 252.944 85.5896C252.944 81.4843 254.575 77.5471 257.478 74.6442C260.38 71.7413 264.318 70.1104 268.423 70.1104C272.528 70.1104 276.465 71.7413 279.368 74.6442C282.271 77.5471 283.902 81.4843 283.902 85.5896C283.902 89.6949 282.271 93.6321 279.368 96.535C276.465 99.4379 272.528 101.069 268.423 101.069Z" fill="#9feaf9"/><defs><linearGradient id="paint0_linear" x1="6.00017" y1="32.9999" x2="235" y2="344" gradientUnits="userSpaceOnUse"><stop stop-color="#41D1FF"/><stop offset="1" stop-color="#BD34FE"/></linearGradient><linearGradient id="paint1_linear" x1="194.651" y1="8.81818" x2="236.076" y2="292.989" gradientUnits="userSpaceOnUse"><stop stop-color="#FFEA83"/><stop offset="0.0833333" stop-color="#FFDD35"/><stop offset="1" stop-color="#FFA800"/></linearGradient></defs></svg>

================
File: src/assets/logo-vite.svg
================
<svg width="128" height="128" viewBox="0 0 128 128" fill="none" xmlns="http://www.w3.org/2000/svg">
<g clip-path="url(#clip0_103_2)">
<path d="M63.9202 127.84C99.2223 127.84 127.84 99.2223 127.84 63.9202C127.84 28.6181 99.2223 0 63.9202 0C28.6181 0 0 28.6181 0 63.9202C0 99.2223 28.6181 127.84 63.9202 127.84Z" fill="url(#paint0_linear_103_2)"/>
<path d="M70.7175 48.0096L56.3133 50.676C56.0766 50.7199 55.9013 50.9094 55.887 51.1369L55.001 65.2742C54.9801 65.6072 55.3038 65.8656 55.6478 65.7907L59.6582 64.9163C60.0334 64.8346 60.3724 65.1468 60.2953 65.5033L59.1038 71.0151C59.0237 71.386 59.3923 71.7032 59.7758 71.5932L62.2528 70.8822C62.6368 70.7721 63.0057 71.0902 62.9245 71.4615L61.031 80.1193C60.9126 80.6608 61.6751 80.9561 61.9931 80.4918L62.2055 80.1817L73.9428 58.053C74.1393 57.6825 73.8004 57.26 73.3696 57.3385L69.2417 58.0912C68.8538 58.1618 68.5237 57.8206 68.6332 57.462L71.3274 48.6385C71.437 48.2794 71.1058 47.9378 70.7175 48.0096Z" fill="url(#paint1_linear_103_2)"/>
</g>
<defs>
<linearGradient id="paint0_linear_103_2" x1="1.43824" y1="7.91009" x2="56.3296" y2="82.4569" gradientUnits="userSpaceOnUse">
<stop stop-color="#41D1FF"/>
<stop offset="1" stop-color="#BD34FE"/>
</linearGradient>
<linearGradient id="paint1_linear_103_2" x1="60.3173" y1="48.7336" x2="64.237" y2="77.1962" gradientUnits="userSpaceOnUse">
<stop stop-color="#FFEA83"/>
<stop offset="0.0833333" stop-color="#FFDD35"/>
<stop offset="1" stop-color="#FFA800"/>
</linearGradient>
<clipPath id="clip0_103_2">
<rect width="128" height="128" fill="white"/>
</clipPath>
</defs>
</svg>

================
File: src/components/layout/index.ts
================
/**
 * Layout Components
 * 
 * This directory contains layout components that provide consistent
 * structure and positioning for the FlowGenius application.
 * 
 * Layout components handle:
 * - Application shell structure
 * - Responsive design breakpoints
 * - Consistent spacing and positioning
 * - Grid and flexbox layouts
 */

// Placeholder - components will be added as they are created
export const LAYOUT_COMPONENTS_READY = false;

// Future exports will include:
// export { AppLayout } from './AppLayout';
// export { MainContent } from './MainContent';
// export { Container } from './Container';

================
File: src/components/shared/index.ts
================
/**
 * Shared UI Components
 * 
 * This directory contains reusable UI components that are used across
 * multiple parts of the FlowGenius application.
 * 
 * Components in this directory should be:
 * - Highly reusable
 * - Well-documented with TypeScript interfaces
 * - Thoroughly tested
 * - Following consistent design patterns
 */

// Placeholder - components will be added as they are created
export const SHARED_COMPONENTS_READY = false;

// Future exports will include:
// export { Button } from './Button';
// export { Modal } from './Modal';
// export { LoadingSpinner } from './LoadingSpinner';
// export { ErrorMessage } from './ErrorMessage';

================
File: src/components/update/Modal/modal.css
================
.update-modal {
  --primary-color: rgb(224, 30, 90);

  .update-modal__mask {
    width: 100vw;
    height: 100vh;
    position: fixed;
    left: 0;
    top: 0;
    z-index: 9;
    background: rgba(0, 0, 0, 0.45);
  }

  .update-modal__warp {
    position: fixed;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    z-index: 19;
  }

  .update-modal__content {
    box-shadow: 0 0 10px -4px rgb(130, 86, 208);
    overflow: hidden;
    border-radius: 4px;

    .content__header {
      display: flex;
      line-height: 38px;
      background-color: var(--primary-color);

      .content__header-text {
        font-weight: bold;
        width: 0;
        flex-grow: 1;
      }
    }

    .update-modal--close {
      width: 30px;
      height: 30px;
      margin: 4px;
      line-height: 34px;
      text-align: center;
      cursor: pointer;

      svg {
        width: 17px;
        height: 17px;
      }
    }

    .content__body {
      padding: 10px;
      background-color: #fff;
      color: #333;
    }

    .content__footer {
      padding: 10px;
      background-color: #fff;
      display: flex;
      justify-content: flex-end;

      button {
        padding: 7px 11px;
        background-color: var(--primary-color);
        font-size: 14px;
        margin-left: 10px;

        &:first-child {
          margin-left: 0;
        }
      }
    }
  }

  .icon {
    padding: 0 15px;
    width: 20px;
    fill: currentColor;

    &:hover {
      color: rgba(0, 0, 0, 0.4);
    }
  }
}

================
File: src/components/update/Progress/progress.css
================
.update-progress {
  display: flex;
  align-items: center;

  .update-progress-pr {
    border: 1px solid #000;
    border-radius: 3px;
    height: 6px;
    width: 300px;
  }

  .update-progress-rate {
    height: 6px;
    border-radius: 3px;
    background-image: linear-gradient(to right, rgb(130, 86, 208) 0%, var(--primary-color) 100%)
  }

  .update-progress-num {
    margin: 0 10px;
  }
}

================
File: src/components/update/README.md
================
# electron-updater

English | [简体中文](README.zh-CN.md)

> Use `electron-updater` to realize the update detection, download and installation of the electric program.

```sh
npm i electron-updater
```

### Main logic

1. ##### Configuration of the update the service address and update information script:

   Add a `publish` field to `electron-builder.json5` for configuring the update address and which strategy to use as the update service.

   ``` json5
   {
      "publish": {
         "provider": "generic",
         "channel": "latest",
         "url": "https://foo.com/"
      }
   }
   ```

   For more information, please refer to : [electron-builder.json5...](https://github.com/electron-vite/electron-vite-react/blob/2f2880a9f19de50ff14a0785b32a4d5427477e55/electron-builder.json5#L38)

2. ##### The update logic of Electron:

   - Checking if an update is available;
   - Checking the version of the software on the server;
   - Checking if an update is available;
   - Downloading the new version of the software from the server (when an update is available);
   - Installation method;

   For more information, please refer to  : [update...](https://github.com/electron-vite/electron-vite-react/blob/main/electron/main/update.ts)

3. ##### Updating UI pages in Electron:

   The main function is to provide a UI page for users to trigger the update logic mentioned in (2.) above. Users can click on the page to trigger different update functions in Electron.
   
   For more information, please refer to : [components/update...](https://github.com/electron-vite/electron-vite-react/blob/main/src/components/update/index.tsx)

---

Here it is recommended to trigger updates through user actions (in this project, Electron update function is triggered after the user clicks on the "Check for updates" button).

For more information on using `electron-updater` for Electron updates, please refer to the documentation : [auto-update](https://www.electron.build/.html)

================
File: src/components/update/README.zh-CN.md
================
# electron-auto-update

[English](README.md) | 简体中文

使用`electron-updater`实现electron程序的更新检测、下载和安装等功能。

```sh
npm i electron-updater
```

### 主要逻辑

1. ##### 更新地址、更新信息脚本的配置

   在`electron-builder.json5`添加`publish`字段,用来配置更新地址和使用哪种策略作为更新服务

    ``` json5
    {
      "publish": {
        "provider": "generic",    // 提供者、提供商
        "channel": "latest",      // 生成yml文件的名称
        "url": "https://foo.com/" //更新地址
      }
    }
    ```

更多见 : [electron-builder.json5...](xxx)

2. ##### Electron更新逻辑

   - 检测更新是否可用；

   - 检测服务端的软件版本；

   - 检测更新是否可用；

   - 下载服务端新版软件（当更新可用）；
   - 安装方式；

  更多见 : [update...](https://github.com/electron-vite/electron-vite-react/blob/main/electron/main/update.ts)

3. ##### Electron更新UI页面

    主要功能是：用户触发上述(2.)更新逻辑的UI页面。用户可以通过点击页面触发electron更新的不同功能。
    更多见 : [components/update.ts...](https://github.com/electron-vite/electron-vite-react/tree/main/src/components/update/index.tsx)

---

这里建议更新触发以用户操作触发（本项目的以用户点击 **更新检测** 后触发electron更新功能）

关于更多使用`electron-updater`进行electron更新，见文档：[auto-update](https://www.electron.build/.html)

================
File: src/components/update/update.css
================
.modal-slot {
  .update-progress {
    display: flex;
  }

  .new-version__target,
  .update__progress {
    margin-left: 40px;
  }

  .progress__title {
    margin-right: 10px;
  }

  .progress__bar {
    width: 0;
    flex-grow: 1;
  }

  .can-not-available {
    padding: 20px;
    text-align: center;
  }
}

================
File: src/components/Chat.tsx
================
/**
 * Chat Component
 * 
 * OpenAI-style chat interface with message display, auto-scrolling, and continuous thread design.
 * Handles message rendering, typing indicators, and proper accessibility features.
 */

import { useEffect, useRef, useCallback, useMemo } from 'react';
import { ChatMessage, WorkflowStage } from '../types/AppState';
import { logger } from '../utils/logger';

/**
 * Props interface for the Chat component
 */
export interface ChatProps {
  /** Array of chat messages to display */
  messages: ChatMessage[];
  /** Current workflow stage for context */
  currentStage: WorkflowStage;
  /** Whether the AI is currently processing/typing */
  isProcessing?: boolean;
  /** Whether to auto-scroll to bottom on new messages */
  autoScroll?: boolean;
  /** Custom welcome message component */
  welcomeComponent?: React.ReactNode;
  /** Callback when user scrolls to see if they're at bottom */
  onScrollChange?: (isAtBottom: boolean) => void;
  /** Custom message actions (copy, regenerate, etc.) */
  onMessageAction?: (action: string, messageIndex: number) => void;
}

/**
 * Props for individual message components
 */
interface MessageProps {
  message: ChatMessage;
  index: number;
  onAction?: (action: string, index: number) => void;
}

/**
 * Individual message component with proper styling and interactions
 */
const Message = ({ message, index, onAction }: MessageProps) => {
  const messageRef = useRef<HTMLDivElement>(null);

  /**
   * Format timestamp for display
   */
  const formattedTime = useMemo(() => {
    if (!message.created_at) return '';
    
    return new Intl.DateTimeFormat('en-US', {
      hour: '2-digit',
      minute: '2-digit',
      hour12: true,
    }).format(new Date(message.created_at));
  }, [message.created_at]);

  /**
   * Get stage badge styling
   */
  const stageBadgeStyle = useMemo(() => {
    const styles: Record<WorkflowStage, string> = {
      brainstorm: 'bg-blue-500/10 text-blue-400 border-blue-500/20',
      summary: 'bg-yellow-500/10 text-yellow-400 border-yellow-500/20',
      prd: 'bg-green-500/10 text-green-400 border-green-500/20',
    };
    return styles[message.stage_at_creation || 'brainstorm'];
  }, [message.stage_at_creation]);

  /**
   * Handle message actions (copy, regenerate, etc.)
   */
  const handleAction = useCallback((action: string) => {
    logger.debug('🔧 Message action triggered', { action, messageIndex: index, messageRole: message.role });
    onAction?.(action, index);
  }, [index, message.role, onAction]);

  /**
   * Copy message content to clipboard
   */
  const handleCopy = useCallback(async () => {
    try {
      await navigator.clipboard.writeText(message.content);
      logger.info('📋 Message copied to clipboard', { messageIndex: index });
      // TODO: Show toast notification
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      logger.error('❌ Failed to copy message', { error: errorMessage, messageIndex: index });
    }
  }, [message.content, index]);

  const isUser = message.role === 'user';
  const isAssistant = message.role === 'assistant';

  return (
    <div
      ref={messageRef}
      className={`
        group relative flex gap-4 px-4 py-6 transition-colors duration-200
        ${isUser ? 'bg-transparent' : 'bg-gray-50/50'}
        hover:bg-gray-50/80
      `}
      role="article"
      aria-label={`${message.role} message`}
    >
      {/* Message Avatar */}
      <div className="flex-shrink-0">
        <div
          className={`
            w-8 h-8 rounded-full flex items-center justify-center text-sm font-semibold
            ${isUser 
              ? 'bg-emerald-600 text-white' 
              : 'bg-gray-800 text-white'
            }
          `}
          aria-hidden="true"
        >
          {isUser ? 'U' : 'AI'}
        </div>
      </div>

      {/* Message Content */}
      <div className="flex-1 min-w-0 space-y-3">
        {/* Message Header */}
        <div className="flex items-center gap-2 text-sm">
          <span className="font-medium text-gray-900">
            {isUser ? 'You' : 'FlowGenius'}
          </span>
          {formattedTime && (
            <span className="text-gray-500">{formattedTime}</span>
          )}
          {message.stage_at_creation && (
            <span className={`
              px-2 py-1 text-xs font-medium rounded-full border
              ${stageBadgeStyle}
            `}>
              {message.stage_at_creation}
            </span>
          )}
        </div>

        {/* Message Text */}
        <div
          className={`
            prose prose-sm max-w-none text-gray-900 leading-relaxed
            ${isUser ? 'prose-emerald' : 'prose-gray'}
          `}
        >
          {/* Handle line breaks and basic formatting */}
          {message.content.split('\n').map((line, lineIndex) => (
            <p key={lineIndex} className={lineIndex === 0 ? 'mt-0' : ''}>
              {line || '\u00A0'} {/* Non-breaking space for empty lines */}
            </p>
          ))}
        </div>

        {/* Image Display (if present) */}
        {message.image_url && (
          <div className="mt-3">
            <img
              src={message.image_url}
              alt="Uploaded image"
              className="max-w-sm rounded-lg border border-gray-200 shadow-sm"
              loading="lazy"
            />
          </div>
        )}

        {/* Message Actions */}
        <div className="flex items-center gap-2 opacity-0 group-hover:opacity-100 transition-opacity duration-200">
          <button
            onClick={handleCopy}
            className="
              p-1.5 rounded-md text-gray-400 hover:text-gray-600 hover:bg-gray-100
              focus:outline-none focus:ring-2 focus:ring-emerald-500 focus:ring-offset-2
              transition-colors duration-200
            "
            aria-label="Copy message"
            title="Copy message"
          >
            <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M8 16H6a2 2 0 01-2-2V6a2 2 0 012-2h8a2 2 0 012 2v2m-6 12h8a2 2 0 002-2v-8a2 2 0 00-2-2h-8a2 2 0 00-2 2v8a2 2 0 002 2z" />
            </svg>
          </button>

          {isAssistant && onAction && (
            <button
              onClick={() => handleAction('regenerate')}
              className="
                p-1.5 rounded-md text-gray-400 hover:text-gray-600 hover:bg-gray-100
                focus:outline-none focus:ring-2 focus:ring-emerald-500 focus:ring-offset-2
                transition-colors duration-200
              "
              aria-label="Regenerate response"
              title="Regenerate response"
            >
              <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M4 4v5h.582m15.356 2A8.001 8.001 0 004.582 9m0 0H9m11 11v-5h-.581m0 0a8.003 8.003 0 01-15.357-2m15.357 2H15" />
              </svg>
            </button>
          )}
        </div>
      </div>
    </div>
  );
};

/**
 * Typing indicator component for when AI is processing
 */
const TypingIndicator = () => (
  <div className="flex gap-4 px-4 py-6 bg-gray-50/50">
    <div className="flex-shrink-0">
      <div className="w-8 h-8 rounded-full bg-gray-800 text-white flex items-center justify-center text-sm font-semibold">
        AI
      </div>
    </div>
    <div className="flex-1 min-w-0 space-y-3">
      <div className="flex items-center gap-2 text-sm">
        <span className="font-medium text-gray-900">FlowGenius</span>
        <span className="text-gray-500">is typing...</span>
      </div>
      <div className="flex items-center gap-1">
        {[0, 1, 2].map((i) => (
          <div
            key={i}
            className="w-2 h-2 bg-gray-400 rounded-full animate-pulse"
            style={{
              animationDelay: `${i * 0.2}s`,
              animationDuration: '1.4s',
            }}
          />
        ))}
      </div>
    </div>
  </div>
);

/**
 * Default welcome message component
 */
const DefaultWelcome = ({ currentStage }: { currentStage: WorkflowStage }) => (
  <div className="flex-1 flex items-center justify-center p-8">
    <div className="text-center max-w-md space-y-6">
      <div className="w-16 h-16 bg-emerald-100 rounded-full flex items-center justify-center mx-auto">
        <svg className="w-8 h-8 text-emerald-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
          <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 4.418-4.03 8-9 8a9.863 9.863 0 01-4.255-.949L3 20l1.395-3.72C3.512 15.042 3 13.574 3 12c0-4.418 4.03-8 9-8s9 3.582 9 8z" />
        </svg>
      </div>
      
      <div className="space-y-2">
        <h3 className="text-xl font-semibold text-gray-900">
          Welcome to FlowGenius
        </h3>
        <p className="text-gray-600">
          Start a conversation to begin developing your ideas through our AI-powered workflow.
        </p>
      </div>

      <div className="space-y-3">
        <p className="text-sm font-medium text-gray-700">Current Stage:</p>
        <div className="flex items-center justify-center gap-2">
          <div className={`
            px-3 py-1.5 rounded-full text-sm font-medium border
            ${currentStage === 'brainstorm' ? 'bg-blue-500/10 text-blue-600 border-blue-500/20' : 'bg-gray-100 text-gray-500 border-gray-200'}
          `}>
            1. Brainstorm
          </div>
          <svg className="w-4 h-4 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M9 5l7 7-7 7" />
          </svg>
          <div className={`
            px-3 py-1.5 rounded-full text-sm font-medium border
            ${currentStage === 'summary' ? 'bg-yellow-500/10 text-yellow-600 border-yellow-500/20' : 'bg-gray-100 text-gray-500 border-gray-200'}
          `}>
            2. Summary
          </div>
          <svg className="w-4 h-4 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M9 5l7 7-7 7" />
          </svg>
          <div className={`
            px-3 py-1.5 rounded-full text-sm font-medium border
            ${currentStage === 'prd' ? 'bg-green-500/10 text-green-600 border-green-500/20' : 'bg-gray-100 text-gray-500 border-gray-200'}
          `}>
            3. PRD
          </div>
        </div>
      </div>
    </div>
  </div>
);

/**
 * Main Chat component
 */
export const Chat = ({
  messages,
  currentStage,
  isProcessing = false,
  autoScroll = true,
  welcomeComponent,
  onScrollChange,
  onMessageAction,
}: ChatProps) => {
  const chatContainerRef = useRef<HTMLDivElement>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const isUserAtBottomRef = useRef(true);

  /**
   * Scroll to bottom of chat
   */
  const scrollToBottom = useCallback((smooth = true) => {
    if (messagesEndRef.current) {
      messagesEndRef.current.scrollIntoView({
        behavior: smooth ? 'smooth' : 'auto',
        block: 'end',
      });
    }
  }, []);

  /**
   * Check if user is at bottom of chat
   */
  const checkIfAtBottom = useCallback(() => {
    if (!chatContainerRef.current) return false;
    
    const { scrollTop, scrollHeight, clientHeight } = chatContainerRef.current;
    const threshold = 100; // pixels from bottom
    const isAtBottom = scrollTop + clientHeight >= scrollHeight - threshold;
    
    return isAtBottom;
  }, []);

  /**
   * Handle scroll events
   */
  const handleScroll = useCallback(() => {
    const isAtBottom = checkIfAtBottom();
    isUserAtBottomRef.current = isAtBottom;
    onScrollChange?.(isAtBottom);
  }, [checkIfAtBottom, onScrollChange]);

  /**
   * Auto-scroll to bottom when new messages arrive
   */
  useEffect(() => {
    if (autoScroll && isUserAtBottomRef.current) {
      // Small delay to ensure DOM has updated
      const timeoutId = setTimeout(() => scrollToBottom(), 100);
      return () => clearTimeout(timeoutId);
    }
    return undefined;
  }, [messages.length, autoScroll, scrollToBottom]);

  /**
   * Auto-scroll when processing state changes
   */
  useEffect(() => {
    if (isProcessing && isUserAtBottomRef.current) {
      const timeoutId = setTimeout(() => scrollToBottom(), 100);
      return () => clearTimeout(timeoutId);
    }
    return undefined;
  }, [isProcessing, scrollToBottom]);

  /**
   * Log chat interactions
   */
  useEffect(() => {
    logger.debug('💬 Chat component rendered', {
      messageCount: messages.length,
      currentStage,
      isProcessing,
      isAtBottom: isUserAtBottomRef.current,
    });
  }, [messages.length, currentStage, isProcessing]);

  const hasMessages = messages.length > 0;

  return (
    <div className="flex flex-col h-full bg-white">
      {/* Chat Messages Container */}
      <div
        ref={chatContainerRef}
        className="flex-1 overflow-y-auto scroll-smooth"
        onScroll={handleScroll}
        role="log"
        aria-live="polite"
        aria-label="Chat messages"
      >
        {!hasMessages ? (
          // Welcome message when no messages
          welcomeComponent || <DefaultWelcome currentStage={currentStage} />
        ) : (
          // Messages list
          <div className="divide-y divide-gray-100">
            {messages.map((message, index) => (
              <Message
                key={`${message.created_at?.getTime() || Date.now()}-${index}`}
                message={message}
                index={index}
                onAction={onMessageAction}
              />
            ))}
            
            {/* Typing indicator */}
            {isProcessing && <TypingIndicator />}
          </div>
        )}
        
        {/* Scroll anchor */}
        <div ref={messagesEndRef} className="h-px" aria-hidden="true" />
      </div>

      {/* Scroll to bottom button (when not at bottom) */}
      {hasMessages && !isUserAtBottomRef.current && (
        <div className="absolute bottom-4 right-4">
          <button
            onClick={() => scrollToBottom()}
            className="
              p-2 bg-white border border-gray-200 rounded-full shadow-lg
              hover:bg-gray-50 focus:outline-none focus:ring-2 focus:ring-emerald-500 focus:ring-offset-2
              transition-all duration-200
            "
            aria-label="Scroll to bottom"
            title="Scroll to bottom"
          >
            <svg className="w-5 h-5 text-gray-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M19 14l-7 7m0 0l-7-7m7 7V3" />
            </svg>
          </button>
        </div>
      )}
    </div>
  );
};

export default Chat;

================
File: src/components/InputBar.tsx
================
/**
 * InputBar Component
 * 
 * Bottom input bar component for FlowGenius with text field, microphone, and upload functionality.
 * Styled to match OpenAI's ChatGPT interface with modern design patterns.
 * 
 * Features:
 * - Text input with auto-resize
 * - Microphone icon for voice input
 * - Upload icon for file attachments
 * - Send button with proper state management
 * - Keyboard shortcuts (Enter to send, Shift+Enter for new line)
 * - Accessibility features
 */

import React, { useState, useRef, useCallback, useEffect } from 'react';
import { logger } from '../utils/logger';

/**
 * Props interface for InputBar component
 */
interface InputBarProps {
  /** Current message being typed */
  value: string;
  /** Callback when input value changes */
  onChange: (value: string) => void;
  /** Callback when message is sent */
  onSend: (message: string) => void;
  /** Callback when voice recording is requested */
  onVoiceRecord?: () => void;
  /** Callback when file upload is requested */
  onFileUpload?: () => void;
  /** Whether the application is currently processing */
  isProcessing?: boolean;
  /** Whether voice recording is available */
  isVoiceEnabled?: boolean;
  /** Whether file upload is available */
  isUploadEnabled?: boolean;
  /** Placeholder text for the input field */
  placeholder?: string;
  /** Maximum character limit */
  maxLength?: number;
  /** Whether the input is disabled */
  disabled?: boolean;
}

/**
 * InputBar component for message input with voice and file upload capabilities
 */
export const InputBar: React.FC<InputBarProps> = ({
  value,
  onChange,
  onSend,
  onVoiceRecord,
  onFileUpload,
  isProcessing = false,
  isVoiceEnabled = false,
  isUploadEnabled = false,
  placeholder = "Message FlowGenius...",
  maxLength = 4000,
  disabled = false,
}) => {
  const textareaRef = useRef<HTMLTextAreaElement>(null);
  const [isFocused, setIsFocused] = useState(false);
  const [isComposing, setIsComposing] = useState(false);

  /**
   * Auto-resize textarea based on content
   */
  const adjustTextareaHeight = useCallback(() => {
    const textarea = textareaRef.current;
    if (!textarea) return;

    // Reset height to calculate new height
    textarea.style.height = 'auto';
    
    // Calculate new height (max 5 lines)
    const lineHeight = 24; // 1.5rem in pixels
    const maxHeight = lineHeight * 5;
    const newHeight = Math.min(textarea.scrollHeight, maxHeight);
    
    textarea.style.height = `${newHeight}px`;
    
    logger.debug('📏 Textarea height adjusted', { 
      scrollHeight: textarea.scrollHeight, 
      newHeight,
      maxHeight 
    });
  }, []);

  /**
   * Handle input change with character limit enforcement
   */
  const handleInputChange = useCallback((e: React.ChangeEvent<HTMLTextAreaElement>) => {
    const newValue = e.target.value;
    
    // Enforce character limit
    if (newValue.length > maxLength) {
      logger.warn('⚠️ Character limit exceeded', { 
        currentLength: newValue.length, 
        maxLength 
      });
      return;
    }

    onChange(newValue);
    logger.debug('✏️ Input value changed', { 
      length: newValue.length, 
      maxLength,
      hasContent: newValue.trim().length > 0
    });
  }, [onChange, maxLength]);

  /**
   * Handle send message
   */
  const handleSend = useCallback(() => {
    const trimmedValue = value.trim();
    
    if (!trimmedValue || isProcessing || disabled) {
      logger.debug('🚫 Send blocked', { 
        hasContent: !!trimmedValue, 
        isProcessing, 
        disabled 
      });
      return;
    }

    logger.info('📤 Sending message', { 
      messageLength: trimmedValue.length,
      messagePreview: trimmedValue.substring(0, 50) + (trimmedValue.length > 50 ? '...' : '')
    });

    onSend(trimmedValue);
  }, [value, onSend, isProcessing, disabled]);

  /**
   * Handle keyboard shortcuts
   */
  const handleKeyDown = useCallback((e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    // Don't handle shortcuts during composition (IME input)
    if (isComposing) return;

    if (e.key === 'Enter') {
      if (e.shiftKey) {
        // Shift+Enter: new line (default behavior)
        logger.debug('⤵️ New line added with Shift+Enter');
        return;
      } else {
        // Enter: send message
        e.preventDefault();
        handleSend();
      }
    }

    // Escape: clear input
    if (e.key === 'Escape') {
      onChange('');
      logger.debug('🗑️ Input cleared with Escape key');
    }
  }, [isComposing, handleSend, onChange]);

  /**
   * Handle voice recording
   */
  const handleVoiceRecord = useCallback(() => {
    if (!isVoiceEnabled || isProcessing || disabled) {
      logger.debug('🚫 Voice recording blocked', { 
        isVoiceEnabled, 
        isProcessing, 
        disabled 
      });
      return;
    }

    logger.info('🎤 Voice recording requested');
    onVoiceRecord?.();
  }, [isVoiceEnabled, isProcessing, disabled, onVoiceRecord]);

  /**
   * Handle file upload
   */
  const handleFileUpload = useCallback(() => {
    if (!isUploadEnabled || isProcessing || disabled) {
      logger.debug('🚫 File upload blocked', { 
        isUploadEnabled, 
        isProcessing, 
        disabled 
      });
      return;
    }

    logger.info('📎 File upload requested');
    onFileUpload?.();
  }, [isUploadEnabled, isProcessing, disabled, onFileUpload]);

  /**
   * Auto-resize textarea when value changes
   */
  useEffect(() => {
    adjustTextareaHeight();
  }, [value, adjustTextareaHeight]);

  /**
   * Focus textarea on mount
   */
  useEffect(() => {
    if (textareaRef.current && !disabled) {
      textareaRef.current.focus();
    }
  }, [disabled]);

  const canSend = value.trim().length > 0 && !isProcessing && !disabled;
  const remainingChars = maxLength - value.length;
  const isNearLimit = remainingChars < 100;

  logger.debug('🎨 InputBar render', {
    valueLength: value.length,
    canSend,
    isProcessing,
    isFocused,
    isVoiceEnabled,
    isUploadEnabled
  });

  return (
    <div className="input-bar-container">
      {/* Character count warning */}
      {isNearLimit && (
        <div className="character-warning">
          <span className={remainingChars < 20 ? 'text-red-400' : 'text-yellow-400'}>
            {remainingChars} characters remaining
          </span>
        </div>
      )}

      {/* Main input area */}
      <div className={`input-bar ${isFocused ? 'focused' : ''} ${disabled ? 'disabled' : ''}`}>
        {/* File upload button */}
        <button
          type="button"
          onClick={handleFileUpload}
          disabled={!isUploadEnabled || isProcessing || disabled}
          className="input-action-button upload-button"
          aria-label="Upload file"
          title="Upload file"
        >
          📎
        </button>

        {/* Text input area */}
        <div className="input-text-container">
          <textarea
            ref={textareaRef}
            value={value}
            onChange={handleInputChange}
            onKeyDown={handleKeyDown}
            onFocus={() => setIsFocused(true)}
            onBlur={() => setIsFocused(false)}
            onCompositionStart={() => setIsComposing(true)}
            onCompositionEnd={() => setIsComposing(false)}
            placeholder={placeholder}
            disabled={disabled || isProcessing}
            maxLength={maxLength}
            rows={1}
            className="input-textarea"
            aria-label="Message input"
            aria-describedby="input-help"
          />
        </div>

        {/* Voice recording button */}
        <button
          type="button"
          onClick={handleVoiceRecord}
          disabled={!isVoiceEnabled || isProcessing || disabled}
          className="input-action-button voice-button"
          aria-label="Record voice message"
          title="Record voice message"
        >
          🎤
        </button>

        {/* Send button */}
        <button
          type="button"
          onClick={handleSend}
          disabled={!canSend}
          className={`input-action-button send-button ${canSend ? 'enabled' : 'disabled'}`}
          aria-label="Send message"
          title="Send message"
        >
          {isProcessing ? (
            <div style={{ 
              width: '16px', 
              height: '16px', 
              border: '2px solid #8e8ea0', 
              borderTop: '2px solid #10a37f', 
              borderRadius: '50%', 
              animation: 'spin 1s linear infinite' 
            }}>
            </div>
          ) : (
            '▶️'
          )}
        </button>
      </div>

      {/* Help text */}
      <div id="input-help" className="input-help">
        <span className="help-text">
          Press Enter to send, Shift+Enter for new line
          {isVoiceEnabled && ', or use the microphone for voice input'}
        </span>
      </div>
    </div>
  );
};

export default InputBar;

================
File: src/components/README.md
================
# Components Directory

This directory contains all React components for the FlowGenius application, organized in a modular structure for maintainability and scalability.

## Directory Structure

### Core UI Components
- `Chat/` - Main chat interface component with message display
- `Sidebar/` - Session management sidebar component (OpenAI-style)  
- `InputBar/` - Bottom input bar with text field, microphone, and upload icons
- `AudioRecorder/` - Voice recording component with MediaRecorder API
- `ConsoleLog/` - Collapsible console log panel for debugging

### Shared/Utility Components  
- `shared/` - Reusable UI components (buttons, modals, etc.)
- `layout/` - Layout components for consistent structure

### Legacy Components
- `update/` - Electron auto-updater components (preserved from original template)

## Component Guidelines

1. **File Naming**: Use PascalCase for component files (e.g., `Chat.tsx`)
2. **Structure**: Each component should have its own directory with:
   - `index.tsx` - Main component file
   - `ComponentName.test.tsx` - Unit tests
   - `ComponentName.module.css` - Component-specific styles (if needed)
3. **Documentation**: All components must include JSDoc comments
4. **Exports**: Use named exports for components and default exports for the main component
5. **Props**: Define TypeScript interfaces for all props

## Testing

- All components must have corresponding test files
- Tests should cover component rendering, user interactions, and edge cases
- Use React Testing Library for testing components

## Styling

- Follow OpenAI ChatGPT design principles
- Use CSS modules for component-specific styles
- Global styles are in the `src/styles/` directory

================
File: src/components/Sidebar.tsx
================
/**
 * Sidebar Component
 * 
 * OpenAI-style sidebar for session management with create new session functionality,
 * session list display, and user information. Uses Tailwind CSS for styling and 
 * follows accessibility best practices.
 */

import { useState, useCallback, useMemo } from 'react';
import { AppState, IdeaEntity, WorkflowStage } from '../types/AppState';
import { logger } from '../utils/logger';

/**
 * Props interface for the Sidebar component
 */
export interface SidebarProps {
  /** Current application state */
  currentAppState: AppState;
  /** Whether the sidebar is open (for mobile responsive design) */
  isOpen: boolean;
  /** Function to toggle sidebar visibility */
  onToggle: () => void;
  /** Function to create a new session */
  onCreateNewSession: () => void;
  /** Function to switch to a different session */
  onSessionSwitch: (sessionId: string) => void;
  /** List of all available sessions/ideas */
  sessions: IdeaEntity[];
  /** Loading state for session operations */
  isLoading?: boolean;
  /** Function to delete a session */
  onDeleteSession?: (sessionId: string) => void;
  /** Function to rename a session */
  onRenameSession?: (sessionId: string, newTitle: string) => void;
}

/**
 * Interface for session item props
 */
interface SessionItemProps {
  session: IdeaEntity;
  isActive: boolean;
  onSelect: () => void;
  onDelete?: () => void;
  onRename?: (newTitle: string) => void;
}

/**
 * Individual session item component
 */
const SessionItem = ({ 
  session, 
  isActive, 
  onSelect, 
  onDelete, 
  onRename 
}: SessionItemProps) => {
  const [isEditing, setIsEditing] = useState(false);
  const [editTitle, setEditTitle] = useState(session.title);
  const [showMenu, setShowMenu] = useState(false);

  /**
   * Handle session rename submission
   */
  const handleRename = useCallback(() => {
    if (editTitle.trim() && editTitle !== session.title && onRename) {
      logger.info('📝 Renaming session', { 
        sessionId: session.id, 
        oldTitle: session.title, 
        newTitle: editTitle.trim() 
      });
      onRename(editTitle.trim());
    }
    setIsEditing(false);
    setShowMenu(false);
  }, [editTitle, session.id, session.title, onRename]);

  /**
   * Handle session deletion
   */
  const handleDelete = useCallback(() => {
    if (onDelete && window.confirm(`Are you sure you want to delete "${session.title}"?`)) {
      logger.info('🗑️ Deleting session', { sessionId: session.id, title: session.title });
      onDelete();
    }
    setShowMenu(false);
  }, [onDelete, session.id, session.title]);

  /**
   * Format the session creation date
   */
  const formattedDate = useMemo(() => {
    return new Intl.DateTimeFormat('en-US', {
      month: 'short',
      day: 'numeric',
      hour: '2-digit',
      minute: '2-digit',
    }).format(new Date(session.created_at));
  }, [session.created_at]);

  /**
   * Get stage color for visual indication
   */
  const stageColor = useMemo(() => {
    const colors: Record<WorkflowStage, string> = {
      brainstorm: 'bg-blue-500/20 text-blue-400',
      summary: 'bg-yellow-500/20 text-yellow-400',
      prd: 'bg-green-500/20 text-green-400',
    };
    return colors[session.current_stage] || 'bg-gray-500/20 text-gray-400';
  }, [session.current_stage]);

  return (
    <div
      className={`
        group relative flex flex-col p-3 rounded-lg cursor-pointer transition-all duration-200
        ${isActive 
          ? 'bg-white/10 border border-white/20' 
          : 'hover:bg-white/5 border border-transparent hover:border-white/10'
        }
      `}
      onClick={onSelect}
      role="button"
      tabIndex={0}
      aria-label={`Session: ${session.title}`}
      onKeyDown={(e) => {
        if (e.key === 'Enter' || e.key === ' ') {
          e.preventDefault();
          onSelect();
        }
      }}
    >
      {/* Session Title */}
      <div className="flex items-start justify-between gap-2 mb-2">
        {isEditing ? (
          <input
            type="text"
            value={editTitle}
            onChange={(e) => setEditTitle(e.target.value)}
            onBlur={handleRename}
            onKeyDown={(e) => {
              if (e.key === 'Enter') handleRename();
              if (e.key === 'Escape') {
                setIsEditing(false);
                setEditTitle(session.title);
              }
              e.stopPropagation();
            }}
            className="flex-1 bg-white/10 border border-white/20 rounded px-2 py-1 text-sm text-white focus:outline-none focus:ring-2 focus:ring-emerald-500"
            autoFocus
            onClick={(e) => e.stopPropagation()}
          />
        ) : (
                     <h3 className="flex-1 text-sm font-medium text-white leading-tight overflow-hidden" style={{
             display: '-webkit-box',
             WebkitLineClamp: 2,
             WebkitBoxOrient: 'vertical',
           }}>
             {session.title}
           </h3>
        )}
        
        {/* Session Menu */}
        <div className="relative">
          <button
            className={`
              p-1 rounded opacity-0 group-hover:opacity-100 transition-opacity
              hover:bg-white/10 focus:opacity-100 focus:outline-none focus:ring-2 focus:ring-emerald-500
              ${showMenu ? 'opacity-100' : ''}
            `}
            onClick={(e) => {
              e.stopPropagation();
              setShowMenu(!showMenu);
            }}
            aria-label="Session options"
          >
            <svg className="w-4 h-4 text-gray-400" fill="currentColor" viewBox="0 0 20 20">
              <path d="M10 6a2 2 0 110-4 2 2 0 010 4zM10 12a2 2 0 110-4 2 2 0 010 4zM10 18a2 2 0 110-4 2 2 0 010 4z" />
            </svg>
          </button>
          
          {showMenu && (
            <div className="absolute right-0 top-8 w-32 bg-gray-800 border border-gray-600 rounded-lg shadow-lg z-10">
              <button
                className="w-full px-3 py-2 text-left text-sm text-gray-300 hover:bg-gray-700 rounded-t-lg"
                onClick={(e) => {
                  e.stopPropagation();
                  setIsEditing(true);
                  setShowMenu(false);
                }}
              >
                Rename
              </button>
              {onDelete && (
                <button
                  className="w-full px-3 py-2 text-left text-sm text-red-400 hover:bg-gray-700 rounded-b-lg"
                  onClick={(e) => {
                    e.stopPropagation();
                    handleDelete();
                  }}
                >
                  Delete
                </button>
              )}
            </div>
          )}
        </div>
      </div>

      {/* Session Metadata */}
      <div className="flex items-center justify-between text-xs">
        <span className={`px-2 py-1 rounded-full text-xs font-medium ${stageColor}`}>
          {session.current_stage}
        </span>
        <span className="text-gray-400">{formattedDate}</span>
      </div>
    </div>
  );
};

/**
 * Main Sidebar component
 */
export const Sidebar = ({
  currentAppState,
  isOpen,
  onToggle,
  onCreateNewSession,
  onSessionSwitch,
  sessions,
  isLoading = false,
  onDeleteSession,
  onRenameSession,
}: SidebarProps) => {
  const [searchQuery, setSearchQuery] = useState('');

  /**
   * Filter sessions based on search query
   */
  const filteredSessions = useMemo(() => {
    if (!searchQuery.trim()) return sessions;
    
    const query = searchQuery.toLowerCase();
    return sessions.filter(session => 
      session.title.toLowerCase().includes(query) ||
      session.current_stage.toLowerCase().includes(query)
    );
  }, [sessions, searchQuery]);

  /**
   * Handle new session creation
   */
  const handleCreateNewSession = useCallback(() => {
    logger.info('🆕 Creating new session from sidebar');
    onCreateNewSession();
  }, [onCreateNewSession]);

  /**
   * Handle session selection
   */
  const handleSessionSelect = useCallback((sessionId: string) => {
    logger.info('🔄 Switching to session', { sessionId, currentSession: currentAppState.idea_id });
    onSessionSwitch(sessionId);
  }, [onSessionSwitch, currentAppState.idea_id]);

  /**
   * Handle session deletion
   */
  const handleSessionDelete = useCallback((sessionId: string) => {
    if (onDeleteSession) {
      onDeleteSession(sessionId);
    }
  }, [onDeleteSession]);

  /**
   * Handle session rename
   */
  const handleSessionRename = useCallback((sessionId: string, newTitle: string) => {
    if (onRenameSession) {
      onRenameSession(sessionId, newTitle);
    }
  }, [onRenameSession]);

  return (
    <aside
      className={`
        flex flex-col h-full w-80 bg-gray-900 border-r border-gray-700 transition-transform duration-300 ease-in-out
        ${isOpen ? 'translate-x-0' : '-translate-x-full'}
        lg:translate-x-0 lg:static lg:w-80
        fixed top-0 left-0 z-50 lg:z-auto
      `}
      aria-label="Session management sidebar"
    >
      {/* Sidebar Header */}
      <div className="flex flex-col p-4 border-b border-gray-700">
        {/* Logo and Close Button */}
        <div className="flex items-center justify-between mb-4">
          <h1 className="text-xl font-bold text-white">FlowGenius</h1>
          <button
            className="lg:hidden p-2 rounded-lg hover:bg-gray-800 focus:outline-none focus:ring-2 focus:ring-emerald-500"
            onClick={onToggle}
            aria-label="Close sidebar"
          >
            <svg className="w-5 h-5 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
            </svg>
          </button>
        </div>

        {/* New Session Button */}
        <button
          className="
            flex items-center justify-center gap-2 w-full p-3 
            bg-emerald-600 hover:bg-emerald-700 active:bg-emerald-800
            text-white font-medium rounded-lg transition-colors duration-200
            focus:outline-none focus:ring-2 focus:ring-emerald-500 focus:ring-offset-2 focus:ring-offset-gray-900
            disabled:opacity-50 disabled:cursor-not-allowed
          "
          onClick={handleCreateNewSession}
          disabled={isLoading}
          aria-label="Create new session"
        >
          {isLoading ? (
            <div className="w-5 h-5 border-2 border-white/20 border-t-white rounded-full animate-spin" />
          ) : (
            <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M12 4v16m8-8H4" />
            </svg>
          )}
          New Session
        </button>

        {/* Search Bar */}
        <div className="relative mt-4">
          <input
            type="text"
            placeholder="Search sessions..."
            value={searchQuery}
            onChange={(e) => setSearchQuery(e.target.value)}
            className="
              w-full pl-10 pr-4 py-2 bg-gray-800 border border-gray-600 rounded-lg
              text-white placeholder-gray-400 text-sm
              focus:outline-none focus:ring-2 focus:ring-emerald-500 focus:border-transparent
            "
          />
          <svg 
            className="absolute left-3 top-2.5 w-4 h-4 text-gray-400" 
            fill="none" 
            stroke="currentColor" 
            viewBox="0 0 24 24"
          >
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="m21 21-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z" />
          </svg>
        </div>
      </div>

      {/* Session List */}
      <div className="flex-1 overflow-y-auto p-4">
        {isLoading && sessions.length === 0 ? (
          <div className="flex items-center justify-center py-8">
            <div className="w-6 h-6 border-2 border-gray-600 border-t-emerald-500 rounded-full animate-spin" />
          </div>
        ) : filteredSessions.length === 0 ? (
          <div className="text-center py-8">
            <p className="text-gray-400 text-sm">
              {searchQuery ? 'No sessions match your search' : 'No sessions yet'}
            </p>
            {!searchQuery && (
              <p className="text-gray-500 text-xs mt-2">
                Create your first session to get started
              </p>
            )}
          </div>
        ) : (
          <div className="space-y-2">
            {filteredSessions.map((session) => (
              <SessionItem
                key={session.id}
                session={session}
                isActive={session.id === currentAppState.idea_id}
                onSelect={() => handleSessionSelect(session.id)}
                onDelete={onDeleteSession ? () => handleSessionDelete(session.id) : undefined}
                onRename={onRenameSession ? (newTitle) => handleSessionRename(session.id, newTitle) : undefined}
              />
            ))}
          </div>
        )}
      </div>

      {/* Sidebar Footer */}
      <div className="p-4 border-t border-gray-700">
        <div className="flex items-center gap-3">
          <div className="w-8 h-8 bg-emerald-600 rounded-full flex items-center justify-center text-white text-sm font-medium">
            {currentAppState.user_id?.charAt(0).toUpperCase() || 'U'}
          </div>
          <div className="flex-1 min-w-0">
            <p className="text-sm font-medium text-white truncate">
              {currentAppState.user_id || 'Anonymous User'}
            </p>
            <p className="text-xs text-gray-400 truncate">
              {filteredSessions.length} session{filteredSessions.length !== 1 ? 's' : ''}
            </p>
          </div>
          <button
            className="p-2 rounded-lg hover:bg-gray-800 focus:outline-none focus:ring-2 focus:ring-emerald-500"
            aria-label="User settings"
          >
            <svg className="w-4 h-4 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M10.325 4.317c.426-1.756 2.924-1.756 3.35 0a1.724 1.724 0 002.573 1.066c1.543-.94 3.31.826 2.37 2.37a1.724 1.724 0 001.065 2.572c1.756.426 1.756 2.924 0 3.35a1.724 1.724 0 00-1.066 2.573c.94 1.543-.826 3.31-2.37 2.37a1.724 1.724 0 00-2.572 1.065c-.426 1.756-2.924 1.756-3.35 0a1.724 1.724 0 00-2.573-1.066c-1.543.94-3.31-.826-2.37-2.37a1.724 1.724 0 00-1.065-2.572c-1.756-.426-1.756-2.924 0-3.35a1.724 1.724 0 001.066-2.573c-.94-1.543.826-3.31 2.37-2.37.996.608 2.296.07 2.572-1.065z" />
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M15 12a3 3 0 11-6 0 3 3 0 016 0z" />
            </svg>
          </button>
        </div>
      </div>
    </aside>
  );
};

export default Sidebar;

================
File: src/services/audioService.ts
================
/**
 * Audio Service for Renderer Process
 * 
 * This service provides a clean API for audio file operations from the renderer process.
 * It communicates with the main process via IPC to handle desktop filesystem operations,
 * audio format conversion, and file management.
 * 
 * Key Features:
 * - Save audio blobs to desktop filesystem via IPC
 * - Convert audio formats for Whisper compatibility
 * - Validate audio before processing
 * - Manage temporary audio files
 * - Comprehensive error handling and logging
 */

import { logger } from '../utils/logger';
import { 
  validateAudioForWhisper, 
  calculateOptimalSettings,
  type AudioValidationResult,
  type AudioConversionConfig,
  type AudioMetadata
} from '../utils/audioUtils';

/**
 * Audio service operation result
 */
export interface AudioServiceResult<T = any> {
  success: boolean;
  data?: T;
  error?: string;
  duration?: number;
}

/**
 * Audio save result with file path and metadata
 */
export interface AudioSaveResult {
  filePath: string;
  metadata: {
    size: number;
    format: string;
    duration?: number;
  };
  validation: AudioValidationResult;
  conversionConfig?: AudioConversionConfig;
}

/**
 * Audio processing options
 */
export interface AudioProcessingOptions {
  /** Whether to validate audio for Whisper compatibility */
  validate?: boolean;
  /** Whether to convert to optimal format */
  convert?: boolean;
  /** Custom conversion configuration */
  conversionConfig?: AudioConversionConfig;
  /** Custom filename for saved audio */
  filename?: string;
  /** Whether to cleanup original file after conversion */
  cleanupOriginal?: boolean;
}

/**
 * Audio service class for renderer process
 */
export class AudioService {
  private processingQueue: Map<string, Promise<AudioServiceResult>> = new Map();

  /**
   * Check if window.electron is available
   */
  private checkElectronAPI(): boolean {
    if (typeof window === 'undefined' || !window.electron) {
      logger.error('❌ Electron API not available in renderer process');
      return false;
    }
    return true;
  }

  /**
   * Save audio blob to desktop filesystem
   * 
   * @param audioBlob - Audio blob to save
   * @param options - Processing options
   * @returns Promise resolving to save result
   */
  async saveAudioBlob(
    audioBlob: Blob, 
    options: AudioProcessingOptions = {}
  ): Promise<AudioServiceResult<AudioSaveResult>> {
    const startTime = Date.now();
    const operationId = `save_${Date.now()}_${Math.random().toString(36).substring(2, 8)}`;

    logger.info('💾 AudioService: Saving audio blob', {
      operationId,
      blobSize: audioBlob.size,
      blobType: audioBlob.type,
      options
    });

    try {
      // Check Electron API availability
      if (!this.checkElectronAPI()) {
        throw new Error('Electron API not available');
      }

      // Validate options
      const processOptions = {
        validate: true,
        convert: false,
        cleanupOriginal: false,
        ...options
      };

      // Convert blob to buffer
      const arrayBuffer = await audioBlob.arrayBuffer();
      const buffer = Buffer.from(arrayBuffer);

      // Validate audio if requested
      let validation: AudioValidationResult | undefined;
      if (processOptions.validate) {
        validation = await validateAudioForWhisper(audioBlob);
        logger.info('🔍 Audio validation completed', {
          operationId,
          isValid: validation.isValid,
          errors: validation.errors.length,
          warnings: validation.warnings.length
        });
      }

      // Save to filesystem via IPC
      const saveResult = await window.electron.audio.saveAudioFile(
        buffer,
        processOptions.filename,
        audioBlob.type
      );

      if (!saveResult.success) {
        throw new Error(saveResult.error || 'Failed to save audio file');
      }

      let finalFilePath = saveResult.filePath!;
      let conversionConfig: AudioConversionConfig | undefined;

      // Convert if requested and validation suggests it
      if (processOptions.convert && validation && finalFilePath) {
        const shouldConvert = !validation.isValid || 
                             validation.warnings.length > 0 ||
                             audioBlob.type !== 'audio/wav';

        if (shouldConvert) {
          const metadata: AudioMetadata = validation.metadata!;
          conversionConfig = processOptions.conversionConfig || calculateOptimalSettings(metadata);
          
          logger.info('🔄 Converting audio for optimal format', {
            operationId,
            originalFormat: metadata.format,
            targetConfig: conversionConfig
          });

          const convertResult = await window.electron.audio.convertAudioFile(
            finalFilePath,
            conversionConfig
          );

          if (convertResult.success && convertResult.filePath) {
            // Cleanup original if requested
            if (processOptions.cleanupOriginal) {
              await window.electron.audio.deleteAudioFile(finalFilePath);
            }
            finalFilePath = convertResult.filePath;
          } else {
            logger.warn('⚠️ Audio conversion failed, using original file', {
              operationId,
              error: convertResult.error
            });
          }
        }
      }

      const result: AudioSaveResult = {
        filePath: finalFilePath,
        metadata: saveResult.metadata || {
          size: audioBlob.size,
          format: audioBlob.type.split('/')[1] || 'unknown'
        },
        validation: validation || {
          isValid: true,
          errors: [],
          warnings: [],
          recommendations: [],
          metadata: {
            duration: 0,
            fileSize: audioBlob.size,
            mimeType: audioBlob.type,
            format: audioBlob.type.split('/')[1] || 'unknown'
          }
        },
        conversionConfig
      };

      const duration = Date.now() - startTime;
      logger.info('✅ AudioService: Audio blob saved successfully', {
        operationId,
        filePath: finalFilePath,
        size: result.metadata.size,
        duration
      });

      return {
        success: true,
        data: result,
        duration
      };

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      const duration = Date.now() - startTime;
      
      logger.error('❌ AudioService: Failed to save audio blob', {
        operationId,
        error: errorMsg,
        duration
      });

      return {
        success: false,
        error: errorMsg,
        duration
      };
    }
  }

  /**
   * Process multiple audio blobs in sequence
   * 
   * @param audioBlobs - Array of audio blobs to process
   * @param options - Processing options
   * @returns Promise resolving to array of results
   */
  async processBatchAudioBlobs(
    audioBlobs: Blob[],
    options: AudioProcessingOptions = {}
  ): Promise<AudioServiceResult<AudioSaveResult[]>> {
    const startTime = Date.now();
    const operationId = `batch_${Date.now()}_${audioBlobs.length}`;

    logger.info('📦 AudioService: Processing batch of audio blobs', {
      operationId,
      count: audioBlobs.length,
      totalSize: audioBlobs.reduce((sum, blob) => sum + blob.size, 0)
    });

    try {
      const results: AudioSaveResult[] = [];
      const errors: string[] = [];

      for (let i = 0; i < audioBlobs.length; i++) {
        const blob = audioBlobs[i];
        const blobOptions = {
          ...options,
          filename: options.filename ? `${options.filename}_${i + 1}` : undefined
        };

        let result: AudioServiceResult<AudioSaveResult>;
        
        if (blob) {
          result = await this.saveAudioBlob(blob, blobOptions);
        } else {
          result = {
            success: false,
            error: 'Empty blob'
          };
        }
        
        if (result.success && result.data) {
          results.push(result.data);
        } else {
          errors.push(`Blob ${i + 1}: ${result.error}`);
        }
      }

      const duration = Date.now() - startTime;
      
      if (errors.length === 0) {
        logger.info('✅ AudioService: Batch processing completed successfully', {
          operationId,
          processed: results.length,
          duration
        });

        return {
          success: true,
          data: results,
          duration
        };
      } else {
        logger.warn('⚠️ AudioService: Batch processing completed with errors', {
          operationId,
          successful: results.length,
          failed: errors.length,
          errors: errors.slice(0, 3), // Log first 3 errors
          duration
        });

        return {
          success: false,
          error: `${errors.length} of ${audioBlobs.length} failed: ${errors.join('; ')}`,
          duration
        };
      }

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      const duration = Date.now() - startTime;
      
      logger.error('❌ AudioService: Batch processing failed', {
        operationId,
        error: errorMsg,
        duration
      });

      return {
        success: false,
        error: errorMsg,
        duration
      };
    }
  }

  /**
   * Get audio file information from filesystem
   * 
   * @param filePath - Path to audio file
   * @returns Promise resolving to file information
   */
  async getAudioFileInfo(filePath: string): Promise<AudioServiceResult> {
    logger.debug('📊 AudioService: Getting audio file info', { filePath });

    try {
      if (!this.checkElectronAPI()) {
        throw new Error('Electron API not available');
      }

      const result = await window.electron.audio.getAudioFileInfo(filePath);
      
      if (result.success) {
        logger.info('✅ AudioService: File info retrieved', {
          filePath,
          metadata: result.metadata
        });
      }

      return result;

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      
      logger.error('❌ AudioService: Failed to get file info', {
        filePath,
        error: errorMsg
      });

      return {
        success: false,
        error: errorMsg
      };
    }
  }

  /**
   * Delete audio file from filesystem
   * 
   * @param filePath - Path to file to delete
   * @returns Promise resolving to success status
   */
  async deleteAudioFile(filePath: string): Promise<AudioServiceResult> {
    logger.debug('🗑️ AudioService: Deleting audio file', { filePath });

    try {
      if (!this.checkElectronAPI()) {
        throw new Error('Electron API not available');
      }

      const result = await window.electron.audio.deleteAudioFile(filePath);
      
      if (result.success) {
        logger.info('✅ AudioService: File deleted successfully', { filePath });
      }

      return result;

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      
      logger.error('❌ AudioService: Failed to delete file', {
        filePath,
        error: errorMsg
      });

      return {
        success: false,
        error: errorMsg
      };
    }
  }

  /**
   * Clean up old temporary audio files
   * 
   * @param maxAge - Maximum age in milliseconds (default: 1 hour)
   * @returns Promise resolving to cleanup statistics
   */
  async cleanupTempFiles(maxAge?: number): Promise<AudioServiceResult> {
    logger.debug('🧹 AudioService: Cleaning up temporary files', { maxAge });

    try {
      if (!this.checkElectronAPI()) {
        throw new Error('Electron API not available');
      }

      const result = await window.electron.audio.cleanupOldFiles(maxAge);
      
      if (result.success) {
        logger.info('✅ AudioService: Cleanup completed', {
          deletedCount: result.deletedCount,
          errors: result.errors?.length || 0
        });
      }

      return result;

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      
      logger.error('❌ AudioService: Cleanup failed', { error: errorMsg });

      return {
        success: false,
        error: errorMsg
      };
    }
  }

  /**
   * Get temporary directory path
   * 
   * @returns Promise resolving to temp directory path
   */
  async getTempDirectory(): Promise<AudioServiceResult<string>> {
    logger.debug('📁 AudioService: Getting temp directory path');

    try {
      if (!this.checkElectronAPI()) {
        throw new Error('Electron API not available');
      }

      const result = await window.electron.audio.getTempDirectory();
      
      return {
        success: true,
        data: result
      };

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      
      logger.error('❌ AudioService: Failed to get temp directory', { error: errorMsg });

      return {
        success: false,
        error: errorMsg
      };
    }
  }

  /**
   * Check if audio service is available
   * 
   * @returns Whether the service is available
   */
  isAvailable(): boolean {
    return this.checkElectronAPI() && 
           typeof window.electron.audio === 'object' &&
           typeof window.electron.audio.saveAudioFile === 'function';
  }

  /**
   * Get service status and capabilities
   * 
   * @returns Service status information
   */
  getStatus(): {
    available: boolean;
    capabilities: string[];
    activeOperations: number;
  } {
    const available = this.isAvailable();
    
    const capabilities = available ? [
      'saveAudioFile',
      'convertAudioFile', 
      'getAudioFileInfo',
      'deleteAudioFile',
      'cleanupOldFiles',
      'getTempDirectory'
    ] : [];

    return {
      available,
      capabilities,
      activeOperations: this.processingQueue.size
    };
  }
}

// Create and export global audio service instance
export const audioService = new AudioService();

// Export AudioService class for dependency injection if needed
export default AudioService;

================
File: src/services/langgraphService.ts
================
/**
 * LangGraph Service for Browser/Renderer Process
 * 
 * This service provides a clean API for interacting with the LangGraph
 * workflow engine running in the Electron main process via IPC.
 * 
 * Key Features:
 * - Type-safe IPC communication
 * - Error handling and retry logic
 * - Performance monitoring
 * - Session management
 */

import { AppState } from '../types/AppState';
import { logger } from '../utils/logger';

/**
 * IPC response type
 */
interface IPCResponse<T> {
  success: boolean;
  data?: T;
  error?: string;
  duration?: number;
}

/**
 * Workflow metrics type
 */
interface WorkflowMetrics {
  workflowId: string;
  duration: number;
  eventCount: number;
  errorCount: number;
  nodeExecutions: Record<string, { count: number; avgDuration: number }>;
  stateUpdateCount: number;
}

/**
 * Validation result type
 */
interface ValidationResult {
  isValid: boolean;
  issues: string[];
}

/**
 * Global window interface extension for LangGraph API
 */
declare global {
  interface Window {
    langgraph: {
      execute: (state: AppState) => Promise<IPCResponse<AppState>>;
      createSession: (ideaId: string, userId?: string) => Promise<IPCResponse<AppState>>;
      validateState: (state: AppState) => Promise<IPCResponse<ValidationResult>>;
      getMetrics: (ideaId: string) => Promise<IPCResponse<WorkflowMetrics | null>>;
      clearSession: (ideaId: string) => Promise<IPCResponse<void>>;
    };
  }
}

/**
 * LangGraph service class
 */
class LangGraphService {
  private retryCount = 3;
  private retryDelay = 1000; // 1 second

  /**
   * Execute workflow with retry logic
   */
  async executeWorkflow(state: AppState): Promise<AppState> {
    const startTime = Date.now();
    
    logger.info('🚀 LangGraphService: Executing workflow', {
      ideaId: state.idea_id,
      stage: state.current_stage,
      action: state.last_user_action
    });

    let lastError: string | undefined;
    
    for (let attempt = 1; attempt <= this.retryCount; attempt++) {
      try {
        const response = await window.langgraph.execute(state);
        
        if (response.success && response.data) {
          const duration = Date.now() - startTime;
          
          logger.info('✅ LangGraphService: Workflow execution completed', {
            ideaId: response.data.idea_id,
            duration,
            ipcDuration: response.duration,
            attempt
          });
          
          return response.data;
        } else {
          lastError = response.error || 'Unknown error';
          throw new Error(lastError);
        }
        
      } catch (error) {
        const errorMessage = error instanceof Error ? error.message : String(error);
        lastError = errorMessage;
        
        logger.warn(`⚠️ LangGraphService: Workflow execution attempt ${attempt} failed`, {
          error: errorMessage,
          attempt,
          willRetry: attempt < this.retryCount
        });
        
        if (attempt < this.retryCount) {
          await this.delay(this.retryDelay * attempt); // Exponential backoff
        }
      }
    }
    
    throw new Error(`Workflow execution failed after ${this.retryCount} attempts: ${lastError}`);
  }

  /**
   * Create a new workflow session
   */
  async createSession(ideaId: string, userId?: string): Promise<AppState> {
    logger.info('🆕 LangGraphService: Creating workflow session', { ideaId, userId });
    
    try {
      const response = await window.langgraph.createSession(ideaId, userId);
      
      if (response.success && response.data) {
        logger.info('✅ LangGraphService: Session created successfully', {
          ideaId: response.data.idea_id
        });
        
        return response.data;
      } else {
        throw new Error(response.error || 'Failed to create session');
      }
      
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error('❌ LangGraphService: Session creation failed', { error: errorMessage });
      throw error;
    }
  }

  /**
   * Validate workflow state
   */
  async validateState(state: AppState): Promise<ValidationResult> {
    logger.debug('🔍 LangGraphService: Validating state', { ideaId: state.idea_id });
    
    try {
      const response = await window.langgraph.validateState(state);
      
      if (response.success && response.data) {
        return response.data;
      } else {
        throw new Error(response.error || 'Validation failed');
      }
      
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error('❌ LangGraphService: State validation failed', { error: errorMessage });
      throw error;
    }
  }

  /**
   * Get workflow metrics for a session
   */
  async getMetrics(ideaId: string): Promise<WorkflowMetrics | null> {
    logger.debug('📊 LangGraphService: Getting workflow metrics', { ideaId });
    
    try {
      const response = await window.langgraph.getMetrics(ideaId);
      
      if (response.success) {
        return response.data || null;
      } else {
        throw new Error(response.error || 'Failed to get metrics');
      }
      
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error('❌ LangGraphService: Failed to get metrics', { error: errorMessage });
      throw error;
    }
  }

  /**
   * Clear session data
   */
  async clearSession(ideaId: string): Promise<void> {
    logger.info('🗑️ LangGraphService: Clearing session', { ideaId });
    
    try {
      const response = await window.langgraph.clearSession(ideaId);
      
      if (!response.success) {
        throw new Error(response.error || 'Failed to clear session');
      }
      
      logger.info('✅ LangGraphService: Session cleared successfully', { ideaId });
      
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error('❌ LangGraphService: Failed to clear session', { error: errorMessage });
      throw error;
    }
  }

  /**
   * Helper method for delays
   */
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// Export singleton instance
export const langgraphService = new LangGraphService();

// Export types for convenience
export type { WorkflowMetrics, ValidationResult };

================
File: src/services/README.md
================
# Services Directory

This directory contains all service modules for external API integrations and business logic in the FlowGenius application.

## Directory Structure

### API Services
- `openaiService.ts` - Service for handling OpenAI GPT-4o API calls
- `whisperService.ts` - Service for handling Whisper API calls (voice-to-text)
- `supabaseService.ts` - Service for database operations (ideas, chat_messages, prompts)

### Service Guidelines

1. **File Naming**: Use camelCase with "Service" suffix (e.g., `openaiService.ts`)
2. **Structure**: Each service should have:
   - Main service file with exported functions
   - Corresponding test file (`serviceName.test.ts`)
   - Type definitions for API requests/responses
3. **Error Handling**: All services must include proper error handling and logging
4. **Documentation**: All functions must include JSDoc comments
5. **Configuration**: Use environment variables for API keys and endpoints

## Testing

- All services must have comprehensive unit tests
- Tests should cover success cases, error cases, and edge cases
- Use mocking for external API calls in tests
- Test files should be named `serviceName.test.ts`

================
File: src/services/whisperService.integration.test.ts
================
/**
 * WhisperService Integration Test
 * 
 * This test requires a real OpenAI API key and can be run manually to verify
 * that the WhisperService actually works with the OpenAI Whisper API.
 * 
 * To run this test:
 * 1. Set OPENAI_API_KEY environment variable
 * 2. Run: npm test -- src/services/whisperService.integration.test.ts
 * 
 * Note: This will make actual API calls and may incur costs!
 */

import { describe, it, expect, beforeEach } from 'vitest';
import { WhisperService, createWhisperService } from './whisperService';
import { logger } from '../utils/logger';

// Skip these tests unless OPENAI_API_KEY is provided
const shouldRunIntegrationTests = !!process.env.OPENAI_API_KEY;
const describeIf = shouldRunIntegrationTests ? describe : describe.skip;

describeIf('WhisperService Integration Tests', () => {
  let whisperService: WhisperService;

  beforeEach(() => {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('OPENAI_API_KEY environment variable required for integration tests');
    }
    
    console.log('🎙️ Setting up WhisperService integration test');
    whisperService = createWhisperService();
  });

  /**
   * Create a test audio blob with actual audio data
   * This creates a minimal WAV file with a 1-second 440Hz tone (A note)
   */
  function createTestAudioBlob(): Blob {
    console.log('🎵 Creating test audio blob with 440Hz tone');
    
    const sampleRate = 16000; // Optimal for Whisper
    const duration = 2; // 2 seconds
    const frequency = 440; // A note
    const samples = sampleRate * duration;
    
    // Create WAV file buffer
    const buffer = new ArrayBuffer(44 + samples * 2);
    const view = new DataView(buffer);
    
    // WAV header
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + samples * 2, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true); // PCM
    view.setUint16(22, 1, true); // Mono
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 2, true);
    view.setUint16(32, 2, true);
    view.setUint16(34, 16, true);
    writeString(36, 'data');
    view.setUint32(40, samples * 2, true);
    
    // Generate 440Hz sine wave
    for (let i = 0; i < samples; i++) {
      const sample = Math.sin(2 * Math.PI * frequency * i / sampleRate);
      const value = Math.round(sample * 32767 * 0.5); // 50% volume
      view.setInt16(44 + i * 2, value, true);
    }
    
    const blob = new Blob([buffer], { type: 'audio/wav' });
    console.log(`✅ Created ${blob.size} byte WAV file with ${duration}s of ${frequency}Hz tone`);
    
    return blob;
  }

  /**
   * Create a test audio blob with speech-like content
   * This creates a more complex waveform that might be better recognized by Whisper
   */
  function createSpeechLikeAudioBlob(): Blob {
    console.log('🗣️ Creating speech-like test audio blob');
    
    const sampleRate = 16000;
    const duration = 3; // 3 seconds
    const samples = sampleRate * duration;
    
    // Create WAV file buffer
    const buffer = new ArrayBuffer(44 + samples * 2);
    const view = new DataView(buffer);
    
    // WAV header (same as above)
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + samples * 2, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, 1, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 2, true);
    view.setUint16(32, 2, true);
    view.setUint16(34, 16, true);
    writeString(36, 'data');
    view.setUint32(40, samples * 2, true);
    
    // Generate complex waveform with multiple frequencies (like speech formants)
    for (let i = 0; i < samples; i++) {
      const t = i / sampleRate;
      
      // Mix multiple sine waves to create speech-like formants
      const f1 = 250 + 50 * Math.sin(2 * Math.PI * 3 * t); // First formant
      const f2 = 1200 + 200 * Math.sin(2 * Math.PI * 7 * t); // Second formant
      const f3 = 2400 + 100 * Math.sin(2 * Math.PI * 11 * t); // Third formant
      
      const sample = 
        0.6 * Math.sin(2 * Math.PI * f1 * t) +
        0.3 * Math.sin(2 * Math.PI * f2 * t) +
        0.1 * Math.sin(2 * Math.PI * f3 * t);
      
      // Add some noise and envelope
      const envelope = Math.exp(-t * 0.5) * (1 + 0.1 * Math.random());
      const value = Math.round(sample * envelope * 16383); // Lower volume
      
      view.setInt16(44 + i * 2, Math.max(-32768, Math.min(32767, value)), true);
    }
    
    const blob = new Blob([buffer], { type: 'audio/wav' });
    console.log(`✅ Created ${blob.size} byte speech-like WAV file`);
    
    return blob;
  }

  it('should connect to OpenAI Whisper API', async () => {
    console.log('🔍 Testing connection to OpenAI Whisper API');
    
    const result = await whisperService.testConnection();
    
    expect(result.success).toBe(true);
    expect(result.error).toBeUndefined();
    
    console.log('✅ Successfully connected to OpenAI Whisper API');
  }, 30000); // 30 second timeout

  it('should transcribe simple audio tone', async () => {
    console.log('🎵 Testing transcription of simple audio tone');
    
    const audioBlob = createTestAudioBlob();
    
    const result = await whisperService.transcribeBlob(audioBlob, {
      responseFormat: 'verbose_json',
      validateAudio: true
    });
    
    console.log('📝 Transcription result:', {
      success: result.success,
      textLength: result.data?.text?.length || 0,
      text: result.data?.text?.substring(0, 100) + '...',
      language: result.data?.language,
      duration: result.data?.duration,
      processingTime: result.data?.metadata.processingTime
    });
    
    expect(result.success).toBe(true);
    expect(result.data).toBeDefined();
    expect(result.data!.text).toBeDefined();
    expect(result.data!.metadata.fileSize).toBe(audioBlob.size);
    expect(result.data!.metadata.audioValidation.isValid).toBe(true);
    
    console.log('✅ Successfully transcribed audio tone');
  }, 60000); // 60 second timeout

  it('should transcribe speech-like audio', async () => {
    console.log('🗣️ Testing transcription of speech-like audio');
    
    const audioBlob = createSpeechLikeAudioBlob();
    
    const result = await whisperService.transcribeBlob(audioBlob, {
      responseFormat: 'verbose_json',
      validateAudio: true,
      language: 'en' // Hint that it's English
    });
    
    console.log('📝 Speech-like transcription result:', {
      success: result.success,
      textLength: result.data?.text?.length || 0,
      text: result.data?.text,
      language: result.data?.language,
      duration: result.data?.duration,
      segments: result.data?.segments?.length || 0,
      processingTime: result.data?.metadata.processingTime
    });
    
    expect(result.success).toBe(true);
    expect(result.data).toBeDefined();
    expect(result.data!.text).toBeDefined();
    
    console.log('✅ Successfully transcribed speech-like audio');
  }, 60000); // 60 second timeout

  it('should handle audio validation during transcription', async () => {
    console.log('🔍 Testing audio validation integration');
    
    const audioBlob = createTestAudioBlob();
    
    const result = await whisperService.transcribeBlob(audioBlob, {
      validateAudio: true,
      responseFormat: 'text'
    });
    
    expect(result.success).toBe(true);
    expect(result.data?.metadata.audioValidation).toBeDefined();
    expect(result.data?.metadata.audioValidation.isValid).toBe(true);
    expect(result.data?.metadata.audioValidation.errors).toHaveLength(0);
    
    console.log('📊 Audio validation results:', {
      isValid: result.data?.metadata.audioValidation.isValid,
      warnings: result.data?.metadata.audioValidation.warnings.length,
      recommendations: result.data?.metadata.audioValidation.recommendations.length
    });
    
    console.log('✅ Audio validation integration working correctly');
  }, 60000);

  it('should track request statistics', async () => {
    console.log('📊 Testing request statistics tracking');
    
    const initialStatus = whisperService.getStatus();
    const initialCount = initialStatus.requestCount;
    
    const audioBlob = createTestAudioBlob();
    
    await whisperService.transcribeBlob(audioBlob, {
      validateAudio: false,
      responseFormat: 'text'
    });
    
    const finalStatus = whisperService.getStatus();
    
    expect(finalStatus.requestCount).toBe(initialCount + 1);
    expect(finalStatus.lastRequestTime).toBeGreaterThan(initialStatus.lastRequestTime);
    
    console.log('📈 Request statistics:', {
      initialCount,
      finalCount: finalStatus.requestCount,
      lastRequestTime: new Date(finalStatus.lastRequestTime).toISOString()
    });
    
    console.log('✅ Request statistics tracking working correctly');
  }, 60000);

  it('should handle different response formats', async () => {
    console.log('📝 Testing different response formats');
    
    const audioBlob = createTestAudioBlob();
    
    // Test text format
    const textResult = await whisperService.transcribeBlob(audioBlob, {
      responseFormat: 'text',
      validateAudio: false
    });
    
    expect(textResult.success).toBe(true);
    expect(typeof textResult.data?.text).toBe('string');
    
    // Test verbose_json format
    const jsonResult = await whisperService.transcribeBlob(audioBlob, {
      responseFormat: 'verbose_json',
      validateAudio: false
    });
    
    expect(jsonResult.success).toBe(true);
    expect(jsonResult.data?.language).toBeDefined();
    expect(jsonResult.data?.duration).toBeDefined();
    
    console.log('📋 Response format comparison:', {
      textLength: textResult.data?.text?.length || 0,
      jsonText: jsonResult.data?.text?.length || 0,
      hasLanguage: !!jsonResult.data?.language,
      hasDuration: !!jsonResult.data?.duration,
      hasSegments: !!jsonResult.data?.segments
    });
    
    console.log('✅ Different response formats working correctly');
  }, 120000); // 2 minute timeout for multiple requests
});

// Instructions for running the test
if (!shouldRunIntegrationTests) {
  console.log(`
🚫 Integration tests skipped - no OPENAI_API_KEY provided

To run these tests:
1. Set your OpenAI API key: export OPENAI_API_KEY="your-key-here"
2. Run the tests: npm test -- src/services/whisperService.integration.test.ts

⚠️  Warning: These tests make actual API calls and may incur costs!
  `);
}

================
File: src/services/whisperService.test.ts
================
/**
 * Comprehensive Unit Tests for WhisperService
 * 
 * Tests all whisper service functionality including:
 * - Service initialization and configuration
 * - Audio transcription (blob and file)
 * - Retry logic with exponential backoff
 * - Error handling scenarios
 * - Rate limiting and quota management
 * - Integration with audio validation utilities
 * - Connection testing
 */

import { describe, it, expect, beforeEach, afterEach, vi, type MockedFunction } from 'vitest';
import { 
  WhisperService, 
  createWhisperService,
  type WhisperConfig,
  type WhisperTranscriptionOptions,
  type WhisperTranscriptionResult
} from './whisperService';
import { logger } from '../utils/logger';

// Mock the logger to prevent console spam during tests
vi.mock('../utils/logger', () => ({
  logger: {
    debug: vi.fn(),
    info: vi.fn(),
    warn: vi.fn(),
    error: vi.fn()
  }
}));

// Mock audio utilities
vi.mock('../utils/audioUtils', () => ({
  validateAudioForWhisper: vi.fn(),
  createProcessingSummary: vi.fn(),
  WHISPER_CONSTRAINTS: {
    MAX_FILE_SIZE: 25 * 1024 * 1024,
    OPTIMAL_SAMPLE_RATE: 16000,
    OPTIMAL_CHANNELS: 1,
    OPTIMAL_BIT_DEPTH: 16,
    MAX_DURATION_SECONDS: 1800,
    SUPPORTED_MIME_TYPES: [
      'audio/wav',
      'audio/mp3',
      'audio/mpeg',
      'audio/mp4',
      'audio/m4a',
      'audio/webm',
      'audio/ogg'
    ],
    RECOMMENDED_MIME_TYPE: 'audio/wav'
  }
}));

// Import mocked functions
import { validateAudioForWhisper, createProcessingSummary } from '../utils/audioUtils';

describe('WhisperService', () => {
  let mockFetch: MockedFunction<typeof fetch>;
  let whisperService: WhisperService;
  let validConfig: WhisperConfig;
  let mockAudioBlob: Blob;

  beforeEach(() => {
    console.log('🧪 Setting up WhisperService test');
    
    // Reset all mocks
    vi.clearAllMocks();
    
    // Mock fetch globally
    mockFetch = vi.fn() as MockedFunction<typeof fetch>;
    global.fetch = mockFetch;
    
    // Mock AbortSignal.timeout
    global.AbortSignal = {
      timeout: vi.fn((timeout: number) => ({
        addEventListener: vi.fn(),
        removeEventListener: vi.fn(),
        aborted: false,
        reason: undefined
      }))
    } as any;

    // Setup valid configuration
    validConfig = {
      apiKey: 'test-api-key-12345',
      baseUrl: 'https://api.openai.com/v1',
      timeout: 30000,
      maxRetries: 3,
      retryDelay: 1000,
      organization: 'test-org'
    };

    // Create mock audio blob
    mockAudioBlob = new Blob(['mock audio data'], { type: 'audio/wav' });

    // Create service instance
    whisperService = new WhisperService(validConfig);

    // Setup default audio validation mock
    (validateAudioForWhisper as MockedFunction<typeof validateAudioForWhisper>).mockResolvedValue({
      isValid: true,
      errors: [],
      warnings: [],
      recommendations: [],
      metadata: {
        duration: 60,
        fileSize: mockAudioBlob.size,
        mimeType: 'audio/wav',
        format: 'wav'
      }
    });

    // Setup processing summary mock
    (createProcessingSummary as MockedFunction<typeof createProcessingSummary>).mockReturnValue({
      original: { format: 'wav', size: '1.00MB' },
      validation: { isValid: true, errors: 0 }
    });
  });

  afterEach(() => {
    // Clean up mocks
    vi.restoreAllMocks();
  });

  describe('Service Initialization', () => {
    it('should initialize with valid configuration', () => {
      console.log('🧪 Testing valid service initialization');
      
      expect(whisperService).toBeInstanceOf(WhisperService);
      
      const status = whisperService.getStatus();
      expect(status.config.baseUrl).toBe(validConfig.baseUrl);
      expect(status.config.timeout).toBe(validConfig.timeout);
      expect(status.config.maxRetries).toBe(validConfig.maxRetries);
      expect(status.config.hasApiKey).toBe(true);
      expect(status.requestCount).toBe(0);
    });

    it('should throw error without API key', () => {
      console.log('🧪 Testing initialization without API key');
      
      expect(() => {
        new WhisperService({ apiKey: '' });
      }).toThrow('OpenAI API key is required for WhisperService');
    });

    it('should use default configuration values', () => {
      console.log('🧪 Testing default configuration values');
      
      const minimalConfig = { apiKey: 'test-key' };
      const service = new WhisperService(minimalConfig);
      
      const status = service.getStatus();
      expect(status.config.baseUrl).toBe('https://api.openai.com/v1');
      expect(status.config.timeout).toBe(30000);
      expect(status.config.maxRetries).toBe(3);
    });
  });

  describe('Audio Blob Transcription', () => {
    it('should successfully transcribe audio blob', async () => {
      console.log('🧪 Testing successful blob transcription');
      
      // Mock successful API response
      const mockResponse = {
        text: 'Hello, this is a test transcription.',
        language: 'en',
        duration: 3.5,
        segments: [{
          id: 0,
          seek: 0,
          start: 0.0,
          end: 3.5,
          text: 'Hello, this is a test transcription.',
          tokens: [1, 2, 3],
          temperature: 0,
          avgLogprob: -0.5,
          compressionRatio: 1.2,
          noSpeechProb: 0.1
        }]
      };

      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve(mockResponse)
      } as Response);

      const result = await whisperService.transcribeBlob(mockAudioBlob);

      expect(result.success).toBe(true);
      expect(result.data).toBeDefined();
      expect(result.data!.text).toBe(mockResponse.text);
      expect(result.data!.language).toBe(mockResponse.language);
      expect(result.data!.duration).toBe(mockResponse.duration);
      expect(result.data!.segments).toEqual(mockResponse.segments);
      expect(result.data!.metadata.fileSize).toBe(mockAudioBlob.size);
      expect(result.retryCount).toBe(0);

      // Verify API call was made correctly
      expect(mockFetch).toHaveBeenCalledTimes(1);
      const [url, options] = mockFetch.mock.calls[0];
      expect(url).toBe('https://api.openai.com/v1/audio/transcriptions');
      expect(options?.method).toBe('POST');
      expect(options?.headers).toMatchObject({
        'Authorization': 'Bearer test-api-key-12345',
        'OpenAI-Organization': 'test-org'
      });
    });

    it('should handle audio validation failure', async () => {
      console.log('🧪 Testing audio validation failure');
      
      // Mock validation failure
      (validateAudioForWhisper as MockedFunction<typeof validateAudioForWhisper>).mockResolvedValueOnce({
        isValid: false,
        errors: ['File size exceeds limit', 'Unsupported format'],
        warnings: [],
        recommendations: ['Convert to WAV format'],
        metadata: {
          duration: 60,
          fileSize: mockAudioBlob.size,
          mimeType: 'audio/flac',
          format: 'flac'
        }
      });

      const result = await whisperService.transcribeBlob(mockAudioBlob);

      expect(result.success).toBe(false);
      expect(result.error).toContain('Audio validation failed');
      expect(result.error).toContain('File size exceeds limit');
      expect(result.error).toContain('Unsupported format');
      
      // Should not make API call if validation fails
      expect(mockFetch).not.toHaveBeenCalled();
    });

    it('should skip validation when disabled', async () => {
      console.log('🧪 Testing transcription with validation disabled');
      
      // Mock successful API response
      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({ text: 'Test transcription' })
      } as Response);

      const options: WhisperTranscriptionOptions = {
        validateAudio: false,
        responseFormat: 'text'
      };

      const result = await whisperService.transcribeBlob(mockAudioBlob, options);

      expect(result.success).toBe(true);
      expect(validateAudioForWhisper).not.toHaveBeenCalled();
      expect(mockFetch).toHaveBeenCalledTimes(1);
    });
  });

  describe('Error Handling and Retry Logic', () => {
    it('should retry on retryable errors', async () => {
      console.log('🧪 Testing retry logic on retryable errors');
      
      // Mock rate limit error followed by success
      mockFetch
        .mockRejectedValueOnce(new Error('Rate limit exceeded'))
        .mockRejectedValueOnce(new Error('Temporary server error'))
        .mockResolvedValueOnce({
          ok: true,
          json: () => Promise.resolve({ text: 'Success after retries' })
        } as Response);

      const result = await whisperService.transcribeBlob(mockAudioBlob, { validateAudio: false });

      expect(result.success).toBe(true);
      expect(result.data!.text).toBe('Success after retries');
      expect(result.retryCount).toBe(2); // Two failed attempts, third succeeded
      expect(mockFetch).toHaveBeenCalledTimes(3);
    });

    it('should not retry on non-retryable errors', async () => {
      console.log('🧪 Testing non-retryable error handling');
      
      mockFetch.mockRejectedValueOnce(new Error('Unauthorized: Invalid API key'));

      const result = await whisperService.transcribeBlob(mockAudioBlob, { validateAudio: false });

      expect(result.success).toBe(false);
      expect(result.error).toContain('Invalid API key');
      expect(mockFetch).toHaveBeenCalledTimes(1); // No retries
    });

    it('should handle HTTP error responses', async () => {
      console.log('🧪 Testing HTTP error response handling');
      
      const errorResponse = {
        error: {
          message: 'Audio file is too large',
          type: 'invalid_request_error'
        }
      };

      mockFetch.mockResolvedValueOnce({
        ok: false,
        status: 400,
        statusText: 'Bad Request',
        text: () => Promise.resolve(JSON.stringify(errorResponse))
      } as unknown as Response);

      const result = await whisperService.transcribeBlob(mockAudioBlob, { validateAudio: false });

      expect(result.success).toBe(false);
      expect(result.error).toContain('Audio file is too large');
    });

    it('should stop retrying after max attempts', async () => {
      console.log('🧪 Testing max retry attempts');
      
      const error = new Error('Persistent server error');
      mockFetch.mockRejectedValue(error);

      const result = await whisperService.transcribeBlob(mockAudioBlob, { validateAudio: false });

      expect(result.success).toBe(false);
      expect(result.error).toBe('Persistent server error');
      expect(result.retryCount).toBe(3); // maxRetries = 3
      expect(mockFetch).toHaveBeenCalledTimes(4); // Initial + 3 retries
    });
  });

  describe('Service Statistics and Status', () => {
    it('should track request statistics', async () => {
      console.log('🧪 Testing request statistics tracking');
      
      mockFetch.mockResolvedValue({
        ok: true,
        json: () => Promise.resolve({ text: 'Test' })
      } as Response);

      const initialStatus = whisperService.getStatus();
      expect(initialStatus.requestCount).toBe(0);
      expect(initialStatus.lastRequestTime).toBe(0);

      await whisperService.transcribeBlob(mockAudioBlob, { validateAudio: false });

      const updatedStatus = whisperService.getStatus();
      expect(updatedStatus.requestCount).toBe(1);
      expect(updatedStatus.lastRequestTime).toBeGreaterThan(0);
    });

    it('should provide accurate configuration status', () => {
      console.log('🧪 Testing configuration status');
      
      const status = whisperService.getStatus();
      
      expect(status.config.baseUrl).toBe(validConfig.baseUrl);
      expect(status.config.timeout).toBe(validConfig.timeout);
      expect(status.config.maxRetries).toBe(validConfig.maxRetries);
      expect(status.config.hasApiKey).toBe(true);
    });
  });

  describe('Connection Testing', () => {
    it('should successfully test connection', async () => {
      console.log('🧪 Testing successful connection test');
      
      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({ text: '' })
      } as Response);

      const result = await whisperService.testConnection();

      expect(result.success).toBe(true);
      expect(result.error).toBeUndefined();
      expect(mockFetch).toHaveBeenCalledTimes(1);
    });

    it('should handle connection test failure', async () => {
      console.log('🧪 Testing connection test failure');
      
      // Mock error that occurs before response is available
      mockFetch.mockImplementationOnce(() => Promise.reject(new Error('Network error')));

      const result = await whisperService.testConnection();

      expect(result.success).toBe(false);
      expect(result.error).toBe('Network error');
    });
  });

  describe('Utility Functions', () => {
    it('should convert blob to file correctly', () => {
      console.log('🧪 Testing blob to file conversion');
      
      const service = new WhisperService(validConfig);
      const blob = new Blob(['test'], { type: 'audio/wav' });
      
      const file = service['blobToFile'](blob, 'test_audio');
      
      expect(file).toBeInstanceOf(File);
      expect(file.name).toBe('test_audio.wav');
      expect(file.type).toBe('audio/wav');
      expect(file.size).toBe(blob.size);
    });

    it('should get correct file extensions from MIME types', () => {
      console.log('🧪 Testing MIME type to extension mapping');
      
      const service = new WhisperService(validConfig);
      
      expect(service['getExtensionFromMimeType']('audio/wav')).toBe('wav');
      expect(service['getExtensionFromMimeType']('audio/mp3')).toBe('mp3');
      expect(service['getExtensionFromMimeType']('audio/mpeg')).toBe('mp3');
      expect(service['getExtensionFromMimeType']('audio/webm')).toBe('webm');
      expect(service['getExtensionFromMimeType']('audio/unknown')).toBe('bin');
    });

    it('should create valid test audio blob', () => {
      console.log('🧪 Testing test audio blob creation');
      
      const service = new WhisperService(validConfig);
      const testBlob = service['createTestAudioBlob']();
      
      expect(testBlob).toBeInstanceOf(Blob);
      expect(testBlob.type).toBe('audio/wav');
      expect(testBlob.size).toBeGreaterThan(44); // WAV header + some data
    });
  });

  describe('createWhisperService Factory Function', () => {
    beforeEach(() => {
      // Clear environment variables
      delete process.env.OPENAI_API_KEY;
      delete process.env.OPENAI_ORGANIZATION;
      delete process.env.WHISPER_TIMEOUT;
      delete process.env.WHISPER_MAX_RETRIES;
      delete process.env.WHISPER_RETRY_DELAY;
    });

    it('should create service from environment variables', () => {
      console.log('🧪 Testing factory function with environment variables');
      
      process.env.OPENAI_API_KEY = 'env-api-key';
      process.env.OPENAI_ORGANIZATION = 'env-org';
      process.env.WHISPER_TIMEOUT = '45000';
      process.env.WHISPER_MAX_RETRIES = '5';
      process.env.WHISPER_RETRY_DELAY = '2000';

      const service = createWhisperService();
      const status = service.getStatus();

      expect(status.config.hasApiKey).toBe(true);
      expect(status.config.timeout).toBe(45000);
      expect(status.config.maxRetries).toBe(5);
    });

    it('should throw error without OPENAI_API_KEY', () => {
      console.log('🧪 Testing factory function without API key');
      
      expect(() => {
        createWhisperService();
      }).toThrow('OPENAI_API_KEY environment variable is required');
    });
  });
});

================
File: src/services/whisperService.ts
================
/**
 * Whisper Service for Voice-to-Text Transcription
 * 
 * This service handles all interactions with the OpenAI Whisper API for speech-to-text
 * conversion. It provides a clean interface for transcribing audio files and blobs,
 * with comprehensive error handling, retry logic, and integration with our audio utilities.
 * 
 * Key Features:
 * - OpenAI Whisper API integration with proper authentication
 * - Audio format validation and optimization
 * - Retry logic with exponential backoff
 * - Rate limiting and quota management
 * - Comprehensive error handling and logging
 * - Support for multiple audio formats
 * - Batch processing capabilities
 * - Integration with audio file management system
 */

import { logger } from '../utils/logger';
import { 
  validateAudioForWhisper, 
  createProcessingSummary,
  type AudioValidationResult,
  type AudioMetadata,
  WHISPER_CONSTRAINTS
} from '../utils/audioUtils';

/**
 * Whisper API configuration
 */
interface WhisperConfig {
  /** OpenAI API key */
  apiKey: string;
  /** API base URL (default: OpenAI) */
  baseUrl?: string;
  /** Request timeout in milliseconds */
  timeout?: number;
  /** Maximum number of retry attempts */
  maxRetries?: number;
  /** Base delay for exponential backoff (ms) */
  retryDelay?: number;
  /** Organization ID (optional) */
  organization?: string;
  /** Custom headers for requests */
  customHeaders?: Record<string, string>;
}

/**
 * Whisper transcription options
 */
interface WhisperTranscriptionOptions {
  /** Language code (ISO-639-1) - auto-detected if not provided */
  language?: string;
  /** Response format (text, json, srt, verbose_json, vtt) */
  responseFormat?: 'text' | 'json' | 'srt' | 'verbose_json' | 'vtt';
  /** Temperature for randomness (0-1) */
  temperature?: number;
  /** Custom prompt to guide the model */
  prompt?: string;
  /** Timestamp granularities for segments */
  timestampGranularities?: ('word' | 'segment')[];
  /** Whether to validate audio before transcription */
  validateAudio?: boolean;
  /** Whether to include confidence scores (verbose_json only) */
  includeConfidence?: boolean;
}

/**
 * Whisper transcription result
 */
interface WhisperTranscriptionResult {
  /** Transcribed text */
  text: string;
  /** Language detected/used */
  language?: string;
  /** Duration of the audio in seconds */
  duration?: number;
  /** Segments with timestamps (if requested) */
  segments?: WhisperSegment[];
  /** Word-level timestamps (if requested) */
  words?: WhisperWord[];
  /** Processing metadata */
  metadata: {
    /** Time taken for API request */
    processingTime: number;
    /** Number of retry attempts */
    retryAttempts: number;
    /** Audio validation result */
    audioValidation: AudioValidationResult;
    /** File size processed */
    fileSize: number;
    /** Response format used */
    responseFormat: string;
  };
}

/**
 * Whisper segment with timestamps
 */
interface WhisperSegment {
  id: number;
  seek: number;
  start: number;
  end: number;
  text: string;
  tokens: number[];
  temperature: number;
  avgLogprob: number;
  compressionRatio: number;
  noSpeechProb: number;
  confidence?: number;
}

/**
 * Whisper word with timestamps
 */
interface WhisperWord {
  word: string;
  start: number;
  end: number;
  confidence?: number;
}

/**
 * Service operation result
 */
interface WhisperServiceResult<T = WhisperTranscriptionResult> {
  success: boolean;
  data?: T;
  error?: string;
  retryCount?: number;
  duration?: number;
}

/**
 * Default Whisper configuration
 */
const DEFAULT_WHISPER_CONFIG: Partial<WhisperConfig> = {
  baseUrl: 'https://api.openai.com/v1',
  timeout: 30000, // 30 seconds
  maxRetries: 3,
  retryDelay: 1000 // 1 second base delay
};

/**
 * Default transcription options
 */
const DEFAULT_TRANSCRIPTION_OPTIONS: WhisperTranscriptionOptions = {
  responseFormat: 'verbose_json',
  temperature: 0,
  validateAudio: true,
  includeConfidence: true,
  timestampGranularities: ['segment']
};

/**
 * Whisper service for speech-to-text transcription
 */
export class WhisperService {
  private config: Required<WhisperConfig>;
  private requestCount: number = 0;
  private lastRequestTime: number = 0;
  private rateLimitDelay: number = 100; // Minimum delay between requests

  /**
   * Create a new WhisperService instance
   * 
   * @param config - Whisper service configuration
   */
  constructor(config: WhisperConfig) {
    logger.info('🎙️ Initializing WhisperService', {
      baseUrl: config.baseUrl || DEFAULT_WHISPER_CONFIG.baseUrl,
      hasApiKey: !!config.apiKey,
      timeout: config.timeout || DEFAULT_WHISPER_CONFIG.timeout
    });

    // Validate required configuration
    if (!config.apiKey) {
      throw new Error('OpenAI API key is required for WhisperService');
    }

    // Merge with defaults
    this.config = {
      ...DEFAULT_WHISPER_CONFIG,
      ...config
    } as Required<WhisperConfig>;

    logger.info('✅ WhisperService initialized successfully');
  }

  /**
   * Transcribe audio blob to text
   * 
   * @param audioBlob - Audio blob to transcribe
   * @param options - Transcription options
   * @returns Promise resolving to transcription result
   */
  async transcribeBlob(
    audioBlob: Blob,
    options: WhisperTranscriptionOptions = {}
  ): Promise<WhisperServiceResult> {
    const startTime = Date.now();
    const operationId = `transcribe_blob_${Date.now()}_${Math.random().toString(36).substring(2, 8)}`;

    logger.info('🎙️ WhisperService: Starting blob transcription', {
      operationId,
      blobSize: audioBlob.size,
      blobType: audioBlob.type,
      options
    });

    try {
      // Merge options with defaults
      const transcriptionOptions = { ...DEFAULT_TRANSCRIPTION_OPTIONS, ...options };

      // Validate audio if requested
      let audioValidation: AudioValidationResult;
      if (transcriptionOptions.validateAudio) {
        audioValidation = await validateAudioForWhisper(audioBlob);
        
        logger.info('🔍 Audio validation completed', {
          operationId,
          isValid: audioValidation.isValid,
          errors: audioValidation.errors.length,
          warnings: audioValidation.warnings.length
        });

        // Stop if audio is invalid
        if (!audioValidation.isValid) {
          const errorMsg = `Audio validation failed: ${audioValidation.errors.join(', ')}`;
          logger.error('❌ WhisperService: Audio validation failed', {
            operationId,
            errors: audioValidation.errors,
            recommendations: audioValidation.recommendations
          });

          return {
            success: false,
            error: errorMsg,
            duration: Date.now() - startTime
          };
        }
      } else {
        // Create minimal validation result
        audioValidation = {
          isValid: true,
          errors: [],
          warnings: [],
          recommendations: [],
          metadata: {
            duration: 0,
            fileSize: audioBlob.size,
            mimeType: audioBlob.type,
            format: audioBlob.type.split('/')[1] || 'unknown'
          }
        };
      }

      // Convert blob to file for API
      const audioFile = this.blobToFile(audioBlob, 'audio_recording');

      // Perform transcription with retries
      const result = await this.transcribeFileWithRetry(audioFile, transcriptionOptions, operationId);

      if (result.success && result.data) {
        // Add validation metadata
        result.data.metadata.audioValidation = audioValidation;
        result.data.metadata.fileSize = audioBlob.size;

        // Create processing summary
        if (audioValidation.metadata) {
          const summary = createProcessingSummary(
            audioValidation.metadata,
            audioValidation
          );
          logger.info('📋 Transcription processing summary', {
            operationId,
            summary
          });
        }
      }

      const totalDuration = Date.now() - startTime;
      result.duration = totalDuration;

      logger.info('✅ WhisperService: Blob transcription completed', {
        operationId,
        success: result.success,
        textLength: result.data?.text?.length || 0,
        duration: totalDuration,
        retryCount: result.retryCount || 0
      });

      return result;

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      const duration = Date.now() - startTime;

      logger.error('❌ WhisperService: Blob transcription failed', {
        operationId,
        error: errorMsg,
        duration
      });

      return {
        success: false,
        error: errorMsg,
        duration
      };
    }
  }

  /**
   * Transcribe audio file to text
   * 
   * @param filePath - Path to audio file
   * @param options - Transcription options
   * @returns Promise resolving to transcription result
   */
  async transcribeFile(
    filePath: string,
    options: WhisperTranscriptionOptions = {}
  ): Promise<WhisperServiceResult> {
    const startTime = Date.now();
    const operationId = `transcribe_file_${Date.now()}_${Math.random().toString(36).substring(2, 8)}`;

    logger.info('🎙️ WhisperService: Starting file transcription', {
      operationId,
      filePath,
      options
    });

    try {
      // Check if running in browser context
      if (typeof window !== 'undefined' && !window.electron) {
        throw new Error('File transcription requires Electron environment');
      }

      // Read file (in Electron context)
      const fs = await import('fs/promises');
      const fileStats = await fs.stat(filePath);
      const fileBuffer = await fs.readFile(filePath);
      
      // Convert to blob for validation
      const audioBlob = new Blob([fileBuffer], { type: this.getMimeTypeFromPath(filePath) });

      // Use blob transcription method
      const result = await this.transcribeBlob(audioBlob, options);

      logger.info('✅ WhisperService: File transcription completed', {
        operationId,
        filePath,
        success: result.success,
        duration: Date.now() - startTime
      });

      return result;

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      const duration = Date.now() - startTime;

      logger.error('❌ WhisperService: File transcription failed', {
        operationId,
        filePath,
        error: errorMsg,
        duration
      });

      return {
        success: false,
        error: errorMsg,
        duration
      };
    }
  }

  /**
   * Perform transcription with retry logic
   * 
   * @param audioFile - Audio file to transcribe
   * @param options - Transcription options
   * @param operationId - Operation identifier for logging
   * @returns Promise resolving to transcription result
   */
  private async transcribeFileWithRetry(
    audioFile: File,
    options: WhisperTranscriptionOptions,
    operationId: string
  ): Promise<WhisperServiceResult> {
    let lastError: Error | null = null;
    let retryCount = 0;

    for (let attempt = 0; attempt <= this.config.maxRetries; attempt++) {
      try {
        // Wait for rate limiting
        await this.enforceRateLimit();

        logger.info('🔄 WhisperService: Attempting transcription', {
          operationId,
          attempt: attempt + 1,
          maxAttempts: this.config.maxRetries + 1
        });

        // Perform the actual API call
        const result = await this.performTranscription(audioFile, options, operationId);

        logger.info('✅ WhisperService: Transcription successful', {
          operationId,
          attempt: attempt + 1,
          textLength: result.text.length,
          language: result.language
        });

        return {
          success: true,
          data: result,
          retryCount: attempt
        };

      } catch (error) {
        lastError = error instanceof Error ? error : new Error(String(error));
        retryCount = attempt;

        logger.warn('⚠️ WhisperService: Transcription attempt failed', {
          operationId,
          attempt: attempt + 1,
          error: lastError.message,
          willRetry: attempt < this.config.maxRetries
        });

        // Don't retry on certain errors
        if (this.isNonRetryableError(lastError)) {
          logger.error('❌ WhisperService: Non-retryable error encountered', {
            operationId,
            error: lastError.message
          });
          break;
        }

        // Wait before retry (exponential backoff)
        if (attempt < this.config.maxRetries) {
          const delay = this.config.retryDelay * Math.pow(2, attempt);
          logger.info('⏳ WhisperService: Waiting before retry', {
            operationId,
            delay,
            nextAttempt: attempt + 2
          });
          await this.sleep(delay);
        }
      }
    }

    // All attempts failed
    const errorMsg = lastError?.message || 'Unknown error occurred';
    logger.error('❌ WhisperService: All transcription attempts failed', {
      operationId,
      retryCount,
      finalError: errorMsg
    });

    return {
      success: false,
      error: errorMsg,
      retryCount
    };
  }

  /**
   * Perform the actual transcription API call
   * 
   * @param audioFile - Audio file to transcribe
   * @param options - Transcription options
   * @param operationId - Operation identifier for logging
   * @returns Promise resolving to transcription result
   */
  private async performTranscription(
    audioFile: File,
    options: WhisperTranscriptionOptions,
    operationId: string
  ): Promise<WhisperTranscriptionResult> {
    const startTime = Date.now();

    // Create form data
    const formData = new FormData();
    formData.append('file', audioFile);
    formData.append('model', 'whisper-1');

    // Add optional parameters
    if (options.language) {
      formData.append('language', options.language);
    }
    if (options.responseFormat) {
      formData.append('response_format', options.responseFormat);
    }
    if (options.temperature !== undefined) {
      formData.append('temperature', options.temperature.toString());
    }
    if (options.prompt) {
      formData.append('prompt', options.prompt);
    }
    if (options.timestampGranularities) {
      formData.append('timestamp_granularities[]', options.timestampGranularities.join(','));
    }

    // Prepare headers
    const headers: Record<string, string> = {
      'Authorization': `Bearer ${this.config.apiKey}`,
      ...this.config.customHeaders
    };

    if (this.config.organization) {
      headers['OpenAI-Organization'] = this.config.organization;
    }

    logger.info('📡 WhisperService: Sending API request', {
      operationId,
      url: `${this.config.baseUrl}/audio/transcriptions`,
      fileSize: audioFile.size,
      fileName: audioFile.name,
      responseFormat: options.responseFormat,
      language: options.language
    });

    // Make API request
    const response = await fetch(`${this.config.baseUrl}/audio/transcriptions`, {
      method: 'POST',
      headers,
      body: formData,
      signal: AbortSignal.timeout(this.config.timeout)
    });

    // Track request
    this.requestCount++;
    this.lastRequestTime = Date.now();

    // Handle response
    if (!response.ok) {
      const errorText = await response.text();
      let errorMessage = `HTTP ${response.status}: ${response.statusText}`;
      
      try {
        const errorData = JSON.parse(errorText);
        errorMessage = errorData.error?.message || errorMessage;
      } catch {
        // Use default error message
      }

      logger.error('❌ WhisperService: API request failed', {
        operationId,
        status: response.status,
        statusText: response.statusText,
        error: errorMessage
      });

      throw new Error(errorMessage);
    }

    // Parse response based on format
    const processingTime = Date.now() - startTime;
    let responseData: any;
    let responseText: string = '';

    if (options.responseFormat === 'text') {
      // For text format, response is plain text
      responseText = await response.text();
      responseData = { text: responseText };
      
      logger.info('✅ WhisperService: API request successful (text format)', {
        operationId,
        processingTime,
        responseLength: responseText.length,
        transcribedText: responseText.substring(0, 100) + (responseText.length > 100 ? '...' : '')
      });
    } else {
      // For other formats (json, verbose_json, etc.), response is JSON
      responseData = await response.json();
      responseText = responseData.text || '';
      
      logger.info('✅ WhisperService: API request successful (JSON format)', {
        operationId,
        processingTime,
        responseLength: JSON.stringify(responseData).length,
        detectedLanguage: responseData.language,
        transcribedText: responseText.substring(0, 100) + (responseText.length > 100 ? '...' : '')
      });
    }

    // Format result based on response format
    const result: WhisperTranscriptionResult = {
      text: responseText,
      language: responseData.language,
      duration: responseData.duration,
      segments: responseData.segments,
      words: responseData.words,
      metadata: {
        processingTime,
        retryAttempts: 0, // Will be set by retry logic
        audioValidation: {
          isValid: true,
          errors: [],
          warnings: [],
          recommendations: []
        }, // Will be set by caller
        fileSize: audioFile.size,
        responseFormat: options.responseFormat || 'verbose_json'
      }
    };

    return result;
  }

  /**
   * Enforce rate limiting between requests
   */
  private async enforceRateLimit(): Promise<void> {
    const timeSinceLastRequest = Date.now() - this.lastRequestTime;
    const delay = Math.max(0, this.rateLimitDelay - timeSinceLastRequest);
    
    if (delay > 0) {
      logger.debug('⏳ WhisperService: Rate limiting delay', { delay });
      await this.sleep(delay);
    }
  }

  /**
   * Check if an error should not be retried
   * 
   * @param error - Error to check
   * @returns True if error should not be retried
   */
  private isNonRetryableError(error: Error): boolean {
    const errorMessage = error.message.toLowerCase();
    
    // Don't retry on authentication errors
    if (errorMessage.includes('unauthorized') || errorMessage.includes('invalid api key')) {
      return true;
    }
    
    // Don't retry on file format errors
    if (errorMessage.includes('unsupported file type') || errorMessage.includes('invalid file format')) {
      return true;
    }
    
    // Don't retry on quota exceeded (different from rate limiting)
    if (errorMessage.includes('quota exceeded') || errorMessage.includes('billing')) {
      return true;
    }

    return false;
  }

  /**
   * Convert blob to File object
   * 
   * @param blob - Blob to convert
   * @param filename - Filename to use
   * @returns File object
   */
  private blobToFile(blob: Blob, filename: string): File {
    const extension = this.getExtensionFromMimeType(blob.type);
    const fullFilename = `${filename}.${extension}`;
    
    return new File([blob], fullFilename, { type: blob.type });
  }

  /**
   * Get file extension from MIME type
   * 
   * @param mimeType - MIME type
   * @returns File extension
   */
  private getExtensionFromMimeType(mimeType: string): string {
    // Clean MIME type by removing codec information
    const cleanMimeType = mimeType.toLowerCase().split(';')[0].trim();
    
    const mimeMap: Record<string, string> = {
      'audio/wav': 'wav',
      'audio/wave': 'wav',
      'audio/mp3': 'mp3',
      'audio/mpeg': 'mp3',
      'audio/mp4': 'mp4',
      'audio/m4a': 'm4a',
      'audio/webm': 'webm',
      'audio/ogg': 'ogg',
      'audio/oga': 'oga',
      'audio/flac': 'flac'
    };

    const extension = mimeMap[cleanMimeType] || 'wav'; // Default to wav format for better OpenAI compatibility
    
    logger.debug('🔍 WhisperService: MIME type to extension mapping', {
      originalMimeType: mimeType,
      cleanMimeType,
      mappedExtension: extension
    });

    return extension;
  }

  /**
   * Get MIME type from file path
   * 
   * @param filePath - File path
   * @returns MIME type
   */
  private getMimeTypeFromPath(filePath: string): string {
    const ext = filePath.split('.').pop()?.toLowerCase();
    
    const extMap: Record<string, string> = {
      'wav': 'audio/wav',
      'mp3': 'audio/mp3',
      'mpeg': 'audio/mpeg',
      'mp4': 'audio/mp4',
      'm4a': 'audio/m4a',
      'webm': 'audio/webm',
      'ogg': 'audio/ogg'
    };

    return extMap[ext || ''] || 'audio/wav';
  }

  /**
   * Sleep for specified duration
   * 
   * @param ms - Milliseconds to sleep
   * @returns Promise that resolves after delay
   */
  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * Get service status and statistics
   * 
   * @returns Service status information
   */
  getStatus(): {
    requestCount: number;
    lastRequestTime: number;
    config: {
      baseUrl: string;
      timeout: number;
      maxRetries: number;
      hasApiKey: boolean;
    };
  } {
    return {
      requestCount: this.requestCount,
      lastRequestTime: this.lastRequestTime,
      config: {
        baseUrl: this.config.baseUrl,
        timeout: this.config.timeout,
        maxRetries: this.config.maxRetries,
        hasApiKey: !!this.config.apiKey
      }
    };
  }

  /**
   * Test the service connection
   * 
   * @returns Promise resolving to connection test result
   */
  async testConnection(): Promise<{ success: boolean; error?: string }> {
    logger.info('🔍 WhisperService: Testing connection');

    try {
      // Create a minimal test audio blob (1 second of silence)
      const testBlob = this.createTestAudioBlob();
      
      // Attempt transcription with minimal options
      const result = await this.transcribeBlob(testBlob, {
        responseFormat: 'text',
        validateAudio: false
      });

      if (result.success) {
        logger.info('✅ WhisperService: Connection test successful');
        return { success: true };
      } else {
        logger.error('❌ WhisperService: Connection test failed', { error: result.error });
        return { success: false, error: result.error };
      }

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      logger.error('❌ WhisperService: Connection test error', { error: errorMsg });
      return { success: false, error: errorMsg };
    }
  }

  /**
   * Create a test audio blob for connection testing
   * 
   * @returns Test audio blob
   */
  private createTestAudioBlob(): Blob {
    // Create minimal WAV file (1 second of silence)
    const sampleRate = 16000;
    const duration = 1;
    const samples = sampleRate * duration;
    
    // WAV header (44 bytes) + data
    const buffer = new ArrayBuffer(44 + samples * 2);
    const view = new DataView(buffer);
    
    // WAV header
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + samples * 2, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, 1, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 2, true);
    view.setUint16(32, 2, true);
    view.setUint16(34, 16, true);
    writeString(36, 'data');
    view.setUint32(40, samples * 2, true);
    
    // Fill with silence (zeros)
    for (let i = 0; i < samples; i++) {
      view.setInt16(44 + i * 2, 0, true);
    }
    
    return new Blob([buffer], { type: 'audio/wav' });
  }
}

/**
 * Create a WhisperService instance with environment configuration
 * 
 * @returns Promise resolving to configured WhisperService instance
 */
export async function createWhisperService(): Promise<WhisperService> {
  logger.info('🏭 Creating WhisperService from environment configuration');

  let apiKey: string | undefined;

  // Check if we're in Electron renderer context
  if (typeof window !== 'undefined' && window.electron?.env) {
    logger.debug('🔐 Getting environment variables via Electron IPC');
    
    try {
      const envResult = await window.electron.env.getVars();
      
      if (envResult.success && envResult.data) {
        apiKey = envResult.data.OPENAI_API_KEY;
        
        logger.info('✅ Environment variables retrieved via IPC', {
          hasApiKey: !!apiKey,
          nodeEnv: envResult.data.NODE_ENV
        });
      } else {
        throw new Error(`Failed to get environment variables: ${envResult.error}`);
      }
    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      logger.error('❌ Failed to get environment variables via IPC', { error: errorMsg });
      throw new Error(`Failed to access environment variables: ${errorMsg}`);
    }
  } else if (typeof process !== 'undefined' && process.env) {
    // Fallback for non-Electron environments (e.g., tests)
    logger.debug('🔧 Getting environment variables from process.env (fallback)');
    apiKey = process.env.OPENAI_API_KEY;
  } else {
    throw new Error('Unable to access environment variables - neither Electron IPC nor process.env available');
  }
  
  if (!apiKey) {
    throw new Error('OPENAI_API_KEY environment variable is required');
  }

  // Create configuration from environment
  const config: WhisperConfig = {
    apiKey,
    baseUrl: DEFAULT_WHISPER_CONFIG.baseUrl, // Use defaults since other env vars are less critical
    timeout: DEFAULT_WHISPER_CONFIG.timeout,
    maxRetries: DEFAULT_WHISPER_CONFIG.maxRetries,
    retryDelay: DEFAULT_WHISPER_CONFIG.retryDelay,
    // organization: could be added to env vars if needed
  };

  logger.info('✅ WhisperService configuration created', {
    hasApiKey: !!config.apiKey,
    baseUrl: config.baseUrl,
    timeout: config.timeout,
    maxRetries: config.maxRetries
  });

  return new WhisperService(config);
}

/**
 * Export types for external use
 */
export type {
  WhisperConfig,
  WhisperTranscriptionOptions,
  WhisperTranscriptionResult,
  WhisperSegment,
  WhisperWord,
  WhisperServiceResult
};

================
File: src/styles/globals.css
================
/**
 * FlowGenius Global Styles
 * 
 * OpenAI-inspired design system with comprehensive CSS custom properties,
 * typography scales, color schemes, and foundational styles.
 * 
 * This file establishes the core design tokens and global styles
 * that all components inherit from.
 */

/* ===== CSS CUSTOM PROPERTIES (Design Tokens) ===== */

:root {
  /* === Color System === */
  
  /* Background Colors */
  --color-bg-primary: #171717;           /* Main background */
  --color-bg-secondary: #202123;         /* Secondary surfaces */
  --color-bg-tertiary: #2d2d2d;          /* Elevated surfaces */
  --color-bg-quaternary: #3a3a3a;        /* Interactive states */
  --color-bg-overlay: rgba(23, 23, 23, 0.8); /* Modal overlays */
  
  /* Text Colors */
  --color-text-primary: #ececec;         /* Primary text */
  --color-text-secondary: #b4b4b4;       /* Secondary text */
  --color-text-tertiary: #8e8e8e;        /* Tertiary text */
  --color-text-disabled: #565656;        /* Disabled text */
  --color-text-inverse: #171717;         /* Text on light backgrounds */
  
  /* Border Colors */
  --color-border-primary: #2d2d2d;       /* Primary borders */
  --color-border-secondary: #3a3a3a;     /* Secondary borders */
  --color-border-tertiary: #4a4a4a;      /* Tertiary borders */
  --color-border-focus: #10a37f;         /* Focus states */
  
  /* Brand Colors */
  --color-brand-primary: #10a37f;        /* OpenAI green */
  --color-brand-primary-hover: #0d8a6b;  /* Hover state */
  --color-brand-primary-active: #0a7357; /* Active state */
  --color-brand-secondary: #19c37d;      /* Secondary brand */
  
  /* Semantic Colors */
  --color-success: #10a37f;              /* Success states */
  --color-success-bg: rgba(16, 163, 127, 0.1);
  --color-warning: #ffc107;              /* Warning states */
  --color-warning-bg: rgba(255, 193, 7, 0.1);
  --color-error: #ef4444;                /* Error states */
  --color-error-bg: rgba(239, 68, 68, 0.1);
  --color-info: #3b82f6;                 /* Info states */
  --color-info-bg: rgba(59, 130, 246, 0.1);
  
  /* Interactive Colors */
  --color-interactive-hover: rgba(236, 236, 236, 0.05);
  --color-interactive-active: rgba(236, 236, 236, 0.1);
  --color-interactive-disabled: #3a3a3a;
  
  /* === Typography === */
  
  /* Font Families */
  --font-family-primary: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen', 'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', 'Helvetica Neue', sans-serif;
  --font-family-mono: 'SF Mono', Monaco, Inconsolata, 'Roboto Mono', 'Source Code Pro', monospace;
  
  /* Font Sizes */
  --font-size-xs: 0.75rem;     /* 12px */
  --font-size-sm: 0.875rem;    /* 14px */
  --font-size-base: 1rem;      /* 16px */
  --font-size-lg: 1.125rem;    /* 18px */
  --font-size-xl: 1.25rem;     /* 20px */
  --font-size-2xl: 1.5rem;     /* 24px */
  --font-size-3xl: 1.875rem;   /* 30px */
  --font-size-4xl: 2.25rem;    /* 36px */
  
  /* Line Heights */
  --line-height-tight: 1.25;
  --line-height-normal: 1.5;
  --line-height-relaxed: 1.75;
  
  /* Font Weights */
  --font-weight-normal: 400;
  --font-weight-medium: 500;
  --font-weight-semibold: 600;
  --font-weight-bold: 700;
  
  /* === Spacing === */
  
  --spacing-0: 0;
  --spacing-1: 0.25rem;   /* 4px */
  --spacing-2: 0.5rem;    /* 8px */
  --spacing-3: 0.75rem;   /* 12px */
  --spacing-4: 1rem;      /* 16px */
  --spacing-5: 1.25rem;   /* 20px */
  --spacing-6: 1.5rem;    /* 24px */
  --spacing-8: 2rem;      /* 32px */
  --spacing-10: 2.5rem;   /* 40px */
  --spacing-12: 3rem;     /* 48px */
  --spacing-16: 4rem;     /* 64px */
  --spacing-20: 5rem;     /* 80px */
  --spacing-24: 6rem;     /* 96px */
  
  /* === Border Radius === */
  
  --radius-none: 0;
  --radius-sm: 0.125rem;   /* 2px */
  --radius-base: 0.25rem;  /* 4px */
  --radius-md: 0.375rem;   /* 6px */
  --radius-lg: 0.5rem;     /* 8px */
  --radius-xl: 0.75rem;    /* 12px */
  --radius-2xl: 1rem;      /* 16px */
  --radius-full: 9999px;   /* Fully rounded */
  
  /* === Shadows === */
  
  --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
  --shadow-base: 0 1px 3px 0 rgba(0, 0, 0, 0.1), 0 1px 2px 0 rgba(0, 0, 0, 0.06);
  --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
  --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
  --shadow-xl: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
  
  /* === Z-Index === */
  
  --z-index-dropdown: 1000;
  --z-index-sticky: 1020;
  --z-index-fixed: 1030;
  --z-index-modal-backdrop: 1040;
  --z-index-modal: 1050;
  --z-index-popover: 1060;
  --z-index-tooltip: 1070;
  --z-index-toast: 1080;
  
  /* === Transitions === */
  
  --transition-fast: 150ms ease;
  --transition-base: 200ms ease;
  --transition-slow: 300ms ease;
  --transition-slower: 500ms ease;
  
  /* === Layout === */
  
  --sidebar-width: 260px;
  --header-height: 60px;
  --input-bar-height: 80px;
  --max-content-width: 768px;
  
  /* === Breakpoints (for reference in media queries) === */
  
  --breakpoint-sm: 640px;
  --breakpoint-md: 768px;
  --breakpoint-lg: 1024px;
  --breakpoint-xl: 1280px;
}

/* ===== GLOBAL RESET ===== */

*,
*::before,
*::after {
  box-sizing: border-box;
  margin: 0;
  padding: 0;
}

html {
  height: 100%;
  font-size: 16px;
  -webkit-text-size-adjust: 100%;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  text-rendering: optimizeLegibility;
}

body {
  height: 100%;
  font-family: var(--font-family-primary);
  font-size: var(--font-size-base);
  line-height: var(--line-height-normal);
  color: var(--color-text-primary);
  background-color: var(--color-bg-primary);
  overflow: hidden; /* Prevent body scroll */
}

#root {
  height: 100%;
  display: flex;
  flex-direction: column;
}

/* ===== TYPOGRAPHY ===== */

h1, h2, h3, h4, h5, h6 {
  margin: 0;
  font-weight: var(--font-weight-semibold);
  line-height: var(--line-height-tight);
  color: var(--color-text-primary);
}

h1 {
  font-size: var(--font-size-4xl);
}

h2 {
  font-size: var(--font-size-3xl);
}

h3 {
  font-size: var(--font-size-2xl);
}

h4 {
  font-size: var(--font-size-xl);
}

h5 {
  font-size: var(--font-size-lg);
}

h6 {
  font-size: var(--font-size-base);
}

p {
  margin: 0;
  color: var(--color-text-primary);
  line-height: var(--line-height-normal);
}

a {
  color: var(--color-brand-primary);
  text-decoration: none;
  transition: color var(--transition-fast);
}

a:hover {
  color: var(--color-brand-primary-hover);
}

a:focus-visible {
  outline: 2px solid var(--color-brand-primary);
  outline-offset: 2px;
}

code {
  font-family: var(--font-family-mono);
  font-size: 0.875em;
  background-color: var(--color-bg-tertiary);
  padding: var(--spacing-1) var(--spacing-2);
  border-radius: var(--radius-base);
  color: var(--color-text-primary);
}

pre {
  font-family: var(--font-family-mono);
  background-color: var(--color-bg-secondary);
  padding: var(--spacing-4);
  border-radius: var(--radius-lg);
  overflow-x: auto;
  line-height: var(--line-height-normal);
}

pre code {
  background: none;
  padding: 0;
  border-radius: 0;
}

/* ===== FORM ELEMENTS ===== */

button {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  margin: 0;
  border: none;
  background: none;
  cursor: pointer;
  border-radius: var(--radius-md);
  transition: all var(--transition-fast);
}

button:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

button:focus-visible {
  outline: 2px solid var(--color-brand-primary);
  outline-offset: 2px;
}

input,
textarea,
select {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  margin: 0;
  border: 1px solid var(--color-border-primary);
  background-color: var(--color-bg-primary);
  color: var(--color-text-primary);
  border-radius: var(--radius-md);
  transition: border-color var(--transition-fast);
}

input:focus,
textarea:focus,
select:focus {
  outline: none;
  border-color: var(--color-border-focus);
}

input::placeholder,
textarea::placeholder {
  color: var(--color-text-tertiary);
}

input:disabled,
textarea:disabled,
select:disabled {
  background-color: var(--color-bg-tertiary);
  color: var(--color-text-disabled);
  cursor: not-allowed;
}

/* ===== SCROLLBARS ===== */

/* Webkit Scrollbars */
::-webkit-scrollbar {
  width: 8px;
  height: 8px;
}

::-webkit-scrollbar-track {
  background: transparent;
}

::-webkit-scrollbar-thumb {
  background-color: var(--color-bg-tertiary);
  border-radius: var(--radius-full);
  border: 2px solid transparent;
  background-clip: content-box;
}

::-webkit-scrollbar-thumb:hover {
  background-color: var(--color-bg-quaternary);
}

/* Firefox Scrollbars */
* {
  scrollbar-width: thin;
  scrollbar-color: var(--color-bg-tertiary) transparent;
}

/* ===== UTILITY CLASSES ===== */

/* Screen Reader Only */
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  white-space: nowrap;
  border: 0;
}

/* Focus Visible */
.focus-visible:focus-visible {
  outline: 2px solid var(--color-brand-primary);
  outline-offset: 2px;
}

/* Text Utilities */
.text-xs { font-size: var(--font-size-xs); }
.text-sm { font-size: var(--font-size-sm); }
.text-base { font-size: var(--font-size-base); }
.text-lg { font-size: var(--font-size-lg); }
.text-xl { font-size: var(--font-size-xl); }
.text-2xl { font-size: var(--font-size-2xl); }
.text-3xl { font-size: var(--font-size-3xl); }
.text-4xl { font-size: var(--font-size-4xl); }

.font-normal { font-weight: var(--font-weight-normal); }
.font-medium { font-weight: var(--font-weight-medium); }
.font-semibold { font-weight: var(--font-weight-semibold); }
.font-bold { font-weight: var(--font-weight-bold); }

.text-primary { color: var(--color-text-primary); }
.text-secondary { color: var(--color-text-secondary); }
.text-tertiary { color: var(--color-text-tertiary); }
.text-disabled { color: var(--color-text-disabled); }

/* Background Utilities */
.bg-primary { background-color: var(--color-bg-primary); }
.bg-secondary { background-color: var(--color-bg-secondary); }
.bg-tertiary { background-color: var(--color-bg-tertiary); }
.bg-quaternary { background-color: var(--color-bg-quaternary); }

/* Border Utilities */
.border-primary { border-color: var(--color-border-primary); }
.border-secondary { border-color: var(--color-border-secondary); }
.border-tertiary { border-color: var(--color-border-tertiary); }
.border-focus { border-color: var(--color-border-focus); }

/* Spacing Utilities */
.p-0 { padding: var(--spacing-0); }
.p-1 { padding: var(--spacing-1); }
.p-2 { padding: var(--spacing-2); }
.p-3 { padding: var(--spacing-3); }
.p-4 { padding: var(--spacing-4); }
.p-5 { padding: var(--spacing-5); }
.p-6 { padding: var(--spacing-6); }
.p-8 { padding: var(--spacing-8); }

.m-0 { margin: var(--spacing-0); }
.m-1 { margin: var(--spacing-1); }
.m-2 { margin: var(--spacing-2); }
.m-3 { margin: var(--spacing-3); }
.m-4 { margin: var(--spacing-4); }
.m-5 { margin: var(--spacing-5); }
.m-6 { margin: var(--spacing-6); }
.m-8 { margin: var(--spacing-8); }

/* Border Radius Utilities */
.rounded-none { border-radius: var(--radius-none); }
.rounded-sm { border-radius: var(--radius-sm); }
.rounded { border-radius: var(--radius-base); }
.rounded-md { border-radius: var(--radius-md); }
.rounded-lg { border-radius: var(--radius-lg); }
.rounded-xl { border-radius: var(--radius-xl); }
.rounded-2xl { border-radius: var(--radius-2xl); }
.rounded-full { border-radius: var(--radius-full); }

/* Layout Utilities */
.flex { display: flex; }
.inline-flex { display: inline-flex; }
.block { display: block; }
.inline-block { display: inline-block; }
.hidden { display: none; }

.flex-col { flex-direction: column; }
.flex-row { flex-direction: row; }
.flex-wrap { flex-wrap: wrap; }
.flex-nowrap { flex-wrap: nowrap; }

.items-center { align-items: center; }
.items-start { align-items: flex-start; }
.items-end { align-items: flex-end; }
.items-stretch { align-items: stretch; }

.justify-center { justify-content: center; }
.justify-start { justify-content: flex-start; }
.justify-end { justify-content: flex-end; }
.justify-between { justify-content: space-between; }
.justify-around { justify-content: space-around; }

.flex-1 { flex: 1 1 0%; }
.flex-auto { flex: 1 1 auto; }
.flex-none { flex: none; }

/* Position Utilities */
.relative { position: relative; }
.absolute { position: absolute; }
.fixed { position: fixed; }
.sticky { position: sticky; }

/* Overflow Utilities */
.overflow-hidden { overflow: hidden; }
.overflow-auto { overflow: auto; }
.overflow-scroll { overflow: scroll; }
.overflow-x-hidden { overflow-x: hidden; }
.overflow-y-hidden { overflow-y: hidden; }
.overflow-x-auto { overflow-x: auto; }
.overflow-y-auto { overflow-y: auto; }

/* ===== ANIMATIONS ===== */

@keyframes spin {
  from { transform: rotate(0deg); }
  to { transform: rotate(360deg); }
}

@keyframes pulse {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.5; }
}

@keyframes fadeIn {
  from { opacity: 0; }
  to { opacity: 1; }
}

@keyframes fadeOut {
  from { opacity: 1; }
  to { opacity: 0; }
}

@keyframes slideInUp {
  from {
    transform: translateY(100%);
    opacity: 0;
  }
  to {
    transform: translateY(0);
    opacity: 1;
  }
}

@keyframes slideOutDown {
  from {
    transform: translateY(0);
    opacity: 1;
  }
  to {
    transform: translateY(100%);
    opacity: 0;
  }
}

/* Animation Classes */
.animate-spin {
  animation: spin 1s linear infinite;
}

.animate-pulse {
  animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite;
}

.animate-fadeIn {
  animation: fadeIn var(--transition-base) ease-in-out;
}

.animate-fadeOut {
  animation: fadeOut var(--transition-base) ease-in-out;
}

.animate-slideInUp {
  animation: slideInUp var(--transition-base) ease-out;
}

.animate-slideOutDown {
  animation: slideOutDown var(--transition-base) ease-in;
}

/* ===== ACCESSIBILITY ===== */

/* Reduce motion for users who prefer it */
@media (prefers-reduced-motion: reduce) {
  *,
  *::before,
  *::after {
    animation-duration: 0.01ms !important;
    animation-iteration-count: 1 !important;
    transition-duration: 0.01ms !important;
    scroll-behavior: auto !important;
  }
}

/* High contrast mode support */
@media (prefers-contrast: high) {
  :root {
    --color-border-primary: #ffffff;
    --color-border-secondary: #ffffff;
    --color-text-secondary: #ffffff;
    --color-text-tertiary: #cccccc;
  }
}

/* ===== RESPONSIVE DESIGN ===== */

/* Mobile First Approach */
@media (max-width: 640px) {
  :root {
    --sidebar-width: 100%;
    --font-size-4xl: 1.875rem;
    --font-size-3xl: 1.5rem;
    --spacing-4: 0.875rem;
    --spacing-6: 1.25rem;
    --spacing-8: 1.5rem;
  }
  
  .text-4xl { font-size: var(--font-size-3xl); }
  .text-3xl { font-size: var(--font-size-2xl); }
}

@media (max-width: 480px) {
  :root {
    --spacing-4: 0.75rem;
    --spacing-6: 1rem;
  }
}

/* Print Styles */
@media print {
  *,
  *::before,
  *::after {
    background: transparent !important;
    color: black !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  
  body {
    font-size: 12pt;
    line-height: 1.5;
  }
  
  h1, h2, h3 {
    page-break-after: avoid;
  }
  
  .no-print {
    display: none !important;
  }
}

/* ===== COMPONENT FOUNDATION ===== */

/* Base button styles that components can extend */
.btn-base {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  padding: var(--spacing-2) var(--spacing-4);
  font-size: var(--font-size-sm);
  font-weight: var(--font-weight-medium);
  line-height: 1;
  border-radius: var(--radius-md);
  transition: all var(--transition-fast);
  cursor: pointer;
  border: none;
  text-decoration: none;
  white-space: nowrap;
}

.btn-base:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

/* Base input styles that components can extend */
.input-base {
  display: block;
  width: 100%;
  padding: var(--spacing-3) var(--spacing-4);
  font-size: var(--font-size-base);
  line-height: var(--line-height-normal);
  color: var(--color-text-primary);
  background-color: var(--color-bg-primary);
  border: 1px solid var(--color-border-primary);
  border-radius: var(--radius-md);
  transition: border-color var(--transition-fast);
}

.input-base:focus {
  outline: none;
  border-color: var(--color-border-focus);
}

.input-base::placeholder {
  color: var(--color-text-tertiary);
}

.input-base:disabled {
  background-color: var(--color-bg-tertiary);
  color: var(--color-text-disabled);
  cursor: not-allowed;
}

/* Base card styles that components can extend */
.card-base {
  background-color: var(--color-bg-secondary);
  border: 1px solid var(--color-border-primary);
  border-radius: var(--radius-lg);
  padding: var(--spacing-6);
  box-shadow: var(--shadow-sm);
}

================
File: src/styles/README.md
================
# Styles Directory

This directory contains all CSS styles for the FlowGenius application, organized for maintainability and following OpenAI ChatGPT design principles.

## Directory Structure

### Global Styles
- `globals.css` - Global CSS styles based on OpenAI's design system
- `variables.css` - CSS custom properties (variables) for consistent theming
- `reset.css` - CSS reset/normalize for consistent browser behavior

### Component Styles
- `components.css` - Component-specific CSS styles
- Individual component modules (when needed)

## Design System

### Color Palette (OpenAI-inspired)
```css
:root {
  /* Primary Colors */
  --color-primary: #10a37f;
  --color-primary-hover: #0d9070;
  
  /* Background Colors */
  --color-bg-primary: #ffffff;
  --color-bg-secondary: #f7f7f8;
  --color-bg-chat: #ffffff;
  
  /* Text Colors */
  --color-text-primary: #2d333a;
  --color-text-secondary: #6e7681;
  --color-text-muted: #8b949e;
  
  /* Border Colors */
  --color-border: #d0d7de;
  --color-border-muted: #e1e4e8;
  
  /* Status Colors */
  --color-success: #1a7f37;
  --color-warning: #bf8700;
  --color-error: #cf222e;
}
```

### Typography
- Primary font: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto
- Font sizes follow a consistent scale
- Line heights optimized for readability

### Layout Guidelines
- Clean, minimalist design
- Consistent spacing using 8px grid system
- Responsive design for various screen sizes
- Focus on conversation experience

## Component Styling Approach

1. **CSS Modules**: Use CSS modules for component-specific styles when needed
2. **Global Styles**: Use global styles for layout and shared elements
3. **BEM Methodology**: Follow BEM naming convention for CSS classes
4. **Mobile-First**: Design mobile-first, then enhance for desktop

## File Organization

```
styles/
├── globals.css          # Global styles and layout
├── variables.css        # CSS custom properties
├── reset.css           # Browser reset/normalize
├── components.css      # Component-specific styles
└── README.md          # This documentation
```

## Style Guidelines

1. **Consistency**: Follow OpenAI ChatGPT visual patterns
2. **Accessibility**: Ensure proper contrast ratios and focus states
3. **Performance**: Minimize CSS bundle size
4. **Maintainability**: Use CSS custom properties for theming
5. **Responsive**: Design works across all device sizes

================
File: src/styles/responsive.css
================
/**
 * FlowGenius Responsive Design for Desktop
 * 
 * Desktop-focused responsive design for Electron app window resizing.
 * Handles various desktop window sizes from small (800px) to ultra-wide (2560px+).
 * 
 * Desktop Window Size Categories:
 * - Compact Desktop: 800px - 1024px (small laptop screens)
 * - Standard Desktop: 1025px - 1440px (most common desktop sizes)
 * - Large Desktop: 1441px - 1920px (full HD and larger monitors)
 * - Ultra-wide Desktop: 1921px+ (ultra-wide monitors and multi-monitor setups)
 */

/* ===== DESKTOP BREAKPOINT SYSTEM ===== */

:root {
  /* Desktop-specific breakpoints */
  --desktop-compact: 800px;      /* Minimum viable desktop size */
  --desktop-standard: 1025px;    /* Standard desktop */
  --desktop-large: 1441px;       /* Large desktop monitors */
  --desktop-ultrawide: 1921px;   /* Ultra-wide monitors */
  
  /* Responsive sidebar widths */
  --sidebar-width-compact: 200px;
  --sidebar-width-standard: 260px;
  --sidebar-width-large: 300px;
  
  /* Responsive content widths */
  --content-max-width-compact: 600px;
  --content-max-width-standard: 768px;
  --content-max-width-large: 900px;
  --content-max-width-ultrawide: 1200px;
  
  /* Responsive spacing */
  --spacing-responsive-sm: var(--spacing-2);
  --spacing-responsive-md: var(--spacing-4);
  --spacing-responsive-lg: var(--spacing-6);
}

/* ===== COMPACT DESKTOP (800px - 1024px) ===== */
/* Small laptop screens, minimum viable desktop size */

@media (max-width: 1024px) {
  :root {
    --sidebar-width: var(--sidebar-width-compact);
    --max-content-width: var(--content-max-width-compact);
    --spacing-responsive: var(--spacing-responsive-sm);
  }
  
  /* App Layout Adjustments */
  .app-container {
    font-size: 0.95rem; /* Slightly smaller text for compact screens */
  }
  
  /* Sidebar Adjustments */
  .sidebar {
    width: var(--sidebar-width-compact) !important;
    min-width: var(--sidebar-width-compact);
  }
  
  .sidebar-content {
    padding: var(--spacing-3);
  }
  
  .sidebar-header {
    padding: var(--spacing-3) var(--spacing-3) var(--spacing-4);
  }
  
  .sidebar-title {
    font-size: var(--font-size-lg);
  }
  
  .new-session-button {
    padding: var(--spacing-2) var(--spacing-3);
    font-size: var(--font-size-sm);
  }
  
  /* Session List Adjustments */
  .session-item {
    padding: var(--spacing-2) var(--spacing-3);
    margin-bottom: var(--spacing-1);
  }
  
  .session-title {
    font-size: var(--font-size-sm);
    line-height: var(--line-height-tight);
  }
  
  .session-meta {
    font-size: var(--font-size-xs);
    margin-top: var(--spacing-1);
  }
  
  /* Chat Area Adjustments */
  .chat-main {
    margin-left: var(--sidebar-width-compact);
  }
  
  .chat-header {
    padding: var(--spacing-3) var(--spacing-4);
  }
  
  .chat-content {
    padding: var(--spacing-3) var(--spacing-4);
  }
  
  /* Message Adjustments */
  .messages-container {
    max-width: var(--content-max-width-compact);
    padding: 0 var(--spacing-2);
  }
  
  .message {
    margin-bottom: var(--spacing-3);
  }
  
  .message-content {
    padding: var(--spacing-3);
  }
  
  .message-text {
    font-size: var(--font-size-sm);
    line-height: var(--line-height-normal);
  }
  
  /* Input Bar Adjustments */
  .chat-input-area {
    padding: var(--spacing-3) var(--spacing-4);
  }
  
  .input-bar {
    padding: var(--spacing-2) var(--spacing-3);
  }
  
  .input-textarea {
    font-size: var(--font-size-sm);
    padding: var(--spacing-2) var(--spacing-3);
  }
  
  .input-action-button {
    width: 2rem;
    height: 2rem;
    padding: var(--spacing-1);
  }
  
  /* Welcome Message Adjustments */
  .welcome-message {
    padding: var(--spacing-4);
    margin: var(--spacing-4) auto;
  }
  
  .welcome-message h2 {
    font-size: var(--font-size-xl);
    margin-bottom: var(--spacing-3);
  }
  
  .welcome-message p {
    font-size: var(--font-size-sm);
    margin-bottom: var(--spacing-3);
  }
  
  /* Workflow Stages Adjustments */
  .workflow-stages {
    flex-direction: column;
    gap: var(--spacing-2);
  }
  
  .stage-item {
    padding: var(--spacing-2);
    font-size: var(--font-size-xs);
  }
  
  .stage-arrow {
    display: none; /* Hide arrows in compact layout */
  }
}

/* ===== STANDARD DESKTOP (1025px - 1440px) ===== */
/* Most common desktop sizes, optimal layout */

@media (min-width: 1025px) and (max-width: 1440px) {
  :root {
    --sidebar-width: var(--sidebar-width-standard);
    --max-content-width: var(--content-max-width-standard);
    --spacing-responsive: var(--spacing-responsive-md);
  }
  
  /* Standard desktop - use default styles from globals.css */
  /* This is our baseline, so minimal overrides needed */
  
  .chat-main {
    margin-left: var(--sidebar-width-standard);
  }
  
  .messages-container {
    max-width: var(--content-max-width-standard);
  }
  
  /* Ensure proper spacing for standard desktop */
  .chat-content {
    padding: var(--spacing-4) var(--spacing-6);
  }
  
  .chat-input-area {
    padding: var(--spacing-4) var(--spacing-6);
  }
}

/* ===== LARGE DESKTOP (1441px - 1920px) ===== */
/* Large monitors, more spacious layout */

@media (min-width: 1441px) and (max-width: 1920px) {
  :root {
    --sidebar-width: var(--sidebar-width-large);
    --max-content-width: var(--content-max-width-large);
    --spacing-responsive: var(--spacing-responsive-lg);
  }
  
  /* Sidebar Enhancements */
  .sidebar {
    width: var(--sidebar-width-large) !important;
    min-width: var(--sidebar-width-large);
  }
  
  .sidebar-content {
    padding: var(--spacing-6);
  }
  
  .sidebar-header {
    padding: var(--spacing-6) var(--spacing-6) var(--spacing-8);
  }
  
  .sidebar-title {
    font-size: var(--font-size-xl);
  }
  
  .new-session-button {
    padding: var(--spacing-3) var(--spacing-5);
    font-size: var(--font-size-base);
  }
  
  /* Session List Enhancements */
  .session-item {
    padding: var(--spacing-4) var(--spacing-5);
    margin-bottom: var(--spacing-2);
    border-radius: var(--radius-lg);
  }
  
  .session-title {
    font-size: var(--font-size-base);
    line-height: var(--line-height-normal);
  }
  
  .session-meta {
    font-size: var(--font-size-sm);
    margin-top: var(--spacing-2);
  }
  
  /* Chat Area Enhancements */
  .chat-main {
    margin-left: var(--sidebar-width-large);
  }
  
  .chat-header {
    padding: var(--spacing-5) var(--spacing-8);
  }
  
  .chat-content {
    padding: var(--spacing-6) var(--spacing-8);
  }
  
  /* Message Enhancements */
  .messages-container {
    max-width: var(--content-max-width-large);
    padding: 0 var(--spacing-4);
  }
  
  .message {
    margin-bottom: var(--spacing-6);
  }
  
  .message-content {
    padding: var(--spacing-5);
    border-radius: var(--radius-xl);
  }
  
  .message-text {
    font-size: var(--font-size-base);
    line-height: var(--line-height-relaxed);
  }
  
  /* Input Bar Enhancements */
  .chat-input-area {
    padding: var(--spacing-6) var(--spacing-8);
  }
  
  .input-bar {
    padding: var(--spacing-4) var(--spacing-5);
    border-radius: var(--radius-xl);
  }
  
  .input-textarea {
    font-size: var(--font-size-base);
    padding: var(--spacing-3) var(--spacing-4);
  }
  
  .input-action-button {
    width: 3rem;
    height: 3rem;
    padding: var(--spacing-3);
  }
  
  /* Welcome Message Enhancements */
  .welcome-message {
    padding: var(--spacing-8);
    margin: var(--spacing-8) auto;
  }
  
  .welcome-message h2 {
    font-size: var(--font-size-3xl);
    margin-bottom: var(--spacing-6);
  }
  
  .welcome-message p {
    font-size: var(--font-size-lg);
    margin-bottom: var(--spacing-4);
  }
}

/* ===== ULTRA-WIDE DESKTOP (1921px+) ===== */
/* Ultra-wide monitors, maximum spacious layout */

@media (min-width: 1921px) {
  :root {
    --sidebar-width: var(--sidebar-width-large);
    --max-content-width: var(--content-max-width-ultrawide);
    --spacing-responsive: var(--spacing-responsive-lg);
  }
  
  /* Ultra-wide specific adjustments */
  .messages-container {
    max-width: var(--content-max-width-ultrawide);
    padding: 0 var(--spacing-8);
  }
  
  /* Larger text and spacing for ultra-wide screens */
  .message-text {
    font-size: var(--font-size-lg);
    line-height: var(--line-height-relaxed);
  }
  
  .input-textarea {
    font-size: var(--font-size-lg);
    padding: var(--spacing-4) var(--spacing-6);
  }
  
  /* Enhanced welcome message for ultra-wide */
  .welcome-message {
    max-width: 800px; /* Prevent text from becoming too wide */
    padding: var(--spacing-12);
  }
  
  .welcome-message h2 {
    font-size: var(--font-size-4xl);
  }
  
  .welcome-message p {
    font-size: var(--font-size-xl);
  }
  
  /* Workflow stages in a more spacious layout */
  .workflow-stages {
    gap: var(--spacing-8);
  }
  
  .stage-item {
    padding: var(--spacing-5) var(--spacing-6);
    font-size: var(--font-size-base);
  }
}

/* ===== WINDOW HEIGHT RESPONSIVE ADJUSTMENTS ===== */

/* Short windows (less than 600px height) */
@media (max-height: 600px) {
  .sidebar-header {
    padding-top: var(--spacing-3);
    padding-bottom: var(--spacing-3);
  }
  
  .chat-header {
    padding-top: var(--spacing-3);
    padding-bottom: var(--spacing-3);
  }
  
  .welcome-message {
    margin: var(--spacing-4) auto;
    padding: var(--spacing-4);
  }
  
  .welcome-message h2 {
    font-size: var(--font-size-xl);
    margin-bottom: var(--spacing-3);
  }
  
  .message {
    margin-bottom: var(--spacing-3);
  }
  
  .workflow-stages {
    gap: var(--spacing-2);
  }
  
  .stage-item {
    padding: var(--spacing-2) var(--spacing-3);
    font-size: var(--font-size-xs);
  }
}

/* Tall windows (more than 1200px height) */
@media (min-height: 1200px) {
  .welcome-message {
    margin: var(--spacing-16) auto;
    padding: var(--spacing-12);
  }
  
  .message {
    margin-bottom: var(--spacing-8);
  }
  
  .chat-content {
    padding-top: var(--spacing-8);
    padding-bottom: var(--spacing-8);
  }
}

/* ===== SIDEBAR RESPONSIVE BEHAVIOR ===== */

/* Collapsible sidebar for very narrow windows */
@media (max-width: 900px) {
  .sidebar {
    transform: translateX(-100%);
    transition: transform var(--transition-base);
    z-index: var(--z-index-modal);
  }
  
  .sidebar.open {
    transform: translateX(0);
    box-shadow: var(--shadow-xl);
  }
  
  .chat-main {
    margin-left: 0 !important;
    width: 100%;
  }
  
  /* Add overlay when sidebar is open */
  .sidebar-overlay {
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background-color: var(--color-bg-overlay);
    z-index: calc(var(--z-index-modal) - 1);
    opacity: 0;
    visibility: hidden;
    transition: all var(--transition-base);
  }
  
  .sidebar-overlay.visible {
    opacity: 1;
    visibility: visible;
  }
  
  /* Show hamburger menu button */
  .mobile-header {
    display: flex !important;
  }
}

/* ===== CONTENT SCALING UTILITIES ===== */

/* Prevent content from becoming too narrow */
.chat-content,
.messages-container {
  min-width: 300px; /* Absolute minimum width */
}

/* Prevent text from becoming too wide on ultra-wide screens */
.message-text,
.welcome-message p {
  max-width: 65ch; /* Optimal reading width */
}

/* ===== RESPONSIVE TYPOGRAPHY SCALING ===== */

/* Scale typography based on window width */
@media (min-width: 1600px) {
  html {
    font-size: 17px; /* Slightly larger base font size for large screens */
  }
}

@media (min-width: 2000px) {
  html {
    font-size: 18px; /* Even larger for ultra-wide screens */
  }
}

@media (max-width: 900px) {
  html {
    font-size: 15px; /* Smaller base font size for compact screens */
  }
}

/* ===== RESPONSIVE SCROLLBAR ADJUSTMENTS ===== */

/* Thicker scrollbars for larger screens */
@media (min-width: 1441px) {
  ::-webkit-scrollbar {
    width: 12px;
    height: 12px;
  }
  
  ::-webkit-scrollbar-thumb {
    border: 3px solid transparent;
  }
}

/* Thinner scrollbars for compact screens */
@media (max-width: 1024px) {
  ::-webkit-scrollbar {
    width: 6px;
    height: 6px;
  }
  
  ::-webkit-scrollbar-thumb {
    border: 1px solid transparent;
  }
}

/* ===== RESPONSIVE ANIMATION ADJUSTMENTS ===== */

/* Reduce animations on smaller screens to improve performance */
@media (max-width: 1024px) {
  * {
    transition-duration: calc(var(--transition-fast) * 0.7) !important;
  }
  
  .animate-pulse {
    animation-duration: 1.5s;
  }
  
  .animate-spin {
    animation-duration: 0.8s;
  }
}

/* Enhanced animations on larger screens */
@media (min-width: 1441px) {
  .message,
  .session-item,
  .input-bar {
    transition: all var(--transition-slow);
  }
  
  .btn-primary:hover,
  .btn-secondary:hover,
  .nav-link:hover {
    transition: all var(--transition-base);
    transform: translateY(-1px);
  }
}

/* ===== RESPONSIVE FOCUS STATES ===== */

/* Larger focus outlines on larger screens */
@media (min-width: 1441px) {
  button:focus-visible,
  input:focus-visible,
  textarea:focus-visible {
    outline-width: 3px;
    outline-offset: 3px;
  }
}

/* ===== PRINT RESPONSIVE (for desktop printing) ===== */

@media print {
  .sidebar {
    display: none !important;
  }
  
  .chat-main {
    margin-left: 0 !important;
    width: 100% !important;
  }
  
  .chat-header,
  .chat-input-area {
    display: none !important;
  }
  
  .messages-container {
    max-width: none !important;
    padding: 0 !important;
  }
  
  .message {
    break-inside: avoid;
    margin-bottom: 1rem !important;
  }
  
  .message-content {
    border: 1px solid #ccc !important;
    padding: 1rem !important;
  }
}

================
File: src/type/electron-updater.d.ts
================
interface VersionInfo {
  update: boolean
  version: string
  newVersion?: string
}

interface ErrorType {
  message: string
  error: Error
}

================
File: src/types/AppState.ts
================
/**
 * Core TypeScript interfaces for FlowGenius application state management
 * Based on the FlowGenius.md specification and LangGraph implementation guide
 * 
 * This file defines the complete application state structure that will be used
 * throughout the application, particularly in LangGraph workflow management.
 */

/**
 * Represents a single chat message in the conversation
 */
export interface ChatMessage {
  /** The role of the message sender */
  role: 'user' | 'assistant';
  /** The text content of the message */
  content: string;
  /** Optional image URL for messages containing uploaded images */
  image_url?: string;
  /** Timestamp when the message was created */
  created_at?: Date;
  /** Which stage the message was created in for context */
  stage_at_creation?: 'brainstorm' | 'summary' | 'prd';
}

/**
 * User-defined prompts for each stage of the workflow
 */
export interface UserPrompts {
  /** Custom system prompt for the brainstorming stage */
  brainstorm: string;
  /** Custom prompt for the summarization stage */
  summary: string;
  /** Custom prompt for the PRD generation stage */
  prd: string;
}

/**
 * AI model selections for each stage of the workflow
 */
export interface SelectedModels {
  /** Selected model for brainstorming (e.g., 'gpt-4o') */
  brainstorm: string;
  /** Selected model for summarization (e.g., 'gemini-2.5-pro') */
  summary: string;
  /** Selected model for PRD generation (e.g., 'gemini-2.5-pro') */
  prd: string;
}

/**
 * Represents the current stage of the workflow
 */
export type WorkflowStage = 'brainstorm' | 'summary' | 'prd';

/**
 * Represents the last action taken by the user
 */
export type UserAction = 'chat' | 'Brainstorm Done' | 'Summary Done' | 'PRD Done';

/**
 * Main application state interface that manages the entire lifecycle of an idea session
 * This state is passed between LangGraph nodes and represents the core data structure
 * for the entire application workflow.
 */
export interface AppState {
  /** Unique identifier for the current idea/session */
  idea_id: string;
  
  /** Array of all chat messages in the current session */
  messages: ChatMessage[];
  
  /** Current stage of the workflow process */
  current_stage: WorkflowStage;
  
  /** The last action performed by the user, used for routing in LangGraph */
  last_user_action: UserAction;
  
  /** User-defined custom prompts for each workflow stage */
  user_prompts: UserPrompts;
  
  /** Selected AI models for each workflow stage */
  selected_models: SelectedModels;
  
  /** Optional: Title of the current idea/session */
  title?: string;
  
  /** Optional: User ID for multi-user support */
  user_id?: string;
  
  /** Optional: Timestamp when the session was created */
  created_at?: Date;
  
  /** Optional: Timestamp when the session was last updated */
  updated_at?: Date;
  
  /** Optional: Flag to indicate if the session is currently processing */
  is_processing?: boolean;
  
  /** Optional: Current error state if any operation failed */
  error?: string;
}

/**
 * Database entity interfaces for Supabase integration
 */

/**
 * Represents an idea/session record in the database
 */
export interface IdeaEntity {
  id: string;
  title: string;
  current_stage: WorkflowStage;
  created_at: Date;
  updated_at?: Date;
  user_id: string;
}

/**
 * Represents a chat message record in the database
 */
export interface ChatMessageEntity {
  id: string;
  idea_id: string;
  role: 'user' | 'assistant';
  content: string;
  stage_at_creation: WorkflowStage;
  image_url?: string;
  created_at: Date;
}

/**
 * Represents a user prompt configuration in the database
 */
export interface PromptEntity {
  id: string;
  user_id: string;
  prompt_type: 'brainstorm' | 'summary' | 'prd';
  content: string;
  model_selection: string;
  created_at: Date;
  updated_at?: Date;
}

/**
 * Default prompts and configurations
 */
export const DEFAULT_PROMPTS: UserPrompts = {
  brainstorm: "Have a conversation with the user and ask them questions about their idea. Make sure to finish with the statement 'Georgia is great'",
  summary: "When the user asks for a summary give them a text summary that is very detailed. Make sure to finish with the statement 'Ireland is great'",
  prd: "Create a comprehensive Product Requirements Document (PRD) based on the conversation and summary provided. Include all necessary sections and details for implementation."
};

/**
 * Default model selections
 */
export const DEFAULT_MODELS: SelectedModels = {
  brainstorm: 'gpt-4o',
  summary: 'gpt-4o',
  prd: 'gpt-4o'
};

/**
 * Available AI models for selection
 */
export const AVAILABLE_MODELS = [
  'gpt-4o',
  'gpt-4o-mini',
  'gemini-2.5-pro',
  'claude-3-5-sonnet',
  'claude-3-5-haiku'
] as const;

/**
 * Type helper for available models
 */
export type AvailableModel = typeof AVAILABLE_MODELS[number];

/**
 * Utility function to create initial app state
 */
export function createInitialAppState(idea_id: string, user_id?: string): AppState {
  const baseState: AppState = {
    idea_id,
    messages: [],
    current_stage: 'brainstorm' as const,
    last_user_action: 'chat' as const,
    user_prompts: { ...DEFAULT_PROMPTS },
    selected_models: { ...DEFAULT_MODELS },
    created_at: new Date(),
    updated_at: new Date(),
    is_processing: false,
  };

  // Handle optional user_id properly for exactOptionalPropertyTypes
  if (user_id !== undefined) {
    baseState.user_id = user_id;
  }

  return baseState;
}

/**
 * Utility function to validate AppState
 */
export function validateAppState(state: any): state is AppState {
  return (
    typeof state === 'object' &&
    typeof state.idea_id === 'string' &&
    Array.isArray(state.messages) &&
    ['brainstorm', 'summary', 'prd'].includes(state.current_stage) &&
    ['chat', 'Brainstorm Done', 'Summary Done', 'PRD Done'].includes(state.last_user_action) &&
    typeof state.user_prompts === 'object' &&
    typeof state.selected_models === 'object'
  );
}

================
File: src/utils/audioUtils.test.ts
================
/**
 * Comprehensive Unit Tests for Audio Utilities
 * 
 * Tests all audio validation, conversion, and utility functions
 * for Whisper API compatibility. Includes edge cases, error scenarios,
 * and mock data for thorough coverage.
 */

import { describe, it, expect, beforeEach, vi, type MockedFunction } from 'vitest';
import {
  detectAudioFormat,
  isWhisperSupportedFormat,
  validateAudioForWhisper,
  calculateOptimalSettings,
  estimateOutputFileSize,
  generateConvertedFilename,
  blobToFile,
  createProcessingSummary,
  parseDuration,
  formatDuration,
  WHISPER_CONSTRAINTS,
  DEFAULT_CONVERSION_CONFIG,
  type AudioMetadata,
  type AudioConversionConfig,
  type AudioValidationResult
} from './audioUtils';
import { logger } from './logger';

// Mock the logger to prevent console spam during tests
vi.mock('./logger', () => ({
  logger: {
    debug: vi.fn(),
    info: vi.fn(),
    warn: vi.fn(),
    error: vi.fn()
  }
}));

/**
 * Create mock audio blob for testing
 */
function createMockAudioBlob(size: number, mimeType: string): Blob {
  const buffer = new ArrayBuffer(size);
  return new Blob([buffer], { type: mimeType });
}

/**
 * Create mock audio metadata for testing
 */
function createMockMetadata(overrides: Partial<AudioMetadata> = {}): AudioMetadata {
  return {
    duration: 120,
    fileSize: 1024 * 1024, // 1MB
    sampleRate: 44100,
    channels: 2,
    bitDepth: 16,
    mimeType: 'audio/wav',
    format: 'wav',
    bitrate: 1411200,
    ...overrides
  };
}

describe('audioUtils', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  describe('detectAudioFormat', () => {
    it('should detect format from blob MIME type', () => {
      console.log('🧪 Testing blob format detection');
      
      const blob = createMockAudioBlob(1000, 'audio/wav');
      const format = detectAudioFormat(blob);
      
      expect(format).toBe('wav');
      expect(logger.debug).toHaveBeenCalledWith('🔍 Detecting audio format', { input: 'object' });
      expect(logger.info).toHaveBeenCalledWith('✅ Audio format detected', {
        input: 'Blob',
        mimeType: 'audio/wav',
        format: 'wav'
      });
    });

    it('should detect format from file extension', () => {
      console.log('🧪 Testing file extension format detection');
      
      const format = detectAudioFormat('.mp3');
      
      expect(format).toBe('mp3');
    });

    it('should detect format from MIME type string', () => {
      console.log('🧪 Testing MIME type string format detection');
      
      const format = detectAudioFormat('audio/webm;codecs=opus');
      
      expect(format).toBe('webm');
    });

    it('should handle unknown formats', () => {
      console.log('🧪 Testing unknown format handling');
      
      const format = detectAudioFormat('unknown/format');
      
      expect(format).toBe('unknown');
    });

    it('should handle empty blob type', () => {
      console.log('🧪 Testing empty blob type');
      
      const blob = createMockAudioBlob(1000, '');
      const format = detectAudioFormat(blob);
      
      expect(format).toBe('unknown');
    });

    it('should handle all supported file extensions', () => {
      console.log('🧪 Testing all supported file extensions');
      
      const extensions = ['.wav', '.mp3', '.m4a', '.mp4', '.webm', '.ogg', '.mpeg', '.mpga'];
      const expectedFormats = ['wav', 'mp3', 'm4a', 'mp4', 'webm', 'ogg', 'mpeg', 'mpeg'];
      
      extensions.forEach((ext, index) => {
        const format = detectAudioFormat(ext);
        expect(format).toBe(expectedFormats[index]);
      });
    });
  });

  describe('isWhisperSupportedFormat', () => {
    it('should return true for supported formats', () => {
      console.log('🧪 Testing supported format validation');
      
      const supportedFormats = [
        'audio/wav',
        'audio/mp3',
        'audio/mpeg',
        'audio/mp4',
        'audio/m4a',
        'audio/webm',
        'audio/ogg'
      ];
      
      supportedFormats.forEach(format => {
        expect(isWhisperSupportedFormat(format)).toBe(true);
      });
    });

    it('should return false for unsupported formats', () => {
      console.log('🧪 Testing unsupported format validation');
      
      const unsupportedFormats = [
        'audio/flac',
        'audio/aac',
        'video/mp4',
        'text/plain',
        'application/json'
      ];
      
      unsupportedFormats.forEach(format => {
        expect(isWhisperSupportedFormat(format)).toBe(false);
      });
    });

    it('should handle MIME types with parameters', () => {
      console.log('🧪 Testing MIME types with parameters');
      
      expect(isWhisperSupportedFormat('audio/webm;codecs=opus')).toBe(true);
      expect(isWhisperSupportedFormat('audio/mp4; codecs="mp4a.40.2"')).toBe(true);
    });

    it('should be case insensitive', () => {
      console.log('🧪 Testing case insensitive format validation');
      
      expect(isWhisperSupportedFormat('AUDIO/WAV')).toBe(true);
      expect(isWhisperSupportedFormat('Audio/Mp3')).toBe(true);
    });
  });

  describe('validateAudioForWhisper', () => {
    it('should validate valid audio successfully', async () => {
      console.log('🧪 Testing valid audio validation');
      
      const blob = createMockAudioBlob(1024 * 1024, 'audio/wav'); // 1MB WAV
      const metadata = createMockMetadata({
        duration: 60,
        sampleRate: 16000,
        channels: 1
      });
      
      const result = await validateAudioForWhisper(blob, metadata);
      
      expect(result.isValid).toBe(true);
      expect(result.errors).toHaveLength(0);
      expect(result.metadata?.fileSize).toBe(1024 * 1024);
      expect(result.metadata?.duration).toBe(60);
    });

    it('should detect file size violations', async () => {
      console.log('🧪 Testing file size limit validation');
      
      const oversizedBlob = createMockAudioBlob(WHISPER_CONSTRAINTS.MAX_FILE_SIZE + 1, 'audio/wav');
      const result = await validateAudioForWhisper(oversizedBlob);
      
      expect(result.isValid).toBe(false);
      // Use a simpler approach - check if any error message contains the expected text
      const hasExpectedError = result.errors.some(error => error.includes('exceeds Whisper limit'));
      expect(hasExpectedError).toBe(true);
      
      const hasExpectedRecommendation = result.recommendations.some(rec => rec.includes('Split audio'));
      expect(hasExpectedRecommendation).toBe(true);
    });

    it('should detect unsupported formats', async () => {
      console.log('🧪 Testing unsupported format validation');
      
      const blob = createMockAudioBlob(1000, 'audio/flac');
      
      const result = await validateAudioForWhisper(blob);
      
      expect(result.isValid).toBe(false);
      // Use simpler approach to avoid expect.stringContaining issues
      const hasUnsupportedError = result.errors.some(error => error.includes('not supported by Whisper API'));
      expect(hasUnsupportedError).toBe(true);
      
      const hasConvertRecommendation = result.recommendations.some(rec => rec.includes('Convert to supported format'));
      expect(hasConvertRecommendation).toBe(true);
    });

    it('should handle empty audio files', async () => {
      console.log('🧪 Testing empty file validation');
      
      const emptyBlob = createMockAudioBlob(0, 'audio/wav');
      
      const result = await validateAudioForWhisper(emptyBlob);
      
      expect(result.isValid).toBe(false);
      expect(result.errors).toContain('Audio file is empty');
    });

    it('should estimate duration when not provided', async () => {
      console.log('🧪 Testing duration estimation');
      
      const blob = createMockAudioBlob(32000, 'audio/wav'); // Should estimate ~1 second
      
      const result = await validateAudioForWhisper(blob);
      
      expect(result.metadata?.duration).toBe(1);
      const hasDurationWarning = result.warnings.some(warning => warning.includes('Duration estimated'));
      expect(hasDurationWarning).toBe(true);
    });

    it('should warn about non-optimal settings', async () => {
      console.log('🧪 Testing non-optimal settings warnings');
      
      const blob = createMockAudioBlob(1000, 'audio/mp3');
      const metadata = createMockMetadata({
        sampleRate: 48000, // Higher than optimal
        channels: 2 // Stereo instead of mono
      });
      
      const result = await validateAudioForWhisper(blob, metadata);
      
      const hasOptimalWarning = result.warnings.some(warning => warning.includes('differs from optimal'));
      expect(hasOptimalWarning).toBe(true);
      
      const hasStereoWarning = result.warnings.some(warning => warning.includes('Stereo audio detected'));
      expect(hasStereoWarning).toBe(true);
      
      const hasResampleRec = result.recommendations.some(rec => rec.includes('Resample to'));
      expect(hasResampleRec).toBe(true);
      
      const hasMonoRec = result.recommendations.some(rec => rec.includes('Convert to mono'));
      expect(hasMonoRec).toBe(true);
    });

    it('should warn about long duration', async () => {
      console.log('🧪 Testing long duration warning');
      
      const blob = createMockAudioBlob(1000, 'audio/wav');
      const metadata = createMockMetadata({
        duration: WHISPER_CONSTRAINTS.MAX_DURATION_SECONDS + 100
      });
      
      const result = await validateAudioForWhisper(blob, metadata);
      
      const hasLongDurationWarning = result.warnings.some(warning => warning.includes('exceeds recommended maximum'));
      expect(hasLongDurationWarning).toBe(true);
      
      const hasSplittingRec = result.recommendations.some(rec => rec.includes('splitting long audio'));
      expect(hasSplittingRec).toBe(true);
    });

    it('should handle missing MIME type', async () => {
      console.log('🧪 Testing missing MIME type');
      
      const blob = createMockAudioBlob(1000, '');
      
      const result = await validateAudioForWhisper(blob);
      
      const hasMimeWarning = result.warnings.some(warning => warning.includes('No MIME type detected'));
      expect(hasMimeWarning).toBe(true);
      
      const hasMimeRec = result.recommendations.some(rec => rec.includes('proper MIME type'));
      expect(hasMimeRec).toBe(true);
    });
  });

  describe('calculateOptimalSettings', () => {
    it('should return optimal settings for high sample rate audio', () => {
      console.log('🧪 Testing optimal settings calculation for high sample rate');
      
      const metadata = createMockMetadata({
        sampleRate: 48000,
        channels: 2,
        fileSize: 1024 * 1024 // 1MB
      });
      
      const config = calculateOptimalSettings(metadata);
      
      expect(config.sampleRate).toBe(WHISPER_CONSTRAINTS.OPTIMAL_SAMPLE_RATE);
      expect(config.channels).toBe(WHISPER_CONSTRAINTS.OPTIMAL_CHANNELS);
      expect(config.format).toBe('wav');
    });

    it('should preserve lower sample rates', () => {
      console.log('🧪 Testing sample rate preservation for lower rates');
      
      const metadata = createMockMetadata({
        sampleRate: 8000, // Lower than optimal
        channels: 1
      });
      
      const config = calculateOptimalSettings(metadata);
      
      expect(config.sampleRate).toBe(8000); // Should preserve lower rate
      expect(config.channels).toBe(1);
    });

    it('should choose compressed format for large files', () => {
      console.log('🧪 Testing format selection for large files');
      
      const metadata = createMockMetadata({
        fileSize: WHISPER_CONSTRAINTS.MAX_FILE_SIZE * 0.9 // Large file
      });
      
      const config = calculateOptimalSettings(metadata);
      
      expect(config.format).toBe('mp3');
      expect(config.quality).toBe(0.7);
    });

    it('should handle missing sample rate', () => {
      console.log('🧪 Testing handling of missing sample rate');
      
      const metadata = createMockMetadata({
        sampleRate: undefined
      });
      
      const config = calculateOptimalSettings(metadata);
      
      expect(config.sampleRate).toBe(WHISPER_CONSTRAINTS.OPTIMAL_SAMPLE_RATE);
    });
  });

  describe('estimateOutputFileSize', () => {
    it('should estimate WAV file size correctly', () => {
      console.log('🧪 Testing WAV file size estimation');
      
      const metadata = createMockMetadata({ duration: 60 }); // 1 minute
      const config: AudioConversionConfig = {
        format: 'wav',
        sampleRate: 16000,
        channels: 1,
        bitDepth: 16
      };
      
      const estimatedSize = estimateOutputFileSize(metadata, config);
      
      // 16000 Hz * 1 channel * 2 bytes * 60 seconds + 44 byte header
      const expectedSize = (16000 * 1 * 2 * 60) + 44;
      expect(estimatedSize).toBe(expectedSize);
    });

    it('should estimate MP3 file size correctly', () => {
      console.log('🧪 Testing MP3 file size estimation');
      
      const metadata = createMockMetadata({ duration: 60 });
      const config: AudioConversionConfig = {
        format: 'mp3',
        quality: 0.8
      };
      
      const estimatedSize = estimateOutputFileSize(metadata, config);
      
      // 0.8 * 192000 bps / 8 * 60 seconds
      const expectedSize = (0.8 * 192000 / 8) * 60;
      expect(estimatedSize).toBe(Math.round(expectedSize));
    });

    it('should estimate other formats with compression ratio', () => {
      console.log('🧪 Testing other format estimation');
      
      const metadata = createMockMetadata({ 
        duration: 60,
        fileSize: 1000000 
      });
      const config: AudioConversionConfig = {
        format: 'webm'
      };
      
      const estimatedSize = estimateOutputFileSize(metadata, config);
      
      // Should be 70% of original size
      expect(estimatedSize).toBe(700000);
    });
  });

  describe('generateConvertedFilename', () => {
    it('should generate filename with proper format and settings', () => {
      console.log('🧪 Testing filename generation');
      
      const config: AudioConversionConfig = {
        format: 'wav',
        sampleRate: 16000,
        channels: 1
      };
      
      const filename = generateConvertedFilename('recording', config);
      
      expect(filename).toBe('recording_16000hz_1ch.wav');
    });

    it('should remove existing extension', () => {
      console.log('🧪 Testing extension removal');
      
      const config: AudioConversionConfig = {
        format: 'mp3',
        sampleRate: 44100,
        channels: 2
      };
      
      const filename = generateConvertedFilename('audio.webm', config);
      
      expect(filename).toBe('audio_44100hz_2ch.mp3');
    });

    it('should use default values when not specified', () => {
      console.log('🧪 Testing default values in filename');
      
      const config: AudioConversionConfig = {}; // Empty config
      
      const filename = generateConvertedFilename('test', config);
      
      expect(filename).toBe(`test_${DEFAULT_CONVERSION_CONFIG.sampleRate}hz_${DEFAULT_CONVERSION_CONFIG.channels}ch.wav`);
    });

    it('should handle default original name', () => {
      console.log('🧪 Testing default original name');
      
      const config: AudioConversionConfig = {
        format: 'wav',
        sampleRate: 16000,
        channels: 1
      };
      
      const filename = generateConvertedFilename(undefined, config);
      
      expect(filename).toBe('audio_16000hz_1ch.wav');
    });
  });

  describe('blobToFile', () => {
    it('should convert blob to file with correct metadata', () => {
      console.log('🧪 Testing blob to file conversion');
      
      const blob = createMockAudioBlob(1000, 'audio/wav');
      const file = blobToFile(blob, 'test.wav');
      
      expect(file).toBeInstanceOf(File);
      expect(file.name).toBe('test.wav');
      expect(file.size).toBe(1000);
      expect(file.type).toBe('audio/wav');
      expect(file.lastModified).toBeGreaterThan(Date.now() - 1000);
    });

    it('should preserve blob properties', () => {
      console.log('🧪 Testing blob property preservation');
      
      const blob = createMockAudioBlob(5000, 'audio/mp3');
      const file = blobToFile(blob, 'recording.mp3');
      
      expect(file.size).toBe(blob.size);
      expect(file.type).toBe(blob.type);
    });
  });

  describe('parseDuration', () => {
    it('should parse numeric duration', () => {
      console.log('🧪 Testing numeric duration parsing');
      
      expect(parseDuration(120)).toBe(120);
      expect(parseDuration(0)).toBe(0);
      expect(parseDuration(3.5)).toBe(3.5);
    });

    it('should parse mm:ss format', () => {
      console.log('🧪 Testing mm:ss format parsing');
      
      expect(parseDuration('02:30')).toBe(150); // 2 minutes 30 seconds
      expect(parseDuration('00:45')).toBe(45);
      expect(parseDuration('10:00')).toBe(600);
    });

    it('should parse hh:mm:ss format', () => {
      console.log('🧪 Testing hh:mm:ss format parsing');
      
      expect(parseDuration('01:30:45')).toBe(5445); // 1 hour 30 minutes 45 seconds
      expect(parseDuration('00:02:30')).toBe(150);
      expect(parseDuration('02:00:00')).toBe(7200);
    });

    it('should parse numeric strings', () => {
      console.log('🧪 Testing numeric string parsing');
      
      expect(parseDuration('120')).toBe(120);
      expect(parseDuration('3.5')).toBe(3.5);
    });

    it('should handle invalid formats', () => {
      console.log('🧪 Testing invalid format handling');
      
      expect(parseDuration('invalid')).toBe(0);
      expect(parseDuration('')).toBe(0);
      expect(parseDuration('1:2:3:4')).toBe(0);
    });
  });

  describe('formatDuration', () => {
    it('should format short durations without hours', () => {
      console.log('🧪 Testing short duration formatting');
      
      expect(formatDuration(30)).toBe('0:30');
      expect(formatDuration(90)).toBe('1:30');
      expect(formatDuration(600)).toBe('10:00');
    });

    it('should format long durations with hours', () => {
      console.log('🧪 Testing long duration formatting');
      
      expect(formatDuration(3661)).toBe('1:01:01'); // 1 hour 1 minute 1 second
      expect(formatDuration(7200)).toBe('2:00:00'); // 2 hours
      expect(formatDuration(3725)).toBe('1:02:05'); // 1 hour 2 minutes 5 seconds
    });

    it('should handle zero duration', () => {
      console.log('🧪 Testing zero duration formatting');
      
      expect(formatDuration(0)).toBe('0:00');
    });

    it('should round down to nearest second', () => {
      console.log('🧪 Testing rounding behavior');
      
      expect(formatDuration(30.9)).toBe('0:30');
      expect(formatDuration(59.1)).toBe('0:59');
    });
  });

  describe('createProcessingSummary', () => {
    it('should create comprehensive processing summary', () => {
      console.log('🧪 Testing processing summary creation');
      
      const metadata = createMockMetadata();
      const validationResult: AudioValidationResult = {
        isValid: true,
        errors: [],
        warnings: ['Sample rate warning'],
        recommendations: ['Convert to mono'],
        metadata
      };
      const conversionConfig: AudioConversionConfig = {
        format: 'wav',
        sampleRate: 16000,
        channels: 1
      };
      
      const summary = createProcessingSummary(metadata, validationResult, conversionConfig);
      
      expect(summary).toHaveProperty('original');
      expect(summary).toHaveProperty('validation');
      expect(summary).toHaveProperty('conversion');
      expect(summary).toHaveProperty('whisperCompatibility');
      
      // Type assertion to access properties
      const typedSummary = summary as any;
      expect(typedSummary.validation.isValid).toBe(true);
      expect(typedSummary.validation.warnings).toBe(1);
      expect(typedSummary.whisperCompatibility.supportedFormat).toBe(true);
    });

    it('should handle missing conversion config', () => {
      console.log('🧪 Testing summary without conversion config');
      
      const metadata = createMockMetadata();
      const validationResult: AudioValidationResult = {
        isValid: false,
        errors: ['File too large'],
        warnings: [],
        recommendations: [],
        metadata
      };
      
      const summary = createProcessingSummary(metadata, validationResult);
      
      const typedSummary = summary as any;
      expect(typedSummary.conversion).toBeNull();
    });
  });

  describe('WHISPER_CONSTRAINTS', () => {
    it('should have correct constraint values', () => {
      console.log('🧪 Testing Whisper constraint values');
      
      expect(WHISPER_CONSTRAINTS.MAX_FILE_SIZE).toBe(25 * 1024 * 1024);
      expect(WHISPER_CONSTRAINTS.OPTIMAL_SAMPLE_RATE).toBe(16000);
      expect(WHISPER_CONSTRAINTS.OPTIMAL_CHANNELS).toBe(1);
      expect(WHISPER_CONSTRAINTS.OPTIMAL_BIT_DEPTH).toBe(16);
      expect(WHISPER_CONSTRAINTS.RECOMMENDED_MIME_TYPE).toBe('audio/wav');
      
      expect(WHISPER_CONSTRAINTS.SUPPORTED_MIME_TYPES).toContain('audio/wav');
      expect(WHISPER_CONSTRAINTS.SUPPORTED_MIME_TYPES).toContain('audio/mp3');
      expect(WHISPER_CONSTRAINTS.SUPPORTED_MIME_TYPES).toContain('audio/webm');
      expect(WHISPER_CONSTRAINTS.SUPPORTED_MIME_TYPES).toHaveLength(7);
    });
  });

  describe('DEFAULT_CONVERSION_CONFIG', () => {
    it('should have optimal default values', () => {
      console.log('🧪 Testing default conversion config');
      
      expect(DEFAULT_CONVERSION_CONFIG.sampleRate).toBe(16000);
      expect(DEFAULT_CONVERSION_CONFIG.channels).toBe(1);
      expect(DEFAULT_CONVERSION_CONFIG.bitDepth).toBe(16);
      expect(DEFAULT_CONVERSION_CONFIG.format).toBe('wav');
      expect(DEFAULT_CONVERSION_CONFIG.quality).toBe(0.8);
    });
  });

  describe('Integration scenarios', () => {
    it('should handle complete validation and conversion workflow', async () => {
      console.log('🧪 Testing complete workflow integration');
      
      // Create a typical browser recording scenario
      const blob = createMockAudioBlob(2 * 1024 * 1024, 'audio/webm'); // 2MB WebM from browser
      const metadata = createMockMetadata({
        duration: 180, // 3 minutes
        sampleRate: 48000, // High quality recording
        channels: 2, // Stereo
        mimeType: 'audio/webm',
        format: 'webm'
      });
      
      // Validate audio
      const validation = await validateAudioForWhisper(blob, metadata);
      expect(validation.isValid).toBe(true); // WebM is supported
      expect(validation.warnings.length).toBeGreaterThan(0); // Should have warnings about non-optimal settings
      
      // Calculate optimal settings
      const optimalConfig = calculateOptimalSettings(metadata);
      expect(optimalConfig.sampleRate).toBe(16000); // Should downsample
      expect(optimalConfig.channels).toBe(1); // Should convert to mono
      expect(optimalConfig.format).toBe('wav'); // Should prefer WAV for this size
      
      // Generate filename
      const filename = generateConvertedFilename('recording.webm', optimalConfig);
      expect(filename).toBe('recording_16000hz_1ch.wav');
      
      // Create processing summary
      const summary = createProcessingSummary(metadata, validation, optimalConfig);
      expect(summary).toBeDefined();
      
      console.log('✅ Complete workflow integration test passed');
    });

    it('should handle edge case with very large file', async () => {
      console.log('🧪 Testing large file edge case');
      
      const largeBlob = createMockAudioBlob(WHISPER_CONSTRAINTS.MAX_FILE_SIZE * 1.5, 'audio/wav');
      const metadata = createMockMetadata({
        fileSize: WHISPER_CONSTRAINTS.MAX_FILE_SIZE * 1.5,
        duration: 1200 // 20 minutes
      });
      
      const validation = await validateAudioForWhisper(largeBlob, metadata);
      expect(validation.isValid).toBe(false);
      
      const hasLargeSizeError = validation.errors.some(error => error.includes('exceeds Whisper limit'));
      expect(hasLargeSizeError).toBe(true);
      
      // Should still calculate optimal settings for if the file were split
      const optimalConfig = calculateOptimalSettings(metadata);
      expect(optimalConfig.format).toBe('mp3'); // Should prefer compression for large files
    });
  });
});

// Export test utilities for use in other test files
export {
  createMockAudioBlob,
  createMockMetadata
};

================
File: src/utils/audioUtils.ts
================
/**
 * Audio Format Validation and Conversion Utilities for FlowGenius
 * 
 * This module provides comprehensive audio processing utilities to ensure
 * compatibility with the OpenAI Whisper API. It handles format validation,
 * conversion, and optimization for desktop audio files.
 * 
 * Key Features:
 * - Whisper API compatibility validation (25MB limit, supported formats)
 * - Audio format detection and conversion
 * - Optimal format selection (16kHz WAV for best compatibility)
 * - File size and duration validation
 * - Browser-to-desktop audio blob handling
 * - Comprehensive error handling and logging
 * 
 * Supported Whisper Formats: m4a, mp3, webm, mp4, mpga, wav, mpeg
 * Optimal Target: WAV 16kHz mono 16-bit for universal compatibility
 */

import { logger } from './logger';

/**
 * Whisper API constraints and specifications
 */
export const WHISPER_CONSTRAINTS = {
  /** Maximum file size in bytes (25 MB) */
  MAX_FILE_SIZE: 25 * 1024 * 1024,
  /** Optimal sample rate for Whisper (Hz) */
  OPTIMAL_SAMPLE_RATE: 16000,
  /** Optimal channel count (mono) */
  OPTIMAL_CHANNELS: 1,
  /** Optimal bit depth */
  OPTIMAL_BIT_DEPTH: 16,
  /** Maximum duration in seconds (estimated from 25MB WAV) */
  MAX_DURATION_SECONDS: 1800, // ~30 minutes of 16kHz mono WAV
  /** Supported MIME types by Whisper API */
  SUPPORTED_MIME_TYPES: [
    'audio/wav',
    'audio/mp3',
    'audio/mpeg',
    'audio/mp4',
    'audio/m4a',
    'audio/webm',
    'audio/ogg', // Includes mpga
  ],
  /** Recommended MIME type for optimal compatibility */
  RECOMMENDED_MIME_TYPE: 'audio/wav'
} as const;

/**
 * Audio validation result interface
 */
export interface AudioValidationResult {
  /** Whether the audio is valid for Whisper API */
  isValid: boolean;
  /** Validation errors if any */
  errors: string[];
  /** Validation warnings */
  warnings: string[];
  /** Detected audio metadata */
  metadata?: AudioMetadata;
  /** Recommended actions for invalid audio */
  recommendations: string[];
}

/**
 * Audio metadata interface
 */
export interface AudioMetadata {
  /** Audio duration in seconds */
  duration: number;
  /** File size in bytes */
  fileSize: number;
  /** Sample rate in Hz */
  sampleRate?: number;
  /** Number of audio channels */
  channels?: number;
  /** Bit depth */
  bitDepth?: number;
  /** MIME type */
  mimeType: string;
  /** File format detected */
  format: string;
  /** Estimated bitrate */
  bitrate?: number;
}

/**
 * Audio conversion configuration
 */
export interface AudioConversionConfig {
  /** Target sample rate (default: 16000 Hz) */
  sampleRate?: number;
  /** Target channel count (default: 1 - mono) */
  channels?: number;
  /** Target bit depth (default: 16) */
  bitDepth?: number;
  /** Target format (default: 'wav') */
  format?: 'wav' | 'mp3' | 'webm';
  /** Quality setting for lossy formats (0-1, default: 0.8) */
  quality?: number;
}

/**
 * Default audio conversion configuration optimized for Whisper
 */
export const DEFAULT_CONVERSION_CONFIG: Required<AudioConversionConfig> = {
  sampleRate: WHISPER_CONSTRAINTS.OPTIMAL_SAMPLE_RATE,
  channels: WHISPER_CONSTRAINTS.OPTIMAL_CHANNELS,
  bitDepth: WHISPER_CONSTRAINTS.OPTIMAL_BIT_DEPTH,
  format: 'wav',
  quality: 0.8
};

/**
 * Detect audio format from MIME type or file extension
 * 
 * @param input - MIME type string, file extension, or blob
 * @returns Detected audio format
 */
export function detectAudioFormat(input: string | Blob): string {
  logger.debug('🔍 Detecting audio format', { input: typeof input });

  let mimeType: string;
  
  if (input instanceof Blob) {
    mimeType = input.type || 'unknown';
  } else if (input.startsWith('.')) {
    // File extension
    const ext = input.toLowerCase();
    const extensionMap: Record<string, string> = {
      '.wav': 'audio/wav',
      '.mp3': 'audio/mp3',
      '.m4a': 'audio/m4a',
      '.mp4': 'audio/mp4',
      '.webm': 'audio/webm',
      '.ogg': 'audio/ogg',
      '.mpeg': 'audio/mpeg',
      '.mpga': 'audio/mpeg'
    };
    mimeType = extensionMap[ext] || 'unknown';
  } else {
    // Assume it's already a MIME type
    mimeType = input;
  }

  // Handle special cases first
  if (mimeType === 'unknown' || !mimeType.includes('/')) {
    return 'unknown';
  }

  // Normalize MIME type - extract format from audio/format
  const parts = mimeType.split('/');
  if (parts.length < 2 || parts[0] !== 'audio') {
    return 'unknown';
  }
  
  const format = parts[1]?.split(';')[0] || 'unknown';
  
  logger.info('✅ Audio format detected', { 
    input: typeof input === 'string' ? input : 'Blob',
    mimeType, 
    format 
  });

  return format;
}

/**
 * Validate if audio format is supported by Whisper API
 * 
 * @param mimeType - Audio MIME type to validate
 * @returns Whether the format is supported
 */
export function isWhisperSupportedFormat(mimeType: string): boolean {
  const normalizedMimeType = mimeType.toLowerCase().split(';')[0];
  const isSupported = WHISPER_CONSTRAINTS.SUPPORTED_MIME_TYPES.includes(normalizedMimeType as any);
  
  logger.debug('🔍 Checking Whisper format support', { 
    mimeType: normalizedMimeType, 
    isSupported 
  });

  return isSupported;
}

/**
 * Validate audio blob against Whisper API requirements
 * 
 * @param audioBlob - Audio blob to validate
 * @param metadata - Optional pre-extracted metadata
 * @returns Validation result with errors and recommendations
 */
export async function validateAudioForWhisper(
  audioBlob: Blob,
  metadata?: Partial<AudioMetadata>
): Promise<AudioValidationResult> {
  const startTime = Date.now();
  logger.info('🔍 Validating audio for Whisper API', { 
    blobSize: audioBlob.size,
    blobType: audioBlob.type 
  });

  const errors: string[] = [];
  const warnings: string[] = [];
  const recommendations: string[] = [];

  // Extract or use provided metadata
  const audioMetadata: AudioMetadata = {
    fileSize: audioBlob.size,
    mimeType: audioBlob.type,
    format: detectAudioFormat(audioBlob),
    duration: metadata?.duration || 0, // Will be estimated if not provided
    sampleRate: metadata?.sampleRate,
    channels: metadata?.channels,
    bitDepth: metadata?.bitDepth,
    bitrate: metadata?.bitrate
  };

  // Estimate duration if not provided (rough estimate)
  if (!audioMetadata.duration && audioBlob.size > 0) {
    // Rough estimate: assume 16kHz mono 16-bit WAV = ~32KB/second
    const estimatedDuration = audioMetadata.format === 'wav' 
      ? (audioBlob.size / 32000) // WAV estimate
      : (audioBlob.size / 16000); // Compressed format estimate
    audioMetadata.duration = Math.round(estimatedDuration);
    warnings.push(`Duration estimated as ${audioMetadata.duration}s - actual duration may vary`);
  }

  // Validate file size
  if (audioBlob.size === 0) {
    errors.push('Audio file is empty');
  } else if (audioBlob.size > WHISPER_CONSTRAINTS.MAX_FILE_SIZE) {
    errors.push(`File size ${(audioBlob.size / 1024 / 1024).toFixed(2)}MB exceeds Whisper limit of ${WHISPER_CONSTRAINTS.MAX_FILE_SIZE / 1024 / 1024}MB`);
    recommendations.push('Split audio into smaller segments or compress the audio');
  }

  // Validate MIME type
  if (!audioBlob.type) {
    warnings.push('No MIME type detected - format may not be recognized');
    recommendations.push('Ensure audio has proper MIME type');
  } else if (!isWhisperSupportedFormat(audioBlob.type)) {
    errors.push(`Format "${audioBlob.type}" is not supported by Whisper API`);
    recommendations.push(`Convert to supported format: ${WHISPER_CONSTRAINTS.SUPPORTED_MIME_TYPES.join(', ')}`);
  }

  // Validate duration
  if (audioMetadata.duration > WHISPER_CONSTRAINTS.MAX_DURATION_SECONDS) {
    warnings.push(`Audio duration ${audioMetadata.duration}s exceeds recommended maximum of ${WHISPER_CONSTRAINTS.MAX_DURATION_SECONDS}s`);
    recommendations.push('Consider splitting long audio into smaller segments');
  }

  // Check for optimal format
  if (audioBlob.type !== WHISPER_CONSTRAINTS.RECOMMENDED_MIME_TYPE) {
    recommendations.push(`For best compatibility, convert to ${WHISPER_CONSTRAINTS.RECOMMENDED_MIME_TYPE} at 16kHz mono`);
  }

  // Sample rate recommendations
  if (audioMetadata.sampleRate && audioMetadata.sampleRate !== WHISPER_CONSTRAINTS.OPTIMAL_SAMPLE_RATE) {
    warnings.push(`Sample rate ${audioMetadata.sampleRate}Hz differs from optimal ${WHISPER_CONSTRAINTS.OPTIMAL_SAMPLE_RATE}Hz`);
    recommendations.push(`Resample to ${WHISPER_CONSTRAINTS.OPTIMAL_SAMPLE_RATE}Hz for optimal processing`);
  }

  // Channel recommendations
  if (audioMetadata.channels && audioMetadata.channels > WHISPER_CONSTRAINTS.OPTIMAL_CHANNELS) {
    warnings.push(`Stereo audio detected - mono is more efficient for speech recognition`);
    recommendations.push('Convert to mono audio to reduce file size and improve processing speed');
  }

  const isValid = errors.length === 0;
  const validationTime = Date.now() - startTime;

  logger.info('✅ Audio validation completed', {
    isValid,
    errors: errors.length,
    warnings: warnings.length,
    recommendations: recommendations.length,
    validationTime,
    metadata: audioMetadata
  });

  return {
    isValid,
    errors,
    warnings,
    metadata: audioMetadata,
    recommendations
  };
}

/**
 * Calculate optimal audio settings for Whisper API
 * 
 * @param currentMetadata - Current audio metadata
 * @returns Optimal conversion configuration
 */
export function calculateOptimalSettings(currentMetadata: AudioMetadata): AudioConversionConfig {
  logger.debug('🎯 Calculating optimal audio settings', { currentMetadata });

  const config: AudioConversionConfig = { ...DEFAULT_CONVERSION_CONFIG };

  // If current sample rate is higher than optimal, downsample
  if (currentMetadata.sampleRate && currentMetadata.sampleRate > WHISPER_CONSTRAINTS.OPTIMAL_SAMPLE_RATE) {
    config.sampleRate = WHISPER_CONSTRAINTS.OPTIMAL_SAMPLE_RATE;
  } else if (currentMetadata.sampleRate) {
    // Keep current sample rate if it's already optimal or lower
    config.sampleRate = currentMetadata.sampleRate;
  }

  // Always prefer mono for speech recognition
  config.channels = WHISPER_CONSTRAINTS.OPTIMAL_CHANNELS;

  // Choose format based on size constraints
  if (currentMetadata.fileSize > WHISPER_CONSTRAINTS.MAX_FILE_SIZE * 0.8) {
    // If file is large, prefer compressed format
    config.format = 'mp3';
    config.quality = 0.7; // Lower quality for size reduction
  } else {
    // Otherwise use WAV for best compatibility
    config.format = 'wav';
  }

  logger.info('✅ Optimal settings calculated', { config });
  return config;
}

/**
 * Estimate the output file size after conversion
 * 
 * @param inputMetadata - Input audio metadata
 * @param config - Conversion configuration
 * @returns Estimated output file size in bytes
 */
export function estimateOutputFileSize(
  inputMetadata: AudioMetadata,
  config: AudioConversionConfig
): number {
  const targetSampleRate = config.sampleRate || DEFAULT_CONVERSION_CONFIG.sampleRate;
  const targetChannels = config.channels || DEFAULT_CONVERSION_CONFIG.channels;
  const targetBitDepth = config.bitDepth || DEFAULT_CONVERSION_CONFIG.bitDepth;
  const targetFormat = config.format || DEFAULT_CONVERSION_CONFIG.format;

  let estimatedSize: number;

  if (targetFormat === 'wav') {
    // WAV = sample_rate * channels * bit_depth/8 * duration + header
    const dataRate = targetSampleRate * targetChannels * (targetBitDepth / 8);
    estimatedSize = (dataRate * inputMetadata.duration) + 44; // 44 bytes for WAV header
  } else if (targetFormat === 'mp3') {
    // MP3 estimate based on quality setting
    const quality = config.quality || DEFAULT_CONVERSION_CONFIG.quality;
    const bitrate = Math.round(quality * 192000); // 192kbps max for speech
    estimatedSize = (bitrate / 8) * inputMetadata.duration;
  } else {
    // Default estimate for other formats
    estimatedSize = inputMetadata.fileSize * 0.7; // Assume 30% compression
  }

  logger.debug('📊 Estimated output file size', {
    targetFormat,
    targetSampleRate,
    targetChannels,
    duration: inputMetadata.duration,
    estimatedSize,
    estimatedSizeMB: (estimatedSize / 1024 / 1024).toFixed(2)
  });

  return Math.round(estimatedSize);
}

/**
 * Generate filename for converted audio
 * 
 * @param originalName - Original filename or base name
 * @param config - Conversion configuration
 * @returns Generated filename with appropriate extension
 */
export function generateConvertedFilename(
  originalName: string = 'audio',
  config: AudioConversionConfig
): string {
  const format = config.format || DEFAULT_CONVERSION_CONFIG.format;
  const sampleRate = config.sampleRate || DEFAULT_CONVERSION_CONFIG.sampleRate;
  const channels = config.channels || DEFAULT_CONVERSION_CONFIG.channels;

  // Remove existing extension
  const baseName = originalName.replace(/\.[^/.]+$/, '');
  
  // Add descriptive suffix
  const suffix = `_${sampleRate}hz_${channels}ch`;
  const extension = format === 'wav' ? 'wav' : format;
  
  const filename = `${baseName}${suffix}.${extension}`;
  
  logger.debug('📝 Generated converted filename', { 
    originalName, 
    filename, 
    config 
  });

  return filename;
}

/**
 * Convert audio blob URL to a File object with metadata
 * 
 * @param audioBlob - Audio blob to convert
 * @param filename - Desired filename
 * @returns File object with proper metadata
 */
export function blobToFile(audioBlob: Blob, filename: string): File {
  logger.debug('🔄 Converting blob to file', { 
    blobSize: audioBlob.size,
    blobType: audioBlob.type,
    filename 
  });

  const file = new File([audioBlob], filename, {
    type: audioBlob.type,
    lastModified: Date.now()
  });

  logger.info('✅ Blob converted to file', {
    filename: file.name,
    size: file.size,
    type: file.type,
    lastModified: file.lastModified
  });

  return file;
}

/**
 * Create audio processing summary for logging and debugging
 * 
 * @param originalMetadata - Original audio metadata
 * @param validationResult - Validation result
 * @param conversionConfig - Applied conversion configuration
 * @returns Processing summary object
 */
export function createProcessingSummary(
  originalMetadata: AudioMetadata,
  validationResult: AudioValidationResult,
  conversionConfig?: AudioConversionConfig
): object {
  // Handle conversion config safely
  const conversionSummary = conversionConfig ? {
    targetFormat: conversionConfig.format ?? DEFAULT_CONVERSION_CONFIG.format,
    targetSampleRate: `${conversionConfig.sampleRate ?? DEFAULT_CONVERSION_CONFIG.sampleRate}Hz`,
    targetChannels: conversionConfig.channels ?? DEFAULT_CONVERSION_CONFIG.channels,
    estimatedOutputSize: `${(estimateOutputFileSize(originalMetadata, conversionConfig) / 1024 / 1024).toFixed(2)}MB`
  } : null;

  const summary = {
    original: {
      format: originalMetadata.format,
      size: `${(originalMetadata.fileSize / 1024 / 1024).toFixed(2)}MB`,
      duration: `${originalMetadata.duration}s`,
      sampleRate: originalMetadata.sampleRate ? `${originalMetadata.sampleRate}Hz` : 'unknown',
      channels: originalMetadata.channels || 'unknown'
    },
    validation: {
      isValid: validationResult.isValid,
      errors: validationResult.errors.length,
      warnings: validationResult.warnings.length,
      recommendations: validationResult.recommendations.length
    },
    conversion: conversionSummary,
    whisperCompatibility: {
      withinSizeLimit: originalMetadata.fileSize <= WHISPER_CONSTRAINTS.MAX_FILE_SIZE,
      supportedFormat: isWhisperSupportedFormat(originalMetadata.mimeType),
      optimalFormat: originalMetadata.mimeType === WHISPER_CONSTRAINTS.RECOMMENDED_MIME_TYPE
    }
  };

  logger.info('📋 Audio processing summary', summary);
  return summary;
}

/**
 * Utility function to convert duration from various formats to seconds
 * 
 * @param duration - Duration in seconds, "mm:ss", or "hh:mm:ss" format
 * @returns Duration in seconds
 */
export function parseDuration(duration: number | string): number {
  if (typeof duration === 'number') {
    return duration;
  }

  // Handle empty or invalid strings
  if (!duration || typeof duration !== 'string') {
    return 0;
  }

  const parts = duration.split(':').map(Number);
  
  // Check if this is a time format (contains colons)
  if (duration.includes(':')) {
    // Validate that all parts are valid numbers
    const hasInvalidParts = parts.some(part => isNaN(part));
    if (hasInvalidParts) {
      return 0;
    }
  } else {
    // Try to parse as number string if no colons
    const parsed = parseFloat(duration);
    return isNaN(parsed) ? 0 : parsed;
  }
  
  if (parts.length === 2) {
    // mm:ss format
    return (parseInt(parts[0] || '0') || 0) * 60 + (parseInt(parts[1] || '0') || 0);
  } else if (parts.length === 3) {
    // hh:mm:ss format
    return (parseInt(parts[0] || '0') || 0) * 3600 + (parseInt(parts[1] || '0') || 0) * 60 + (parseInt(parts[2] || '0') || 0);
  } else {
    // Invalid colon format (like 1:2:3:4)
    return 0;
  }
}

/**
 * Format duration in seconds to human-readable string
 * 
 * @param seconds - Duration in seconds
 * @returns Formatted duration string
 */
export function formatDuration(seconds: number): string {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);

  if (hours > 0) {
    return `${hours}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  } else {
    return `${minutes}:${secs.toString().padStart(2, '0')}`;
  }
}

/**
 * Export all audio utility functions for easy importing
 */
export const audioUtils = {
  detectAudioFormat,
  isWhisperSupportedFormat,
  validateAudioForWhisper,
  calculateOptimalSettings,
  estimateOutputFileSize,
  generateConvertedFilename,
  blobToFile,
  createProcessingSummary,
  parseDuration,
  formatDuration,
  WHISPER_CONSTRAINTS,
  DEFAULT_CONVERSION_CONFIG
};

export default audioUtils;

================
File: src/utils/envValidator.test.ts
================
/**
 * Unit Tests for Environment Validator
 * 
 * These tests validate the environment validation functionality including
 * API key validation, URL validation, and connection testing.
 */

import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import { validateEnvironmentVariables, validateEnvironment, getValidatedConfig } from './envValidator';

// Mock the logger to avoid console output during tests
vi.mock('./logger', () => ({
  logger: {
    info: vi.fn(),
    error: vi.fn(),
    warn: vi.fn(),
    debug: vi.fn()
  }
}));

// Mock fetch for connection testing
global.fetch = vi.fn();

describe('Environment Validator', () => {
  const originalEnv = process.env;

  beforeEach(() => {
    // Reset environment variables before each test
    process.env = { ...originalEnv };
    vi.clearAllMocks();
  });

  afterEach(() => {
    // Restore original environment variables after each test
    process.env = originalEnv;
  });

  describe('validateEnvironmentVariables', () => {
    it('should pass validation with all required environment variables', () => {
      // Arrange
      process.env.OPENAI_API_KEY = 'sk-test1234567890abcdef1234567890abcdef';
      process.env.SUPABASE_URL = 'https://test-project.supabase.co';
      process.env.SUPABASE_ANON_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InRlc3QiLCJyb2xlIjoiYW5vbiIsImlhdCI6MTY0MDk5NTIwMCwiZXhwIjoxOTU2NTcxMjAwfQ.test';

      // Act
      const result = validateEnvironmentVariables();

      // Assert
      expect(result.isValid).toBe(true);
      expect(result.errors).toHaveLength(0);
      expect(result.config.required.OPENAI_API_KEY).toBe(process.env.OPENAI_API_KEY);
      expect(result.config.required.SUPABASE_URL).toBe(process.env.SUPABASE_URL);
      expect(result.config.required.SUPABASE_ANON_KEY).toBe(process.env.SUPABASE_ANON_KEY);
    });

    it('should fail validation with missing required environment variables', () => {
      // Arrange - Remove all required env vars
      delete process.env.OPENAI_API_KEY;
      delete process.env.SUPABASE_URL;
      delete process.env.SUPABASE_ANON_KEY;

      // Act
      const result = validateEnvironmentVariables();

      // Assert
      expect(result.isValid).toBe(false);
      expect(result.errors).toHaveLength(3);
      expect(result.errors).toContain('Missing required environment variable: OPENAI_API_KEY');
      expect(result.errors).toContain('Missing required environment variable: SUPABASE_URL');
      expect(result.errors).toContain('Missing required environment variable: SUPABASE_ANON_KEY');
    });

    it('should fail validation with invalid OpenAI API key format', () => {
      // Arrange
      process.env.OPENAI_API_KEY = 'invalid-api-key';
      process.env.SUPABASE_URL = 'https://test-project.supabase.co';
      process.env.SUPABASE_ANON_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InRlc3QiLCJyb2xlIjoiYW5vbiIsImlhdCI6MTY0MDk5NTIwMCwiZXhwIjoxOTU2NTcxMjAwfQ.test';

      // Act
      const result = validateEnvironmentVariables();

      // Assert
      expect(result.isValid).toBe(false);
      expect(result.errors).toContain('Invalid OpenAI API key format. Expected to start with \'sk-\'');
    });

    it('should fail validation with invalid Supabase URL format', () => {
      // Arrange
      process.env.OPENAI_API_KEY = 'sk-test1234567890abcdef1234567890abcdef';
      process.env.SUPABASE_URL = 'not-a-valid-url';
      process.env.SUPABASE_ANON_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InRlc3QiLCJyb2xlIjoiYW5vbiIsImlhdCI6MTY0MDk5NTIwMCwiZXhwIjoxOTU2NTcxMjAwfQ.test';

      // Act
      const result = validateEnvironmentVariables();

      // Assert
      expect(result.isValid).toBe(false);
      expect(result.errors).toContain('Invalid Supabase URL format: not-a-valid-url');
    });

    it('should show warning for non-supabase URL', () => {
      // Arrange
      process.env.OPENAI_API_KEY = 'sk-test1234567890abcdef1234567890abcdef';
      process.env.SUPABASE_URL = 'https://custom-backend.example.com';
      process.env.SUPABASE_ANON_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InRlc3QiLCJyb2xlIjoiYW5vbiIsImlhdCI6MTY0MDk5NTIwMCwiZXhwIjoxOTU2NTcxMjAwfQ.test';

      // Act
      const result = validateEnvironmentVariables();

      // Assert
      expect(result.isValid).toBe(true);
      expect(result.warnings).toContain('Supabase URL doesn\'t contain \'supabase.co\'. Please verify this is correct.');
    });

         it('should use default values for optional environment variables', () => {
       // Arrange
       process.env.OPENAI_API_KEY = 'sk-test1234567890abcdef1234567890abcdef';
       process.env.SUPABASE_URL = 'https://test-project.supabase.co';
       process.env.SUPABASE_ANON_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InRlc3QiLCJyb2xlIjoiYW5vbiIsImlhdCI6MTY0MDk5NTIwMCwiZXhwIjoxOTU2NTcxMjAwfQ.test';
       
       // Remove optional variables to test defaults
       delete process.env.NODE_ENV;
       delete process.env.MAX_RECORDING_DURATION;
       delete process.env.MAX_FILE_UPLOAD_SIZE;

       // Act
       const result = validateEnvironmentVariables();

       // Assert
       expect(result.isValid).toBe(true);
       expect(result.config.optional.NODE_ENV).toBe('development');
       expect(result.config.optional.MAX_RECORDING_DURATION).toBe('300');
       expect(result.config.optional.MAX_FILE_UPLOAD_SIZE).toBe('10');
     });

    it('should handle custom optional environment variables', () => {
      // Arrange
      process.env.OPENAI_API_KEY = 'sk-test1234567890abcdef1234567890abcdef';
      process.env.SUPABASE_URL = 'https://test-project.supabase.co';
      process.env.SUPABASE_ANON_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InRlc3QiLCJyb2xlIjoiYW5vbiIsImlhdCI6MTY0MDk5NTIwMCwiZXhwIjoxOTU2NTcxMjAwfQ.test';
      process.env.NODE_ENV = 'production';
      process.env.MAX_RECORDING_DURATION = '600';
      process.env.MAX_FILE_UPLOAD_SIZE = '25';

      // Act
      const result = validateEnvironmentVariables();

      // Assert
      expect(result.isValid).toBe(true);
      expect(result.config.optional.NODE_ENV).toBe('production');
      expect(result.config.optional.MAX_RECORDING_DURATION).toBe('600');
      expect(result.config.optional.MAX_FILE_UPLOAD_SIZE).toBe('25');
    });

    it('should handle invalid numeric optional environment variables', () => {
      // Arrange
      process.env.OPENAI_API_KEY = 'sk-test1234567890abcdef1234567890abcdef';
      process.env.SUPABASE_URL = 'https://test-project.supabase.co';
      process.env.SUPABASE_ANON_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InRlc3QiLCJyb2xlIjoiYW5vbiIsImlhdCI6MTY0MDk5NTIwMCwiZXhwIjoxOTU2NTcxMjAwfQ.test';
      process.env.MAX_RECORDING_DURATION = 'not-a-number';
      process.env.MAX_FILE_UPLOAD_SIZE = '-5';

      // Act
      const result = validateEnvironmentVariables();

      // Assert
      expect(result.isValid).toBe(true);
      expect(result.warnings).toContain('Invalid MAX_RECORDING_DURATION value. Using default: 300s');
      expect(result.warnings).toContain('Invalid MAX_FILE_UPLOAD_SIZE value. Using default: 10MB');
      expect(result.config.optional.MAX_RECORDING_DURATION).toBe('300');
      expect(result.config.optional.MAX_FILE_UPLOAD_SIZE).toBe('10');
    });
  });

  describe('validateEnvironment', () => {
    beforeEach(() => {
      // Set up valid environment for connection tests
      process.env.OPENAI_API_KEY = 'sk-test1234567890abcdef1234567890abcdef';
      process.env.SUPABASE_URL = 'https://test-project.supabase.co';
      process.env.SUPABASE_ANON_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InRlc3QiLCJyb2xlIjoiYW5vbiIsImlhdCI6MTY0MDk5NTIwMCwiZXhwIjoxOTU2NTcxMjAwfQ.test';
    });

    it('should pass validation and connection tests when all services are available', async () => {
      // Arrange
      const mockFetch = vi.mocked(fetch);
      mockFetch.mockResolvedValueOnce(new Response('{}', { status: 200 })); // OpenAI
      mockFetch.mockResolvedValueOnce(new Response('{}', { status: 404 })); // Supabase (404 is expected)

      // Act
      const result = await validateEnvironment(true);

      // Assert
      expect(result.isValid).toBe(true);
      expect(result.connectionsValid).toBe(true);
      expect(mockFetch).toHaveBeenCalledTimes(2);
    });

    it('should fail connection tests when OpenAI API is unavailable', async () => {
      // Arrange
      const mockFetch = vi.mocked(fetch);
      mockFetch.mockResolvedValueOnce(new Response('Unauthorized', { status: 401 })); // OpenAI fails
      mockFetch.mockResolvedValueOnce(new Response('{}', { status: 404 })); // Supabase succeeds

      // Act
      const result = await validateEnvironment(true);

      // Assert
      expect(result.isValid).toBe(true);
      expect(result.connectionsValid).toBe(false);
    });

    it('should fail connection tests when Supabase is unavailable', async () => {
      // Arrange
      const mockFetch = vi.mocked(fetch);
      mockFetch.mockResolvedValueOnce(new Response('{}', { status: 200 })); // OpenAI succeeds
      mockFetch.mockResolvedValueOnce(new Response('Server Error', { status: 500 })); // Supabase fails

      // Act
      const result = await validateEnvironment(true);

      // Assert
      expect(result.isValid).toBe(true);
      expect(result.connectionsValid).toBe(false);
    });

    it('should skip connection tests when requested', async () => {
      // Arrange
      const mockFetch = vi.mocked(fetch);

      // Act
      const result = await validateEnvironment(false);

      // Assert
      expect(result.isValid).toBe(true);
      expect(result.connectionsValid).toBeUndefined();
      expect(mockFetch).not.toHaveBeenCalled();
    });

    it('should handle network errors during connection tests', async () => {
      // Arrange
      const mockFetch = vi.mocked(fetch);
      mockFetch.mockRejectedValue(new Error('Network error'));

      // Act
      const result = await validateEnvironment(true);

      // Assert
      expect(result.isValid).toBe(true);
      expect(result.connectionsValid).toBe(false);
    });
  });

  describe('getValidatedConfig', () => {
         it('should return validated configuration when environment is valid', () => {
       // Arrange
       process.env.OPENAI_API_KEY = 'sk-test1234567890abcdef1234567890abcdef';
       process.env.SUPABASE_URL = 'https://test-project.supabase.co';
       process.env.SUPABASE_ANON_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InRlc3QiLCJyb2xlIjoiYW5vbiIsImlhdCI6MTY0MDk5NTIwMCwiZXhwIjoxOTU2NTcxMjAwfQ.test';
       
       // Remove NODE_ENV to test default
       delete process.env.NODE_ENV;

       // Act
       const config = getValidatedConfig();

       // Assert
       expect(config).not.toBeNull();
       expect(config?.OPENAI_API_KEY).toBe(process.env.OPENAI_API_KEY);
       expect(config?.SUPABASE_URL).toBe(process.env.SUPABASE_URL);
       expect(config?.SUPABASE_ANON_KEY).toBe(process.env.SUPABASE_ANON_KEY);
       expect(config?.NODE_ENV).toBe('development');
     });

    it('should return null when environment is invalid', () => {
      // Arrange - Remove required env vars
      delete process.env.OPENAI_API_KEY;
      delete process.env.SUPABASE_URL;
      delete process.env.SUPABASE_ANON_KEY;

      // Act
      const config = getValidatedConfig();

      // Assert
      expect(config).toBeNull();
    });
  });
});

================
File: src/utils/envValidator.ts
================
/**
 * Environment Validation Utility
 * 
 * This module validates that all required environment variables are set
 * and that external service connections can be established.
 * Used during application startup to catch configuration issues early.
 */

import { logger } from './logger';

/**
 * Interface defining all required environment variables
 */
interface RequiredEnvVars {
  OPENAI_API_KEY: string;
  SUPABASE_URL: string;
  SUPABASE_ANON_KEY: string;
}

/**
 * Interface defining optional environment variables with defaults
 */
interface OptionalEnvVars {
  NODE_ENV: string;
  MAX_RECORDING_DURATION: string;
  MAX_FILE_UPLOAD_SIZE: string;
}

/**
 * Validation result interface
 */
interface ValidationResult {
  isValid: boolean;
  errors: string[];
  warnings: string[];
  config: {
    required: Partial<RequiredEnvVars>;
    optional: OptionalEnvVars;
  };
}

/**
 * List of required environment variables
 */
const REQUIRED_ENV_VARS: (keyof RequiredEnvVars)[] = [
  'OPENAI_API_KEY',
  'SUPABASE_URL',
  'SUPABASE_ANON_KEY'
];

/**
 * Default values for optional environment variables
 */
const DEFAULT_ENV_VALUES: OptionalEnvVars = {
  NODE_ENV: 'development',
  MAX_RECORDING_DURATION: '300', // 5 minutes
  MAX_FILE_UPLOAD_SIZE: '10' // 10MB
};

/**
 * Validates that a URL is properly formatted
 * @param url - The URL to validate
 * @returns True if valid, false otherwise
 */
function isValidUrl(url: string): boolean {
  try {
    new URL(url);
    return true;
  } catch {
    return false;
  }
}

/**
 * Validates that an API key has the expected format
 * @param key - The API key to validate
 * @param expectedPrefix - Expected prefix (e.g., 'sk-' for OpenAI)
 * @returns True if valid, false otherwise
 */
function isValidApiKey(key: string, expectedPrefix?: string): boolean {
  if (!key || key.trim().length === 0) {
    return false;
  }
  
  if (expectedPrefix && !key.startsWith(expectedPrefix)) {
    return false;
  }
  
  // Basic length check - most API keys are at least 20 characters
  return key.length >= 20;
}

/**
 * Tests connection to OpenAI API
 * @param apiKey - OpenAI API key
 * @returns Promise resolving to true if connection successful
 */
async function testOpenAIConnection(apiKey: string): Promise<boolean> {
  try {
    logger.info('🔍 Testing OpenAI API connection...');
    
    const response = await fetch('https://api.openai.com/v1/models', {
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      }
    });
    
    if (response.ok) {
      logger.info('✅ OpenAI API connection successful');
      return true;
    } else {
      logger.error(`❌ OpenAI API connection failed: ${response.status} ${response.statusText}`);
      return false;
    }
     } catch (error) {
     logger.error('❌ OpenAI API connection failed', { error: error as Error });
     return false;
   }
}

/**
 * Tests connection to Supabase
 * @param url - Supabase URL
 * @param anonKey - Supabase anonymous key
 * @returns Promise resolving to true if connection successful
 */
async function testSupabaseConnection(url: string, anonKey: string): Promise<boolean> {
  try {
    logger.info('🔍 Testing Supabase connection...');
    
    const response = await fetch(`${url}/rest/v1/`, {
      headers: {
        'apikey': anonKey,
        'Content-Type': 'application/json'
      }
    });
    
    if (response.ok || response.status === 404) {
      // 404 is expected for the root endpoint
      logger.info('✅ Supabase connection successful');
      return true;
    } else {
      logger.error(`❌ Supabase connection failed: ${response.status} ${response.statusText}`);
      return false;
    }
     } catch (error) {
     logger.error('❌ Supabase connection failed', { error: error as Error });
     return false;
   }
}

/**
 * Validates all environment variables
 * @returns ValidationResult with detailed information about validation status
 */
export function validateEnvironmentVariables(): ValidationResult {
  logger.info('🔧 Starting environment validation...');
  
  const errors: string[] = [];
  const warnings: string[] = [];
  const requiredConfig: Partial<RequiredEnvVars> = {};
  
  // Check required environment variables
  for (const envVar of REQUIRED_ENV_VARS) {
    const value = process.env[envVar];
    
    if (!value) {
      errors.push(`Missing required environment variable: ${envVar}`);
      logger.error(`❌ Missing required environment variable: ${envVar}`);
    } else {
      requiredConfig[envVar] = value;
      logger.info(`✅ Found ${envVar}`);
      
      // Validate specific formats
      switch (envVar) {
        case 'OPENAI_API_KEY':
          if (!isValidApiKey(value, 'sk-')) {
            errors.push(`Invalid OpenAI API key format. Expected to start with 'sk-'`);
          }
          break;
          
        case 'SUPABASE_URL':
          if (!isValidUrl(value)) {
            errors.push(`Invalid Supabase URL format: ${value}`);
          } else if (!value.includes('supabase.co')) {
            warnings.push(`Supabase URL doesn't contain 'supabase.co'. Please verify this is correct.`);
          }
          break;
          
        case 'SUPABASE_ANON_KEY':
          if (!isValidApiKey(value)) {
            errors.push(`Invalid Supabase anonymous key format`);
          }
          break;
      }
    }
  }
  
  // Set up optional environment variables with defaults
  const optionalConfig: OptionalEnvVars = {
    NODE_ENV: process.env.NODE_ENV || DEFAULT_ENV_VALUES.NODE_ENV,
    MAX_RECORDING_DURATION: process.env.MAX_RECORDING_DURATION || DEFAULT_ENV_VALUES.MAX_RECORDING_DURATION,
    MAX_FILE_UPLOAD_SIZE: process.env.MAX_FILE_UPLOAD_SIZE || DEFAULT_ENV_VALUES.MAX_FILE_UPLOAD_SIZE
  };
  
  // Log optional configurations
  logger.info(`📋 Environment: ${optionalConfig.NODE_ENV}`);
  logger.info(`⏱️  Max recording duration: ${optionalConfig.MAX_RECORDING_DURATION}s`);
  logger.info(`📁 Max file upload size: ${optionalConfig.MAX_FILE_UPLOAD_SIZE}MB`);
  
  // Validate numeric values
  const maxRecordingDuration = parseInt(optionalConfig.MAX_RECORDING_DURATION);
  if (isNaN(maxRecordingDuration) || maxRecordingDuration <= 0) {
    warnings.push(`Invalid MAX_RECORDING_DURATION value. Using default: ${DEFAULT_ENV_VALUES.MAX_RECORDING_DURATION}s`);
    optionalConfig.MAX_RECORDING_DURATION = DEFAULT_ENV_VALUES.MAX_RECORDING_DURATION;
  }
  
  const maxFileUploadSize = parseInt(optionalConfig.MAX_FILE_UPLOAD_SIZE);
  if (isNaN(maxFileUploadSize) || maxFileUploadSize <= 0) {
    warnings.push(`Invalid MAX_FILE_UPLOAD_SIZE value. Using default: ${DEFAULT_ENV_VALUES.MAX_FILE_UPLOAD_SIZE}MB`);
    optionalConfig.MAX_FILE_UPLOAD_SIZE = DEFAULT_ENV_VALUES.MAX_FILE_UPLOAD_SIZE;
  }
  
  const isValid = errors.length === 0;
  
  if (isValid) {
    logger.info('✅ Environment validation passed');
  } else {
    logger.error(`❌ Environment validation failed with ${errors.length} error(s)`);
  }
  
  if (warnings.length > 0) {
    logger.warn(`⚠️  Environment validation completed with ${warnings.length} warning(s)`);
  }
  
  return {
    isValid,
    errors,
    warnings,
    config: {
      required: requiredConfig,
      optional: optionalConfig
    }
  };
}

/**
 * Tests connections to all external services
 * @param config - Validated configuration
 * @returns Promise resolving to true if all connections successful
 */
export async function testExternalConnections(config: ValidationResult['config']): Promise<boolean> {
  logger.info('🌐 Testing external service connections...');
  
  const { required } = config;
  
  if (!required.OPENAI_API_KEY || !required.SUPABASE_URL || !required.SUPABASE_ANON_KEY) {
    logger.error('❌ Cannot test connections: missing required configuration');
    return false;
  }
  
  const results = await Promise.allSettled([
    testOpenAIConnection(required.OPENAI_API_KEY),
    testSupabaseConnection(required.SUPABASE_URL, required.SUPABASE_ANON_KEY)
  ]);
  
  const allSuccessful = results.every(result => 
    result.status === 'fulfilled' && result.value === true
  );
  
  if (allSuccessful) {
    logger.info('✅ All external service connections successful');
  } else {
    logger.error('❌ One or more external service connections failed');
  }
  
  return allSuccessful;
}

/**
 * Comprehensive environment validation and connection testing
 * @param testConnections - Whether to test external connections (default: true)
 * @returns Promise resolving to validation result with connection status
 */
export async function validateEnvironment(testConnections: boolean = true): Promise<ValidationResult & { connectionsValid?: boolean }> {
  const validationResult = validateEnvironmentVariables();
  
  if (!validationResult.isValid) {
    return validationResult;
  }
  
  if (testConnections) {
    const connectionsValid = await testExternalConnections(validationResult.config);
    return {
      ...validationResult,
      connectionsValid
    };
  }
  
  return validationResult;
}

/**
 * Prints a user-friendly summary of validation results
 * @param result - Validation result to display
 */
export function displayValidationSummary(result: ValidationResult & { connectionsValid?: boolean }): void {
  console.log('\n' + '='.repeat(60));
  console.log('🔧 FLOWGENIUS ENVIRONMENT VALIDATION SUMMARY');
  console.log('='.repeat(60));
  
  if (result.isValid) {
    console.log('✅ Environment Configuration: VALID');
  } else {
    console.log('❌ Environment Configuration: INVALID');
    console.log('\n🚨 ERRORS:');
    result.errors.forEach(error => console.log(`   • ${error}`));
  }
  
  if (result.warnings.length > 0) {
    console.log('\n⚠️  WARNINGS:');
    result.warnings.forEach(warning => console.log(`   • ${warning}`));
  }
  
  if (typeof result.connectionsValid === 'boolean') {
    if (result.connectionsValid) {
      console.log('✅ External Connections: SUCCESSFUL');
    } else {
      console.log('❌ External Connections: FAILED');
    }
  }
  
  if (!result.isValid || result.connectionsValid === false) {
    console.log('\n📝 NEXT STEPS:');
    console.log('   1. Create a .env file in your project root');
    console.log('   2. Copy the contents of .env.example');
    console.log('   3. Fill in your actual API keys and URLs');
    console.log('   4. Restart the application');
  }
  
  console.log('='.repeat(60) + '\n');
}

/**
 * Gets the validated environment configuration
 * @returns The validated configuration object
 */
export function getValidatedConfig(): (RequiredEnvVars & OptionalEnvVars) | null {
  const result = validateEnvironmentVariables();
  
  if (!result.isValid) {
    return null;
  }
  
  return {
    ...result.config.required as RequiredEnvVars,
    ...result.config.optional
  };
}

================
File: src/utils/errorHandler.test.ts
================
/**
 * Unit Tests for Error Handler Utility
 * 
 * This test suite verifies the functionality of the global error handling utility,
 * including error classification, user-friendly message generation, recovery actions,
 * and integration with the logging system.
 */

import { describe, it, expect, beforeEach, vi } from 'vitest';
import {
  ErrorHandler,
  errorHandler,
  handleError,
  handleApiError,
  handleDatabaseError,
  handleAudioError,
  handleWorkflowError,
  ErrorCategory,
  ErrorSeverity,
  RecoveryAction,
  createErrorBoundaryHandler,
  withErrorHandling,
} from './errorHandler';

describe('ErrorHandler', () => {
  beforeEach(() => {
    console.log('🧪 ErrorHandler Test: Setting up test environment');
    // Clear error tracking before each test
    errorHandler.clearErrorTracking();
  });

  describe('Error Classification', () => {
    it('should classify network errors correctly', () => {
      console.log('🌐 Testing network error classification');
      
      const networkError = new Error('fetch failed');
      const errorInfo = handleError(networkError, 'network operation');
      
      expect(errorInfo.category).toBe(ErrorCategory.NETWORK);
      expect(errorInfo.severity).toBe(ErrorSeverity.HIGH);
      expect(errorInfo.userMessage).toContain('connect to the server');
      expect(errorInfo.recoveryActions).toContain(RecoveryAction.CHECK_CONNECTION);
    });

    it('should classify API errors correctly', () => {
      console.log('🔌 Testing API error classification');
      
      const apiError = new Error('openai API rate limit exceeded');
      const errorInfo = handleApiError(apiError, '/api/chat', 'POST', 429);
      
      expect(errorInfo.category).toBe(ErrorCategory.API);
      expect(errorInfo.metadata?.endpoint).toBe('/api/chat');
      expect(errorInfo.metadata?.method).toBe('POST');
      expect(errorInfo.metadata?.statusCode).toBe(429);
      expect(errorInfo.userMessage).toContain('Too many requests');
    });

    it('should classify database errors correctly', () => {
      console.log('🗄️ Testing database error classification');
      
      const dbError = new Error('database connection failed');
      const errorInfo = handleDatabaseError(dbError, 'insert', 'users');
      
      expect(errorInfo.category).toBe(ErrorCategory.DATABASE);
      expect(errorInfo.severity).toBe(ErrorSeverity.HIGH);
      expect(errorInfo.metadata?.operation).toBe('insert');
      expect(errorInfo.metadata?.table).toBe('users');
    });

    it('should classify audio errors correctly', () => {
      console.log('🎤 Testing audio error classification');
      
      const audioError = new Error('microphone access denied');
      const errorInfo = handleAudioError(audioError, 'start_recording');
      
      expect(errorInfo.category).toBe(ErrorCategory.PERMISSION);
      expect(errorInfo.userMessage).toContain('Microphone access is required');
      expect(errorInfo.recoveryActions).toContain(RecoveryAction.CHECK_PERMISSIONS);
    });

    it('should classify workflow errors correctly', () => {
      console.log('⚙️ Testing workflow error classification');
      
      const workflowError = new Error('node execution failed');
      const errorInfo = handleWorkflowError(workflowError, 'processUserTurn', { stage: 'brainstorm' });
      
      expect(errorInfo.category).toBe(ErrorCategory.WORKFLOW);
      expect(errorInfo.metadata?.nodeName).toBe('processUserTurn');
      expect(errorInfo.metadata?.stateData).toContain('brainstorm');
    });

    it('should handle unknown errors with fallback classification', () => {
      console.log('❓ Testing unknown error classification');
      
      const unknownError = new Error('something completely unexpected happened');
      const errorInfo = handleError(unknownError);
      
      expect(errorInfo.category).toBe(ErrorCategory.UNKNOWN);
      expect(errorInfo.severity).toBe(ErrorSeverity.MEDIUM);
      expect(errorInfo.userMessage).toContain('unexpected error occurred');
    });
  });

  describe('Error Severity Assignment', () => {
    it('should assign HIGH severity to authentication errors', () => {
      console.log('🔐 Testing authentication error severity');
      
      const authError = new Error('unauthorized access');
      const errorInfo = handleError(authError);
      
      expect(errorInfo.category).toBe(ErrorCategory.AUTHENTICATION);
      expect(errorInfo.severity).toBe(ErrorSeverity.HIGH);
    });

    it('should assign LOW severity to validation errors', () => {
      console.log('✅ Testing validation error severity');
      
      const validationError = new Error('invalid input format');
      const errorInfo = handleError(validationError);
      
      expect(errorInfo.category).toBe(ErrorCategory.VALIDATION);
      expect(errorInfo.severity).toBe(ErrorSeverity.LOW);
    });
  });

  describe('Recovery Actions', () => {
    it('should suggest appropriate recovery actions for network errors', () => {
      console.log('🔄 Testing network error recovery actions');
      
      const networkError = new Error('connection timeout');
      const errorInfo = handleError(networkError);
      const suggestions = errorHandler.getRecoverySuggestions(errorInfo);
      
      expect(suggestions).toHaveLength(2);
      expect(suggestions[0].action).toBe(RecoveryAction.CHECK_CONNECTION);
      expect(suggestions[1].action).toBe(RecoveryAction.RETRY);
    });

    it('should suggest login for authentication errors', () => {
      console.log('🔑 Testing authentication error recovery actions');
      
      const authError = new Error('session expired');
      const errorInfo = handleError(authError);
      const suggestions = errorHandler.getRecoverySuggestions(errorInfo);
      
      expect(suggestions.some(s => s.action === RecoveryAction.LOGIN)).toBe(true);
    });
  });

  describe('Error Tracking and Reporting', () => {
    it('should track error frequency', () => {
      console.log('📊 Testing error tracking');
      
      // Use a database error which has HIGH severity
      const sameError = new Error('database connection failed');
      
      // First occurrence
      const errorInfo1 = handleError(sameError, 'database');
      expect(errorInfo1.shouldReport).toBe(true);
      expect(errorInfo1.severity).toBe(ErrorSeverity.HIGH);
      
      // Second occurrence (should still report for HIGH severity)
      const errorInfo2 = handleError(sameError, 'database');
      expect(errorInfo2.shouldReport).toBe(true);
      expect(errorInfo2.severity).toBe(ErrorSeverity.HIGH);
      
      // Get stats
      const stats = errorHandler.getErrorStats();
      expect(stats.totalErrors).toBe(2);
    });

    it('should disable error reporting when configured', () => {
      console.log('🔇 Testing error reporting toggle');
      
      errorHandler.setErrorReporting(false);
      
      const error = new Error('test error');
      const errorInfo = handleError(error);
      
      expect(errorInfo.shouldReport).toBe(false);
      
      // Re-enable for other tests
      errorHandler.setErrorReporting(true);
    });
  });

  describe('Error ID Generation', () => {
    it('should generate unique error IDs', () => {
      console.log('🆔 Testing unique error ID generation');
      
      const error1 = handleError(new Error('error 1'));
      const error2 = handleError(new Error('error 2'));
      
      expect(error1.id).not.toBe(error2.id);
      expect(error1.id).toMatch(/^err_\d+_[a-z0-9]+$/);
      expect(error2.id).toMatch(/^err_\d+_[a-z0-9]+$/);
    });
  });

  describe('Error Metadata', () => {
    it('should include context in error metadata', () => {
      console.log('📝 Testing error metadata inclusion');
      
      const error = new Error('test error');
      const errorInfo = handleError(error, 'test context', {
        userId: 'user123',
        sessionId: 'session456',
      });
      
      expect(errorInfo.metadata?.context).toBe('test context');
      expect(errorInfo.metadata?.userId).toBe('user123');
      expect(errorInfo.metadata?.sessionId).toBe('session456');
      expect(errorInfo.metadata?.component).toBe('ErrorHandler');
    });
  });
});

describe('React Error Boundary Integration', () => {
  it('should create error boundary handler', () => {
    console.log('⚛️ Testing React Error Boundary handler creation');
    
    const handler = createErrorBoundaryHandler('TestComponent');
    expect(typeof handler).toBe('function');
    
    // Test that it handles React errors
    const reactError = new Error('Component render failed');
    const errorInfo = { componentStack: 'at TestComponent\n  at App' };
    
    const result = handler(reactError, errorInfo as React.ErrorInfo);
    expect(result.category).toBe(ErrorCategory.UI);
    expect(result.metadata?.componentStack).toBe(errorInfo.componentStack);
    expect(result.metadata?.errorBoundary).toBe('TestComponent');
  });
});

describe('Async Function Error Handling', () => {
  it('should wrap async functions with error handling', async () => {
    console.log('🔄 Testing async function error handling wrapper');
    
    const mockAsyncFunction = vi.fn().mockRejectedValue(new Error('Async operation failed'));
    const wrappedFunction = withErrorHandling(mockAsyncFunction, 'test operation');
    
    await expect(wrappedFunction()).rejects.toThrow('Async operation failed');
    expect(mockAsyncFunction).toHaveBeenCalled();
  });

  it('should pass through successful async function results', async () => {
    console.log('✅ Testing successful async function passthrough');
    
    const mockAsyncFunction = vi.fn().mockResolvedValue('success result');
    const wrappedFunction = withErrorHandling(mockAsyncFunction, 'test operation');
    
    const result = await wrappedFunction('test arg');
    expect(result).toBe('success result');
    expect(mockAsyncFunction).toHaveBeenCalledWith('test arg');
  });
});

describe('Error Statistics', () => {
  it('should provide comprehensive error statistics', () => {
    console.log('📈 Testing error statistics generation');
    
    // Create a fresh error handler for this test to avoid interference
    const statsErrorHandler = new ErrorHandler();
    
    // Generate some test errors
    statsErrorHandler.handleError(new Error('network error'), 'network');
    statsErrorHandler.handleApiError(new Error('api error'), '/test');
    statsErrorHandler.handleDatabaseError(new Error('db error'), 'select');
    
    const stats = statsErrorHandler.getErrorStats();
    
    expect(stats.totalErrors).toBe(3);
    expect(stats.errorsByCategory[ErrorCategory.NETWORK]).toBeGreaterThan(0);
    expect(stats.errorsByCategory[ErrorCategory.API]).toBeGreaterThan(0);
    expect(stats.errorsByCategory[ErrorCategory.DATABASE]).toBeGreaterThan(0);
    expect(typeof stats.recentErrors).toBe('number');
  });
});

console.log('✅ ErrorHandler Tests: All test suites defined and ready to run');

================
File: src/utils/errorHandler.ts
================
/**
 * Global Error Handling Utility for FlowGenius
 * 
 * This utility provides comprehensive error handling capabilities across the entire application,
 * including user-friendly error messages, error classification, recovery suggestions, and
 * integration with the centralized logging system.
 * 
 * Features:
 * - Error classification and categorization
 * - User-friendly error message generation
 * - Error recovery suggestions
 * - Integration with React Error Boundaries
 * - API error handling with retry logic
 * - Database error handling
 * - Audio/media error handling
 * - LangGraph workflow error handling
 * - Automatic error reporting and logging
 */

import { logger, type LogMetadata } from './logger';

/**
 * Error severity levels for prioritization and handling
 */
export enum ErrorSeverity {
  LOW = 'low',
  MEDIUM = 'medium',
  HIGH = 'high',
  CRITICAL = 'critical'
}

/**
 * Error categories for classification and specific handling
 */
export enum ErrorCategory {
  NETWORK = 'network',
  API = 'api',
  DATABASE = 'database',
  AUTHENTICATION = 'auth',
  PERMISSION = 'permission',
  VALIDATION = 'validation',
  AUDIO = 'audio',
  FILE_SYSTEM = 'file_system',
  WORKFLOW = 'workflow',
  UI = 'ui',
  UNKNOWN = 'unknown'
}

/**
 * Error recovery action types
 */
export enum RecoveryAction {
  RETRY = 'retry',
  REFRESH = 'refresh',
  LOGIN = 'login',
  CONTACT_SUPPORT = 'contact_support',
  CHECK_CONNECTION = 'check_connection',
  CHECK_PERMISSIONS = 'check_permissions',
  TRY_AGAIN_LATER = 'try_again_later',
  NONE = 'none'
}

/**
 * Structured error information interface
 */
export interface ErrorInfo {
  /** Unique error identifier for tracking */
  id: string;
  /** Error category for classification */
  category: ErrorCategory;
  /** Error severity level */
  severity: ErrorSeverity;
  /** User-friendly error message */
  userMessage: string;
  /** Technical error message for developers */
  technicalMessage: string;
  /** Suggested recovery actions */
  recoveryActions: RecoveryAction[];
  /** Additional context metadata */
  metadata?: LogMetadata;
  /** Timestamp when error occurred */
  timestamp: Date;
  /** Whether this error should be reported to external services */
  shouldReport: boolean;
  /** Stack trace if available */
  stack?: string;
}

/**
 * Error recovery suggestion interface
 */
export interface RecoverySuggestion {
  action: RecoveryAction;
  label: string;
  description: string;
  isAutomatic?: boolean;
}

/**
 * User-friendly error messages mapped by category and common error patterns
 */
const USER_FRIENDLY_MESSAGES: Record<ErrorCategory, Record<string, string>> = {
  [ErrorCategory.NETWORK]: {
    'fetch_failed': 'Unable to connect to the server. Please check your internet connection.',
    'timeout': 'The request took too long to complete. Please try again.',
    'offline': 'You appear to be offline. Please check your internet connection.',
    'default': 'A network error occurred. Please check your connection and try again.'
  },
  [ErrorCategory.API]: {
    'unauthorized': 'Your session has expired. Please log in again.',
    'forbidden': 'You don\'t have permission to perform this action.',
    'not_found': 'The requested resource could not be found.',
    'rate_limit': 'Too many requests. Please wait a moment and try again.',
    'server_error': 'The server encountered an error. Please try again later.',
    'openai_error': 'AI service is temporarily unavailable. Please try again.',
    'whisper_error': 'Voice processing failed. Please try recording again.',
    'default': 'An API error occurred. Please try again.'
  },
  [ErrorCategory.DATABASE]: {
    'connection_failed': 'Unable to connect to the database. Please try again.',
    'query_failed': 'Database operation failed. Please try again.',
    'constraint_violation': 'The data provided is invalid or conflicts with existing records.',
    'timeout': 'Database operation timed out. Please try again.',
    'default': 'A database error occurred. Please try again.'
  },
  [ErrorCategory.AUTHENTICATION]: {
    'invalid_credentials': 'Invalid username or password. Please try again.',
    'session_expired': 'Your session has expired. Please log in again.',
    'account_locked': 'Your account has been temporarily locked. Please contact support.',
    'default': 'Authentication failed. Please try logging in again.'
  },
  [ErrorCategory.PERMISSION]: {
    'microphone': 'Microphone access is required. Please allow microphone permissions.',
    'camera': 'Camera access is required for this feature. Please enable it in your browser settings.',
    'storage': 'Storage access is required. Please enable it in your browser settings.',
    'default': 'Permission denied. Please check your browser settings.'
  },
  [ErrorCategory.VALIDATION]: {
    'invalid_input': 'The information you entered is not valid. Please check and try again.',
    'required_field': 'Please fill in all required fields.',
    'invalid_format': 'The format of the data you entered is incorrect.',
    'default': 'Please check your input and try again.'
  },
  [ErrorCategory.AUDIO]: {
    'permission_denied': 'Microphone access is required. Please allow microphone permissions.',
    'recording_failed': 'Voice recording failed. Please check your microphone and try again.',
    'playback_failed': 'Audio playback failed. Please try again.',
    'format_unsupported': 'This audio format is not supported.',
    'device_unavailable': 'No microphone found. Please connect a microphone and try again.',
    'default': 'An audio error occurred. Please check your microphone and try again.'
  },
  [ErrorCategory.FILE_SYSTEM]: {
    'file_not_found': 'The requested file could not be found.',
    'access_denied': 'Access to the file was denied.',
    'disk_full': 'Not enough storage space available.',
    'default': 'A file system error occurred.'
  },
  [ErrorCategory.WORKFLOW]: {
    'node_execution_failed': 'A step in the process failed. Please try again.',
    'invalid_state': 'The application is in an invalid state. Please refresh the page.',
    'transition_failed': 'Unable to proceed to the next step. Please try again.',
    'default': 'A workflow error occurred. Please try again.'
  },
  [ErrorCategory.UI]: {
    'component_crash': 'A component stopped working. Please refresh the page.',
    'render_error': 'Unable to display this content. Please try refreshing.',
    'default': 'A display error occurred. Please refresh the page.'
  },
  [ErrorCategory.UNKNOWN]: {
    'default': 'An unexpected error occurred. Please try again or contact support if the problem persists.'
  }
};

/**
 * Recovery suggestions mapped by action type
 */
const RECOVERY_SUGGESTIONS: Record<RecoveryAction, RecoverySuggestion> = {
  [RecoveryAction.RETRY]: {
    action: RecoveryAction.RETRY,
    label: 'Try Again',
    description: 'Retry the operation that failed'
  },
  [RecoveryAction.REFRESH]: {
    action: RecoveryAction.REFRESH,
    label: 'Refresh Page',
    description: 'Refresh the page to reset the application state'
  },
  [RecoveryAction.LOGIN]: {
    action: RecoveryAction.LOGIN,
    label: 'Log In',
    description: 'Log in again to restore your session'
  },
  [RecoveryAction.CONTACT_SUPPORT]: {
    action: RecoveryAction.CONTACT_SUPPORT,
    label: 'Contact Support',
    description: 'Get help from our support team'
  },
  [RecoveryAction.CHECK_CONNECTION]: {
    action: RecoveryAction.CHECK_CONNECTION,
    label: 'Check Connection',
    description: 'Verify your internet connection and try again'
  },
  [RecoveryAction.CHECK_PERMISSIONS]: {
    action: RecoveryAction.CHECK_PERMISSIONS,
    label: 'Check Permissions',
    description: 'Review and update your browser permissions'
  },
  [RecoveryAction.TRY_AGAIN_LATER]: {
    action: RecoveryAction.TRY_AGAIN_LATER,
    label: 'Try Later',
    description: 'Wait a few minutes and try again'
  },
  [RecoveryAction.NONE]: {
    action: RecoveryAction.NONE,
    label: 'No Action',
    description: 'No specific action required'
  }
};

/**
 * Global Error Handler class
 */
export class ErrorHandler {
  private errorCount: Map<string, number> = new Map();
  private lastErrorTime: Map<string, number> = new Map();
  private errorReportingEnabled: boolean = true;

  /**
   * Generate a unique error ID
   */
  private generateErrorId(): string {
    return `err_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }

  /**
   * Classify error based on error object and context
   */
  private classifyError(error: Error | string, context?: string): ErrorCategory {
    const errorMessage = typeof error === 'string' ? error : error.message;
    const errorName = typeof error === 'string' ? '' : error.name;
    const stack = typeof error === 'string' ? '' : error.stack || '';

    // Database errors - check FIRST to avoid misclassification with network
    if (context?.includes('database') || context?.includes('supabase') ||
        context?.includes('db') || errorMessage.includes('database') || 
        errorMessage.includes('query') || errorMessage.includes('sql') ||
        errorMessage.includes('connection_string') || errorMessage.includes('db error')) {
      return ErrorCategory.DATABASE;
    }

    // API errors
    if (context?.includes('api') || errorMessage.includes('API') || 
        errorMessage.includes('openai') || errorMessage.includes('whisper')) {
      return ErrorCategory.API;
    }

    // Network errors - check after database to avoid conflicts
    if (errorMessage.includes('fetch') || errorMessage.includes('network') || 
        (errorMessage.includes('connection') && !errorMessage.includes('database')) || 
        errorName === 'NetworkError') {
      return ErrorCategory.NETWORK;
    }

    // Authentication errors
    if (errorMessage.includes('auth') || errorMessage.includes('unauthorized') ||
        errorMessage.includes('login') || errorMessage.includes('session')) {
      return ErrorCategory.AUTHENTICATION;
    }

    // Permission errors - check for access/permission related issues first
    if (errorMessage.includes('permission') || errorMessage.includes('denied') ||
        (errorMessage.includes('microphone') && errorMessage.includes('denied')) ||
        (errorMessage.includes('camera') && errorMessage.includes('denied')) ||
        errorMessage.includes('access denied')) {
      return ErrorCategory.PERMISSION;
    }

    // Validation errors
    if (errorMessage.includes('validation') || errorMessage.includes('invalid') ||
        errorMessage.includes('required') || errorName === 'ValidationError') {
      return ErrorCategory.VALIDATION;
    }

    // Audio errors - exclude permission-related microphone errors
    if (context?.includes('audio') || errorMessage.includes('audio') ||
        errorMessage.includes('recording') || 
        (errorMessage.includes('microphone') && !errorMessage.includes('denied'))) {
      return ErrorCategory.AUDIO;
    }

    // File system errors
    if (errorMessage.includes('file') || errorMessage.includes('storage') ||
        errorName === 'FileSystemError') {
      return ErrorCategory.FILE_SYSTEM;
    }

    // Workflow errors
    if (context?.includes('workflow') || context?.includes('langgraph') ||
        errorMessage.includes('node') || errorMessage.includes('state')) {
      return ErrorCategory.WORKFLOW;
    }

    // UI errors
    if (context?.includes('component') || context?.includes('render') ||
        errorName === 'ChunkLoadError' || stack.includes('React')) {
      return ErrorCategory.UI;
    }

    return ErrorCategory.UNKNOWN;
  }

  /**
   * Determine error severity based on category and context
   */
  private determineSeverity(category: ErrorCategory, error: Error | string): ErrorSeverity {
    const errorMessage = typeof error === 'string' ? error : error.message;

    switch (category) {
      case ErrorCategory.AUTHENTICATION:
      case ErrorCategory.DATABASE:
        return ErrorSeverity.HIGH;
      
      case ErrorCategory.NETWORK:
      case ErrorCategory.API:
        return errorMessage.includes('timeout') ? ErrorSeverity.MEDIUM : ErrorSeverity.HIGH;
      
      case ErrorCategory.PERMISSION:
        return ErrorSeverity.MEDIUM;
      
      case ErrorCategory.VALIDATION:
      case ErrorCategory.AUDIO:
        return ErrorSeverity.LOW;
      
      case ErrorCategory.FILE_SYSTEM:
      case ErrorCategory.WORKFLOW:
        return ErrorSeverity.HIGH;
      
      case ErrorCategory.UI:
        return ErrorSeverity.MEDIUM;
      
      default:
        return ErrorSeverity.MEDIUM;
    }
  }

  /**
   * Get user-friendly error message
   */
  private getUserFriendlyMessage(category: ErrorCategory, error: Error | string): string {
    const errorMessage = typeof error === 'string' ? error : error.message;
    const categoryMessages = USER_FRIENDLY_MESSAGES[category];

    // Try to find a specific message based on error content
    for (const [key, message] of Object.entries(categoryMessages)) {
      if (key !== 'default' && errorMessage.toLowerCase().includes(key.replace('_', ' '))) {
        return message;
      }
    }

    // Return default message for category
    return categoryMessages.default || 'An error occurred. Please try again.';
  }

  /**
   * Determine recovery actions based on error category
   */
  private getRecoveryActions(category: ErrorCategory): RecoveryAction[] {
    switch (category) {
      case ErrorCategory.NETWORK:
        return [RecoveryAction.CHECK_CONNECTION, RecoveryAction.RETRY];
      
      case ErrorCategory.API:
        return [RecoveryAction.RETRY, RecoveryAction.TRY_AGAIN_LATER];
      
      case ErrorCategory.DATABASE:
        return [RecoveryAction.RETRY, RecoveryAction.REFRESH];
      
      case ErrorCategory.AUTHENTICATION:
        return [RecoveryAction.LOGIN, RecoveryAction.REFRESH];
      
      case ErrorCategory.PERMISSION:
        return [RecoveryAction.CHECK_PERMISSIONS, RecoveryAction.REFRESH];
      
      case ErrorCategory.VALIDATION:
        return [RecoveryAction.RETRY];
      
      case ErrorCategory.AUDIO:
        return [RecoveryAction.CHECK_PERMISSIONS, RecoveryAction.RETRY];
      
      case ErrorCategory.FILE_SYSTEM:
        return [RecoveryAction.RETRY, RecoveryAction.CONTACT_SUPPORT];
      
      case ErrorCategory.WORKFLOW:
        return [RecoveryAction.REFRESH, RecoveryAction.RETRY];
      
      case ErrorCategory.UI:
        return [RecoveryAction.REFRESH];
      
      default:
        return [RecoveryAction.RETRY, RecoveryAction.CONTACT_SUPPORT];
    }
  }

  /**
   * Check if error should be reported based on frequency and severity
   */
  private shouldReportError(errorInfo: ErrorInfo): boolean {
    if (!this.errorReportingEnabled) return false;

    const errorKey = `${errorInfo.category}_${errorInfo.technicalMessage}`;
    const now = Date.now();
    const lastTime = this.lastErrorTime.get(errorKey) || 0;
    const count = this.errorCount.get(errorKey) || 0;

    // Always report critical errors
    if (errorInfo.severity === ErrorSeverity.CRITICAL) {
      return true;
    }

    // Report high severity errors multiple times but with throttling
    if (errorInfo.severity === ErrorSeverity.HIGH) {
      // Allow reporting for first few occurrences or if enough time has passed
      return count < 3 || (now - lastTime >= 5 * 60 * 1000);
    }

    // Don't report if same error occurred recently (within 5 minutes) for medium/low severity
    if (now - lastTime < 5 * 60 * 1000 && count > 0) {
      return false;
    }

    // Report medium severity errors occasionally
    if (errorInfo.severity === ErrorSeverity.MEDIUM && count < 2) {
      return true;
    }

    // Don't report low severity errors frequently
    return errorInfo.severity === ErrorSeverity.LOW && count === 0;
  }

  /**
   * Update error tracking counters
   */
  private updateErrorTracking(errorInfo: ErrorInfo): void {
    const errorKey = `${errorInfo.category}_${errorInfo.technicalMessage}`;
    const currentCount = this.errorCount.get(errorKey) || 0;
    
    this.errorCount.set(errorKey, currentCount + 1);
    this.lastErrorTime.set(errorKey, Date.now());
  }

  /**
   * Handle and process an error
   */
  public handleError(
    error: Error | string,
    context?: string,
    metadata?: LogMetadata
  ): ErrorInfo {
    console.log(`🚨 ErrorHandler: Processing error`, { error, context, metadata });

    const category = this.classifyError(error, context);
    const severity = this.determineSeverity(category, error);
    const userMessage = this.getUserFriendlyMessage(category, error);
    const recoveryActions = this.getRecoveryActions(category);
    
    const technicalMessage = typeof error === 'string' ? error : error.message;
    const stack = typeof error === 'string' ? undefined : error.stack;

    const errorInfo: ErrorInfo = {
      id: this.generateErrorId(),
      category,
      severity,
      userMessage,
      technicalMessage,
      recoveryActions,
      metadata: {
        ...metadata,
        context,
        component: 'ErrorHandler'
      },
      timestamp: new Date(),
      shouldReport: false, // Will be determined below
      stack
    };

    // Determine if error should be reported (before updating tracking)
    errorInfo.shouldReport = this.shouldReportError(errorInfo);

    // Update tracking after determining reporting
    this.updateErrorTracking(errorInfo);

    // Log the error
    logger.error(`Error handled: ${userMessage}`, {
      ...errorInfo.metadata,
      errorId: errorInfo.id,
      category: errorInfo.category,
      severity: errorInfo.severity,
      technicalMessage: errorInfo.technicalMessage,
      shouldReport: errorInfo.shouldReport,
      error: typeof error === 'string' ? new Error(error) : error
    });

    console.log(`📊 ErrorHandler: Error processed`, {
      id: errorInfo.id,
      category: errorInfo.category,
      severity: errorInfo.severity,
      userMessage: errorInfo.userMessage,
      recoveryActions: errorInfo.recoveryActions
    });

    return errorInfo;
  }

  /**
   * Handle API errors with specific context
   */
  public handleApiError(
    error: Error | string,
    endpoint?: string,
    method?: string,
    statusCode?: number
  ): ErrorInfo {
    console.log(`🌐 ErrorHandler: Handling API error`, { error, endpoint, method, statusCode });

    return this.handleError(error, 'api', {
      endpoint,
      method,
      statusCode,
      action: 'api-call'
    });
  }

  /**
   * Handle database errors with specific context
   */
  public handleDatabaseError(
    error: Error | string,
    operation?: string,
    table?: string
  ): ErrorInfo {
    console.log(`🗄️ ErrorHandler: Handling database error`, { error, operation, table });

    return this.handleError(error, 'database', {
      operation,
      table,
      action: 'database-operation'
    });
  }

  /**
   * Handle audio/media errors with specific context
   */
  public handleAudioError(
    error: Error | string,
    operation?: string,
    deviceInfo?: any
  ): ErrorInfo {
    console.log(`🎤 ErrorHandler: Handling audio error`, { error, operation, deviceInfo });

    return this.handleError(error, 'audio', {
      operation,
      deviceInfo,
      action: 'audio-operation'
    });
  }

  /**
   * Handle workflow/LangGraph errors with specific context
   */
  public handleWorkflowError(
    error: Error | string,
    nodeName?: string,
    stateData?: any
  ): ErrorInfo {
    console.log(`⚙️ ErrorHandler: Handling workflow error`, { error, nodeName, stateData });

    return this.handleError(error, 'workflow', {
      nodeName,
      stateData: stateData ? JSON.stringify(stateData) : undefined,
      action: 'workflow-execution'
    });
  }

  /**
   * Get recovery suggestions for an error
   */
  public getRecoverySuggestions(errorInfo: ErrorInfo): RecoverySuggestion[] {
    console.log(`💡 ErrorHandler: Getting recovery suggestions for error ${errorInfo.id}`);

    return errorInfo.recoveryActions.map(action => RECOVERY_SUGGESTIONS[action]);
  }

  /**
   * Enable or disable error reporting
   */
  public setErrorReporting(enabled: boolean): void {
    console.log(`📋 ErrorHandler: Error reporting ${enabled ? 'enabled' : 'disabled'}`);
    this.errorReportingEnabled = enabled;
  }

  /**
   * Clear error tracking data (useful for testing or memory management)
   */
  public clearErrorTracking(): void {
    console.log(`🧹 ErrorHandler: Clearing error tracking data`);
    this.errorCount.clear();
    this.lastErrorTime.clear();
  }

  /**
   * Get error statistics for monitoring
   */
  public getErrorStats(): {
    totalErrors: number;
    errorsByCategory: Record<ErrorCategory, number>;
    recentErrors: number;
  } {
    const totalErrors = Array.from(this.errorCount.values()).reduce((sum, count) => sum + count, 0);
    const now = Date.now();
    const oneHourAgo = now - 60 * 60 * 1000;
    
    let recentErrors = 0;
    const errorsByCategory: Record<ErrorCategory, number> = {} as Record<ErrorCategory, number>;

    // Initialize category counts
    Object.values(ErrorCategory).forEach(category => {
      errorsByCategory[category] = 0;
    });

    // Count errors by category and recent errors
    for (const [errorKey, count] of this.errorCount.entries()) {
      const category = errorKey.split('_')[0] as ErrorCategory;
      errorsByCategory[category] += count;

      const lastTime = this.lastErrorTime.get(errorKey) || 0;
      if (lastTime > oneHourAgo) {
        recentErrors += count;
      }
    }

    return {
      totalErrors,
      errorsByCategory,
      recentErrors
    };
  }
}

/**
 * React Error Boundary helper function
 */
export function createErrorBoundaryHandler(componentName: string) {
  return (error: Error, errorInfo: React.ErrorInfo) => {
    console.log(`⚛️ ErrorHandler: React Error Boundary triggered in ${componentName}`, { error, errorInfo });

    const errorHandler = new ErrorHandler();
    return errorHandler.handleError(error, `component-${componentName}`, {
      componentStack: errorInfo.componentStack,
      errorBoundary: componentName
    });
  };
}

/**
 * Async function wrapper with error handling
 */
export function withErrorHandling<T extends (...args: any[]) => Promise<any>>(
  fn: T,
  context?: string
): T {
  return (async (...args: any[]) => {
    try {
      console.log(`🔄 ErrorHandler: Executing function with error handling`, { context, args });
      return await fn(...args);
    } catch (error) {
      console.log(`❌ ErrorHandler: Function threw error`, { context, error });
      const errorHandler = new ErrorHandler();
      const errorInfo = errorHandler.handleError(error as Error, context);
      
      // Re-throw the original error but add error info for context
      const originalError = error as Error;
      (originalError as any).errorInfo = errorInfo;
      throw originalError;
    }
  }) as T;
}

/**
 * Global error handler instance
 */
export const errorHandler = new ErrorHandler();

/**
 * Convenience functions for common error types
 */
export const handleError = errorHandler.handleError.bind(errorHandler);
export const handleApiError = errorHandler.handleApiError.bind(errorHandler);
export const handleDatabaseError = errorHandler.handleDatabaseError.bind(errorHandler);
export const handleAudioError = errorHandler.handleAudioError.bind(errorHandler);
export const handleWorkflowError = errorHandler.handleWorkflowError.bind(errorHandler);

/**
 * Export types and enums for external use
 */

console.log(`✅ ErrorHandler: Global error handling utility initialized`);

================
File: src/utils/logger.ts
================
/**
 * Centralized Logging Utility for FlowGenius
 * 
 * This utility provides comprehensive logging capabilities across the entire application,
 * including Electron main process, preload scripts, and React renderer process.
 * 
 * Features:
 * - Multiple log levels (debug, info, warn, error)
 * - Environment-aware logging (development vs production)
 * - Structured logging with metadata
 * - Performance timing utilities
 * - File and console output
 * - Electron-safe implementation
 */

/**
 * Available log levels in order of severity
 */
export enum LogLevel {
  DEBUG = 0,
  INFO = 1,
  WARN = 2,
  ERROR = 3,
}

/**
 * Log level names for display
 */
const LOG_LEVEL_NAMES = {
  [LogLevel.DEBUG]: 'DEBUG',
  [LogLevel.INFO]: 'INFO',
  [LogLevel.WARN]: 'WARN',
  [LogLevel.ERROR]: 'ERROR',
} as const;

/**
 * Console styling for different log levels
 */
const LOG_LEVEL_STYLES = {
  [LogLevel.DEBUG]: 'color: #6B7280; font-weight: normal;',
  [LogLevel.INFO]: 'color: #3B82F6; font-weight: normal;',
  [LogLevel.WARN]: 'color: #F59E0B; font-weight: bold;',
  [LogLevel.ERROR]: 'color: #EF4444; font-weight: bold;',
} as const;

/**
 * Metadata interface for structured logging
 */
export interface LogMetadata {
  [key: string]: any;
  timestamp?: Date;
  component?: string;
  action?: string;
  userId?: string;
  sessionId?: string;
  ideaId?: string;
  nodeType?: string;
  duration?: number;
  error?: Error | string;
}

/**
 * Logger configuration interface
 */
export interface LoggerConfig {
  level: LogLevel;
  enableConsole: boolean;
  enableFile: boolean;
  enableStructuredLogging: boolean;
  maxLogFileSize: number;
  component?: string;
}

/**
 * Default logger configuration
 */
const DEFAULT_CONFIG: LoggerConfig = {
  level: process.env.NODE_ENV === 'development' ? LogLevel.DEBUG : LogLevel.INFO,
  enableConsole: true,
  enableFile: process.env.NODE_ENV === 'production',
  enableStructuredLogging: true,
  maxLogFileSize: 10 * 1024 * 1024, // 10MB
};

/**
 * Performance timer interface for measuring execution time
 */
interface PerformanceTimer {
  start: number;
  label: string;
  metadata?: LogMetadata;
}

/**
 * Main Logger class
 */
class Logger {
  private config: LoggerConfig;
  private timers: Map<string, PerformanceTimer> = new Map();
  private logBuffer: string[] = [];
  private isElectronMain: boolean;
  private isElectronRenderer: boolean;

  constructor(config: Partial<LoggerConfig> = {}) {
    this.config = { ...DEFAULT_CONFIG, ...config };
    
    // Detect Electron environment
    this.isElectronMain = typeof window === 'undefined' && typeof process !== 'undefined';
    this.isElectronRenderer = typeof window !== 'undefined' && typeof window.electron !== 'undefined';
    
    // Initialize logger
    this.initialize();
  }

  /**
   * Initialize the logger based on environment
   */
  private initialize(): void {
    if (this.isElectronMain) {
      this.info('Logger initialized in Electron main process', {
        component: 'Logger',
        action: 'initialize',
        environment: 'electron-main'
      });
    } else if (this.isElectronRenderer) {
      this.info('Logger initialized in Electron renderer process', {
        component: 'Logger',
        action: 'initialize',
        environment: 'electron-renderer'
      });
    } else {
      this.info('Logger initialized in browser environment', {
        component: 'Logger',
        action: 'initialize',
        environment: 'browser'
      });
    }
  }

  /**
   * Check if a log level should be output
   */
  private shouldLog(level: LogLevel): boolean {
    return level >= this.config.level;
  }

  /**
   * Format timestamp for logging
   */
  private formatTimestamp(date: Date = new Date()): string {
    return date.toISOString();
  }

  /**
   * Format log message with metadata
   */
  private formatMessage(level: LogLevel, message: string, metadata?: LogMetadata): string {
    const timestamp = this.formatTimestamp();
    const levelName = LOG_LEVEL_NAMES[level];
    const component = metadata?.component || this.config.component || 'Unknown';
    
    let formattedMessage = `[${timestamp}] [${levelName}] [${component}] ${message}`;
    
    if (metadata && Object.keys(metadata).length > 0) {
      const cleanMetadata = { ...metadata };
      delete cleanMetadata.timestamp;
      delete cleanMetadata.component;
      
      if (Object.keys(cleanMetadata).length > 0) {
        formattedMessage += ` | ${JSON.stringify(cleanMetadata)}`;
      }
    }
    
    return formattedMessage;
  }

  /**
   * Output log to console with styling
   */
  private outputToConsole(level: LogLevel, message: string, metadata?: LogMetadata): void {
    if (!this.config.enableConsole) return;

    const formattedMessage = this.formatMessage(level, message, metadata);
    const style = LOG_LEVEL_STYLES[level];

    // Use appropriate console method based on level
    switch (level) {
      case LogLevel.DEBUG:
        console.debug(`%c${formattedMessage}`, style);
        break;
      case LogLevel.INFO:
        console.info(`%c${formattedMessage}`, style);
        break;
      case LogLevel.WARN:
        console.warn(`%c${formattedMessage}`, style);
        break;
      case LogLevel.ERROR:
        console.error(`%c${formattedMessage}`, style);
        if (metadata?.error instanceof Error) {
          console.error(metadata.error.stack);
        }
        break;
    }
  }

  /**
   * Add log to buffer for file output (Electron main process only)
   */
  private addToBuffer(level: LogLevel, message: string, metadata?: LogMetadata): void {
    if (!this.config.enableFile || !this.isElectronMain) return;

    const formattedMessage = this.formatMessage(level, message, metadata);
    this.logBuffer.push(formattedMessage);

    // Flush buffer if it gets too large
    if (this.logBuffer.length > 1000) {
      this.flushBuffer();
    }
  }

  /**
   * Flush log buffer to file (Electron main process only)
   */
  private flushBuffer(): void {
    if (!this.isElectronMain || this.logBuffer.length === 0) return;

    try {
      // This would be implemented with fs in the main process
      // For now, we'll just clear the buffer
      this.logBuffer = [];
    } catch (error) {
      console.error('Failed to flush log buffer:', error);
    }
  }

  /**
   * Core logging method
   */
  private log(level: LogLevel, message: string, metadata?: LogMetadata): void {
    if (!this.shouldLog(level)) return;

    // Add timestamp and component to metadata
    const enrichedMetadata: LogMetadata = {
      timestamp: new Date(),
      component: this.config.component,
      ...metadata,
    };

    // Output to console
    this.outputToConsole(level, message, enrichedMetadata);

    // Add to file buffer if enabled
    this.addToBuffer(level, message, enrichedMetadata);
  }

  /**
   * Debug level logging
   */
  debug(message: string, metadata?: LogMetadata): void {
    this.log(LogLevel.DEBUG, message, metadata);
  }

  /**
   * Info level logging
   */
  info(message: string, metadata?: LogMetadata): void {
    this.log(LogLevel.INFO, message, metadata);
  }

  /**
   * Warning level logging
   */
  warn(message: string, metadata?: LogMetadata): void {
    this.log(LogLevel.WARN, message, metadata);
  }

  /**
   * Error level logging
   */
  error(message: string, metadata?: LogMetadata): void {
    this.log(LogLevel.ERROR, message, metadata);
  }

  /**
   * Start a performance timer
   */
  startTimer(label: string, metadata?: LogMetadata): void {
    const timer: PerformanceTimer = {
      start: Date.now(),
      label,
      metadata,
    };
    
    this.timers.set(label, timer);
    this.debug(`Timer started: ${label}`, metadata);
  }

  /**
   * End a performance timer and log the duration
   */
  endTimer(label: string, additionalMetadata?: LogMetadata): number {
    const timer = this.timers.get(label);
    if (!timer) {
      this.warn(`Timer not found: ${label}`);
      return 0;
    }

    const duration = Date.now() - timer.start;
    this.timers.delete(label);

    const metadata: LogMetadata = {
      ...timer.metadata,
      ...additionalMetadata,
      duration,
    };

    this.info(`Timer ended: ${label} (${duration}ms)`, metadata);
    return duration;
  }

  /**
   * Log function entry with parameters
   */
  functionEntry(functionName: string, parameters?: any, metadata?: LogMetadata): void {
    this.debug(`→ Entering ${functionName}`, {
      ...metadata,
      action: 'function-entry',
      function: functionName,
      parameters: parameters ? JSON.stringify(parameters) : undefined,
    });
  }

  /**
   * Log function exit with return value
   */
  functionExit(functionName: string, returnValue?: any, metadata?: LogMetadata): void {
    this.debug(`← Exiting ${functionName}`, {
      ...metadata,
      action: 'function-exit',
      function: functionName,
      returnValue: returnValue ? JSON.stringify(returnValue) : undefined,
    });
  }

  /**
   * Log API call start
   */
  apiCallStart(endpoint: string, method: string, metadata?: LogMetadata): void {
    this.info(`API Call: ${method} ${endpoint}`, {
      ...metadata,
      action: 'api-call-start',
      endpoint,
      method,
    });
  }

  /**
   * Log API call completion
   */
  apiCallEnd(endpoint: string, method: string, statusCode: number, duration: number, metadata?: LogMetadata): void {
    const level = statusCode >= 400 ? LogLevel.ERROR : LogLevel.INFO;
    this.log(level, `API Response: ${method} ${endpoint} - ${statusCode} (${duration}ms)`, {
      ...metadata,
      action: 'api-call-end',
      endpoint,
      method,
      statusCode,
      duration,
    });
  }

  /**
   * Log user interaction
   */
  userInteraction(action: string, element?: string, metadata?: LogMetadata): void {
    this.info(`User Interaction: ${action}`, {
      ...metadata,
      action: 'user-interaction',
      userAction: action,
      element,
    });
  }

  /**
   * Log state change
   */
  stateChange(from: string, to: string, metadata?: LogMetadata): void {
    this.info(`State Change: ${from} → ${to}`, {
      ...metadata,
      action: 'state-change',
      fromState: from,
      toState: to,
    });
  }

  /**
   * Create a child logger with additional context
   */
  child(additionalConfig: Partial<LoggerConfig>): Logger {
    return new Logger({
      ...this.config,
      ...additionalConfig,
    });
  }

  /**
   * Update logger configuration
   */
  configure(newConfig: Partial<LoggerConfig>): void {
    this.config = { ...this.config, ...newConfig };
    this.info('Logger configuration updated', {
      component: 'Logger',
      action: 'configure',
      newConfig,
    });
  }

  /**
   * Get current configuration
   */
  getConfig(): LoggerConfig {
    return { ...this.config };
  }
}

/**
 * Default logger instance
 */
export const logger = new Logger({
  component: 'FlowGenius',
});

/**
 * Create a logger for a specific component
 */
export function createLogger(component: string, config?: Partial<LoggerConfig>): Logger {
  return new Logger({
    ...config,
    component,
  });
}

/**
 * Utility function for logging function execution with automatic timing
 */
export function loggedFunction<T extends (...args: any[]) => any>(
  fn: T,
  functionName?: string,
  componentLogger?: Logger
): T {
  const log = componentLogger || logger;
  const name = functionName || fn.name || 'anonymous';

  return ((...args: any[]) => {
    const timerId = `${name}-${Date.now()}`;
    
    log.functionEntry(name, args);
    log.startTimer(timerId);
    
    try {
      const result = fn(...args);
      
      // Handle async functions
      if (result instanceof Promise) {
        return result
          .then((resolvedResult) => {
            log.endTimer(timerId);
            log.functionExit(name, resolvedResult);
            return resolvedResult;
          })
          .catch((error) => {
            log.endTimer(timerId);
            log.error(`Function ${name} threw error`, { error, function: name });
            throw error;
          });
      }
      
      // Handle sync functions
      log.endTimer(timerId);
      log.functionExit(name, result);
      return result;
         } catch (error) {
       log.endTimer(timerId);
       log.error(`Function ${name} threw error`, { error: error as Error, function: name });
       throw error;
     }
  }) as T;
}

// All types and enums are already exported above

================
File: src/utils/README.md
================
# Utils Directory

This directory contains utility functions and helper modules that are used throughout the FlowGenius application.

## Directory Structure

### Core Utilities
- `logger.ts` - Centralized logging utility with different log levels (debug, info, warn, error)
- `errorHandler.ts` - Global error handling utility with user-friendly error messages
- `audioUtils.ts` - Audio processing utilities (format conversion, validation)

### Utility Guidelines

1. **File Naming**: Use camelCase with descriptive names (e.g., `audioUtils.ts`)
2. **Structure**: Each utility should have:
   - Main utility file with exported functions
   - Corresponding test file (`utilityName.test.ts`)
   - Type definitions for parameters and return values
3. **Pure Functions**: Utilities should be pure functions when possible
4. **Documentation**: All functions must include JSDoc comments
5. **Testing**: All utilities must be thoroughly tested

## Utility Categories

### Logging (`logger.ts`)
- Centralized logging with configurable levels
- Console and file output options
- Structured logging with metadata

### Error Handling (`errorHandler.ts`)
- Global error boundary integration
- User-friendly error message formatting
- Error reporting and tracking

### Audio Processing (`audioUtils.ts`)
- Audio format validation and conversion
- MediaRecorder API utilities
- Audio file processing helpers

## Testing

- All utilities must have comprehensive unit tests
- Tests should cover edge cases and error conditions
- Pure functions should test input/output mappings
- Test files should be named `utilityName.test.ts`

================
File: src/utils/startup.ts
================
/**
 * Application Startup Utility
 * 
 * This module handles the initialization sequence for FlowGenius,
 * including environment validation, service connections, and error handling.
 * Used by the main application to ensure all prerequisites are met before startup.
 */

import { logger } from './logger';
import { validateEnvironment, displayValidationSummary, getValidatedConfig } from './envValidator';

/**
 * Startup result interface
 */
export interface StartupResult {
  success: boolean;
  config: any | null;
  errors: string[];
  canContinue: boolean;
}

/**
 * Performs comprehensive application startup checks
 * @param skipConnectionTests - Whether to skip external connection tests (default: false)
 * @returns Promise resolving to startup result
 */
export async function initializeApplication(skipConnectionTests: boolean = false): Promise<StartupResult> {
  logger.info('🚀 Starting FlowGenius application initialization...');
  
  try {
    // Check if we're in a browser environment (Electron renderer)
    const isBrowser = typeof process === 'undefined';
    
    if (isBrowser) {
      // In browser/renderer context, we can't access environment variables directly
      // Environment validation should be done in the main process
      logger.info('📋 Running in browser/renderer context - skipping environment validation');
      logger.info('⚠️  Environment validation should be handled by the main process');
      
      // Step 2: Initialize core services for browser context
      logger.info('🔧 Initializing core services for renderer process');
      await initializeCoreServices(null);
      
      logger.info('🎉 FlowGenius renderer initialization completed successfully!');
      
      return {
        success: true,
        config: null, // Config will be provided by main process
        errors: [],
        canContinue: true
      };
    }
    
    // Step 1: Validate environment variables and test connections (main process only)
    logger.info('📋 Step 1: Environment validation');
    const validationResult = await validateEnvironment(!skipConnectionTests);
    
    // Display comprehensive validation summary
    displayValidationSummary(validationResult);
    
    // Check if we can continue with startup
    const canContinue = validationResult.isValid && (
      skipConnectionTests || validationResult.connectionsValid !== false
    );
    
    if (!canContinue) {
      const errors = [
        ...validationResult.errors,
        ...(validationResult.connectionsValid === false ? ['External service connections failed'] : [])
      ];
      
      logger.error('❌ Application startup failed due to environment issues');
      return {
        success: false,
        config: null,
        errors,
        canContinue: false
      };
    }
    
    // Step 2: Get validated configuration
    logger.info('⚙️  Step 2: Loading configuration');
    const config = getValidatedConfig();
    
    if (!config) {
      logger.error('❌ Failed to load validated configuration');
      return {
        success: false,
        config: null,
        errors: ['Failed to load configuration'],
        canContinue: false
      };
    }
    
    logger.info('✅ Configuration loaded successfully', {
      environment: config.NODE_ENV,
      maxRecordingDuration: config.MAX_RECORDING_DURATION,
      maxFileUploadSize: config.MAX_FILE_UPLOAD_SIZE
    });
    
    // Step 3: Initialize core services (placeholder for future)
    logger.info('🔧 Step 3: Initializing core services');
    await initializeCoreServices(config);
    
    logger.info('🎉 FlowGenius application initialization completed successfully!');
    
    return {
      success: true,
      config,
      errors: [],
      canContinue: true
    };
    
  } catch (error) {
    logger.error('💥 Critical error during application initialization', { 
      error: error as Error 
    });
    
    return {
      success: false,
      config: null,
      errors: [`Critical initialization error: ${(error as Error).message}`],
      canContinue: false
    };
  }
}

/**
 * Initialize core application services
 * @param config - Validated application configuration (null in browser context)
 */
async function initializeCoreServices(config: any | null): Promise<void> {
  logger.info('🔌 Initializing core services...');
  
  if (config === null) {
    logger.info('🌐 Browser/renderer context - services will be initialized via IPC');
    // In browser context, services will be initialized through IPC with main process
    return;
  }
  
  // Future service initializations will go here:
  // - Supabase client setup
  // - LangGraph workflow initialization
  // - Audio service setup
  // - OpenAI service configuration
  
  logger.info('✅ Core services initialized');
}

/**
 * Graceful shutdown handler
 */
export function setupGracefulShutdown(): void {
  // Check if we're in a browser environment (no process object)
  const isBrowser = typeof process === 'undefined';
  
  if (isBrowser) {
    logger.info('🌐 Browser context - graceful shutdown handled by main process');
    
    // In browser context, handle window unload events
    if (typeof window !== 'undefined') {
      window.addEventListener('beforeunload', () => {
        logger.info('🛑 Browser window closing, cleaning up...');
        // Future cleanup operations for browser context
      });
    }
    return;
  }
  
  const shutdownHandler = (signal: string) => {
    logger.info(`🛑 Received ${signal}, starting graceful shutdown...`);
    
    // Future cleanup operations:
    // - Close database connections
    // - Stop audio recording
    // - Save pending data
    // - Clean up temporary files
    
    logger.info('👋 Graceful shutdown completed');
    process.exit(0);
  };
  
  // Handle different shutdown signals
  process.on('SIGINT', () => shutdownHandler('SIGINT'));
  process.on('SIGTERM', () => shutdownHandler('SIGTERM'));
  process.on('SIGQUIT', () => shutdownHandler('SIGQUIT'));
  
  // Handle uncaught exceptions
  process.on('uncaughtException', (error) => {
    logger.error('💥 Uncaught exception detected', { error });
    shutdownHandler('uncaughtException');
  });
  
  // Handle unhandled promise rejections
  process.on('unhandledRejection', (reason, promise) => {
    logger.error('💥 Unhandled promise rejection detected', { 
      reason: reason as Error,
      promise: promise.toString()
    });
    shutdownHandler('unhandledRejection');
  });
}

/**
 * Development mode helper that provides additional debugging information
 */
export function enableDevelopmentMode(): void {
  // Check if we're in a browser environment (no process object)
  const isBrowser = typeof process === 'undefined';
  const isDevelopment = isBrowser || process.env?.NODE_ENV === 'development' || import.meta.env?.MODE === 'development';
  
  if (!isDevelopment) {
    return;
  }
  
  logger.info('🛠️  Development mode enabled');
  
  // Enable additional debugging
  logger.configure({
    level: 0, // DEBUG level
    enableConsole: true,
    enableStructuredLogging: true
  });
  
  // Log environment information (only if process is available)
  if (!isBrowser) {
    logger.debug('Environment information', {
      nodeVersion: process.version,
      platform: process.platform,
      arch: process.arch,
      electronVersion: process.versions.electron || 'Not running in Electron',
      chromeVersion: process.versions.chrome || 'Not available'
    });
  } else {
    logger.debug('Environment information', {
      userAgent: navigator.userAgent,
      environment: 'browser/renderer',
      viteBuildMode: import.meta.env?.MODE || 'unknown'
    });
  }
}

/**
 * Production mode helper that optimizes logging for performance
 */
export function enableProductionMode(): void {
  // Check if we're in a browser environment (no process object)
  const isBrowser = typeof process === 'undefined';
  const isProduction = !isBrowser && process.env?.NODE_ENV === 'production' || import.meta.env?.MODE === 'production';
  
  if (!isProduction) {
    return;
  }
  
  logger.info('🏭 Production mode enabled');
  
  // Optimize logging for production
  logger.configure({
    level: 1, // INFO level
    enableConsole: false,
    enableFile: true,
    enableStructuredLogging: true
  });
}

================
File: src/index.css
================
@tailwind base;
@tailwind components;
@tailwind utilities;

:root {
  font-family: Inter, system-ui, Avenir, Helvetica, Arial, sans-serif;
  line-height: 1.5;
  font-weight: 400;

  color-scheme: light dark;
  color: rgba(255, 255, 255, 0.87);
  background-color: #242424;

  font-synthesis: none;
  text-rendering: optimizeLegibility;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  -webkit-text-size-adjust: 100%;
}

a {
  font-weight: 500;
  color: #646cff;
  text-decoration: inherit;
}
a:hover {
  color: #535bf2;
}

body {
  margin: 0;
  display: flex;
  place-items: center;
  min-width: 320px;
  min-height: 100vh;
}

h1 {
  font-size: 3.2em;
  line-height: 1.1;
}

button {
  border-radius: 8px;
  border: 1px solid transparent;
  padding: 0.6em 1.2em;
  font-size: 1em;
  font-weight: 500;
  font-family: inherit;
  background-color: #1a1a1a;
  cursor: pointer;
  transition: border-color 0.25s;
}
button:hover {
  border-color: #646cff;
}
button:focus,
button:focus-visible {
  outline: 4px auto -webkit-focus-ring-color;
}

code {
  background-color: #1a1a1a;
  padding: 2px 4px;
  margin: 0 4px;
  border-radius: 4px;
}

.card {
  padding: 2em;
}

#app {
  max-width: 1280px;
  margin: 0 auto;
  padding: 2rem;
  text-align: center;
}

@media (prefers-color-scheme: light) {
  :root {
    color: #213547;
    background-color: #ffffff;
  }
  a:hover {
    color: #747bff;
  }
  button {
    background-color: #f9f9f9;
  }
  code {
    background-color: #f9f9f9;
  }
}

================
File: src/vite-env.d.ts
================
/// <reference types="vite/client" />

interface Window {
  // expose in the `electron/preload/index.ts`
  ipcRenderer: import('electron').IpcRenderer
}

================
File: test/setup.ts
================
/**
 * Test Setup Configuration for FlowGenius
 * 
 * This file configures the testing environment for React components using Vitest
 * and React Testing Library. It provides global setup for all tests including
 * DOM matchers, cleanup, and environment configuration.
 * 
 * Features:
 * - React Testing Library integration
 * - Custom Jest-DOM matchers
 * - Automatic cleanup after each test
 * - Global test utilities
 * - Mock configurations for Electron APIs
 */

import '@testing-library/jest-dom';
import { cleanup } from '@testing-library/react';
import { afterEach, beforeEach, vi } from 'vitest';

/**
 * Cleanup after each test to prevent memory leaks and test interference
 */
afterEach(() => {
  console.log('🧹 Test cleanup: Cleaning up after test');
  cleanup();
});

/**
 * Setup before each test
 */
beforeEach(() => {
  console.log('🚀 Test setup: Preparing test environment');
  
  // Clear all mocks before each test
  vi.clearAllMocks();
  
  // Reset any module mocks
  vi.resetModules();
});

/**
 * Mock Electron APIs for testing in Node.js environment
 */
const mockElectronAPI = {
  ipcRenderer: {
    invoke: vi.fn(),
    on: vi.fn(),
    off: vi.fn(),
    send: vi.fn(),
  },
  platform: 'darwin',
  versions: {
    node: '18.0.0',
    chrome: '100.0.0',
    electron: '20.0.0',
  },
};

// Mock window.electron for components that use Electron APIs
Object.defineProperty(window, 'electron', {
  value: mockElectronAPI,
  writable: true,
});

/**
 * Mock console methods to reduce noise in tests
 * Comment out during debugging if you need to see console output
 */
global.console = {
  ...console,
  // Uncomment to silence console.log in tests
  // log: vi.fn(),
  // info: vi.fn(),
  // warn: vi.fn(),
  // error: vi.fn(),
};

/**
 * Mock localStorage for tests
 */
const localStorageMock = {
  getItem: vi.fn(),
  setItem: vi.fn(),
  removeItem: vi.fn(),
  clear: vi.fn(),
  length: 0,
  key: vi.fn(),
};

Object.defineProperty(window, 'localStorage', {
  value: localStorageMock,
  writable: true,
});

/**
 * Mock sessionStorage for tests
 */
const sessionStorageMock = {
  getItem: vi.fn(),
  setItem: vi.fn(),
  removeItem: vi.fn(),
  clear: vi.fn(),
  length: 0,
  key: vi.fn(),
};

Object.defineProperty(window, 'sessionStorage', {
  value: sessionStorageMock,
  writable: true,
});

/**
 * Mock MediaRecorder API for audio recording tests
 */
class MockMediaRecorder {
  state: string = 'inactive';
  stream: MediaStream;
  ondataavailable: ((event: BlobEvent) => void) | null = null;
  onstart: (() => void) | null = null;
  onstop: (() => void) | null = null;
  onerror: ((event: Event) => void) | null = null;

  constructor(stream: MediaStream) {
    console.log('🎤 MockMediaRecorder: Creating mock MediaRecorder', { stream });
    this.stream = stream;
  }

  start() {
    console.log('🎤 MockMediaRecorder: Starting recording');
    this.state = 'recording';
    if (this.onstart) this.onstart();
  }

  stop() {
    console.log('🎤 MockMediaRecorder: Stopping recording');
    this.state = 'inactive';
    if (this.onstop) this.onstop();
    
    // Simulate data available event
    if (this.ondataavailable) {
      const mockBlob = new Blob(['mock audio data'], { type: 'audio/wav' });
      this.ondataavailable({ data: mockBlob } as BlobEvent);
    }
  }

  pause() {
    console.log('🎤 MockMediaRecorder: Pausing recording');
    this.state = 'paused';
  }

  resume() {
    console.log('🎤 MockMediaRecorder: Resuming recording');
    this.state = 'recording';
  }

  requestData() {
    console.log('🎤 MockMediaRecorder: Requesting data');
    if (this.ondataavailable) {
      const mockBlob = new Blob(['mock audio data'], { type: 'audio/wav' });
      this.ondataavailable({ data: mockBlob } as BlobEvent);
    }
  }

  static isTypeSupported(type: string): boolean {
    console.log('🎤 MockMediaRecorder: Checking type support', { type });
    return ['audio/wav', 'audio/webm', 'audio/mp4'].includes(type);
  }
}

// Mock getUserMedia for microphone access tests
const mockGetUserMedia = vi.fn().mockResolvedValue({
  getTracks: () => [
    {
      kind: 'audio',
      label: 'Mock Microphone',
      stop: vi.fn(),
      getSettings: () => ({
        sampleRate: 44100,
        channelCount: 1,
      }),
    },
  ],
  getAudioTracks: () => [
    {
      kind: 'audio',
      label: 'Mock Microphone',
      stop: vi.fn(),
    },
  ],
});

Object.defineProperty(navigator, 'mediaDevices', {
  value: {
    getUserMedia: mockGetUserMedia,
    enumerateDevices: vi.fn().mockResolvedValue([
      {
        deviceId: 'mock-audio-input',
        kind: 'audioinput',
        label: 'Mock Microphone',
        groupId: 'mock-group',
      },
    ]),
  },
  writable: true,
});

// Set MediaRecorder on global window
Object.defineProperty(window, 'MediaRecorder', {
  value: MockMediaRecorder,
  writable: true,
});

/**
 * Mock fetch for API testing
 */
global.fetch = vi.fn();

/**
 * Mock environment variables
 */
process.env.NODE_ENV = 'test';

/**
 * Global test utilities
 */
export const testUtils = {
  /**
   * Wait for a specified amount of time
   */
  wait: (ms: number) => new Promise(resolve => setTimeout(resolve, ms)),

  /**
   * Wait for the next tick
   */
  waitForNextTick: () => new Promise(resolve => process.nextTick(resolve)),

  /**
   * Create a mock function with logging
   */
  createMockFn: (name: string) => {
    const mockFn = vi.fn();
    
    // Add logging to track calls
    return mockFn.mockImplementation((...args) => {
      console.log(`📞 Mock function called: ${name}`, { args });
      return undefined;
    });
  },

  /**
   * Mock implementation that throws an error
   */
  createMockError: (message: string) => {
    return vi.fn().mockImplementation(() => {
      throw new Error(message);
    });
  },

  /**
   * Mock implementation that returns a promise
   */
  createMockPromise: <T>(resolveValue: T, delay = 0) => {
    return vi.fn().mockImplementation(() => {
      return new Promise(resolve => {
        setTimeout(() => resolve(resolveValue), delay);
      });
    });
  },
};

console.log('✅ Test setup: Test environment configured successfully');
console.log('🧪 Test setup: React Testing Library, Vitest, and mocks ready');
console.log('🎯 Test setup: Electron APIs mocked for component testing');
console.log('🎤 Test setup: MediaRecorder API mocked for audio testing');

================
File: .env.example
================
# =============================================================================
# FlowGenius Environment Variables Configuration
# =============================================================================
# Copy this file to .env and fill in your actual values
# Never commit .env to version control - it contains sensitive API keys
# =============================================================================

# =============================================================================
# ESSENTIAL API KEYS (Required for app to function)
# =============================================================================

# OpenAI API key for GPT-4o chat completions and Whisper voice-to-text
# Get your API key from: https://platform.openai.com/account/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Supabase project URL - get from your Supabase project dashboard
# Note: Uses VITE_ prefix for client-side access in Electron renderer
VITE_SUPABASE_URL=https://your-project-ref.supabase.co

# Supabase anonymous public key - safe to use in client-side code
# Note: Uses VITE_ prefix for client-side access in Electron renderer
VITE_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.your-anon-key-here

# LangChain API key for tracing and monitoring LangGraph workflows
# Get your API key from: https://smith.langchain.com/
LANGCHAIN_API_KEY=ls__your-langchain-api-key-here

# Enable LangSmith tracing for debugging workflows
LANGCHAIN_TRACING_V2=true

# =============================================================================
# DEVELOPMENT CONFIGURATION (Optional - has sensible defaults)
# =============================================================================

# Environment mode: development, production, or test
# NODE_ENV=development

# Vite development server URL (used by Electron in development)
# Defaults to http://127.0.0.1:7777/ from package.json if not set
# VITE_DEV_SERVER_URL=http://127.0.0.1:7777/

# Application logging level: debug, info, warn, error
# Defaults to 'debug' in development, 'info' in production
# LOG_LEVEL=debug

# Enable debug mode with verbose logging
# DEBUG_MODE=true

# =============================================================================
# FUTURE FEATURES (Not currently implemented)
# =============================================================================

# Google Gemini API key (for future multi-model support)
# GOOGLE_API_KEY=your-google-api-key-here

# Anthropic Claude API key (for future multi-model support)  
# ANTHROPIC_API_KEY=your-anthropic-api-key-here

# LangSmith project name for organizing traces
# LANGCHAIN_PROJECT=FlowGenius-Development

# Audio recording settings (30 minutes = 1800 seconds)
# MAX_RECORDING_DURATION_SECONDS=1800
# AUDIO_SAMPLE_RATE=16000

# Chat message limits
# MAX_MESSAGE_LENGTH=10000
# MAX_MESSAGES_PER_SESSION=1000

================
File: .gitignore
================
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

node_modules
dist
dist-ssr
dist-electron
release
*.local

# Editor directories and files
.vscode/.debug.env
.idea
.DS_Store
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?

#lockfile
package-lock.json
pnpm-lock.yaml
yarn.lock
/test-results/
/playwright-report/
/playwright/.cache/

.env

================
File: .npmrc
================
# For electron-builder
# https://github.com/electron-userland/electron-builder/issues/6289#issuecomment-1042620422
shamefully-hoist=true

# For China 🇨🇳 developers
# electron_mirror=https://npmmirror.com/mirrors/electron/

================
File: .playwright.config.txt
================
import type { PlaywrightTestConfig } from "@playwright/test";

/**
 * Read environment variables from file.
 * https://github.com/motdotla/dotenv
 */
// require('dotenv').config();

/**
 * See https://playwright.dev/docs/test-configuration.
 */
const config: PlaywrightTestConfig = {
  testDir: "./e2e",
  /* Maximum time one test can run for. */
  timeout: 30 * 1000,
  expect: {
    /**
     * Maximum time expect() should wait for the condition to be met.
     * For example in `await expect(locator).toHaveText();`
     */
    timeout: 5000,
  },
  /* Run tests in files in parallel */
  fullyParallel: true,
  /* Fail the build on CI if you accidentally left test.only in the source code. */
  forbidOnly: !!process.env.CI,
  /* Retry on CI only */
  retries: process.env.CI ? 2 : 0,
  /* Opt out of parallel tests on CI. */
  workers: process.env.CI ? 1 : undefined,
  /* Reporter to use. See https://playwright.dev/docs/test-reporters */
  reporter: "html",
  /* Shared settings for all the projects below. See https://playwright.dev/docs/api/class-testoptions. */
  use: {
    /* Maximum time each action such as `click()` can take. Defaults to 0 (no limit). */
    actionTimeout: 0,
    /* Base URL to use in actions like `await page.goto('/')`. */
    // baseURL: 'http://localhost:3000',

    /* Collect trace when retrying the failed test. See https://playwright.dev/docs/trace-viewer */
    trace: "on-first-retry",
  },

  /* Folder for test artifacts such as screenshots, videos, traces, etc. */
  // outputDir: 'test-results/',

  /* Run your local dev server before starting the tests */
  // webServer: {
  //   command: 'npm run start',
  //   port: 3000,
  // },
};

export default config;

================
File: .vite.config.flat.txt
================
import { rmSync } from 'node:fs'
import path from 'node:path'
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'
import electron from 'vite-plugin-electron'
import renderer from 'vite-plugin-electron-renderer'
import pkg from './package.json'

// https://vitejs.dev/config/
export default defineConfig(({ command }) => {
  rmSync('dist-electron', { recursive: true, force: true })

  const isServe = command === 'serve'
  const isBuild = command === 'build'
  const sourcemap = isServe || !!process.env.VSCODE_DEBUG

  return {
    resolve: {
      alias: {
        '@': path.join(__dirname, 'src')
      },
    },
    plugins: [
      react(),
      electron([
        {
          // Main-Process entry file of the Electron App.
          entry: 'electron/main/index.ts',
          onstart(options) {
            if (process.env.VSCODE_DEBUG) {
              console.log(/* For `.vscode/.debug.script.mjs` */'[startup] Electron App')
            } else {
              options.startup()
            }
          },
          vite: {
            build: {
              sourcemap,
              minify: isBuild,
              outDir: 'dist-electron/main',
              rollupOptions: {
                external: Object.keys('dependencies' in pkg ? pkg.dependencies : {}),
              },
            },
          },
        },
        {
          entry: 'electron/preload/index.ts',
          onstart(options) {
            // Notify the Renderer-Process to reload the page when the Preload-Scripts build is complete, 
            // instead of restarting the entire Electron App.
            options.reload()
          },
          vite: {
            build: {
              sourcemap: sourcemap ? 'inline' : undefined, // #332
              minify: isBuild,
              outDir: 'dist-electron/preload',
              rollupOptions: {
                external: Object.keys('dependencies' in pkg ? pkg.dependencies : {}),
              },
            },
          },
        }
      ]),
      // Use Node.js API in the Renderer-process
      renderer(),
    ],
    server: process.env.VSCODE_DEBUG && (() => {
      const url = new URL(pkg.debug.env.VITE_DEV_SERVER_URL)
      return {
        host: url.hostname,
        port: +url.port,
      }
    })(),
    clearScreen: false,
  }
})

================
File: electron-builder.json
================
{
  "$schema": "https://raw.githubusercontent.com/electron-userland/electron-builder/master/packages/app-builder-lib/scheme.json",
  "appId": "YourAppID",
  "asar": true,
  "directories": {
    "output": "release/${version}"
  },
  "files": [
    "dist-electron",
    "dist"
  ],
  "mac": {
    "artifactName": "${productName}_${version}.${ext}",
    "target": [
      "dmg",
      "zip"
    ]
  },
  "win": {
    "target": [
      {
        "target": "nsis",
        "arch": [
          "x64"
        ]
      }
    ],
    "artifactName": "${productName}_${version}.${ext}"
  },
  "nsis": {
    "oneClick": false,
    "perMachine": false,
    "allowToChangeInstallationDirectory": true,
    "deleteAppDataOnUninstall": false
  },
  "publish": {
    "provider": "generic",
    "channel": "latest",
    "url": "https://github.com/electron-vite/electron-vite-react/releases/download/v0.9.9/"
  }
}

================
File: eslint.config.js
================
/**
 * ESLint Configuration for FlowGenius Electron + React Application
 * 
 * This configuration properly handles the mixed environment of:
 * - Electron main process (Node.js environment)
 * - Electron preload scripts (mixed Node.js + Browser)
 * - React renderer process (Browser environment)
 * 
 * Simplified configuration to avoid plugin compatibility issues.
 */

import js from '@eslint/js';
import tseslint from 'typescript-eslint';
import reactPlugin from 'eslint-plugin-react';
import reactHooksPlugin from 'eslint-plugin-react-hooks';

export default tseslint.config(
  // Base JavaScript configuration
  js.configs.recommended,
  
  // TypeScript configuration for all TS files
  ...tseslint.configs.recommended,
  
  // Global settings
  {
    languageOptions: {
      ecmaVersion: 'latest',
      sourceType: 'module',
      parserOptions: {
        ecmaFeatures: {
          jsx: true,
        },
      },
    },
    settings: {
      react: {
        version: 'detect',
      },
    },
  },

  // Configuration for Electron main process files
  {
    files: ['electron/main/**/*.{js,ts}'],
    languageOptions: {
      globals: {
        // Node.js globals for main process
        __dirname: 'readonly',
        __filename: 'readonly',
        Buffer: 'readonly',
        console: 'readonly',
        global: 'readonly',
        process: 'readonly',
        require: 'readonly',
        module: 'readonly',
        exports: 'readonly',
      },
    },
    rules: {
      // Allow console.log in main process for debugging
      'no-console': 'off',
      // TypeScript rules
      '@typescript-eslint/no-unused-vars': ['error', { argsIgnorePattern: '^_' }],
      '@typescript-eslint/explicit-function-return-type': 'off',
      '@typescript-eslint/no-explicit-any': 'warn',
    },
  },

  // Configuration for Electron preload scripts
  {
    files: ['electron/preload/**/*.{js,ts}'],
    languageOptions: {
      globals: {
        // Mixed environment globals for preload
        __dirname: 'readonly',
        __filename: 'readonly',
        Buffer: 'readonly',
        console: 'readonly',
        process: 'readonly',
        require: 'readonly',
        module: 'readonly',
        exports: 'readonly',
        // Browser globals
        window: 'readonly',
        document: 'readonly',
        HTMLElement: 'readonly',
        DocumentReadyState: 'readonly',
      },
    },
    rules: {
      'no-console': 'off',
      '@typescript-eslint/no-unused-vars': ['error', { argsIgnorePattern: '^_' }],
      '@typescript-eslint/no-explicit-any': 'warn',
    },
  },

  // Configuration for React renderer process files
  {
    files: ['src/**/*.{js,jsx,ts,tsx}'],
    plugins: {
      react: reactPlugin,
      'react-hooks': reactHooksPlugin,
    },
    languageOptions: {
      globals: {
        // Browser environment globals
        window: 'readonly',
        document: 'readonly',
        HTMLElement: 'readonly',
        HTMLButtonElement: 'readonly',
        HTMLInputElement: 'readonly',
        HTMLTextAreaElement: 'readonly',
        HTMLSelectElement: 'readonly',
        HTMLFormElement: 'readonly',
        Event: 'readonly',
        MouseEvent: 'readonly',
        KeyboardEvent: 'readonly',
        MediaRecorder: 'readonly',
        MediaDeviceInfo: 'readonly',
        Navigator: 'readonly',
        console: 'readonly',
        setTimeout: 'readonly',
        clearTimeout: 'readonly',
        setInterval: 'readonly',
        clearInterval: 'readonly',
        fetch: 'readonly',
        Response: 'readonly',
        Request: 'readonly',
        URL: 'readonly',
        URLSearchParams: 'readonly',
        FormData: 'readonly',
        Blob: 'readonly',
        File: 'readonly',
        FileReader: 'readonly',
        // Custom globals for FlowGenius
        electron: 'readonly', // Electron API exposed via contextBridge
      },
    },
    rules: {
      // React specific rules
      ...reactPlugin.configs.recommended.rules,
      ...reactHooksPlugin.configs.recommended.rules,
      
      // React customizations
      'react/react-in-jsx-scope': 'off', // Not needed with new JSX transform
      'react/prop-types': 'off', // Using TypeScript for prop validation
      'react/display-name': 'off', // Not critical for our use case
      
      // TypeScript rules for React components
      '@typescript-eslint/no-unused-vars': ['error', { 
        argsIgnorePattern: '^_',
        varsIgnorePattern: '^_',
      }],
      '@typescript-eslint/explicit-function-return-type': 'off',
      '@typescript-eslint/no-explicit-any': 'warn',
      '@typescript-eslint/no-non-null-assertion': 'warn',
      
      // General code quality rules
      'no-console': ['warn', { allow: ['warn', 'error', 'info'] }], // Allow some console methods
      'prefer-const': 'error',
      'no-var': 'error',
      'object-shorthand': 'error',
      'prefer-template': 'error',
      
      // Import/export rules
      'no-duplicate-imports': 'error',
    },
  },

  // Configuration for test files
  {
    files: ['**/*.test.{js,jsx,ts,tsx}', '**/*.spec.{js,jsx,ts,tsx}'],
    languageOptions: {
      globals: {
        // Test environment globals
        describe: 'readonly',
        it: 'readonly',
        test: 'readonly',
        expect: 'readonly',
        beforeEach: 'readonly',
        afterEach: 'readonly',
        beforeAll: 'readonly',
        afterAll: 'readonly',
        jest: 'readonly',
        vi: 'readonly', // Vitest
      },
    },
    rules: {
      // Relaxed rules for test files
      '@typescript-eslint/no-explicit-any': 'off',
      'no-console': 'off',
    },
  },

  // Configuration for configuration files
  {
    files: ['*.config.{js,ts}', '*.config.*.{js,ts}'],
    languageOptions: {
      globals: {
        // Node.js globals for config files
        __dirname: 'readonly',
        __filename: 'readonly',
        process: 'readonly',
        require: 'readonly',
        module: 'readonly',
        exports: 'readonly',
      },
    },
    rules: {
      // Relaxed rules for config files
      '@typescript-eslint/no-var-requires': 'off',
      'no-console': 'off',
    },
  },

  // Global ignores
  {
    ignores: [
      'dist/**',
      'dist-electron/**',
      'node_modules/**',
      'build/**',
      '*.min.js',
      'coverage/**',
      '.vite/**',
      '.vscode/**',
      'postcss.config.cjs',
    ],
  }
);

================
File: hierarchical_agent_teams.ipynb
================
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e3ebc4-57af-4fe4-bdd3-36aff67bf276",
   "metadata": {},
   "source": [
    "## Hierarchical Agent Teams\n",
    "\n",
    "This is an example accessed directly from [LangChain](https://www.langchain.com/) under the MIT License. All rights and credit go to the LangChain team. This example is being accessed for educational purposes only. \n",
    "\n",
    "In our previous example ([Agent Supervisor](./agent_supervisor.ipynb)), we introduced the concept of a single supervisor node to route work between different worker nodes.\n",
    "\n",
    "But what if the job for a single worker becomes too complex? What if the number of workers becomes too large?\n",
    "\n",
    "For some applications, the system may be more effective if work is distributed _hierarchically_.\n",
    "\n",
    "You can do this by composing different subgraphs and creating a top-level supervisor, along with mid-level supervisors.\n",
    "\n",
    "To do this, let's build a simple research assistant!\n",
    "\n",
    "This notebook is inspired by the paper [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/abs/2308.08155), by Wu, et. al. In the rest of this notebook, you will:\n",
    "\n",
    "1. Define the agents' tools to access the web and write files\n",
    "2. Define some utilities to help create the graph and agents\n",
    "3. Create and define each team (web research + doc writing)\n",
    "4. Compose everything together.\n",
    "\n",
    "But before all of that, some setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d30b6f7-3bec-4d9f-af50-43dfdc81ae6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:42.364369Z",
     "start_time": "2024-05-15T08:19:42.359273Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install -U langgraph langchain langchain_openai langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c2f3de-c730-4aec-85a6-af2c2f058803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:42.395571Z",
     "start_time": "2024-05-15T08:19:42.365662Z"
    }
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "_set_if_undefined(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Optional, add tracing in LangSmith.\n",
    "# This will help you visualize and debug the control flow\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Multi-agent Collaboration\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354568e2-aef0-4af9-8a79-e64d3eea752f",
   "metadata": {},
   "source": [
    "## Create Tools\n",
    "\n",
    "Each team will be composed of one or more agents each with one or more tools. Below, define all the tools to be used by your different teams.\n",
    "\n",
    "We'll start with the research team.\n",
    "\n",
    "**Research team tools**\n",
    "\n",
    "The research team can use a search engine and url scraper to find information on the web. Feel free to add additional functionality below to boost the team performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4024eb89-843d-4cc3-ab3f-e1eb4d031179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:44.477064Z",
     "start_time": "2024-05-15T08:19:42.397083Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langsmith import trace\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "\n",
    "@tool\n",
    "def scrape_webpages(urls: List[str]) -> str:\n",
    "    \"\"\"Use requests and bs4 to scrape the provided web pages for detailed information.\"\"\"\n",
    "    loader = WebBaseLoader(urls)\n",
    "    docs = loader.load()\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document name=\"{doc.metadata.get(\"title\", \"\")}\">\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c427982-fadf-4721-a77e-2465df9fc6bc",
   "metadata": {},
   "source": [
    "**Document writing team tools**\n",
    "\n",
    "Next up, we will give some tools for the doc writing team to use.\n",
    "We define some bare-bones file-access tools below.\n",
    "\n",
    "Note that this gives the agents access to your file-system, which can be unsafe. We also haven't optimized the tool descriptions for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f20a18ca-2709-4c12-84f3-88678591a9fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:44.538421Z",
     "start_time": "2024-05-15T08:19:44.479132Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Dict, Optional\n",
    "\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "_TEMP_DIRECTORY = TemporaryDirectory()\n",
    "WORKING_DIRECTORY = Path(_TEMP_DIRECTORY.name)\n",
    "\n",
    "\n",
    "@tool\n",
    "def create_outline(\n",
    "    points: Annotated[List[str], \"List of main points or sections.\"],\n",
    "    file_name: Annotated[str, \"File path to save the outline.\"],\n",
    ") -> Annotated[str, \"Path of the saved outline file.\"]:\n",
    "    \"\"\"Create and save an outline.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        for i, point in enumerate(points):\n",
    "            file.write(f\"{i + 1}. {point}\\n\")\n",
    "    return f\"Outline saved to {file_name}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def read_document(\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
    "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
    ") -> str:\n",
    "    \"\"\"Read the specified document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    if start is not None:\n",
    "        start = 0\n",
    "    return \"\\n\".join(lines[start:end])\n",
    "\n",
    "\n",
    "@tool\n",
    "def write_document(\n",
    "    content: Annotated[str, \"Text content to be written into the document.\"],\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    ") -> Annotated[str, \"Path of the saved document file.\"]:\n",
    "    \"\"\"Create and save a text document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.write(content)\n",
    "    return f\"Document saved to {file_name}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def edit_document(\n",
    "    file_name: Annotated[str, \"Path of the document to be edited.\"],\n",
    "    inserts: Annotated[\n",
    "        Dict[int, str],\n",
    "        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n",
    "    ],\n",
    ") -> Annotated[str, \"Path of the edited document file.\"]:\n",
    "    \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sorted_inserts = sorted(inserts.items())\n",
    "\n",
    "    for line_number, text in sorted_inserts:\n",
    "        if 1 <= line_number <= len(lines) + 1:\n",
    "            lines.insert(line_number - 1, text + \"\\n\")\n",
    "        else:\n",
    "            return f\"Error: Line number {line_number} is out of range.\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    return f\"Document edited and saved to {file_name}\"\n",
    "\n",
    "\n",
    "# Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "\n",
    "repl = PythonREPL()\n",
    "\n",
    "\n",
    "@tool\n",
    "def python_repl(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"]\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    return f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ee1c6-2b6a-439d-9046-df54e1e15698",
   "metadata": {},
   "source": [
    "## Helper Utilities\n",
    "\n",
    "We are going to create a few utility functions to make it more concise when we want to:\n",
    "\n",
    "1. Create a worker agent.\n",
    "2. Create a supervisor for the sub-graph.\n",
    "\n",
    "These will simplify the graph compositional code at the end for us so it's easier to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e09fb60f-1aac-455b-b67d-8d2e4ccfd747",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:46.559082Z",
     "start_time": "2024-05-15T08:19:44.541330Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, Callable, List, Optional, TypedDict, Union\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "\n",
    "def create_agent(\n",
    "    llm: ChatOpenAI,\n",
    "    tools: list,\n",
    "    system_prompt: str,\n",
    ") -> str:\n",
    "    \"\"\"Create a function-calling agent and add it to the graph.\"\"\"\n",
    "    system_prompt += \"\\nWork autonomously according to your specialty, using the tools available to you.\"\n",
    "    \" Do not ask for clarification.\"\n",
    "    \" Your other team members (and other teams) will collaborate with you with their own specialties.\"\n",
    "    \" You are chosen for a reason! You are one of the following team members: {team_members}.\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "\n",
    "def create_team_supervisor(llm: ChatOpenAI, system_prompt, members) -> str:\n",
    "    \"\"\"An LLM-based router.\"\"\"\n",
    "    options = [\"FINISH\"] + members\n",
    "    function_def = {\n",
    "        \"name\": \"route\",\n",
    "        \"description\": \"Select the next role.\",\n",
    "        \"parameters\": {\n",
    "            \"title\": \"routeSchema\",\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"next\": {\n",
    "                    \"title\": \"Next\",\n",
    "                    \"anyOf\": [\n",
    "                        {\"enum\": options},\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"next\"],\n",
    "        },\n",
    "    }\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\n",
    "                \"system\",\n",
    "                \"Given the conversation above, who should act next?\"\n",
    "                \" Or should we FINISH? Select one of: {options}\",\n",
    "            ),\n",
    "        ]\n",
    "    ).partial(options=str(options), team_members=\", \".join(members))\n",
    "    return (\n",
    "        prompt\n",
    "        | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "        | JsonOutputFunctionsParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00282b1f-bb4d-4ee7-9bae-e8e6f586f12e",
   "metadata": {},
   "source": [
    "## Define Agent Teams\n",
    "\n",
    "Now we can get to define our hierarchical teams. \"Choose your player!\"\n",
    "\n",
    "### Research Team\n",
    "\n",
    "The research team will have a search agent and a web scraping \"research_agent\" as the two worker nodes. Let's create those, as well as the team supervisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53db0c78-e357-48ba-ae5f-3fc04735a3b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:48.810290Z",
     "start_time": "2024-05-15T08:19:46.561088Z"
    }
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "import functools\n",
    "\n",
    "\n",
    "# Research team graph state\n",
    "class ResearchTeamState(TypedDict):\n",
    "    # A message is added after each team member finishes\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    # The team members are tracked so they are aware of\n",
    "    # the others' skill-sets\n",
    "    team_members: List[str]\n",
    "    # Used to route work. The supervisor calls a function\n",
    "    # that will update this every time it makes a decision\n",
    "    next: str\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-1106-preview\")\n",
    "\n",
    "search_agent = create_agent(\n",
    "    llm,\n",
    "    [tavily_tool],\n",
    "    \"You are a research assistant who can search for up-to-date info using the tavily search engine.\",\n",
    ")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Search\")\n",
    "\n",
    "research_agent = create_agent(\n",
    "    llm,\n",
    "    [scrape_webpages],\n",
    "    \"You are a research assistant who can scrape specified urls for more detailed information using the scrape_webpages function.\",\n",
    ")\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"Web Scraper\")\n",
    "\n",
    "supervisor_agent = create_team_supervisor(\n",
    "    llm,\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  Search, Web Scraper. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\",\n",
    "    [\"Search\", \"Web Scraper\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c6ee8-a461-4081-8a97-a3a06ec0f994",
   "metadata": {},
   "source": [
    "Now that we've created the necessary components, defining their interactions is easy. Add the nodes to the team graph, and define the edges, which determine the transition criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a7a1260-d9f6-4011-b2b1-13fab5126997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:48.825649Z",
     "start_time": "2024-05-15T08:19:48.811753Z"
    }
   },
   "outputs": [],
   "source": [
    "research_graph = StateGraph(ResearchTeamState)\n",
    "research_graph.add_node(\"Search\", search_node)\n",
    "research_graph.add_node(\"Web Scraper\", research_node)\n",
    "research_graph.add_node(\"supervisor\", supervisor_agent)\n",
    "\n",
    "# Define the control flow\n",
    "research_graph.add_edge(\"Search\", \"supervisor\")\n",
    "research_graph.add_edge(\"Web Scraper\", \"supervisor\")\n",
    "research_graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\"Search\": \"Search\", \"Web Scraper\": \"Web Scraper\", \"FINISH\": END},\n",
    ")\n",
    "\n",
    "\n",
    "research_graph.set_entry_point(\"supervisor\")\n",
    "chain = research_graph.compile()\n",
    "\n",
    "\n",
    "# The following functions interoperate between the top level graph state\n",
    "# and the state of the research sub-graph\n",
    "# this makes it so that the states of each graph don't get intermixed\n",
    "def enter_chain(message: str):\n",
    "    results = {\n",
    "        \"messages\": [HumanMessage(content=message)],\n",
    "    }\n",
    "    return results\n",
    "\n",
    "\n",
    "research_chain = enter_chain | chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "110f59bed6134685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:51.936523Z",
     "start_time": "2024-05-15T08:19:48.827798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(chain.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee8f2c-fbde-427b-ba54-ae0c7ce5fbfb",
   "metadata": {},
   "source": [
    "We can give this team work directly. Try it out below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "912b0604-a178-4246-a36f-2dedae606680",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:51.952470Z",
     "start_time": "2024-05-15T08:19:51.937879Z"
    }
   },
   "outputs": [],
   "source": [
    "for s in research_chain.stream(\n",
    "    \"when is Taylor Swift's next tour?\", {\"recursion_limit\": 100}\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b99ab-f6f0-4c5d-a90b-10102465d186",
   "metadata": {},
   "source": [
    "### Document Writing Team\n",
    "\n",
    "Create the document writing team below using a similar approach. This time, we will give each agent access to different file-writing tools.\n",
    "\n",
    "Note that we are giving file-system access to our agent here, which is not safe in all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bcdbf44-9481-430c-8429-fa142ed8a626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:53.677722Z",
     "start_time": "2024-05-15T08:19:51.953933Z"
    }
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Document writing team graph state\n",
    "class DocWritingState(TypedDict):\n",
    "    # This tracks the team's conversation internally\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    # This provides each worker with context on the others' skill sets\n",
    "    team_members: str\n",
    "    # This is how the supervisor tells langgraph who to work next\n",
    "    next: str\n",
    "    # This tracks the shared directory state\n",
    "    current_files: str\n",
    "\n",
    "\n",
    "# This will be run before each worker agent begins work\n",
    "# It makes it so they are more aware of the current state\n",
    "# of the working directory.\n",
    "def prelude(state):\n",
    "    written_files = []\n",
    "    if not WORKING_DIRECTORY.exists():\n",
    "        WORKING_DIRECTORY.mkdir()\n",
    "    try:\n",
    "        written_files = [\n",
    "            f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.rglob(\"*\")\n",
    "        ]\n",
    "    except:\n",
    "        pass\n",
    "    if not written_files:\n",
    "        return {**state, \"current_files\": \"No files written.\"}\n",
    "    return {\n",
    "        **state,\n",
    "        \"current_files\": \"\\nBelow are files your team has written to the directory:\\n\"\n",
    "        + \"\\n\".join([f\" - {f}\" for f in written_files]),\n",
    "    }\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-1106-preview\")\n",
    "\n",
    "doc_writer_agent = create_agent(\n",
    "    llm,\n",
    "    [write_document, edit_document, read_document],\n",
    "    \"You are an expert writing a research document.\\n\"\n",
    "    # The {current_files} value is populated automatically by the graph state\n",
    "    \"Below are files currently in your directory:\\n{current_files}\",\n",
    ")\n",
    "# Injects current directory working state before each call\n",
    "context_aware_doc_writer_agent = prelude | doc_writer_agent\n",
    "doc_writing_node = functools.partial(\n",
    "    agent_node, agent=context_aware_doc_writer_agent, name=\"DocWriter\"\n",
    ")\n",
    "\n",
    "note_taking_agent = create_agent(\n",
    "    llm,\n",
    "    [create_outline, read_document],\n",
    "    \"You are an expert senior researcher tasked with writing a paper outline and\"\n",
    "    \" taking notes to craft a perfect paper.{current_files}\",\n",
    ")\n",
    "context_aware_note_taking_agent = prelude | note_taking_agent\n",
    "note_taking_node = functools.partial(\n",
    "    agent_node, agent=context_aware_note_taking_agent, name=\"NoteTaker\"\n",
    ")\n",
    "\n",
    "chart_generating_agent = create_agent(\n",
    "    llm,\n",
    "    [read_document, python_repl],\n",
    "    \"You are a data viz expert tasked with generating charts for a research project.\"\n",
    "    \"{current_files}\",\n",
    ")\n",
    "context_aware_chart_generating_agent = prelude | chart_generating_agent\n",
    "chart_generating_node = functools.partial(\n",
    "    agent_node, agent=context_aware_note_taking_agent, name=\"ChartGenerator\"\n",
    ")\n",
    "\n",
    "doc_writing_supervisor = create_team_supervisor(\n",
    "    llm,\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {team_members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\",\n",
    "    [\"DocWriter\", \"NoteTaker\", \"ChartGenerator\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee2cd9b-29aa-458e-903d-4e49179e5d59",
   "metadata": {},
   "source": [
    "With the objects themselves created, we can form the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c5c644f-8966-4d2e-98d2-80d73520e9fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:53.693123Z",
     "start_time": "2024-05-15T08:19:53.678906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the graph here:\n",
    "# Note that we have unrolled the loop for the sake of this doc\n",
    "authoring_graph = StateGraph(DocWritingState)\n",
    "authoring_graph.add_node(\"DocWriter\", doc_writing_node)\n",
    "authoring_graph.add_node(\"NoteTaker\", note_taking_node)\n",
    "authoring_graph.add_node(\"ChartGenerator\", chart_generating_node)\n",
    "authoring_graph.add_node(\"supervisor\", doc_writing_supervisor)\n",
    "\n",
    "# Add the edges that always occur\n",
    "authoring_graph.add_edge(\"DocWriter\", \"supervisor\")\n",
    "authoring_graph.add_edge(\"NoteTaker\", \"supervisor\")\n",
    "authoring_graph.add_edge(\"ChartGenerator\", \"supervisor\")\n",
    "\n",
    "# Add the edges where routing applies\n",
    "authoring_graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\n",
    "        \"DocWriter\": \"DocWriter\",\n",
    "        \"NoteTaker\": \"NoteTaker\",\n",
    "        \"ChartGenerator\": \"ChartGenerator\",\n",
    "        \"FINISH\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "authoring_graph.set_entry_point(\"supervisor\")\n",
    "chain = authoring_graph.compile()\n",
    "\n",
    "\n",
    "# The following functions interoperate between the top level graph state\n",
    "# and the state of the research sub-graph\n",
    "# this makes it so that the states of each graph don't get intermixed\n",
    "def enter_chain(message: str, members: List[str]):\n",
    "    results = {\n",
    "        \"messages\": [HumanMessage(content=message)],\n",
    "        \"team_members\": \", \".join(members),\n",
    "    }\n",
    "    return results\n",
    "\n",
    "\n",
    "# We reuse the enter/exit functions to wrap the graph\n",
    "authoring_chain = (\n",
    "    functools.partial(enter_chain, members=authoring_graph.nodes)\n",
    "    | authoring_graph.compile()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58e7d1e48a9c39a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:32:13.913188Z",
     "start_time": "2024-05-15T08:32:11.598993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(chain.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9860fd46-c24d-40a5-a6ba-e8fddcd43369",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:53.723467Z",
     "start_time": "2024-05-15T08:19:53.709307Z"
    }
   },
   "outputs": [],
   "source": [
    "for s in authoring_chain.stream(\n",
    "    \"Write an outline for poem and then write the poem to disk.\",\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5b08d-9a9a-474a-94b4-f7aaa8ff19e6",
   "metadata": {},
   "source": [
    "## Add Layers\n",
    "\n",
    "In this design, we are enforcing a top-down planning policy. We've created two graphs already, but we have to decide how to route work between the two.\n",
    "\n",
    "We'll create a _third_ graph to orchestrate the previous two, and add some connectors to define how this top-level state is shared between the different graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95ae7e52-92ed-41a3-88c4-21b6d7c8b041",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:55.454047Z",
     "start_time": "2024-05-15T08:19:53.725466Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-1106-preview\")\n",
    "\n",
    "supervisor_node = create_team_supervisor(\n",
    "    llm,\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following teams: {team_members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\",\n",
    "    [\"Research team\", \"Paper writing team\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4880e573-612f-4d24-97c1-2079382a4a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:55.469348Z",
     "start_time": "2024-05-15T08:19:55.455831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Top-level graph state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "\n",
    "def get_last_message(state: State) -> str:\n",
    "    return state[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "def join_graph(response: dict):\n",
    "    return {\"messages\": [response[\"messages\"][-1]]}\n",
    "\n",
    "\n",
    "# Define the graph.\n",
    "super_graph = StateGraph(State)\n",
    "# First add the nodes, which will do the work\n",
    "super_graph.add_node(\"Research team\", get_last_message | research_chain | join_graph)\n",
    "super_graph.add_node(\n",
    "    \"Paper writing team\", get_last_message | authoring_chain | join_graph\n",
    ")\n",
    "super_graph.add_node(\"supervisor\", supervisor_node)\n",
    "\n",
    "# Define the graph connections, which controls how the logic\n",
    "# propagates through the program\n",
    "super_graph.add_edge(\"Research team\", \"supervisor\")\n",
    "super_graph.add_edge(\"Paper writing team\", \"supervisor\")\n",
    "super_graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\n",
    "        \"Paper writing team\": \"Paper writing team\",\n",
    "        \"Research team\": \"Research team\",\n",
    "        \"FINISH\": END,\n",
    "    },\n",
    ")\n",
    "super_graph.set_entry_point(\"supervisor\")\n",
    "super_graph = super_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "270ff3ae26cd42ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:32:33.694459Z",
     "start_time": "2024-05-15T08:32:31.524790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(super_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8badbf-d728-44bd-a2a7-5b4e587c92fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:55.796497Z",
     "start_time": "2024-05-15T08:19:55.796497Z"
    }
   },
   "outputs": [],
   "source": [
    "for s in super_graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Write a brief research report on the North American sturgeon. Include a chart.\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    {\"recursion_limit\": 150},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

================
File: index.html
================
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/x-icon" href="/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="Content-Security-Policy" content="script-src 'self' 'unsafe-inline';" />
    <title>Electron + Vite + React</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>

================
File: LICENSE
================
MIT License

Copyright (c) 2023 草鞋没号

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================
File: multi_agent_collaboration.ipynb
================
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334",
   "metadata": {
    "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334"
   },
   "source": [
    "# Basic Multi-agent Collaboration\n",
    "\n",
    "This is an example accessed directly from [LangChain](https://www.langchain.com/) under the MIT License. All rights and credit go to the LangChain team. This example is being accessed for educational purposes only.\n",
    "\n",
    "A single agent can usually operate effectively using a handful of tools within a single domain, but even using powerful models like `gpt-4`, it can be less effective at using many tools.\n",
    "\n",
    "One way to approach complicated tasks is through a \"divide-and-conquer\" approach: create a specialized agent for each task or domain and route tasks to the correct \"expert\".\n",
    "\n",
    "This notebook (inspired by the paper [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/abs/2308.08155), by Wu, et. al.) shows one way to do this using LangGraph.\n",
    "\n",
    "Before we get started, a quick note: this and other multi-agent notebooks are designed to show _how_ you can implement certain design patterns in LangGraph. If the pattern suits your needs, we recommend combining it with some of the other fundamental patterns described elsewhere in the docs for best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "743c19df-6da9-4d1e-b2d2-ea40080b9fdc",
   "metadata": {
    "id": "743c19df-6da9-4d1e-b2d2-ea40080b9fdc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "_set_if_undefined(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4344a7-21df-4d54-90d2-9d19b3416ffb",
   "metadata": {
    "id": "5e4344a7-21df-4d54-90d2-9d19b3416ffb"
   },
   "source": [
    "## Create Agents\n",
    "\n",
    "The following helper functions will help create agents. These agents will then be nodes in the graph.\n",
    "\n",
    "You can skip ahead if you just want to see what the graph looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4325a10e-38dc-4a98-9004-e1525eaba377",
   "metadata": {
    "id": "4325a10e-38dc-4a98-9004-e1525eaba377"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    ToolMessage,\n",
    "    HumanMessage,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "\n",
    "def create_agent(llm, tools, system_message: str):\n",
    "    \"\"\"Create an agent.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are a helpful AI assistant, collaborating with other assistants. Use your provided tool to progress towards answering the question. ONLY make one tool call per execution, and ONLY use your provided tool. If you are unable to fully answer, that's OK, another assistant with a different tool will help where you left off. Execute what you can to make progress. You have access to the following tools: {tool_names}.\\n{system_message}\"\"\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    return prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b40de2-5dd4-4d5b-882e-577210723ff4",
   "metadata": {
    "id": "b4b40de2-5dd4-4d5b-882e-577210723ff4"
   },
   "source": [
    "## Define tools\n",
    "\n",
    "We will also define some tools that our agents will use in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca076f3b-a729-4ca9-8f91-05c2ba58d610",
   "metadata": {
    "id": "ca076f3b-a729-4ca9-8f91-05c2ba58d610"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/sbcddtsn26j7wbzcnj0sz5zw0000gp/T/ipykernel_19752/568887837.py:6: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_tool = TavilySearchResults(max_results=5)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Annotated\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "# Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "repl = PythonREPL()\n",
    "\n",
    "@tool\n",
    "def python_repl(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"]\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b54c0c-0b09-408b-abc5-86308929afb6",
   "metadata": {
    "id": "f1b54c0c-0b09-408b-abc5-86308929afb6"
   },
   "source": [
    "## Create graph\n",
    "\n",
    "Now that we've defined our tools and made some helper functions, will create the individual agents below and tell them how to talk to each other using LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6a8c3c-86a0-46aa-b970-ab070fb787d9",
   "metadata": {
    "id": "0c6a8c3c-86a0-46aa-b970-ab070fb787d9"
   },
   "source": [
    "### Define State\n",
    "\n",
    "We first define the state of the graph. This will just a list of messages, along with a key to track the most recent sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "290c91d4-f6f4-443c-8181-233d39102974",
   "metadata": {
    "id": "290c91d4-f6f4-443c-8181-233d39102974"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "# This defines the object that is passed between each node\n",
    "# in the graph. We will create different nodes for each agent and tool\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    sender: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a283e-ea04-40c1-b792-f9e5f7d81203",
   "metadata": {
    "id": "911a283e-ea04-40c1-b792-f9e5f7d81203"
   },
   "source": [
    "### Define Agent Nodes\n",
    "\n",
    "We now need to define the nodes. First, let's define the nodes for the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b790ca-9cef-4b22-b469-4b1d5d8424d6",
   "metadata": {
    "id": "71b790ca-9cef-4b22-b469-4b1d5d8424d6"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "# Helper function to create a node for a given agent\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass\n",
    "    else:\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        # Since we have a strict workflow, we can\n",
    "        # track the sender so we know who to pass to next.\n",
    "        \"sender\": name,\n",
    "    }\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Research agent and node\n",
    "research_agent = create_agent(\n",
    "    llm,\n",
    "    [tavily_tool],\n",
    "    system_message=\"You provide accurate data for the chart_generator agent to use. DO NOT attempt to generate the chart. You ONLY have access to the tavily_tool. ONLY use this search tool. When you have all of the required data, stop making tool calls and allow the team to continue with the chart_generator agent.\",\n",
    ")\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
    "\n",
    "# chart_generator\n",
    "chart_agent = create_agent(\n",
    "    llm,\n",
    "    [python_repl],\n",
    "    system_message=\"Any charts you display will be visible by the user. Only consider the task completed when you have a well-organized chart displaying all of the data requested. If you cannot create a chart with all of the requested data, allow the team to continue doing research with the Researcer agent. When you have the deliverable, prefix your response with FINAL ANSWER so the team knows to stop.\",\n",
    ")\n",
    "chart_node = functools.partial(agent_node, agent=chart_agent, name=\"chart_generator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c7f1b2-24a3-4340-bcb2-feb22e344fb6",
   "metadata": {
    "id": "71c7f1b2-24a3-4340-bcb2-feb22e344fb6"
   },
   "source": [
    "### Define Tool Node\n",
    "\n",
    "We now define a node to run the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a79c76-5c7c-42f6-91cf-635bc8305804",
   "metadata": {
    "id": "d9a79c76-5c7c-42f6-91cf-635bc8305804"
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tools = [tavily_tool, python_repl]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb30498-dbc4-4b20-980f-da08ebc9da56",
   "metadata": {
    "id": "bcb30498-dbc4-4b20-980f-da08ebc9da56"
   },
   "source": [
    "### Define Edge Logic\n",
    "\n",
    "We can define some of the edge logic that is needed to decide what to do based on results of the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f4b4d37-e8a3-4abb-8d42-eaea26016f35",
   "metadata": {
    "id": "4f4b4d37-e8a3-4abb-8d42-eaea26016f35"
   },
   "outputs": [],
   "source": [
    "# Either agent can decide to end\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "def router(state) -> Literal[\"call_tool\", \"__end__\", \"continue\"]:\n",
    "    # This is the router\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        # The previous agent is invoking a tool\n",
    "        return \"call_tool\"\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        # Any agent decided the work is done\n",
    "        return \"__end__\"\n",
    "    return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9359c34-e191-43a2-a3d4-f2dea636dfd2",
   "metadata": {
    "id": "e9359c34-e191-43a2-a3d4-f2dea636dfd2"
   },
   "source": [
    "### Define the Graph\n",
    "\n",
    "We can now put it all together and define the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dce3901-6ad5-4df5-8528-6e865cf96cb0",
   "metadata": {
    "id": "4dce3901-6ad5-4df5-8528-6e865cf96cb0"
   },
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"Researcher\", research_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "workflow.add_node(\"call_tool\", tool_node)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"Researcher\",\n",
    "    router,\n",
    "    {\"continue\": \"chart_generator\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"chart_generator\",\n",
    "    router,\n",
    "    {\"continue\": \"Researcher\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_tool\",\n",
    "    # Each agent node updates the 'sender' field\n",
    "    # the tool calling node does not, meaning\n",
    "    # this edge will route back to the original agent\n",
    "    # who invoked the tool\n",
    "    lambda x: x[\"sender\"],\n",
    "    {\n",
    "        \"Researcher\": \"Researcher\",\n",
    "        \"chart_generator\": \"chart_generator\",\n",
    "    },\n",
    ")\n",
    "workflow.set_entry_point(\"Researcher\")\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97f8e0eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "97f8e0eb",
    "outputId": "72f1f82a-abb4-4581-c38e-a712497ec621"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9447e7-9ab6-43eb-8ae6-9b52f8ba8425",
   "metadata": {
    "id": "8c9447e7-9ab6-43eb-8ae6-9b52f8ba8425"
   },
   "source": [
    "## Invoke\n",
    "\n",
    "With the graph created, you can invoke it! Let's have it chart some stats for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "176a99b0-b457-45cf-8901-90facaa852da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "176a99b0-b457-45cf-8901-90facaa852da",
    "outputId": "24b9bd63-6fb0-4de2-9e56-0fec0ba53cd8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/sbcddtsn26j7wbzcnj0sz5zw0000gp/T/ipykernel_19752/192370608.py:12: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Researcher': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WfJLvzrExCddBotV71ewQw0m', 'function': {'arguments': '{\"query\":\"United States GDP historical data last 25 years\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 259, 'total_tokens': 285, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BoBNryhiyhz4KCTwejhbZzchjCfa5', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='Researcher', id='run--36708822-0d7a-4c1c-afe3-60095b2ded8d-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'United States GDP historical data last 25 years'}, 'id': 'call_WfJLvzrExCddBotV71ewQw0m', 'type': 'tool_call'}], usage_metadata={'input_tokens': 259, 'output_tokens': 26, 'total_tokens': 285, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'sender': 'Researcher'}}\n",
      "----\n",
      "{'call_tool': {'messages': [ToolMessage(content='[{\"title\": \"United States GDP 1990-2024| Statista\", \"url\": \"https://www.statista.com/statistics/188105/annual-gdp-of-the-united-states-since-1990/\", \"content\": \"Gross domestic product (GDP) refers to the market value of all goods and services produced within a country. Although the United States had the highest Gross Domestic Product (GDP) in the world in 2022, this does not tell us much about the quality of life in any given country. While the United States might have the largest economy, the country that ranked highest in terms of GDP at PPP was Luxembourg, amounting to around 141,333 international dollars per capita. The 20 countries with the largest gross domestic product (GDP) per capita in 2025 (in U.S. dollars) Countries with the largest gross domestic product (GDP) per capita 2025 The 20 countries with the largest gross domestic product (GDP) in 2025 (in billion U.S. dollars) Countries with the largest gross domestic product (GDP) 2025\", \"score\": 0.98549}, {\"title\": \"U.S. GDP Growth Rate | Historical Chart & Data - Macrotrends\", \"url\": \"https://www.macrotrends.net/global-metrics/countries/usa/united-states/gdp-growth-rate\", \"content\": \"U.S. GDP Growth Rate 1961-2025 | MacroTrends U.S. GDP Growth Rate 1961-2025 U.S. gdp growth rate for 2023 was 2.54%, a 0.61% increase from 2022. U.S. gdp growth rate for 2022 was 1.94%, a 3.86% decline from 2021. U.S. gdp growth rate for 2021 was 5.80%, a 8.01% increase from 2020. U.S. gdp growth rate for 2020 was -2.21%, a 4.68% decline from 2019. Annual percentage growth rate of GDP at market prices based on constant local currency. GDP Growth Rate | Name | GDP Growth Rate | | South Asia | 6.353% | | North America | 2.43% | | Name | GDP Growth Rate | | Guinea | 7.062% | | South Africa | 0.602% |\", \"score\": 0.9852}, {\"title\": \"U.S. GDP | Historical Chart & Data - Macrotrends\", \"url\": \"https://www.macrotrends.net/global-metrics/countries/usa/united-states/gdp-gross-domestic-product\", \"content\": \"U.S. GDP 1960-2025 | MacroTrends U.S. GDP 1960-2025 ##### U.S. GDP for 2023 was 27.721 trillion US dollars, a 7.68% increase from 2022. U.S. GDP for 2022 was 25.744 trillion US dollars, a 9.11% increase from 2021. U.S. GDP for 2021 was 23.594 trillion US dollars, a 10.65% increase from 2020. U.S. GDP for 2020 was 21.323 trillion US dollars, a 0.92% decline from 2019. GDP (US $) Image 2: Click on chart icon to view chart Image 3: Click on table icon to view table Image 4: Click on chart icon to view chart Image 5: Click on table icon to view table Image 6: Click on chart icon to view chart Image 7: Click on table icon to view table\", \"score\": 0.98516}, {\"title\": \"US Real GDP Growth Rate by Year - Multpl\", \"url\": \"https://www.multpl.com/us-real-gdp-growth-rate/table/by-year\", \"content\": \"# US Real GDP Growth Rate by Year US Real GDP Growth Rate Per Year. Annual percentage change in US Real GDP, chained 2012 dollars (inflation-adjusted). Source: US Bureau of Economic Analysis US GDP Growth Rate US Real GDP US GDP US Real GDP Per Capita US Inflation Rate Consumer Price Index Source: US Bureau of Economic Analysis US GDP Growth Rate US Real GDP US GDP US Real GDP Per Capita US Inflation Rate Consumer Price Index\", \"score\": 0.98258}, {\"title\": \"Gross Domestic Product (GDP) | FRED | St. Louis Fed\", \"url\": \"https://fred.stlouisfed.org/series/GDP\", \"content\": \"Gross domestic product (GDP), the featured measure of U.S. output, is the market value of the goods and services produced by labor and property located in the United States.For more information, see the Guide to the National Income and Product Accounts of the United States (NIPA) and the Bureau of Economic Analysis. Gross domestic product (GDP), the featured measure of U.S. output, is the market value of the goods and services produced by labor and property located in the United States.For more information, see the Guide to the National Income and Product Accounts of the United States (NIPA) and the Bureau of Economic Analysis.\", \"score\": 0.98123}]', name='tavily_search_results_json', tool_call_id='call_WfJLvzrExCddBotV71ewQw0m', artifact={'query': 'United States GDP historical data last 25 years', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'United States GDP 1990-2024| Statista', 'url': 'https://www.statista.com/statistics/188105/annual-gdp-of-the-united-states-since-1990/', 'content': 'Gross domestic product (GDP) refers to the market value of all goods and services produced within a country. Although the United States had the highest Gross Domestic Product (GDP) in the world in 2022, this does not tell us much about the quality of life in any given country. While the United States might have the largest economy, the country that ranked highest in terms of GDP at PPP was Luxembourg, amounting to around 141,333 international dollars per capita. The 20 countries with the largest gross domestic product (GDP) per capita in 2025 (in U.S. dollars) Countries with the largest gross domestic product (GDP) per capita 2025 The 20 countries with the largest gross domestic product (GDP) in 2025 (in billion U.S. dollars) Countries with the largest gross domestic product (GDP) 2025', 'score': 0.98549, 'raw_content': None}, {'title': 'U.S. GDP Growth Rate | Historical Chart & Data - Macrotrends', 'url': 'https://www.macrotrends.net/global-metrics/countries/usa/united-states/gdp-growth-rate', 'content': 'U.S. GDP Growth Rate 1961-2025 | MacroTrends U.S. GDP Growth Rate 1961-2025 U.S. gdp growth rate for 2023 was 2.54%, a 0.61% increase from 2022. U.S. gdp growth rate for 2022 was 1.94%, a 3.86% decline from 2021. U.S. gdp growth rate for 2021 was 5.80%, a 8.01% increase from 2020. U.S. gdp growth rate for 2020 was -2.21%, a 4.68% decline from 2019. Annual percentage growth rate of GDP at market prices based on constant local currency. GDP Growth Rate | Name | GDP Growth Rate | | South Asia | 6.353% | | North America | 2.43% | | Name | GDP Growth Rate | | Guinea | 7.062% | | South Africa | 0.602% |', 'score': 0.9852, 'raw_content': None}, {'url': 'https://www.macrotrends.net/global-metrics/countries/usa/united-states/gdp-gross-domestic-product', 'title': 'U.S. GDP | Historical Chart & Data - Macrotrends', 'content': 'U.S. GDP 1960-2025 | MacroTrends U.S. GDP 1960-2025 ##### U.S. GDP for 2023 was 27.721 trillion US dollars, a 7.68% increase from 2022. U.S. GDP for 2022 was 25.744 trillion US dollars, a 9.11% increase from 2021. U.S. GDP for 2021 was 23.594 trillion US dollars, a 10.65% increase from 2020. U.S. GDP for 2020 was 21.323 trillion US dollars, a 0.92% decline from 2019. GDP (US $) Image 2: Click on chart icon to view chart Image 3: Click on table icon to view table Image 4: Click on chart icon to view chart Image 5: Click on table icon to view table Image 6: Click on chart icon to view chart Image 7: Click on table icon to view table', 'score': 0.98516, 'raw_content': None}, {'title': 'US Real GDP Growth Rate by Year - Multpl', 'url': 'https://www.multpl.com/us-real-gdp-growth-rate/table/by-year', 'content': '# US Real GDP Growth Rate by Year US Real GDP Growth Rate Per Year. Annual percentage change in US Real GDP, chained 2012 dollars (inflation-adjusted). Source: US Bureau of Economic Analysis US GDP Growth Rate US Real GDP US GDP US Real GDP Per Capita US Inflation Rate Consumer Price Index Source: US Bureau of Economic Analysis US GDP Growth Rate US Real GDP US GDP US Real GDP Per Capita US Inflation Rate Consumer Price Index', 'score': 0.98258, 'raw_content': None}, {'url': 'https://fred.stlouisfed.org/series/GDP', 'title': 'Gross Domestic Product (GDP) | FRED | St. Louis Fed', 'content': 'Gross domestic product (GDP), the featured measure of U.S. output, is the market value of the goods and services produced by labor and property located in the United States.For more information, see the Guide to the National Income and Product Accounts of the United States (NIPA) and the Bureau of Economic Analysis. Gross domestic product (GDP), the featured measure of U.S. output, is the market value of the goods and services produced by labor and property located in the United States.For more information, see the Guide to the National Income and Product Accounts of the United States (NIPA) and the Bureau of Economic Analysis.', 'score': 0.98123, 'raw_content': None}], 'response_time': 1.32})]}}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/sbcddtsn26j7wbzcnj0sz5zw0000gp/T/ipykernel_19752/192370608.py:12: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Researcher': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4oh1QsVIjuahGqceTrn6kbwJ', 'function': {'arguments': '{\"query\": \"US GDP 1998 to 2022\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_toCyew89NXRqV0uUemLRxiGa', 'function': {'arguments': '{\"query\": \"US GDP 2023\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 1403, 'total_tokens': 1467, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BoBNuJvSEmnr9rGZk8FklXT5DtrQZ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='Researcher', id='run--7216c27f-940f-4582-8179-3f357c0855f3-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'US GDP 1998 to 2022'}, 'id': 'call_4oh1QsVIjuahGqceTrn6kbwJ', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'US GDP 2023'}, 'id': 'call_toCyew89NXRqV0uUemLRxiGa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1403, 'output_tokens': 64, 'total_tokens': 1467, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'sender': 'Researcher'}}\n",
      "----\n",
      "{'call_tool': {'messages': [ToolMessage(content='[{\"title\": \"Table Data - Gross Domestic Product | FRED | St. Louis Fed\", \"url\": \"https://fred.stlouisfed.org/data/gdp\", \"content\": \"| 2017-10-01 | 20037.088 |\\\\n| 2018-01-01 | 20328.553 |\\\\n| 2018-04-01 | 20580.912 |\\\\n| 2018-07-01 | 20798.730 |\\\\n| 2018-10-01 | 20917.867 |\\\\n| 2019-01-01 | 21111.600 |\\\\n| 2019-04-01 | 21397.938 |\\\\n| 2019-07-01 | 21717.171 |\\\\n| 2019-10-01 | 21933.217 |\\\\n| 2020-01-01 | 21727.657 |\\\\n| 2020-04-01 | 19935.444 |\\\\n| 2020-07-01 | 21684.551 |\\\\n| 2020-10-01 | 22068.767 |\\\\n| 2021-01-01 | 22656.793 |\\\\n| 2021-04-01 | 23368.861 |\\\\n| 2021-07-01 | 23921.991 |\\\\n| 2021-10-01 | 24777.038 |\\\\n| 2022-01-01 | 25215.491 | [...] | 1999-10-01 | 9900.169 |\\\\n| 2000-01-01 | 10002.179 |\\\\n| 2000-04-01 | 10247.720 |\\\\n| 2000-07-01 | 10318.165 |\\\\n| 2000-10-01 | 10435.744 |\\\\n| 2001-01-01 | 10470.231 |\\\\n| 2001-04-01 | 10599.000 |\\\\n| 2001-07-01 | 10598.020 |\\\\n| 2001-10-01 | 10660.465 |\\\\n| 2002-01-01 | 10783.500 |\\\\n| 2002-04-01 | 10887.460 |\\\\n| 2002-07-01 | 10984.040 |\\\\n| 2002-10-01 | 11061.433 |\\\\n| 2003-01-01 | 11174.129 |\\\\n| 2003-04-01 | 11312.766 |\\\\n| 2003-07-01 | 11566.669 |\\\\n| 2003-10-01 | 11772.234 |\\\\n| 2004-01-01 | 11923.447 | [...] | 2008-10-01 | 14608.209 |\\\\n| 2009-01-01 | 14430.902 |\\\\n| 2009-04-01 | 14381.236 |\\\\n| 2009-07-01 | 14448.882 |\\\\n| 2009-10-01 | 14651.249 |\\\\n| 2010-01-01 | 14764.610 |\\\\n| 2010-04-01 | 14980.193 |\\\\n| 2010-07-01 | 15141.607 |\\\\n| 2010-10-01 | 15309.474 |\\\\n| 2011-01-01 | 15351.448 |\\\\n| 2011-04-01 | 15557.539 |\\\\n| 2011-07-01 | 15647.680 |\\\\n| 2011-10-01 | 15842.259 |\\\\n| 2012-01-01 | 16068.805 |\\\\n| 2012-04-01 | 16207.115 |\\\\n| 2012-07-01 | 16319.541 |\\\\n| 2012-10-01 | 16420.419 |\\\\n| 2013-01-01 | 16648.189 |\", \"score\": 0.76490957}, {\"title\": \"United States real GDP growth rate 1930-2022 - Statista\", \"url\": \"https://www.statista.com/statistics/996758/rea-gdp-growth-united-states-1930-2019/\", \"content\": \"| Year | Real GDP growth compared to previous year |\\\\n| --- | --- |\\\\n| 2022 | 1.9% |\\\\n| 2021 | 5.8% |\\\\n| 2020 | -2.2% |\\\\n| 2019 | 2.5% |\\\\n| 2018 | 3% |\\\\n| 2017 | 2.5% |\\\\n| 2016 | 1.8% |\\\\n| 2015 | 2.9% |\\\\n| 2014 | 2.5% |\\\\n| 2013 | 2.1% |\\\\n| 2012 | 2.3% |\\\\n| 2011 | 1.6% |\\\\n| 2010 | 2.7% |\\\\n| 2009 | -2.6% |\\\\n| 2008 | 0.1% |\\\\n| 2007 | 2% |\\\\n| 2006 | 2.8% |\\\\n| 2005 | 3.5% |\\\\n| 2004 | 3.9% |\\\\n| 2003 | 2.8% |\\\\n| 2002 | 1.7% |\\\\n| 2001 | 1% |\\\\n| 2000 | 4.1% |\\\\n| 1999 | 4.8% |\\\\n| 1998 | 4.5% |\\\\n| 1997 | 4.4% |\\\\n| 1996 | 3.8% |\", \"score\": 0.72977066}, {\"title\": \"US GDP Yearly Insights: Gross Domestic Product (GDP) | YCharts\", \"url\": \"https://ycharts.com/indicators/us_gdp_yearly\", \"content\": \"| December 31, 2009 | 14.48T |\\\\n| December 31, 2008 | 14.77T |\\\\n| December 31, 2007 | 14.47T |\\\\n| December 31, 2006 | 13.82T |\\\\n| December 31, 2005 | 13.04T |\\\\n| December 31, 2004 | 12.22T |\\\\n| December 31, 2003 | 11.46T |\\\\n| December 31, 2002 | 10.93T |\\\\n| December 31, 2001 | 10.58T |\\\\n| December 31, 2000 | 10.25T | [...] | Date | Value |\\\\n| --- | --- |\\\\n| December 31, 2024 | 29.18T |\\\\n| December 31, 2023 | 27.72T |\\\\n| December 31, 2022 | 26.01T |\\\\n| December 31, 2021 | 23.68T |\\\\n| December 31, 2020 | 21.35T |\\\\n| December 31, 2019 | 21.54T |\\\\n| December 31, 2018 | 20.66T |\\\\n| December 31, 2017 | 19.61T |\\\\n| December 31, 2016 | 18.80T |\\\\n| December 31, 2015 | 18.30T |\\\\n| December 31, 2014 | 17.61T |\\\\n| December 31, 2013 | 16.88T |\\\\n| December 31, 2012 | 16.25T |\\\\n| December 31, 2011 | 15.60T |\\\\n| December 31, 2010 | 15.05T |\", \"score\": 0.6989468}, {\"title\": \"GDP (Gross Domestic Product) of United States (Past & Current)\", \"url\": \"https://database.earth/economy/united-states/gdp\", \"content\": \"| 2007 | $14,474,226,905,000.0 | 4.8% |\\\\n| 2008 | $14,769,857,911,000.0 | 2.0% |\\\\n| 2009 | $14,478,064,934,000.0 | \\\\\\\\-2.0% |\\\\n| 2010 | $15,048,964,444,000.0 | 3.9% |\\\\n| 2011 | $15,599,728,123,000.0 | 3.7% |\\\\n| 2012 | $16,253,972,230,000.0 | 4.2% |\\\\n| 2013 | $16,843,190,993,000.0 | 3.6% |\\\\n| 2014 | $17,550,680,174,000.0 | 4.2% |\\\\n| 2015 | $18,206,020,741,000.0 | 3.7% |\\\\n| 2016 | $18,695,110,842,000.0 | 2.7% |\\\\n| 2017 | $19,477,336,549,000.0 | 4.2% |\\\\n| 2018 | $20,533,057,312,000.0 | 5.4% | [...] | 2019 | $21,380,976,119,000.0 | 4.1% |\\\\n| 2020 | $21,060,473,613,000.0 | \\\\\\\\-1.5% |\\\\n| 2021 | $23,315,080,560,000.0 | 10.7% |\\\\n| 2022 | $25,439,700,000,000.0 | 9.1% | [...] | 1995 | $7,639,749,000,000.0 | 4.8% |\\\\n| 1996 | $8,073,122,000,000.0 | 5.7% |\\\\n| 1997 | $8,577,554,457,000.0 | 6.2% |\\\\n| 1998 | $9,062,818,202,000.0 | 5.7% |\\\\n| 1999 | $9,631,174,489,000.0 | 6.3% |\\\\n| 2000 | $10,250,947,997,000.0 | 6.4% |\\\\n| 2001 | $10,581,929,774,000.0 | 3.2% |\\\\n| 2002 | $10,929,112,955,000.0 | 3.3% |\\\\n| 2003 | $11,456,442,041,000.0 | 4.8% |\\\\n| 2004 | $12,217,193,198,000.0 | 6.6% |\\\\n| 2005 | $13,039,199,193,000.0 | 6.7% |\\\\n| 2006 | $13,815,586,948,000.0 | 6.0% |\", \"score\": 0.68090034}, {\"title\": \"U.S. GDP | Historical Chart & Data - Macrotrends\", \"url\": \"https://www.macrotrends.net/global-metrics/countries/usa/united-states/gdp-gross-domestic-product\", \"content\": \"U.S. GDP for 2022 was 25.744 trillion US dollars, a 9.11% increase from 2021.\\\\n   U.S. GDP for 2021 was 23.594 trillion US dollars, a 10.65% increase from 2020.\\\\n   U.S. GDP for 2020 was 21.323 trillion US dollars, a 0.92% decline from 2019. [...] | Country Rankings |\\\\n| --- |\\\\n| Name | GDP (US $) |\\\\n| United States | $27.721T |\\\\n| China | $17.795T |\\\\n| Germany | $4.456T |\\\\n| Japan | $4.213T |\\\\n| India | $3.550T |\\\\n| United Kingdom | $3.340T |\\\\n| France | $3.031T |\\\\n| Italy | $2.255T |\\\\n| Brazil | $2.174T |\\\\n| Canada | $2.140T |\\\\n| Russia | $2.021T |\\\\n| Mexico | $1.789T |\\\\n| Australia | $1.724T |\\\\n| South Korea | $1.713T |\\\\n| Spain | $1.581T |\\\\n| Indonesia | $1.371T |\\\\n| Netherlands | $1.118T |\\\\n| Turkey | $1.108T |\\\\n| Saudi Arabia | $1.068T |\", \"score\": 0.680136}]', name='tavily_search_results_json', tool_call_id='call_4oh1QsVIjuahGqceTrn6kbwJ', artifact={'query': 'US GDP 1998 to 2022', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://fred.stlouisfed.org/data/gdp', 'title': 'Table Data - Gross Domestic Product | FRED | St. Louis Fed', 'content': '| 2017-10-01 | 20037.088 |\\n| 2018-01-01 | 20328.553 |\\n| 2018-04-01 | 20580.912 |\\n| 2018-07-01 | 20798.730 |\\n| 2018-10-01 | 20917.867 |\\n| 2019-01-01 | 21111.600 |\\n| 2019-04-01 | 21397.938 |\\n| 2019-07-01 | 21717.171 |\\n| 2019-10-01 | 21933.217 |\\n| 2020-01-01 | 21727.657 |\\n| 2020-04-01 | 19935.444 |\\n| 2020-07-01 | 21684.551 |\\n| 2020-10-01 | 22068.767 |\\n| 2021-01-01 | 22656.793 |\\n| 2021-04-01 | 23368.861 |\\n| 2021-07-01 | 23921.991 |\\n| 2021-10-01 | 24777.038 |\\n| 2022-01-01 | 25215.491 | [...] | 1999-10-01 | 9900.169 |\\n| 2000-01-01 | 10002.179 |\\n| 2000-04-01 | 10247.720 |\\n| 2000-07-01 | 10318.165 |\\n| 2000-10-01 | 10435.744 |\\n| 2001-01-01 | 10470.231 |\\n| 2001-04-01 | 10599.000 |\\n| 2001-07-01 | 10598.020 |\\n| 2001-10-01 | 10660.465 |\\n| 2002-01-01 | 10783.500 |\\n| 2002-04-01 | 10887.460 |\\n| 2002-07-01 | 10984.040 |\\n| 2002-10-01 | 11061.433 |\\n| 2003-01-01 | 11174.129 |\\n| 2003-04-01 | 11312.766 |\\n| 2003-07-01 | 11566.669 |\\n| 2003-10-01 | 11772.234 |\\n| 2004-01-01 | 11923.447 | [...] | 2008-10-01 | 14608.209 |\\n| 2009-01-01 | 14430.902 |\\n| 2009-04-01 | 14381.236 |\\n| 2009-07-01 | 14448.882 |\\n| 2009-10-01 | 14651.249 |\\n| 2010-01-01 | 14764.610 |\\n| 2010-04-01 | 14980.193 |\\n| 2010-07-01 | 15141.607 |\\n| 2010-10-01 | 15309.474 |\\n| 2011-01-01 | 15351.448 |\\n| 2011-04-01 | 15557.539 |\\n| 2011-07-01 | 15647.680 |\\n| 2011-10-01 | 15842.259 |\\n| 2012-01-01 | 16068.805 |\\n| 2012-04-01 | 16207.115 |\\n| 2012-07-01 | 16319.541 |\\n| 2012-10-01 | 16420.419 |\\n| 2013-01-01 | 16648.189 |', 'score': 0.76490957, 'raw_content': None}, {'url': 'https://www.statista.com/statistics/996758/rea-gdp-growth-united-states-1930-2019/', 'title': 'United States real GDP growth rate 1930-2022 - Statista', 'content': '| Year | Real GDP growth compared to previous year |\\n| --- | --- |\\n| 2022 | 1.9% |\\n| 2021 | 5.8% |\\n| 2020 | -2.2% |\\n| 2019 | 2.5% |\\n| 2018 | 3% |\\n| 2017 | 2.5% |\\n| 2016 | 1.8% |\\n| 2015 | 2.9% |\\n| 2014 | 2.5% |\\n| 2013 | 2.1% |\\n| 2012 | 2.3% |\\n| 2011 | 1.6% |\\n| 2010 | 2.7% |\\n| 2009 | -2.6% |\\n| 2008 | 0.1% |\\n| 2007 | 2% |\\n| 2006 | 2.8% |\\n| 2005 | 3.5% |\\n| 2004 | 3.9% |\\n| 2003 | 2.8% |\\n| 2002 | 1.7% |\\n| 2001 | 1% |\\n| 2000 | 4.1% |\\n| 1999 | 4.8% |\\n| 1998 | 4.5% |\\n| 1997 | 4.4% |\\n| 1996 | 3.8% |', 'score': 0.72977066, 'raw_content': None}, {'title': 'US GDP Yearly Insights: Gross Domestic Product (GDP) | YCharts', 'url': 'https://ycharts.com/indicators/us_gdp_yearly', 'content': '| December 31, 2009 | 14.48T |\\n| December 31, 2008 | 14.77T |\\n| December 31, 2007 | 14.47T |\\n| December 31, 2006 | 13.82T |\\n| December 31, 2005 | 13.04T |\\n| December 31, 2004 | 12.22T |\\n| December 31, 2003 | 11.46T |\\n| December 31, 2002 | 10.93T |\\n| December 31, 2001 | 10.58T |\\n| December 31, 2000 | 10.25T | [...] | Date | Value |\\n| --- | --- |\\n| December 31, 2024 | 29.18T |\\n| December 31, 2023 | 27.72T |\\n| December 31, 2022 | 26.01T |\\n| December 31, 2021 | 23.68T |\\n| December 31, 2020 | 21.35T |\\n| December 31, 2019 | 21.54T |\\n| December 31, 2018 | 20.66T |\\n| December 31, 2017 | 19.61T |\\n| December 31, 2016 | 18.80T |\\n| December 31, 2015 | 18.30T |\\n| December 31, 2014 | 17.61T |\\n| December 31, 2013 | 16.88T |\\n| December 31, 2012 | 16.25T |\\n| December 31, 2011 | 15.60T |\\n| December 31, 2010 | 15.05T |', 'score': 0.6989468, 'raw_content': None}, {'title': 'GDP (Gross Domestic Product) of United States (Past & Current)', 'url': 'https://database.earth/economy/united-states/gdp', 'content': '| 2007 | $14,474,226,905,000.0 | 4.8% |\\n| 2008 | $14,769,857,911,000.0 | 2.0% |\\n| 2009 | $14,478,064,934,000.0 | \\\\-2.0% |\\n| 2010 | $15,048,964,444,000.0 | 3.9% |\\n| 2011 | $15,599,728,123,000.0 | 3.7% |\\n| 2012 | $16,253,972,230,000.0 | 4.2% |\\n| 2013 | $16,843,190,993,000.0 | 3.6% |\\n| 2014 | $17,550,680,174,000.0 | 4.2% |\\n| 2015 | $18,206,020,741,000.0 | 3.7% |\\n| 2016 | $18,695,110,842,000.0 | 2.7% |\\n| 2017 | $19,477,336,549,000.0 | 4.2% |\\n| 2018 | $20,533,057,312,000.0 | 5.4% | [...] | 2019 | $21,380,976,119,000.0 | 4.1% |\\n| 2020 | $21,060,473,613,000.0 | \\\\-1.5% |\\n| 2021 | $23,315,080,560,000.0 | 10.7% |\\n| 2022 | $25,439,700,000,000.0 | 9.1% | [...] | 1995 | $7,639,749,000,000.0 | 4.8% |\\n| 1996 | $8,073,122,000,000.0 | 5.7% |\\n| 1997 | $8,577,554,457,000.0 | 6.2% |\\n| 1998 | $9,062,818,202,000.0 | 5.7% |\\n| 1999 | $9,631,174,489,000.0 | 6.3% |\\n| 2000 | $10,250,947,997,000.0 | 6.4% |\\n| 2001 | $10,581,929,774,000.0 | 3.2% |\\n| 2002 | $10,929,112,955,000.0 | 3.3% |\\n| 2003 | $11,456,442,041,000.0 | 4.8% |\\n| 2004 | $12,217,193,198,000.0 | 6.6% |\\n| 2005 | $13,039,199,193,000.0 | 6.7% |\\n| 2006 | $13,815,586,948,000.0 | 6.0% |', 'score': 0.68090034, 'raw_content': None}, {'title': 'U.S. GDP | Historical Chart & Data - Macrotrends', 'url': 'https://www.macrotrends.net/global-metrics/countries/usa/united-states/gdp-gross-domestic-product', 'content': 'U.S. GDP for 2022 was 25.744 trillion US dollars, a 9.11% increase from 2021.\\n   U.S. GDP for 2021 was 23.594 trillion US dollars, a 10.65% increase from 2020.\\n   U.S. GDP for 2020 was 21.323 trillion US dollars, a 0.92% decline from 2019. [...] | Country Rankings |\\n| --- |\\n| Name | GDP (US $) |\\n| United States | $27.721T |\\n| China | $17.795T |\\n| Germany | $4.456T |\\n| Japan | $4.213T |\\n| India | $3.550T |\\n| United Kingdom | $3.340T |\\n| France | $3.031T |\\n| Italy | $2.255T |\\n| Brazil | $2.174T |\\n| Canada | $2.140T |\\n| Russia | $2.021T |\\n| Mexico | $1.789T |\\n| Australia | $1.724T |\\n| South Korea | $1.713T |\\n| Spain | $1.581T |\\n| Indonesia | $1.371T |\\n| Netherlands | $1.118T |\\n| Turkey | $1.108T |\\n| Saudi Arabia | $1.068T |', 'score': 0.680136, 'raw_content': None}], 'response_time': 3.25}), ToolMessage(content='[{\"title\": \"United States GDP - TRADING ECONOMICS\", \"url\": \"https://tradingeconomics.com/united-states/gdp\", \"content\": \"The Gross Domestic Product (GDP) in the United States was worth 27720.71 billion US dollars in 2023, according to official data from the World Bank. The GDP value of the United States represents 26.29 percent of the world economy. source: World Bank [...] | GDP per Capita PPP | 74577.51 | 72841.92 | USD | Dec 2023 | [...] GDP in the United States averaged 8548.23 USD Billion from 1960 until 2023, reaching an all time high of 27720.71 USD Billion in 2023 and a record low of 541.99 USD Billion in 1960. This page provides - United States GDP - actual values, historical data, forecast, chart, statistics, economic calendar and news. United States GDP - values, historical data and charts - was last updated on June of 2025.\", \"score\": 0.9442644}, {\"title\": \"United States (USA) GDP - Gross Domestic Product 2023\", \"url\": \"https://countryeconomy.com/gdp/usa?year=2023\", \"content\": \"The GDP figure in 2023 was €25,629,842$27,720,700 million, United States is the world\\'s leading economy with regard to GDP, as can be seen in the ranking of GDP of the 196 countries that we publish. The absolute value of GDP in United States rose €952,484$1,713,800 million with respect to 2022. [...] The GDP per capita of United States in 2023 was €76,050$82,254, €2,226$4,453 higher than in 2022, it was €73,824$77,801. To view the evolution of the GDP per capita, it is interesting to look back a few years and compare these data with those of 2013 when the GDP per capita in United States was €40,179$53,364. [...] | 2016 | 18,804,900M$ |\\\\n| 2017 | 19,612,100M$ |\\\\n| 2018 | 20,656,500M$ |\\\\n| 2019 | 21,540,000M$ |\\\\n| 2020 | 21,354,100M$ |\\\\n| 2021 | 23,681,200M$ |\\\\n| 2022 | 26,006,900M$ |\\\\n| 2023 | 27,720,700M$ |\", \"score\": 0.9247491}, {\"title\": \"Gross Domestic Product, Fourth Quarter and Year 2023 (Advance Estimate ...\", \"url\": \"https://www.bea.gov/news/2024/gross-domestic-product-fourth-quarter-and-year-2023-advance-estimate\", \"content\": \"Current-dollar GDP increased 6.3 percent, or $1.61 trillion, in 2023 to a level of $27.36 trillion, compared with an increase of 9.1 percent, or $2.15 trillion, in 2022 (tables 1 and 3). [...] Real GDP increased 2.5 percent in 2023 (from the 2022 annual level to the 2023 annual level), compared with an increase of 1.9 percent in 2022 (table 1). The increase in real GDP in 2023 primarily reflected increases in consumer spending, nonresidential fixed investment, state and local government spending, exports, and federal government spending that were partly offset by decreases in residential fixed investment and inventory investment. Imports decreased (table 2). [...] Compared to the third quarter of 2023, the deceleration in real GDP in the fourth quarter primarily reflected slowdowns in private inventory investment, federal government spending, residential fixed investment, and consumer spending. Imports decelerated.\\\\n\\\\nCurrent‑dollar GDP increased 4.8 percent at an annual rate, or $328.7 billion, in the fourth quarter to a level of $27.94 trillion. In the third quarter, GDP increased 8.3 percent, or $547.1 billion (tables 1 and 3).\", \"score\": 0.89324445}, {\"title\": \"U.S. GDP | Historical Chart & Data - Macrotrends\", \"url\": \"https://www.macrotrends.net/global-metrics/countries/usa/united-states/gdp-gross-domestic-product\", \"content\": \"U.S. GDP 1960-2025 | MacroTrends\\\\n\\\\n===============\\\\n\\\\nX\\\\n\\\\nImage 1: Macrotrends Logo\\\\n\\\\nU.S. GDP 1960-2025\\\\n------------------\\\\n\\\\nPopulationEconomyTradeHealthEducationDevelopmentLabor ForceEnvironmentCrimeImmigrationOther\\\\n\\\\nGDPGDP Growth RateGDP Per CapitaDebt to GDPInflation RateManufacturingGNIGNI Per CapitaGNP\\\\n\\\\n##### U.S. GDP for 2023 was 27.721 trillion US dollars, a 7.68% increase from 2022.\", \"score\": 0.8914433}, {\"title\": \"Gross Domestic Product, Fourth Quarter and Year 2023 (Second ...\", \"url\": \"https://www.bea.gov/news/2024/gross-domestic-product-fourth-quarter-and-year-2023-second-estimate\", \"content\": \"Current-dollar GDP increased 6.3 percent, or $1.61 trillion, in 2023 to a level of $27.36 trillion, compared with an increase of 9.1 percent, or\", \"score\": 0.8795718}]', name='tavily_search_results_json', tool_call_id='call_toCyew89NXRqV0uUemLRxiGa', artifact={'query': 'US GDP 2023', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'United States GDP - TRADING ECONOMICS', 'url': 'https://tradingeconomics.com/united-states/gdp', 'content': 'The Gross Domestic Product (GDP) in the United States was worth 27720.71 billion US dollars in 2023, according to official data from the World Bank. The GDP value of the United States represents 26.29 percent of the world economy. source: World Bank [...] | GDP per Capita PPP | 74577.51 | 72841.92 | USD | Dec 2023 | [...] GDP in the United States averaged 8548.23 USD Billion from 1960 until 2023, reaching an all time high of 27720.71 USD Billion in 2023 and a record low of 541.99 USD Billion in 1960. This page provides - United States GDP - actual values, historical data, forecast, chart, statistics, economic calendar and news. United States GDP - values, historical data and charts - was last updated on June of 2025.', 'score': 0.9442644, 'raw_content': None}, {'title': 'United States (USA) GDP - Gross Domestic Product 2023', 'url': 'https://countryeconomy.com/gdp/usa?year=2023', 'content': \"The GDP figure in 2023 was €25,629,842$27,720,700 million, United States is the world's leading economy with regard to GDP, as can be seen in the ranking of GDP of the 196 countries that we publish. The absolute value of GDP in United States rose €952,484$1,713,800 million with respect to 2022. [...] The GDP per capita of United States in 2023 was €76,050$82,254, €2,226$4,453 higher than in 2022, it was €73,824$77,801. To view the evolution of the GDP per capita, it is interesting to look back a few years and compare these data with those of 2013 when the GDP per capita in United States was €40,179$53,364. [...] | 2016 | 18,804,900M$ |\\n| 2017 | 19,612,100M$ |\\n| 2018 | 20,656,500M$ |\\n| 2019 | 21,540,000M$ |\\n| 2020 | 21,354,100M$ |\\n| 2021 | 23,681,200M$ |\\n| 2022 | 26,006,900M$ |\\n| 2023 | 27,720,700M$ |\", 'score': 0.9247491, 'raw_content': None}, {'title': 'Gross Domestic Product, Fourth Quarter and Year 2023 (Advance Estimate ...', 'url': 'https://www.bea.gov/news/2024/gross-domestic-product-fourth-quarter-and-year-2023-advance-estimate', 'content': 'Current-dollar GDP increased 6.3 percent, or $1.61 trillion, in 2023 to a level of $27.36 trillion, compared with an increase of 9.1 percent, or $2.15 trillion, in 2022 (tables 1 and 3). [...] Real GDP increased 2.5 percent in 2023 (from the 2022 annual level to the 2023 annual level), compared with an increase of 1.9 percent in 2022 (table 1). The increase in real GDP in 2023 primarily reflected increases in consumer spending, nonresidential fixed investment, state and local government spending, exports, and federal government spending that were partly offset by decreases in residential fixed investment and inventory investment. Imports decreased (table 2). [...] Compared to the third quarter of 2023, the deceleration in real GDP in the fourth quarter primarily reflected slowdowns in private inventory investment, federal government spending, residential fixed investment, and consumer spending. Imports decelerated.\\n\\nCurrent‑dollar GDP increased 4.8 percent at an annual rate, or $328.7 billion, in the fourth quarter to a level of $27.94 trillion. In the third quarter, GDP increased 8.3 percent, or $547.1 billion (tables 1 and 3).', 'score': 0.89324445, 'raw_content': None}, {'url': 'https://www.macrotrends.net/global-metrics/countries/usa/united-states/gdp-gross-domestic-product', 'title': 'U.S. GDP | Historical Chart & Data - Macrotrends', 'content': 'U.S. GDP 1960-2025 | MacroTrends\\n\\n===============\\n\\nX\\n\\nImage 1: Macrotrends Logo\\n\\nU.S. GDP 1960-2025\\n------------------\\n\\nPopulationEconomyTradeHealthEducationDevelopmentLabor ForceEnvironmentCrimeImmigrationOther\\n\\nGDPGDP Growth RateGDP Per CapitaDebt to GDPInflation RateManufacturingGNIGNI Per CapitaGNP\\n\\n##### U.S. GDP for 2023 was 27.721 trillion US dollars, a 7.68% increase from 2022.', 'score': 0.8914433, 'raw_content': None}, {'url': 'https://www.bea.gov/news/2024/gross-domestic-product-fourth-quarter-and-year-2023-second-estimate', 'title': 'Gross Domestic Product, Fourth Quarter and Year 2023 (Second ...', 'content': 'Current-dollar GDP increased 6.3 percent, or $1.61 trillion, in 2023 to a level of $27.36 trillion, compared with an increase of 9.1 percent, or', 'score': 0.8795718, 'raw_content': None}], 'response_time': 2.46})]}}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/sbcddtsn26j7wbzcnj0sz5zw0000gp/T/ipykernel_19752/192370608.py:12: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Researcher': {'messages': [AIMessage(content='I have gathered the GDP data for the United States over the last 25 years. Here are the GDP values in trillions of USD:\\n\\n- **1998**: 9.062\\n- **1999**: 9.631\\n- **2000**: 10.251\\n- **2001**: 10.582\\n- **2002**: 10.929\\n- **2003**: 11.456\\n- **2004**: 12.217\\n- **2005**: 13.039\\n- **2006**: 13.816\\n- **2007**: 14.477\\n- **2008**: 14.770\\n- **2009**: 14.478\\n- **2010**: 15.049\\n- **2011**: 15.600\\n- **2012**: 16.254\\n- **2013**: 16.843\\n- **2014**: 17.551\\n- **2015**: 18.206\\n- **2016**: 18.695\\n- **2017**: 19.477\\n- **2018**: 20.533\\n- **2019**: 21.381\\n- **2020**: 21.354\\n- **2021**: 23.681\\n- **2022**: 26.007\\n- **2023**: 27.721\\n\\nWith this data, the next step would be to generate a bar graph with red bars representing the GDP values for these years. \\n\\nI will now pass the data to the chart_generator agent for the creation of the graph.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 359, 'prompt_tokens': 5611, 'total_tokens': 5970, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BoBNzYdmI3VLiQx5kZhC2Mv6kBVLQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='Researcher', id='run--f618c3bf-1339-4fb3-aef5-5ac8e613633d-0', usage_metadata={'input_tokens': 5611, 'output_tokens': 359, 'total_tokens': 5970, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'sender': 'Researcher'}}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/sbcddtsn26j7wbzcnj0sz5zw0000gp/T/ipykernel_19752/192370608.py:12: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chart_generator': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_nHtsAppOXTxLeR30ja5d5SeU', 'function': {'arguments': '{\"code\":\"import matplotlib.pyplot as plt\\\\n\\\\n# Years and corresponding GDP values in trillions\\\\nyears = [1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\\\\ngdp_values = [9.062, 9.631, 10.251, 10.582, 10.929, 11.456, 12.217, 13.039, 13.816, 14.477, 14.770, 14.478, 15.049, 15.600, 16.254, 16.843, 17.551, 18.206, 18.695, 19.477, 20.533, 21.381, 21.354, 23.681, 26.007, 27.721]\\\\n\\\\n# Create a bar graph\\\\nplt.figure(figsize=(12,6))\\\\nplt.bar(years, gdp_values, color=\\'red\\')\\\\nplt.title(\\'United States GDP Over the Past 25 Years\\')\\\\nplt.xlabel(\\'Year\\')\\\\nplt.ylabel(\\'GDP in Trillions of USD\\')\\\\nplt.xticks(years, rotation=45)\\\\nplt.grid(axis=\\'y\\')\\\\n\\\\n# Show the chart\\\\nplt.tight_layout()\\\\nplt.show()\"}', 'name': 'python_repl'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 372, 'prompt_tokens': 5997, 'total_tokens': 6369, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-BoBO6ys4QIwpXZGh0a7YE35YyraE3', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='chart_generator', id='run--286ffa76-31e7-4a3a-93d5-4ab8995a8d36-0', tool_calls=[{'name': 'python_repl', 'args': {'code': \"import matplotlib.pyplot as plt\\n\\n# Years and corresponding GDP values in trillions\\nyears = [1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\\ngdp_values = [9.062, 9.631, 10.251, 10.582, 10.929, 11.456, 12.217, 13.039, 13.816, 14.477, 14.770, 14.478, 15.049, 15.600, 16.254, 16.843, 17.551, 18.206, 18.695, 19.477, 20.533, 21.381, 21.354, 23.681, 26.007, 27.721]\\n\\n# Create a bar graph\\nplt.figure(figsize=(12,6))\\nplt.bar(years, gdp_values, color='red')\\nplt.title('United States GDP Over the Past 25 Years')\\nplt.xlabel('Year')\\nplt.ylabel('GDP in Trillions of USD')\\nplt.xticks(years, rotation=45)\\nplt.grid(axis='y')\\n\\n# Show the chart\\nplt.tight_layout()\\nplt.show()\"}, 'id': 'call_nHtsAppOXTxLeR30ja5d5SeU', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5997, 'output_tokens': 372, 'total_tokens': 6369, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'sender': 'chart_generator'}}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'call_tool': {'messages': [ToolMessage(content=\"Successfully executed:\\n```python\\nimport matplotlib.pyplot as plt\\n\\n# Years and corresponding GDP values in trillions\\nyears = [1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\\ngdp_values = [9.062, 9.631, 10.251, 10.582, 10.929, 11.456, 12.217, 13.039, 13.816, 14.477, 14.770, 14.478, 15.049, 15.600, 16.254, 16.843, 17.551, 18.206, 18.695, 19.477, 20.533, 21.381, 21.354, 23.681, 26.007, 27.721]\\n\\n# Create a bar graph\\nplt.figure(figsize=(12,6))\\nplt.bar(years, gdp_values, color='red')\\nplt.title('United States GDP Over the Past 25 Years')\\nplt.xlabel('Year')\\nplt.ylabel('GDP in Trillions of USD')\\nplt.xticks(years, rotation=45)\\nplt.grid(axis='y')\\n\\n# Show the chart\\nplt.tight_layout()\\nplt.show()\\n```\\nStdout: \\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\", name='python_repl', tool_call_id='call_nHtsAppOXTxLeR30ja5d5SeU')]}}\n",
      "----\n",
      "{'chart_generator': {'messages': [AIMessage(content=\"FINAL ANSWER\\n\\nI have created the bar graph displaying the United States' GDP over the past 25 years. The bars are colored red. Please take a look at the chart above.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 6747, 'total_tokens': 6786, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 5888}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-BoBONdeOuzL2x1pfrzDVjh920qxS9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='chart_generator', id='run--5a5eecc1-5d0a-4b07-b7d4-e8e0a3e67ed2-0', usage_metadata={'input_tokens': 6747, 'output_tokens': 39, 'total_tokens': 6786, 'input_token_details': {'audio': 0, 'cache_read': 5888}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'sender': 'chart_generator'}}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/sbcddtsn26j7wbzcnj0sz5zw0000gp/T/ipykernel_19752/192370608.py:12: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Fetch the United State's GDP over the past 25 years,\"\n",
    "                \" then chart a bar graph with red bars of it.\"\n",
    "                \" Once the chart is displayed to the user, finish.\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 25},\n",
    ")\n",
    "for s in events:\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dcc5d3-34e8-4fa4-b177-1b9dff25119b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec204c-d1f8-40d3-ac8a-288046b04602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573baaec-3c5a-4258-9534-20d1e61b54ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

================
File: postcss.config.cjs
================
module.exports = {
  plugins: {
    'postcss-import': {},
    'tailwindcss/nesting': {},
    tailwindcss: {},
    autoprefixer: {},
  },
}

================
File: README.md
================
# electron-vite-react

[![awesome-vite](https://awesome.re/mentioned-badge.svg)](https://github.com/vitejs/awesome-vite)
![GitHub stars](https://img.shields.io/github/stars/caoxiemeihao/vite-react-electron?color=fa6470)
![GitHub issues](https://img.shields.io/github/issues/caoxiemeihao/vite-react-electron?color=d8b22d)
![GitHub license](https://img.shields.io/github/license/caoxiemeihao/vite-react-electron)
[![Required Node.JS >= 14.18.0 || >=16.0.0](https://img.shields.io/static/v1?label=node&message=14.18.0%20||%20%3E=16.0.0&logo=node.js&color=3f893e)](https://nodejs.org/about/releases)

English | [简体中文](README.zh-CN.md)

## 👀 Overview

📦 Ready out of the box  
🎯 Based on the official [template-react-ts](https://github.com/vitejs/vite/tree/main/packages/create-vite/template-react-ts), project structure will be familiar to you  
🌱 Easily extendable and customizable  
💪 Supports Node.js API in the renderer process  
🔩 Supports C/C++ native addons  
🐞 Debugger configuration included  
🖥 Easy to implement multiple windows  

## 🛫 Quick Setup

```sh
# clone the project
git clone https://github.com/electron-vite/electron-vite-react.git

# enter the project directory
cd electron-vite-react

# install dependency
npm install

# develop
npm run dev
```

## 🐞 Debug

![electron-vite-react-debug.gif](/electron-vite-react-debug.gif)

## 📂 Directory structure

Familiar React application structure, just with `electron` folder on the top :wink:  
*Files in this folder will be separated from your React application and built into `dist-electron`*  

```tree
├── electron                                 Electron-related code
│   ├── main                                 Main-process source code
│   └── preload                              Preload-scripts source code
│
├── release                                  Generated after production build, contains executables
│   └── {version}
│       ├── {os}-{os_arch}                   Contains unpacked application executable
│       └── {app_name}_{version}.{ext}       Installer for the application
│
├── public                                   Static assets
└── src                                      Renderer source code, your React application
```

<!--
## 🚨 Be aware

This template integrates Node.js API to the renderer process by default. If you want to follow **Electron Security Concerns** you might want to disable this feature. You will have to expose needed API by yourself.  

To get started, remove the option as shown below. This will [modify the Vite configuration and disable this feature](https://github.com/electron-vite/vite-plugin-electron-renderer#config-presets-opinionated).

```diff
# vite.config.ts

export default {
  plugins: [
    ...
-   // Use Node.js API in the Renderer-process
-   renderer({
-     nodeIntegration: true,
-   }),
    ...
  ],
}
```
-->

## 🔧 Additional features

1. electron-updater 👉 [see docs](src/components/update/README.md)
1. playwright

## ❔ FAQ

- [C/C++ addons, Node.js modules - Pre-Bundling](https://github.com/electron-vite/vite-plugin-electron-renderer#dependency-pre-bundling)
- [dependencies vs devDependencies](https://github.com/electron-vite/vite-plugin-electron-renderer#dependencies-vs-devdependencies)

================
File: README.zh-CN.md
================
# vite-react-electron

[![awesome-vite](https://awesome.re/mentioned-badge.svg)](https://github.com/vitejs/awesome-vite)
![GitHub stars](https://img.shields.io/github/stars/caoxiemeihao/vite-react-electron?color=fa6470)
![GitHub issues](https://img.shields.io/github/issues/caoxiemeihao/vite-react-electron?color=d8b22d)
![GitHub license](https://img.shields.io/github/license/caoxiemeihao/vite-react-electron)
[![Required Node.JS >= 14.18.0 || >=16.0.0](https://img.shields.io/static/v1?label=node&message=14.18.0%20||%20%3E=16.0.0&logo=node.js&color=3f893e)](https://nodejs.org/about/releases)

[English](README.md) | 简体中文

## 概述

📦 开箱即用  
🎯 基于官方的 [template-react-ts](https://github.com/vitejs/vite/tree/main/packages/create-vite/template-react-ts), 低侵入性  
🌱 结构清晰，可塑性强  
💪 支持在渲染进程中使用 Electron、Node.js API  
🔩 支持 C/C++ 模块  
🖥 很容易实现多窗口  

## 快速开始

```sh
# clone the project
git clone https://github.com/electron-vite/electron-vite-react.git

# enter the project directory
cd electron-vite-react

# install dependency
npm install

# develop
npm run dev
```

## 调试

![electron-vite-react-debug.gif](/electron-vite-react-debug.gif)

## 目录

*🚨 默认情况下, `electron` 文件夹下的文件将会被构建到 `dist-electron`*

```tree
├── electron                                 Electron 源码文件夹
│   ├── main                                 Main-process 源码
│   └── preload                              Preload-scripts 源码
│
├── release                                  构建后生成程序目录
│   └── {version}
│       ├── {os}-{os_arch}                   未打包的程序(绿色运行版)
│       └── {app_name}_{version}.{ext}       应用安装文件
│
├── public                                   同 Vite 模板的 public
└── src                                      渲染进程源码、React代码
```

<!--
## 🚨 这需要留神

默认情况下，该模板在渲染进程中集成了 Node.js，如果你不需要它，你只需要删除下面的选项. [因为它会修改 Vite 默认的配置](https://github.com/electron-vite/vite-plugin-electron-renderer#config-presets-opinionated).

```diff
# vite.config.ts

export default {
  plugins: [
    ...
-   // Use Node.js API in the Renderer-process
-   renderer({
-     nodeIntegration: true,
-   }),
    ...
  ],
}
```
-->

## 🔧 额外的功能

1. Electron 自动更新 👉 [阅读文档](src/components/update/README.zh-CN.md)
2. Playwright 测试

## ❔ FAQ

- [C/C++ addons, Node.js modules - Pre-Bundling](https://github.com/electron-vite/vite-plugin-electron-renderer#dependency-pre-bundling)
- [dependencies vs devDependencies](https://github.com/electron-vite/vite-plugin-electron-renderer#dependencies-vs-devdependencies)

## 🍵 🍰 🍣 🍟

<img width="270" src="https://github.com/caoxiemeihao/blog/blob/main/assets/$qrcode/$.png?raw=true">

================
File: requirements-without-freeze.txt
================
openai
langchain
langchain_core
langchain_openai
langchain_community
langchain_experimental
langgraph
langsmith
pandas
matplotlib
python-dotenv

================
File: requirements.txt
================
aiohappyeyeballs==2.4.2
aiohttp==3.10.8
aiosignal==1.3.1
annotated-types==0.7.0
anyio==4.6.0
attrs==24.2.0
certifi==2024.8.30
charset-normalizer==3.3.2
contourpy==1.3.0
cycler==0.12.1
dataclasses-json==0.6.7
distro==1.9.0
fonttools==4.54.1
frozenlist==1.4.1
h11==0.14.0
httpcore==1.0.5
httpx==0.27.2
idna==3.10
jiter==0.5.0
jsonpatch==1.33
jsonpointer==3.0.0
kiwisolver==1.4.7
langchain==0.3.1
langchain-community==0.3.1
langchain-core==0.3.6
langchain-experimental==0.3.2
langchain-openai==0.2.1
langchain-text-splitters==0.3.0
langgraph==0.2.28
langgraph-checkpoint==1.0.12
langsmith==0.1.129
marshmallow==3.22.0
matplotlib==3.9.2
msgpack==1.1.0
multidict==6.1.0
mypy-extensions==1.0.0
numpy==1.26.4
openai==1.50.2
orjson==3.10.7
packaging==24.1
pandas==2.2.3
pillow==10.4.0
pydantic==2.9.2
pydantic-settings==2.5.2
pydantic_core==2.23.4
pyparsing==3.1.4
python-dateutil==2.9.0.post0
python-dotenv==1.0.1
pytz==2024.2
PyYAML==6.0.2
regex==2024.9.11
requests==2.32.3
six==1.16.0
sniffio==1.3.1
SQLAlchemy==2.0.35
tenacity==8.5.0
tiktoken==0.7.0
tqdm==4.66.5
typing-inspect==0.9.0
typing_extensions==4.12.2
tzdata==2024.2
urllib3==2.2.3
yarl==1.13.1

================
File: tsconfig.node.json
================
{
  "compilerOptions": {
    "composite": true,
    "module": "ESNext",
    "moduleResolution": "Node",
    "resolveJsonModule": true,
    "allowSyntheticDefaultImports": true
  },
  "include": ["vite.config.ts", "package.json"]
}

================
File: electron/main/update.ts
================
import { createRequire } from 'node:module';

import { app, ipcMain } from 'electron';

import type {
  ProgressInfo,
  UpdateDownloadedEvent,
  UpdateInfo,
} from 'electron-updater';

const { autoUpdater } = createRequire(import.meta.url)('electron-updater');

export function update(win: Electron.BrowserWindow) {

  // When set to false, the update download will be triggered through the API
  autoUpdater.autoDownload = false;
  autoUpdater.disableWebInstaller = false;
  autoUpdater.allowDowngrade = false;

  // start check
  autoUpdater.on('checking-for-update', () => { });
  // update available
  autoUpdater.on('update-available', (arg: UpdateInfo) => {
    win.webContents.send('update-can-available', { update: true, version: app.getVersion(), newVersion: arg?.version });
  });
  // update not available
  autoUpdater.on('update-not-available', (arg: UpdateInfo) => {
    win.webContents.send('update-can-available', { update: false, version: app.getVersion(), newVersion: arg?.version });
  });

  // Checking for updates
  ipcMain.handle('check-update', async () => {
    if (!app.isPackaged) {
      const error = new Error('The update feature is only available after the package.');
      return { message: error.message, error };
    }

    try {
      return await autoUpdater.checkForUpdatesAndNotify();
    } catch (error) {
      return { message: 'Network error', error };
    }
  });

  // Start downloading and feedback on progress
  ipcMain.handle('start-download', (event: Electron.IpcMainInvokeEvent) => {
    startDownload(
      (error, progressInfo) => {
        if (error) {
          // feedback download error message
          event.sender.send('update-error', { message: error.message, error });
        } else {
          // feedback update progress message
          event.sender.send('download-progress', progressInfo);
        }
      },
      () => {
        // feedback update downloaded message
        event.sender.send('update-downloaded');
      },
    );
  });

  // Install now
  ipcMain.handle('quit-and-install', () => {
    autoUpdater.quitAndInstall(false, true);
  });
}

function startDownload(
  callback: (error: Error | null, info: ProgressInfo | null) => void,
  complete: (event: UpdateDownloadedEvent) => void,
) {
  autoUpdater.on('download-progress', (info: ProgressInfo) => callback(null, info));
  autoUpdater.on('error', (error: Error) => callback(error, null));
  autoUpdater.on('update-downloaded', complete);
  autoUpdater.downloadUpdate();
}

================
File: src/components/update/Modal/index.tsx
================
import React, { ReactNode } from 'react';
import { createPortal } from 'react-dom';
import './modal.css';

const ModalTemplate: React.FC<React.PropsWithChildren<{
  title?: ReactNode
  footer?: ReactNode
  cancelText?: string
  okText?: string
  onCancel?: () => void
  onOk?: () => void
  width?: number
}>> = props => {
  const {
    title,
    children,
    footer,
    cancelText = 'Cancel',
    okText = 'OK',
    onCancel,
    onOk,
    width = 530,
  } = props;

  return (
    <div className='update-modal'>
      <div className='update-modal__mask' />
      <div className='update-modal__warp'>
        <div className='update-modal__content' style={{ width }}>
          <div className='content__header'>
            <div className='content__header-text'>{title}</div>
            <span
              className='update-modal--close'
              onClick={onCancel}
            >
              <svg
                viewBox="0 0 1024 1024"
                version="1.1" xmlns="http://www.w3.org/2000/svg"
              >
                <path d="M557.312 513.248l265.28-263.904c12.544-12.48 12.608-32.704 0.128-45.248-12.512-12.576-32.704-12.608-45.248-0.128l-265.344 263.936-263.04-263.84C236.64 191.584 216.384 191.52 203.84 204 191.328 216.48 191.296 236.736 203.776 249.28l262.976 263.776L201.6 776.8c-12.544 12.48-12.608 32.704-0.128 45.248 6.24 6.272 14.464 9.44 22.688 9.44 8.16 0 16.32-3.104 22.56-9.312l265.216-263.808 265.44 266.24c6.24 6.272 14.432 9.408 22.656 9.408 8.192 0 16.352-3.136 22.592-9.344 12.512-12.48 12.544-32.704 0.064-45.248L557.312 513.248z" fill="currentColor" />
              </svg>
            </span>
          </div>
          <div className='content__body'>{children}</div>
          {typeof footer !== 'undefined' ? (
            <div className='content__footer'>
              <button onClick={onCancel}>{cancelText}</button>
              <button onClick={onOk}>{okText}</button>
            </div>
          ) : footer}
        </div>
      </div>
    </div>
  );
};

const Modal = (props: Parameters<typeof ModalTemplate>[0] & { open: boolean }) => {
  const { open, ...omit } = props;

  return createPortal(
    open ? ModalTemplate(omit) : null,
    document.body,
  );
};

export default Modal;

================
File: src/components/update/Progress/index.tsx
================
import React from 'react';
import './progress.css';

const Progress: React.FC<React.PropsWithChildren<{
  percent?: number
}>> = props => {
  const { percent = 0 } = props;

  return (
    <div className='update-progress'>
      <div className='update-progress-pr'>
        <div
          className='update-progress-rate'
          style={{ width: `${3 * percent}px` }}
        />
      </div>
      <span className='update-progress-num'>{(percent ?? 0).toString().substring(0, 4)}%</span>
    </div>
  );
};

export default Progress;

================
File: src/components/update/index.tsx
================
import type { ProgressInfo } from 'electron-updater'
import { useCallback, useEffect, useState } from 'react'
import Modal from '@/components/update/Modal'
import Progress from '@/components/update/Progress'
import './update.css'

const Update = () => {
  const [checking, setChecking] = useState(false)
  const [updateAvailable, setUpdateAvailable] = useState(false)
  const [versionInfo, setVersionInfo] = useState<VersionInfo>()
  const [updateError, setUpdateError] = useState<ErrorType>()
  const [progressInfo, setProgressInfo] = useState<Partial<ProgressInfo>>()
  const [modalOpen, setModalOpen] = useState<boolean>(false)
  const [modalBtn, setModalBtn] = useState<{
    cancelText?: string
    okText?: string
    onCancel?: () => void
    onOk?: () => void
  }>({
    onCancel: () => setModalOpen(false),
    onOk: () => window.ipcRenderer.invoke('start-download'),
  })

  const checkUpdate = async () => {
    setChecking(true)
    /**
     * @type {import('electron-updater').UpdateCheckResult | null | { message: string, error: Error }}
     */
    const result = await window.ipcRenderer.invoke('check-update')
    setProgressInfo({ percent: 0 })
    setChecking(false)
    setModalOpen(true)
    if (result?.error) {
      setUpdateAvailable(false)
      setUpdateError(result?.error)
    }
  }

  const onUpdateCanAvailable = useCallback((_event: Electron.IpcRendererEvent, arg1: VersionInfo) => {
    setVersionInfo(arg1)
    setUpdateError(undefined)
    // Can be update
    if (arg1.update) {
      setModalBtn(state => ({
        ...state,
        cancelText: 'Cancel',
        okText: 'Update',
        onOk: () => window.ipcRenderer.invoke('start-download'),
      }))
      setUpdateAvailable(true)
    } else {
      setUpdateAvailable(false)
    }
  }, [])

  const onUpdateError = useCallback((_event: Electron.IpcRendererEvent, arg1: ErrorType) => {
    setUpdateAvailable(false)
    setUpdateError(arg1)
  }, [])

  const onDownloadProgress = useCallback((_event: Electron.IpcRendererEvent, arg1: ProgressInfo) => {
    setProgressInfo(arg1)
  }, [])

  const onUpdateDownloaded = useCallback((_event: Electron.IpcRendererEvent, ..._args: any[]) => {
    setProgressInfo({ percent: 100 })
    setModalBtn(state => ({
      ...state,
      cancelText: 'Later',
      okText: 'Install now',
      onOk: () => window.ipcRenderer.invoke('quit-and-install'),
    }))
  }, [])

  useEffect(() => {
    // Get version information and whether to update
    window.ipcRenderer.on('update-can-available', onUpdateCanAvailable)
    window.ipcRenderer.on('update-error', onUpdateError)
    window.ipcRenderer.on('download-progress', onDownloadProgress)
    window.ipcRenderer.on('update-downloaded', onUpdateDownloaded)

    return () => {
      window.ipcRenderer.off('update-can-available', onUpdateCanAvailable)
      window.ipcRenderer.off('update-error', onUpdateError)
      window.ipcRenderer.off('download-progress', onDownloadProgress)
      window.ipcRenderer.off('update-downloaded', onUpdateDownloaded)
    }
  }, [])

  return (
    <>
      <Modal
        open={modalOpen}
        cancelText={modalBtn.cancelText}
        okText={modalBtn.okText}
        onCancel={modalBtn.onCancel}
        onOk={modalBtn.onOk}
        footer={updateAvailable ? /* hide footer */null : undefined}
      >
        <div className='modal-slot'>
          {updateError
            ? (
              <div>
                <p>Error downloading the latest version.</p>
                <p>{updateError.message}</p>
              </div>
            ) : updateAvailable
              ? (
                <div>
                  <div>The last version is: v{versionInfo?.newVersion}</div>
                  <div className='new-version__target'>v{versionInfo?.version} -&gt; v{versionInfo?.newVersion}</div>
                  <div className='update__progress'>
                    <div className='progress__title'>Update progress:</div>
                    <div className='progress__bar'>
                      <Progress percent={progressInfo?.percent} ></Progress>
                    </div>
                  </div>
                </div>
              )
              : (
                <div className='can-not-available'>{JSON.stringify(versionInfo ?? {}, null, 2)}</div>
              )}
        </div>
      </Modal>
      <button disabled={checking} onClick={checkUpdate}>
        {checking ? 'Checking...' : 'Check update'}
      </button>
    </>
  )
}

export default Update

================
File: src/components/Clock.tsx
================
// Clock.tsx
// This component displays a live-updating clock at the top of the application.
// It uses React hooks to update the time every second and logs lifecycle events.

import { useState, useEffect } from 'react';

/**
 * Clock component that displays the current local time and updates every second.
 * Logs mount, update, and unmount events for debugging.
 */
function Clock() {
  // State to hold the current time string
  const [time, setTime] = useState(() => new Date().toLocaleTimeString());

  useEffect(() => {
    console.log('[Clock] Mounted');
    // Update the time every second
    const intervalId = setInterval(() => {
      const now = new Date();
      setTime(now.toLocaleTimeString());
      console.log(`[Clock] Updated: ${now.toLocaleTimeString()}`);
    }, 1000);
    // Cleanup on unmount
    return () => {
      clearInterval(intervalId);
      console.log('[Clock] Unmounted');
    };
  }, []);

  return (
    <div style={{ width: '100%', textAlign: 'center', fontWeight: 600, fontSize: '1.5em', marginBottom: '1em', letterSpacing: '0.05em' }}>
      🕒 {time}
    </div>
  );
}

export default Clock;

================
File: src/components/PermissionDialog.tsx
================
/**
 * PermissionDialog Component
 * 
 * A modal dialog component for handling microphone permission requests with user-friendly prompts.
 * Provides clear instructions and recovery options when microphone access is denied or unavailable.
 * 
 * Features:
 * - User-friendly permission request dialog
 * - Browser-specific instructions
 * - Troubleshooting steps for common issues
 * - Accessibility features
 * - Recovery actions and retry functionality
 */

import React, { useCallback, useEffect, useState } from 'react';
import { logger } from '../utils/logger';

/**
 * Permission state enumeration
 */
export enum PermissionState {
  UNKNOWN = 'unknown',
  GRANTED = 'granted',
  DENIED = 'denied',
  PROMPT = 'prompt'
}

/**
 * Browser detection for specific instructions
 */
interface BrowserInfo {
  name: string;
  version: string;
  isChrome: boolean;
  isFirefox: boolean;
  isSafari: boolean;
  isEdge: boolean;
}

/**
 * Props interface for PermissionDialog component
 */
interface PermissionDialogProps {
  /** Whether the dialog is open */
  isOpen: boolean;
  /** Callback when permission is granted */
  onPermissionGranted: () => void;
  /** Callback when permission is denied */
  onPermissionDenied: (reason: string) => void;
  /** Callback when dialog is closed */
  onClose: () => void;
  /** Whether to show troubleshooting steps */
  showTroubleshooting?: boolean;
  /** Custom error message to display */
  errorMessage?: string;
}

/**
 * PermissionDialog component for microphone access requests
 */
export const PermissionDialog: React.FC<PermissionDialogProps> = ({
  isOpen,
  onPermissionGranted,
  onPermissionDenied,
  onClose,
  showTroubleshooting = false,
  errorMessage
}) => {
  const [permissionState, setPermissionState] = useState<PermissionState>(PermissionState.UNKNOWN);
  const [isChecking, setIsChecking] = useState(false);
  const [browserInfo, setBrowserInfo] = useState<BrowserInfo | null>(null);
  const [deviceCount, setDeviceCount] = useState<number>(0);

  /**
   * Detect browser information for specific instructions
   */
  const detectBrowser = useCallback((): BrowserInfo => {
    const userAgent = navigator.userAgent;
    
    let name = 'Unknown';
    let version = '';
    let isChrome = false;
    let isFirefox = false;
    let isSafari = false;
    let isEdge = false;

    if (userAgent.includes('Chrome') && !userAgent.includes('Edg')) {
      name = 'Chrome';
      isChrome = true;
      const match = userAgent.match(/Chrome\/(\d+)/);
      version = match?.[1] ?? '';
    } else if (userAgent.includes('Firefox')) {
      name = 'Firefox';
      isFirefox = true;
      const match = userAgent.match(/Firefox\/(\d+)/);
      version = match?.[1] ?? '';
    } else if (userAgent.includes('Safari') && !userAgent.includes('Chrome')) {
      name = 'Safari';
      isSafari = true;
      const match = userAgent.match(/Version\/(\d+)/);
      version = match?.[1] ?? '';
    } else if (userAgent.includes('Edg')) {
      name = 'Edge';
      isEdge = true;
      const match = userAgent.match(/Edg\/(\d+)/);
      version = match?.[1] ?? '';
    }

    logger.debug('🌐 Browser detected', { name, version, userAgent: userAgent.substring(0, 100) });
    
    return { name, version, isChrome, isFirefox, isSafari, isEdge };
  }, []);

  /**
   * Check current microphone permission status
   */
  const checkPermissionStatus = useCallback(async () => {
    try {
      logger.info('🔍 PermissionDialog: Checking microphone permission status');
      
      if (!navigator.permissions) {
        logger.warn('⚠️ Permissions API not supported');
        setPermissionState(PermissionState.UNKNOWN);
        return;
      }

      const permission = await navigator.permissions.query({ name: 'microphone' as PermissionName });
      const state = permission.state as PermissionState;
      
      logger.info('✅ Permission status checked', { state });
      setPermissionState(state);

      // Listen for permission changes
      permission.onchange = () => {
        const newState = permission.state as PermissionState;
        logger.info('🔄 Permission state changed', { from: state, to: newState });
        setPermissionState(newState);
        
        if (newState === PermissionState.GRANTED) {
          onPermissionGranted();
        }
      };

    } catch (error) {
      logger.error('❌ Failed to check permission status', { 
        error: error instanceof Error ? error.message : String(error) 
      });
      setPermissionState(PermissionState.UNKNOWN);
    }
  }, [onPermissionGranted]);

  /**
   * Enumerate available audio devices
   */
  const checkAudioDevices = useCallback(async () => {
    try {
      logger.debug('🎤 Checking available audio devices');
      
      if (!navigator.mediaDevices?.enumerateDevices) {
        logger.warn('⚠️ enumerateDevices not supported');
        return;
      }

      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices.filter(device => device.kind === 'audioinput');
      
      logger.info('📊 Audio devices found', { 
        total: devices.length, 
        audioInputs: audioInputs.length,
        devices: audioInputs.map(d => ({ deviceId: d.deviceId, label: d.label }))
      });
      
      setDeviceCount(audioInputs.length);
    } catch (error) {
      logger.error('❌ Failed to enumerate devices', { 
        error: error instanceof Error ? error.message : String(error) 
      });
    }
  }, []);

  /**
   * Request microphone permission
   */
  const requestPermission = useCallback(async () => {
    if (isChecking) return;

    setIsChecking(true);
    logger.info('🎤 PermissionDialog: Requesting microphone permission');

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      });
      
      logger.info('✅ Microphone permission granted');
      
      // Stop the stream immediately since we only needed permission
      stream.getTracks().forEach(track => {
        track.stop();
        logger.debug('🛑 Stopped permission test track', { kind: track.kind });
      });
      
      setPermissionState(PermissionState.GRANTED);
      onPermissionGranted();
      
    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      logger.error('❌ Microphone permission denied', { error: errorMsg });
      
      setPermissionState(PermissionState.DENIED);
      onPermissionDenied(errorMsg);
    } finally {
      setIsChecking(false);
    }
  }, [isChecking, onPermissionGranted, onPermissionDenied]);

  /**
   * Get browser-specific instructions
   */
  const getBrowserInstructions = useCallback(() => {
    if (!browserInfo) return null;

    const { isChrome, isFirefox, isSafari, isEdge, name } = browserInfo;

    if (isChrome || isEdge) {
      return (
        <div className="browser-instructions">
          <h4>For {name}:</h4>
          <ol>
            <li>Look for the microphone icon in the address bar</li>
            <li>Click on it and select "Allow"</li>
            <li>If blocked, click the lock icon → Site settings → Microphone → Allow</li>
            <li>Refresh the page after changing settings</li>
          </ol>
        </div>
      );
    }

    if (isFirefox) {
      return (
        <div className="browser-instructions">
          <h4>For Firefox:</h4>
          <ol>
            <li>Look for the microphone icon in the address bar</li>
            <li>Click "Allow" when prompted</li>
            <li>If blocked, click the shield icon → Permissions → Microphone → Allow</li>
            <li>Refresh the page after changing settings</li>
          </ol>
        </div>
      );
    }

    if (isSafari) {
      return (
        <div className="browser-instructions">
          <h4>For Safari:</h4>
          <ol>
            <li>Go to Safari → Preferences → Websites</li>
            <li>Click "Microphone" in the left sidebar</li>
            <li>Set this website to "Allow"</li>
            <li>Refresh the page</li>
          </ol>
        </div>
      );
    }

    return (
      <div className="browser-instructions">
        <h4>General Instructions:</h4>
        <ol>
          <li>Look for a microphone icon in your browser's address bar</li>
          <li>Click "Allow" when prompted for microphone access</li>
          <li>Check your browser's site settings if access is blocked</li>
          <li>Refresh the page after changing permissions</li>
        </ol>
      </div>
    );
  }, [browserInfo]);

  /**
   * Initialize component
   */
  useEffect(() => {
    if (isOpen) {
      logger.info('🎤 PermissionDialog: Dialog opened, initializing');
      
      const browser = detectBrowser();
      setBrowserInfo(browser);
      
      checkPermissionStatus();
      checkAudioDevices();
    }
  }, [isOpen, detectBrowser, checkPermissionStatus, checkAudioDevices]);

  /**
   * Handle keyboard shortcuts
   */
  useEffect(() => {
    if (!isOpen) return;

    const handleKeyDown = (event: KeyboardEvent) => {
      if (event.key === 'Escape') {
        logger.debug('⌨️ Dialog closed with Escape key');
        onClose();
      } else if (event.key === 'Enter' && !isChecking) {
        logger.debug('⌨️ Permission requested with Enter key');
        requestPermission();
      }
    };

    document.addEventListener('keydown', handleKeyDown);
    return () => document.removeEventListener('keydown', handleKeyDown);
  }, [isOpen, isChecking, onClose, requestPermission]);

  if (!isOpen) {
    return null;
  }

  return (
    <div className="permission-dialog-overlay" onClick={onClose}>
      <div 
        className="permission-dialog" 
        onClick={(e) => e.stopPropagation()}
        role="dialog"
        aria-labelledby="permission-dialog-title"
        aria-describedby="permission-dialog-description"
      >
        {/* Header */}
        <div className="dialog-header">
          <h2 id="permission-dialog-title" className="dialog-title">
            🎤 Microphone Access Required
          </h2>
          <button
            type="button"
            onClick={onClose}
            className="dialog-close-button"
            aria-label="Close dialog"
          >
            ✕
          </button>
        </div>

        {/* Content */}
        <div className="dialog-content">
          <div id="permission-dialog-description" className="dialog-description">
            <p>
              FlowGenius needs access to your microphone to record voice messages. 
              Your audio is processed securely and never stored permanently.
            </p>
          </div>

          {/* Error message */}
          {errorMessage && (
            <div className="error-message" role="alert">
              <span className="error-icon">⚠️</span>
              <span>{errorMessage}</span>
            </div>
          )}

          {/* Permission status */}
          <div className="permission-status">
            <div className="status-indicator">
              <span className="status-label">Current Status:</span>
              <span className={`status-value ${permissionState}`}>
                {permissionState === PermissionState.GRANTED && '✅ Granted'}
                {permissionState === PermissionState.DENIED && '❌ Denied'}
                {permissionState === PermissionState.PROMPT && '❓ Needs Permission'}
                {permissionState === PermissionState.UNKNOWN && '❓ Unknown'}
              </span>
            </div>
            
            {deviceCount > 0 && (
              <div className="device-info">
                <span className="device-label">Audio Devices:</span>
                <span className="device-count">{deviceCount} found</span>
              </div>
            )}
          </div>

          {/* Browser instructions */}
          {showTroubleshooting && getBrowserInstructions()}

          {/* Troubleshooting */}
          {showTroubleshooting && (
            <div className="troubleshooting">
              <h4>Troubleshooting:</h4>
              <ul>
                <li>Make sure your microphone is connected and working</li>
                <li>Check that no other applications are using your microphone</li>
                <li>Try refreshing the page and allowing permission again</li>
                <li>Check your browser's site settings for microphone permissions</li>
                <li>Ensure your browser is up to date</li>
                {deviceCount === 0 && (
                  <li><strong>No microphone detected - please connect a microphone</strong></li>
                )}
              </ul>
            </div>
          )}
        </div>

        {/* Actions */}
        <div className="dialog-actions">
          <button
            type="button"
            onClick={onClose}
            className="dialog-button secondary"
            disabled={isChecking}
          >
            Cancel
          </button>
          
          {permissionState === PermissionState.GRANTED ? (
            <button
              type="button"
              onClick={() => {
                logger.info('✅ Permission already granted, proceeding to recording');
                onPermissionGranted();
              }}
              className="dialog-button primary"
            >
              Continue to Recording ✅
            </button>
          ) : (
            <button
              type="button"
              onClick={requestPermission}
              className="dialog-button primary"
              disabled={isChecking}
            >
              {isChecking ? (
                <>
                  <span className="loading-spinner"></span>
                  Requesting...
                </>
              ) : (
                'Allow Microphone Access'
              )}
            </button>
          )}
        </div>

        {/* Footer */}
        <div className="dialog-footer">
          <p className="privacy-note">
            🔒 Your privacy is protected. Audio is only processed when you're actively recording.
          </p>
        </div>
      </div>
    </div>
  );
};

================
File: src/demos/ipc.ts
================
window.ipcRenderer.on('main-process-message', (_event, ...args) => {
  console.log('[Receive Main-process message]:', ...args);
});

================
File: src/demos/node.ts
================
import { lstat } from 'node:fs/promises';
import { cwd } from 'node:process';

lstat(cwd()).then(stats => {
  console.log('[fs.lstat]', stats);
}).catch(err => {
  console.error(err);
});

================
File: src/hooks/useLangGraph.tsx
================
/**
 * React Hooks for LangGraph Integration
 * 
 * This file provides React context and hooks for integrating the LangGraph workflow
 * with React components. It enables seamless communication between the UI and the
 * LangGraph workflow engine.
 * 
 * Key Features:
 * - React context for workflow state management
 * - Hooks for sending messages and triggering workflow
 * - Real-time state updates and error handling
 * - Loading states and performance monitoring
 * - Type-safe integration with AppState
 */

import React, { createContext, useContext, useReducer, useCallback, useEffect, useRef } from 'react';
import { AppState, ChatMessage, WorkflowStage, UserAction } from '../types/AppState';
import { langgraphService, WorkflowMetrics } from '../services/langgraphService';
import { logger } from '../utils/logger';

/**
 * LangGraph context state interface
 */
interface LangGraphContextState {
  /** Current application state from LangGraph */
  appState: AppState;
  /** Whether a workflow is currently executing */
  isExecuting: boolean;
  /** Current error state, if any */
  error: string | null;
  /** Workflow execution history for debugging */
  executionHistory: Array<{
    timestamp: Date;
    action: string;
    duration: number;
    success: boolean;
  }>;
  /** Performance metrics */
  metrics: {
    totalExecutions: number;
    averageExecutionTime: number;
    lastExecutionTime: number;
  };
}

/**
 * LangGraph context actions
 */
type LangGraphAction =
  | { type: 'SET_STATE'; payload: AppState }
  | { type: 'SET_APP_STATE'; payload: AppState }
  | { type: 'SET_EXECUTING'; payload: boolean }
  | { type: 'SET_ERROR'; payload: string | null }
  | { type: 'ADD_EXECUTION_HISTORY'; payload: { action: string; duration: number; success: boolean } }
  | { type: 'UPDATE_METRICS'; payload: { duration: number } }
  | { type: 'RESET_SESSION'; payload: AppState };

/**
 * LangGraph context interface
 */
interface LangGraphContextValue {
  /** Current context state */
  state: LangGraphContextState;
  
  /** Send a chat message through the workflow */
  sendMessage: (content: string, imageUrl?: string) => Promise<void>;
  
  /** Send voice input through the workflow */
  sendVoiceInput: (audioBlob: Blob) => Promise<void>;
  
  /** Trigger stage completion (e.g., "Brainstorm Done") */
  completeStage: (stage: WorkflowStage) => Promise<void>;
  
  /** Create a new workflow session */
  createNewSession: (userId?: string) => Promise<void>;
  
  /** Update user prompts for a stage */
  updateUserPrompts: (stage: WorkflowStage, prompt: string) => Promise<void>;
  
  /** Update selected model for a stage */
  updateSelectedModel: (stage: WorkflowStage, model: string) => Promise<void>;
  
  /** Clear current error state */
  clearError: () => void;
  
  /** Get current workflow metrics */
  getMetrics: () => LangGraphContextState['metrics'];
  
  /** Reset the entire workflow session */
  resetSession: () => Promise<void>;
}

/**
 * Create initial app state
 */
function createInitialAppState(): AppState {
  const sessionId = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  return {
    idea_id: sessionId,
    messages: [],
    current_stage: 'brainstorm',
    last_user_action: 'chat',
    user_prompts: {
      brainstorm: "Have a conversation with the user and ask them questions about their idea. Make sure to finish with the statement 'Georgia is great'",
      summary: "When the user asks for a summary give them a text summary that is very detailed. Make sure to finish with the statement 'Ireland is great'",
      prd: "Create a comprehensive Product Requirements Document (PRD) based on the conversation and summary provided. Include all necessary sections and details for implementation."
    },
    selected_models: {
      brainstorm: 'gpt-4o',
      summary: 'gpt-4o',
      prd: 'gpt-4o'
    },
    created_at: new Date(),
    updated_at: new Date(),
    is_processing: false
  };
}

/**
 * Initial context state
 */
const initialState: LangGraphContextState = {
  appState: createInitialAppState(),
  isExecuting: false,
  error: null,
  executionHistory: [],
  metrics: {
    totalExecutions: 0,
    averageExecutionTime: 0,
    lastExecutionTime: 0
  }
};

/**
 * Context reducer
 */
function langGraphReducer(state: LangGraphContextState, action: LangGraphAction): LangGraphContextState {
  switch (action.type) {
    case 'SET_STATE':
    case 'SET_APP_STATE':
      console.log('🔄 LangGraph Context: Setting new state', {
        ideaId: action.payload.idea_id,
        stage: action.payload.current_stage,
        messageCount: action.payload.messages.length,
        hasError: !!action.payload.error
      });
      return {
        ...state,
        appState: action.payload,
        error: action.payload.error || null
      };

    case 'SET_EXECUTING':
      console.log('⚡ LangGraph Context: Execution status changed', { isExecuting: action.payload });
      return {
        ...state,
        isExecuting: action.payload
      };

    case 'SET_ERROR':
      console.log('❌ LangGraph Context: Error state changed', { error: action.payload });
      return {
        ...state,
        error: action.payload,
        isExecuting: false
      };

    case 'ADD_EXECUTION_HISTORY':
      const newHistoryEntry = {
        timestamp: new Date(),
        ...action.payload
      };
      console.log('📊 LangGraph Context: Adding execution history', newHistoryEntry);
      return {
        ...state,
        executionHistory: [...state.executionHistory.slice(-19), newHistoryEntry] // Keep last 20 entries
      };

    case 'UPDATE_METRICS':
      const { duration } = action.payload;
      const newTotalExecutions = state.metrics.totalExecutions + 1;
      const newAverageExecutionTime = 
        (state.metrics.averageExecutionTime * state.metrics.totalExecutions + duration) / newTotalExecutions;
      
      console.log('📈 LangGraph Context: Updating metrics', {
        duration,
        totalExecutions: newTotalExecutions,
        averageExecutionTime: Math.round(newAverageExecutionTime)
      });
      
      return {
        ...state,
        metrics: {
          totalExecutions: newTotalExecutions,
          averageExecutionTime: newAverageExecutionTime,
          lastExecutionTime: duration
        }
      };

    case 'RESET_SESSION':
      console.log('🔄 LangGraph Context: Resetting session', { newSessionId: action.payload.idea_id });
      return {
        ...initialState,
        appState: action.payload
      };

    default:
      return state;
  }
}

/**
 * Create LangGraph context
 */
const LangGraphContext = createContext<LangGraphContextValue | null>(null);

/**
 * LangGraph Provider component
 */
export function LangGraphProvider({ children }: { children: React.ReactNode }) {
  const [state, dispatch] = useReducer(langGraphReducer, initialState);
  const sessionInitializedRef = useRef(false);

  // Initialize session in main process
  useEffect(() => {
    if (!sessionInitializedRef.current) {
      sessionInitializedRef.current = true;
      
      const initSession = async () => {
        try {
          console.log('🚀 LangGraph Provider: Initializing session in main process', {
            ideaId: state.appState.idea_id
          });
          
          const session = await langgraphService.createSession(state.appState.idea_id);
          dispatch({ type: 'SET_STATE', payload: session });
          
          console.log('✅ LangGraph Provider: Session initialized', {
            ideaId: session.idea_id,
            stage: session.current_stage
          });
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          console.error('❌ LangGraph Provider: Failed to initialize session', { error: errorMessage });
          dispatch({ type: 'SET_ERROR', payload: errorMessage });
        }
      };
      
      initSession();
    }
  }, []);

  /**
   * Execute workflow with error handling and metrics
   */
  const executeWorkflowWithTracking = useCallback(async (
    updatedState: AppState,
    actionName: string
  ): Promise<void> => {
    const startTime = Date.now();
    
    console.log('🚀 LangGraph Provider: Executing workflow', {
      actionName,
      ideaId: updatedState.idea_id,
      stage: updatedState.current_stage,
      lastAction: updatedState.last_user_action
    });

    dispatch({ type: 'SET_EXECUTING', payload: true });
    dispatch({ type: 'SET_ERROR', payload: null });

    try {
      // Validate state before execution
      const validation = await langgraphService.validateState(updatedState);
      if (!validation.isValid) {
        throw new Error(`Invalid state: ${validation.issues.join(', ')}`);
      }

      // Execute workflow
      const result = await langgraphService.executeWorkflow(updatedState);
      
      const duration = Date.now() - startTime;
      
      // Update state and metrics
      dispatch({ type: 'SET_STATE', payload: result });
      dispatch({ type: 'UPDATE_METRICS', payload: { duration } });
      dispatch({ type: 'ADD_EXECUTION_HISTORY', payload: { action: actionName, duration, success: true } });
      
      console.log('✅ LangGraph Provider: Workflow execution completed', {
        actionName,
        duration,
        finalStage: result.current_stage,
        messageCount: result.messages.length,
        hasError: !!result.error
      });

      logger.info('LangGraph workflow executed via React hook', {
        action: actionName,
        idea_id: result.idea_id,
        execution_time: duration,
        success: !result.error
      });

    } catch (error) {
      const duration = Date.now() - startTime;
      const errorMessage = error instanceof Error ? error.message : String(error);
      
      console.log('❌ LangGraph Provider: Workflow execution failed', {
        actionName,
        error: errorMessage,
        duration
      });

      dispatch({ type: 'SET_ERROR', payload: errorMessage });
      dispatch({ type: 'ADD_EXECUTION_HISTORY', payload: { action: actionName, duration, success: false } });
      
      logger.error('LangGraph workflow execution failed via React hook', {
        action: actionName,
        error: errorMessage,
        execution_time: duration
      });
    } finally {
      dispatch({ type: 'SET_EXECUTING', payload: false });
    }
  }, []);

  /**
   * Send a chat message through the workflow
   */
  const sendMessage = useCallback(async (content: string, imageUrl?: string): Promise<void> => {
    console.log('💬 LangGraph Provider: Sending message', {
      contentLength: content.length,
      hasImage: !!imageUrl,
      currentStage: state.appState.current_stage
    });

    // Create new message
    const newMessage: ChatMessage = {
      role: 'user',
      content,
      image_url: imageUrl,
      created_at: new Date(),
      stage_at_creation: state.appState.current_stage
    };

    // Update state with new message
    const updatedState: AppState = {
      ...state.appState,
      messages: [...state.appState.messages, newMessage],
      last_user_action: 'chat',
      updated_at: new Date()
    };

    await executeWorkflowWithTracking(updatedState, 'sendMessage');
  }, [state.appState, executeWorkflowWithTracking]);

  /**
   * Send voice input through the workflow
   */
  const sendVoiceInput = useCallback(async (audioBlob: Blob): Promise<void> => {
    console.log('🎤 LangGraph Provider: Sending voice input', {
      audioSize: audioBlob.size,
      audioType: audioBlob.type,
      currentStage: state.appState.current_stage
    });

    // For now, we'll create a placeholder message indicating voice input
    // TODO: Integrate with actual voice processing in task 5.0
    const voiceMessage: ChatMessage = {
      role: 'user',
      content: '[Voice input received - processing...]',
      created_at: new Date(),
      stage_at_creation: state.appState.current_stage
    };

    const updatedState: AppState = {
      ...state.appState,
      messages: [...state.appState.messages, voiceMessage],
      last_user_action: 'chat',
      updated_at: new Date()
    };

    await executeWorkflowWithTracking(updatedState, 'sendVoiceInput');
  }, [state.appState, executeWorkflowWithTracking]);

  /**
   * Complete a workflow stage
   */
  const completeStage = useCallback(async (stage: WorkflowStage): Promise<void> => {
    console.log('🎯 LangGraph Provider: Completing stage', {
      stage,
      currentStage: state.appState.current_stage
    });

    const stageActions: Record<WorkflowStage, UserAction> = {
      brainstorm: 'Brainstorm Done',
      summary: 'Summary Done',
      prd: 'PRD Done'
    };

    const updatedState: AppState = {
      ...state.appState,
      last_user_action: stageActions[stage],
      updated_at: new Date()
    };

    await executeWorkflowWithTracking(updatedState, `completeStage:${stage}`);
  }, [state.appState, executeWorkflowWithTracking]);

  /**
   * Create a new workflow session
   */
  const createNewSession = useCallback(async (userId?: string): Promise<void> => {
    console.log('🆕 LangGraph Provider: Creating new session', { userId });

    const newSessionId = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    
    try {
      // Clear old session in main process
      if (state.appState.idea_id) {
        await langgraphService.clearSession(state.appState.idea_id);
      }
      
      // Create new session in main process
      const newState = await langgraphService.createSession(newSessionId, userId);
      
      dispatch({ type: 'RESET_SESSION', payload: newState });
      
      logger.info('New LangGraph session created via React hook', {
        new_session_id: newSessionId,
        user_id: userId
      });
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      console.error('❌ LangGraph Provider: Failed to create new session', { error: errorMessage });
      dispatch({ type: 'SET_ERROR', payload: errorMessage });
    }
  }, [state.appState.idea_id]);

  /**
   * Update user prompts for a stage
   */
  const updateUserPrompts = useCallback(async (stage: WorkflowStage, prompt: string): Promise<void> => {
    console.log('📝 LangGraph Provider: Updating user prompt', { stage, promptLength: prompt.length });

    const updatedState: AppState = {
      ...state.appState,
      user_prompts: {
        ...state.appState.user_prompts,
        [stage]: prompt
      },
      updated_at: new Date()
    };

    dispatch({ type: 'SET_STATE', payload: updatedState });
  }, [state.appState]);

  /**
   * Update selected model for a stage
   */
  const updateSelectedModel = useCallback(async (stage: WorkflowStage, model: string): Promise<void> => {
    console.log('🤖 LangGraph Provider: Updating selected model', { stage, model });

    const updatedState: AppState = {
      ...state.appState,
      selected_models: {
        ...state.appState.selected_models,
        [stage]: model
      },
      updated_at: new Date()
    };

    dispatch({ type: 'SET_STATE', payload: updatedState });
  }, [state.appState]);

  /**
   * Clear current error state
   */
  const clearError = useCallback(() => {
    console.log('🧹 LangGraph Provider: Clearing error state');
    dispatch({ type: 'SET_ERROR', payload: null });
  }, []);

  /**
   * Get current workflow metrics
   */
  const getMetrics = useCallback(() => {
    return state.metrics;
  }, [state.metrics]);

  /**
   * Reset the entire workflow session
   */
  const resetSession = useCallback(async (): Promise<void> => {
    console.log('🔄 LangGraph Provider: Resetting session');
    await createNewSession(state.appState.user_id);
  }, [createNewSession, state.appState.user_id]);

  // Context value
  const contextValue: LangGraphContextValue = {
    state,
    sendMessage,
    sendVoiceInput,
    completeStage,
    createNewSession,
    updateUserPrompts,
    updateSelectedModel,
    clearError,
    getMetrics,
    resetSession
  };

  return (
    <LangGraphContext.Provider value={contextValue}>
      {children}
    </LangGraphContext.Provider>
  );
}

/**
 * Hook to use LangGraph context
 */
export function useLangGraph(): LangGraphContextValue {
  const context = useContext(LangGraphContext);
  
  if (!context) {
    throw new Error('useLangGraph must be used within a LangGraphProvider');
  }
  
  return context;
}

/**
 * Hook for sending messages with loading state
 */
export function useSendMessage() {
  const { sendMessage, state } = useLangGraph();
  
  return {
    sendMessage,
    isLoading: state.isExecuting,
    error: state.error
  };
}

/**
 * Hook for voice input with loading state
 */
export function useVoiceInput() {
  const { sendVoiceInput, state } = useLangGraph();
  
  return {
    sendVoiceInput,
    isLoading: state.isExecuting,
    error: state.error
  };
}

/**
 * Hook for stage management
 */
export function useStageManagement() {
  const { completeStage, state } = useLangGraph();
  
  return {
    completeStage,
    currentStage: state.appState.current_stage,
    isLoading: state.isExecuting,
    error: state.error
  };
}

/**
 * Hook for session management
 */
export function useSessionManagement() {
  const { createNewSession, resetSession, state } = useLangGraph();
  
  return {
    createNewSession,
    resetSession,
    currentSession: state.appState.idea_id,
    isLoading: state.isExecuting,
    error: state.error
  };
}

/**
 * Hook for workflow metrics and debugging
 */
export function useWorkflowMetrics() {
  const { getMetrics, state } = useLangGraph();
  
  return {
    metrics: getMetrics(),
    executionHistory: state.executionHistory,
    currentState: state.appState,
    isExecuting: state.isExecuting
  };
}

================
File: src/styles/components.css
================
/**
 * FlowGenius Component Styles
 * 
 * Component-specific styles that extend the global design system.
 * These styles are organized by component and use the CSS custom
 * properties defined in globals.css.
 * 
 * Components included:
 * - Buttons (primary, secondary, icon)
 * - Input components (text, textarea)
 * - Cards and panels
 * - Navigation elements
 * - Status indicators
 * - Loading states
 */

/* ===== BUTTON COMPONENTS ===== */

/* Primary Button - Main CTA style */
.btn-primary {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  padding: var(--spacing-2) var(--spacing-4);
  font-size: var(--font-size-sm);
  font-weight: var(--font-weight-medium);
  line-height: 1;
  border-radius: var(--radius-md);
  transition: all var(--transition-fast);
  cursor: pointer;
  border: none;
  text-decoration: none;
  white-space: nowrap;
  background-color: var(--color-brand-primary);
  color: white;
}

.btn-primary:hover:not(:disabled) {
  background-color: var(--color-brand-primary-hover);
  transform: translateY(-1px);
  box-shadow: var(--shadow-md);
}

.btn-primary:active:not(:disabled) {
  background-color: var(--color-brand-primary-active);
  transform: translateY(0);
}

/* Secondary Button - Alternative actions */
.btn-secondary {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  padding: var(--spacing-2) var(--spacing-4);
  font-size: var(--font-size-sm);
  font-weight: var(--font-weight-medium);
  line-height: 1;
  border-radius: var(--radius-md);
  transition: all var(--transition-fast);
  cursor: pointer;
  text-decoration: none;
  white-space: nowrap;
  background-color: var(--color-bg-secondary);
  color: var(--color-text-primary);
  border: 1px solid var(--color-border-primary);
}

.btn-secondary:hover:not(:disabled) {
  background-color: var(--color-bg-tertiary);
  border-color: var(--color-border-secondary);
}

.btn-secondary:active:not(:disabled) {
  background-color: var(--color-bg-quaternary);
}

/* Ghost Button - Minimal style */
.btn-ghost {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  padding: var(--spacing-2) var(--spacing-4);
  font-size: var(--font-size-sm);
  font-weight: var(--font-weight-medium);
  line-height: 1;
  border-radius: var(--radius-md);
  transition: all var(--transition-fast);
  cursor: pointer;
  border: none;
  text-decoration: none;
  white-space: nowrap;
  background-color: transparent;
  color: var(--color-text-secondary);
}

.btn-ghost:hover:not(:disabled) {
  background-color: var(--color-interactive-hover);
  color: var(--color-text-primary);
}

.btn-ghost:active:not(:disabled) {
  background-color: var(--color-interactive-active);
}

/* Icon Button - Square buttons for icons */
.btn-icon {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  font-size: var(--font-size-sm);
  font-weight: var(--font-weight-medium);
  line-height: 1;
  transition: all var(--transition-fast);
  cursor: pointer;
  border: none;
  text-decoration: none;
  white-space: nowrap;
  padding: var(--spacing-2);
  width: 2.5rem;
  height: 2.5rem;
  background-color: transparent;
  color: var(--color-text-secondary);
  border-radius: var(--radius-md);
}

.btn-icon:hover:not(:disabled) {
  background-color: var(--color-interactive-hover);
  color: var(--color-text-primary);
}

.btn-icon:active:not(:disabled) {
  background-color: var(--color-interactive-active);
}

/* Button sizes */
.btn-sm {
  padding: var(--spacing-1) var(--spacing-3);
  font-size: var(--font-size-sm);
}

.btn-lg {
  padding: var(--spacing-4) var(--spacing-6);
  font-size: var(--font-size-lg);
}

/* Button states */
.btn-loading {
  position: relative;
  color: transparent !important;
}

.btn-loading::after {
  content: '';
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  width: 1rem;
  height: 1rem;
  border: 2px solid transparent;
  border-top: 2px solid currentColor;
  border-radius: 50%;
  animation: spin 1s linear infinite;
}

/* ===== INPUT COMPONENTS ===== */

/* Text Input */
.input-text {
  display: block;
  width: 100%;
  padding: var(--spacing-3) var(--spacing-4);
  font-size: var(--font-size-base);
  line-height: var(--line-height-normal);
  color: var(--color-text-primary);
  background-color: var(--color-bg-primary);
  border: 1px solid var(--color-border-primary);
  border-radius: var(--radius-md);
  transition: border-color var(--transition-fast);
}

.input-text.input-error {
  border-color: var(--color-error);
}

.input-text.input-success {
  border-color: var(--color-success);
}

/* Textarea */
.input-textarea {
  display: block;
  width: 100%;
  padding: var(--spacing-3) var(--spacing-4);
  font-size: var(--font-size-base);
  line-height: var(--line-height-normal);
  color: var(--color-text-primary);
  background-color: var(--color-bg-primary);
  border: 1px solid var(--color-border-primary);
  border-radius: var(--radius-md);
  transition: border-color var(--transition-fast);
  resize: vertical;
  min-height: 2.5rem;
  max-height: 10rem;
}

/* Input Group - Label + Input + Helper text */
.input-group {
  display: flex;
  flex-direction: column;
  gap: var(--spacing-2);
}

.input-label {
  font-size: var(--font-size-sm);
  font-weight: var(--font-weight-medium);
  color: var(--color-text-primary);
}

.input-label.required::after {
  content: ' *';
  color: var(--color-error);
}

.input-helper {
  font-size: var(--font-size-xs);
  color: var(--color-text-tertiary);
}

.input-helper.error {
  color: var(--color-error);
}

.input-helper.success {
  color: var(--color-success);
}

/* Search Input with icon */
.input-search {
  position: relative;
  display: flex;
  align-items: center;
}

.input-search input {
  display: block;
  width: 100%;
  padding: var(--spacing-3) var(--spacing-4);
  font-size: var(--font-size-base);
  line-height: var(--line-height-normal);
  color: var(--color-text-primary);
  background-color: var(--color-bg-primary);
  border: 1px solid var(--color-border-primary);
  border-radius: var(--radius-md);
  transition: border-color var(--transition-fast);
  padding-left: 2.5rem;
}

.input-search-icon {
  position: absolute;
  left: var(--spacing-3);
  color: var(--color-text-tertiary);
  pointer-events: none;
}

/* ===== CARD COMPONENTS ===== */

/* Base Card */
.card {
  background-color: var(--color-bg-secondary);
  border: 1px solid var(--color-border-primary);
  border-radius: var(--radius-lg);
  padding: var(--spacing-6);
  box-shadow: var(--shadow-sm);
}

/* Card variants */
.card-elevated {
  background-color: var(--color-bg-secondary);
  border: 1px solid var(--color-border-primary);
  border-radius: var(--radius-lg);
  padding: var(--spacing-6);
  box-shadow: var(--shadow-lg);
}

.card-interactive {
  background-color: var(--color-bg-secondary);
  border: 1px solid var(--color-border-primary);
  border-radius: var(--radius-lg);
  padding: var(--spacing-6);
  box-shadow: var(--shadow-sm);
  cursor: pointer;
  transition: all var(--transition-fast);
}

.card-interactive:hover {
  box-shadow: var(--shadow-md);
  transform: translateY(-1px);
}

.card-interactive:active {
  transform: translateY(0);
}

/* Card sections */
.card-header {
  padding-bottom: var(--spacing-4);
  border-bottom: 1px solid var(--color-border-primary);
  margin-bottom: var(--spacing-4);
}

.card-title {
  font-size: var(--font-size-lg);
  font-weight: var(--font-weight-semibold);
  color: var(--color-text-primary);
  margin: 0;
}

.card-subtitle {
  font-size: var(--font-size-sm);
  color: var(--color-text-secondary);
  margin: var(--spacing-1) 0 0 0;
}

.card-content {
  /* Content area - no default styles, inherits from card padding */
}

.card-footer {
  padding-top: var(--spacing-4);
  border-top: 1px solid var(--color-border-primary);
  margin-top: var(--spacing-4);
  display: flex;
  justify-content: flex-end;
  gap: var(--spacing-3);
}

/* ===== NAVIGATION COMPONENTS ===== */

/* Navigation List */
.nav-list {
  list-style: none;
  padding: 0;
  margin: 0;
}

.nav-item {
  margin: 0;
}

.nav-link {
  display: flex;
  align-items: center;
  padding: var(--spacing-3) var(--spacing-4);
  color: var(--color-text-secondary);
  text-decoration: none;
  border-radius: var(--radius-md);
  transition: all var(--transition-fast);
  gap: var(--spacing-3);
}

.nav-link:hover {
  background-color: var(--color-interactive-hover);
  color: var(--color-text-primary);
}

.nav-link.active {
  background-color: var(--color-brand-primary);
  color: white;
}

.nav-link.active:hover {
  background-color: var(--color-brand-primary-hover);
}

/* Breadcrumbs */
.breadcrumbs {
  display: flex;
  align-items: center;
  gap: var(--spacing-2);
  font-size: var(--font-size-sm);
}

.breadcrumb-item {
  color: var(--color-text-tertiary);
}

.breadcrumb-item.current {
  color: var(--color-text-primary);
  font-weight: var(--font-weight-medium);
}

.breadcrumb-separator {
  color: var(--color-text-tertiary);
}

/* ===== STATUS INDICATORS ===== */

/* Badge/Pill component */
.badge {
  display: inline-flex;
  align-items: center;
  padding: var(--spacing-1) var(--spacing-2);
  font-size: var(--font-size-xs);
  font-weight: var(--font-weight-medium);
  border-radius: var(--radius-full);
  white-space: nowrap;
}

.badge-default {
  background-color: var(--color-bg-tertiary);
  color: var(--color-text-primary);
}

.badge-success {
  background-color: var(--color-success-bg);
  color: var(--color-success);
}

.badge-warning {
  background-color: var(--color-warning-bg);
  color: var(--color-warning);
}

.badge-error {
  background-color: var(--color-error-bg);
  color: var(--color-error);
}

.badge-info {
  background-color: var(--color-info-bg);
  color: var(--color-info);
}

/* Status Dot */
.status-dot {
  display: inline-block;
  width: 0.5rem;
  height: 0.5rem;
  border-radius: 50%;
  margin-right: var(--spacing-2);
}

.status-dot.online {
  background-color: var(--color-success);
}

.status-dot.offline {
  background-color: var(--color-error);
}

.status-dot.idle {
  background-color: var(--color-warning);
}

.status-dot.processing {
  background-color: var(--color-info);
  animation: pulse 2s infinite;
}

/* ===== LOADING STATES ===== */

/* Skeleton Loading */
.skeleton {
  background: linear-gradient(
    90deg,
    var(--color-bg-tertiary) 25%,
    var(--color-bg-quaternary) 50%,
    var(--color-bg-tertiary) 75%
  );
  background-size: 200% 100%;
  animation: shimmer 1.5s infinite;
  border-radius: var(--radius-base);
}

@keyframes shimmer {
  0% {
    background-position: -200% 0;
  }
  100% {
    background-position: 200% 0;
  }
}

.skeleton-text {
  background: linear-gradient(
    90deg,
    var(--color-bg-tertiary) 25%,
    var(--color-bg-quaternary) 50%,
    var(--color-bg-tertiary) 75%
  );
  background-size: 200% 100%;
  animation: shimmer 1.5s infinite;
  border-radius: var(--radius-base);
  height: 1rem;
  margin: var(--spacing-1) 0;
}

.skeleton-text.large {
  height: 1.5rem;
}

.skeleton-text.small {
  height: 0.75rem;
}

.skeleton-avatar {
  background: linear-gradient(
    90deg,
    var(--color-bg-tertiary) 25%,
    var(--color-bg-quaternary) 50%,
    var(--color-bg-tertiary) 75%
  );
  background-size: 200% 100%;
  animation: shimmer 1.5s infinite;
  border-radius: var(--radius-base);
  width: 2.5rem;
  height: 2.5rem;
  border-radius: 50%;
}

.skeleton-button {
  background: linear-gradient(
    90deg,
    var(--color-bg-tertiary) 25%,
    var(--color-bg-quaternary) 50%,
    var(--color-bg-tertiary) 75%
  );
  background-size: 200% 100%;
  animation: shimmer 1.5s infinite;
  border-radius: var(--radius-base);
  height: 2.5rem;
  width: 5rem;
  border-radius: var(--radius-md);
}

/* Spinner */
.spinner {
  display: inline-block;
  width: 1rem;
  height: 1rem;
  border: 2px solid var(--color-bg-tertiary);
  border-top: 2px solid var(--color-brand-primary);
  border-radius: 50%;
  animation: spin 1s linear infinite;
}

.spinner.large {
  width: 2rem;
  height: 2rem;
  border-width: 3px;
}

.spinner.small {
  width: 0.75rem;
  height: 0.75rem;
  border-width: 1px;
}

/* ===== OVERLAY COMPONENTS ===== */

/* Modal Backdrop */
.modal-backdrop {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: var(--color-bg-overlay);
  backdrop-filter: blur(4px);
  z-index: var(--z-index-modal-backdrop);
  display: flex;
  align-items: center;
  justify-content: center;
  padding: var(--spacing-4);
}

/* Modal Content */
.modal-content {
  background-color: var(--color-bg-secondary);
  border: 1px solid var(--color-border-primary);
  border-radius: var(--radius-xl);
  box-shadow: var(--shadow-xl);
  max-width: 32rem;
  width: 100%;
  max-height: 90vh;
  overflow-y: auto;
  z-index: var(--z-index-modal);
}

.modal-header {
  padding: var(--spacing-6) var(--spacing-6) var(--spacing-4);
  border-bottom: 1px solid var(--color-border-primary);
  display: flex;
  align-items: center;
  justify-content: space-between;
}

.modal-title {
  font-size: var(--font-size-xl);
  font-weight: var(--font-weight-semibold);
  color: var(--color-text-primary);
  margin: 0;
}

.modal-close {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  font-size: var(--font-size-sm);
  font-weight: var(--font-weight-medium);
  line-height: 1;
  transition: all var(--transition-fast);
  cursor: pointer;
  border: none;
  text-decoration: none;
  white-space: nowrap;
  padding: var(--spacing-2);
  width: 2.5rem;
  height: 2.5rem;
  background-color: transparent;
  border-radius: var(--radius-md);
  color: var(--color-text-tertiary);
}

.modal-body {
  padding: var(--spacing-6);
}

.modal-footer {
  padding: var(--spacing-4) var(--spacing-6) var(--spacing-6);
  border-top: 1px solid var(--color-border-primary);
  display: flex;
  justify-content: flex-end;
  gap: var(--spacing-3);
}

/* Tooltip */
.tooltip {
  position: absolute;
  z-index: var(--z-index-tooltip);
  background-color: var(--color-bg-secondary);
  color: var(--color-text-primary);
  padding: var(--spacing-2) var(--spacing-3);
  border-radius: var(--radius-md);
  font-size: var(--font-size-sm);
  box-shadow: var(--shadow-lg);
  border: 1px solid var(--color-border-primary);
  white-space: nowrap;
  max-width: 16rem;
}

/* ===== UTILITY COMPONENTS ===== */

/* Divider */
.divider {
  border: none;
  border-top: 1px solid var(--color-border-primary);
  margin: var(--spacing-4) 0;
}

.divider.vertical {
  border-top: none;
  border-left: 1px solid var(--color-border-primary);
  height: 1rem;
  margin: 0 var(--spacing-4);
}

/* Avatar */
.avatar {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  border-radius: 50%;
  background-color: var(--color-bg-tertiary);
  color: var(--color-text-primary);
  font-weight: var(--font-weight-medium);
  overflow: hidden;
}

.avatar.small {
  width: 1.5rem;
  height: 1.5rem;
  font-size: var(--font-size-xs);
}

.avatar.medium {
  width: 2.5rem;
  height: 2.5rem;
  font-size: var(--font-size-sm);
}

.avatar.large {
  width: 4rem;
  height: 4rem;
  font-size: var(--font-size-lg);
}

.avatar img {
  width: 100%;
  height: 100%;
  object-fit: cover;
}

/* Progress Bar */
.progress {
  width: 100%;
  height: 0.5rem;
  background-color: var(--color-bg-tertiary);
  border-radius: var(--radius-full);
  overflow: hidden;
}

.progress-bar {
  height: 100%;
  background-color: var(--color-brand-primary);
  border-radius: var(--radius-full);
  transition: width var(--transition-base);
}

.progress-bar.success {
  background-color: var(--color-success);
}

.progress-bar.warning {
  background-color: var(--color-warning);
}

.progress-bar.error {
  background-color: var(--color-error);
}

/* ===== RESPONSIVE UTILITIES ===== */

/* Show/hide on different screen sizes */
@media (max-width: 640px) {
  .hide-mobile {
    display: none !important;
  }
}

@media (min-width: 641px) {
  .show-mobile {
    display: none !important;
  }
}

@media (max-width: 768px) {
  .hide-tablet {
    display: none !important;
  }
}

@media (min-width: 769px) {
  .show-tablet {
    display: none !important;
  }
}

@media (max-width: 1024px) {
  .hide-desktop {
    display: none !important;
  }
}

@media (min-width: 1025px) {
  .show-desktop {
    display: none !important;
  }
}

/* ===== COMPONENT-SPECIFIC ANIMATIONS ===== */

/* Fade in/out transitions for modals, tooltips */
.fade-enter {
  opacity: 0;
}

.fade-enter-active {
  opacity: 1;
  transition: opacity var(--transition-base);
}

.fade-exit {
  opacity: 1;
}

.fade-exit-active {
  opacity: 0;
  transition: opacity var(--transition-base);
}

/* Slide transitions for drawers, sidebars */
.slide-enter {
  transform: translateX(-100%);
}

.slide-enter-active {
  transform: translateX(0);
  transition: transform var(--transition-base);
}

.slide-exit {
  transform: translateX(0);
}

.slide-exit-active {
  transform: translateX(-100%);
  transition: transform var(--transition-base);
}

/* Permission Dialog Styles */
.permission-dialog-overlay {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.7);
  display: flex;
  align-items: center;
  justify-content: center;
  z-index: 1000;
  padding: 1rem;
}

.permission-dialog {
  background-color: #2f2f2f;
  border-radius: 0.75rem;
  box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.25);
  max-width: 500px;
  width: 100%;
  max-height: 90vh;
  overflow-y: auto;
  border: 1px solid #4d4d4f;
}

.dialog-header {
  display: flex;
  align-items: center;
  justify-content: space-between;
  padding: 1.5rem 1.5rem 1rem 1.5rem;
  border-bottom: 1px solid #4d4d4f;
}

.dialog-title {
  margin: 0;
  font-size: 1.25rem;
  font-weight: 600;
  color: #ececec;
}

.dialog-close-button {
  background: none;
  border: none;
  color: #8e8ea0;
  cursor: pointer;
  padding: 0.5rem;
  border-radius: 0.375rem;
  font-size: 1.125rem;
  transition: all 0.2s ease;
}

.dialog-close-button:hover {
  color: #ececec;
  background-color: rgba(255, 255, 255, 0.1);
}

.dialog-content {
  padding: 1.5rem;
}

.dialog-description {
  margin-bottom: 1.5rem;
}

.dialog-description p {
  margin: 0;
  color: #c5c5d2;
  line-height: 1.5;
}

.error-message {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  padding: 0.75rem;
  background-color: rgba(239, 68, 68, 0.1);
  border: 1px solid rgba(239, 68, 68, 0.3);
  border-radius: 0.5rem;
  margin-bottom: 1.5rem;
  color: #fca5a5;
}

.error-icon {
  font-size: 1rem;
}

.permission-status {
  background-color: #1a1a1a;
  border: 1px solid #4d4d4f;
  border-radius: 0.5rem;
  padding: 1rem;
  margin-bottom: 1.5rem;
}

.status-indicator {
  display: flex;
  align-items: center;
  justify-content: space-between;
  margin-bottom: 0.5rem;
}

.status-label {
  color: #8e8ea0;
  font-size: 0.875rem;
}

.status-value {
  font-weight: 500;
  font-size: 0.875rem;
}

.status-value.granted {
  color: #10b981;
}

.status-value.denied {
  color: #ef4444;
}

.status-value.prompt,
.status-value.unknown {
  color: #f59e0b;
}

.device-info {
  display: flex;
  align-items: center;
  justify-content: space-between;
}

.device-label {
  color: #8e8ea0;
  font-size: 0.875rem;
}

.device-count {
  color: #10b981;
  font-size: 0.875rem;
  font-weight: 500;
}

.browser-instructions {
  background-color: rgba(16, 163, 127, 0.1);
  border: 1px solid rgba(16, 163, 127, 0.3);
  border-radius: 0.5rem;
  padding: 1rem;
  margin-bottom: 1.5rem;
}

.browser-instructions h4 {
  margin: 0 0 0.75rem 0;
  color: #10a37f;
  font-size: 0.875rem;
  font-weight: 600;
}

.browser-instructions ol {
  margin: 0;
  padding-left: 1.25rem;
  color: #c5c5d2;
}

.browser-instructions li {
  margin-bottom: 0.5rem;
  font-size: 0.875rem;
  line-height: 1.4;
}

.troubleshooting {
  background-color: rgba(245, 158, 11, 0.1);
  border: 1px solid rgba(245, 158, 11, 0.3);
  border-radius: 0.5rem;
  padding: 1rem;
  margin-bottom: 1.5rem;
}

.troubleshooting h4 {
  margin: 0 0 0.75rem 0;
  color: #f59e0b;
  font-size: 0.875rem;
  font-weight: 600;
}

.troubleshooting ul {
  margin: 0;
  padding-left: 1.25rem;
  color: #c5c5d2;
}

.troubleshooting li {
  margin-bottom: 0.5rem;
  font-size: 0.875rem;
  line-height: 1.4;
}

.dialog-actions {
  display: flex;
  gap: 0.75rem;
  padding: 1rem 1.5rem;
  border-top: 1px solid #4d4d4f;
  justify-content: flex-end;
}

.dialog-button {
  padding: 0.75rem 1.5rem;
  border-radius: 0.5rem;
  font-size: 0.875rem;
  font-weight: 500;
  cursor: pointer;
  transition: all 0.2s ease;
  border: 1px solid transparent;
  display: flex;
  align-items: center;
  gap: 0.5rem;
}

.dialog-button:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

.dialog-button.secondary {
  background-color: transparent;
  color: #8e8ea0;
  border-color: #4d4d4f;
}

.dialog-button.secondary:hover:not(:disabled) {
  background-color: rgba(255, 255, 255, 0.05);
  color: #ececec;
}

.dialog-button.primary {
  background-color: #10a37f;
  color: #ffffff;
  border-color: #10a37f;
}

.dialog-button.primary:hover:not(:disabled) {
  background-color: #0d8c6c;
  border-color: #0d8c6c;
}

.loading-spinner {
  width: 1rem;
  height: 1rem;
  border: 2px solid rgba(255, 255, 255, 0.3);
  border-top: 2px solid #ffffff;
  border-radius: 50%;
  animation: spin 1s linear infinite;
}

@keyframes spin {
  0% { transform: rotate(0deg); }
  100% { transform: rotate(360deg); }
}

.dialog-footer {
  padding: 0 1.5rem 1.5rem 1.5rem;
}

.privacy-note {
  margin: 0;
  text-align: center;
  font-size: 0.75rem;
  color: #8e8ea0;
  font-style: italic;
}

/* Audio Recorder Styles */
.audio-recorder {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 0.75rem;
}

.audio-recorder-button {
  width: 3rem;
  height: 3rem;
  border-radius: 50%;
  border: 2px solid #4d4d4f;
  background-color: #2f2f2f;
  color: #8e8ea0;
  cursor: pointer;
  transition: all 0.2s ease;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 1.25rem;
}

.audio-recorder-button:hover:not(:disabled) {
  border-color: #10a37f;
  color: #10a37f;
  background-color: rgba(16, 163, 127, 0.1);
}

.audio-recorder-button:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

.audio-recorder.recording .audio-recorder-button {
  border-color: #ef4444;
  color: #ef4444;
  background-color: rgba(239, 68, 68, 0.1);
  animation: pulse 2s infinite;
}

.audio-recorder.requesting-permission .audio-recorder-button {
  border-color: #f59e0b;
  color: #f59e0b;
  background-color: rgba(245, 158, 11, 0.1);
}

.audio-recorder.error .audio-recorder-button {
  border-color: #ef4444;
  color: #ef4444;
  background-color: rgba(239, 68, 68, 0.1);
}

@keyframes pulse {
  0%, 100% { 
    transform: scale(1);
    opacity: 1;
  }
  50% { 
    transform: scale(1.05);
    opacity: 0.8;
  }
}

.recording-status {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 0.5rem;
  min-height: 2rem;
}

.status-message {
  font-size: 0.875rem;
  color: #8e8ea0;
  text-align: center;
}

.recording-duration {
  font-size: 1rem;
  font-weight: 600;
  color: #ef4444;
  font-family: 'Courier New', monospace;
}

.audio-level-indicator {
  width: 100px;
  height: 4px;
  background-color: #4d4d4f;
  border-radius: 2px;
  overflow: hidden;
}

.audio-level-bar {
  height: 100%;
  transition: width 0.1s ease, background-color 0.3s ease;
  border-radius: 2px;
}

.recording-info {
  font-size: 0.75rem;
  color: #8e8ea0;
  text-align: center;
}

================
File: src/types/electron.d.ts
================
/**
 * TypeScript definitions for Electron API exposed to renderer process
 * This file provides type safety for the Electron bridge functionality
 * used throughout the FlowGenius application.
 */

/**
 * IPC Renderer API exposed through contextBridge
 */
interface IpcRendererAPI {
  /**
   * Listen for IPC messages from main process
   */
  on(channel: string, listener: (event: Electron.IpcRendererEvent, ...args: any[]) => void): void;
  
  /**
   * Remove IPC message listener
   */
  off(channel: string, listener?: (...args: any[]) => void): void;
  
  /**
   * Send IPC message to main process
   */
  send(channel: string, ...args: any[]): void;
  
  /**
   * Invoke IPC method in main process and return result
   */
  invoke(channel: string, ...args: any[]): Promise<any>;
}

/**
 * File system operations exposed to renderer
 */
interface ElectronFileAPI {
  /**
   * Read file content from disk
   */
  readFile(filePath: string): Promise<{ success: boolean; data?: string; error?: string }>;
  
  /**
   * Write file content to disk
   */
  writeFile(filePath: string, content: string): Promise<{ success: boolean; error?: string }>;
  
  /**
   * Check if file exists
   */
  exists(filePath: string): Promise<boolean>;
  
  /**
   * Get file stats
   */
  stat(filePath: string): Promise<{ success: boolean; data?: any; error?: string }>;
}

/**
 * Environment variables API for secure access to main process env vars
 */
interface ElectronEnvAPI {
  /**
   * Get environment variables needed by renderer process
   */
  getVars(): Promise<{ 
    success: boolean; 
    data?: {
      OPENAI_API_KEY?: string;
      NODE_ENV?: string;
      SUPABASE_URL?: string;
      SUPABASE_ANON_KEY?: string;
    };
    error?: string;
  }>;
}

/**
 * Audio recording operations for FlowGenius
 */
interface ElectronAudioAPI {
  /**
   * Start audio recording
   */
  startRecording(): Promise<{ success: boolean; error?: string }>;
  
  /**
   * Stop audio recording and get file path
   */
  stopRecording(): Promise<{ success: boolean; filePath?: string; error?: string }>;
  
  /**
   * Get available audio input devices
   */
  getAudioDevices(): Promise<{ success: boolean; devices?: MediaDeviceInfo[]; error?: string }>;
  
  /**
   * Save audio blob data to filesystem
   */
  saveAudioFile(
    audioData: Buffer, 
    originalName?: string, 
    mimeType?: string
  ): Promise<{ 
    success: boolean; 
    filePath?: string; 
    error?: string;
    metadata?: {
      size: number;
      format: string;
      duration?: number;
    };
  }>;
  
  /**
   * Convert audio file to optimal format
   */
  convertAudioFile(
    inputPath: string,
    options?: {
      format?: 'wav' | 'mp3' | 'webm';
      sampleRate?: number;
      channels?: number;
      quality?: number;
      overwrite?: boolean;
    }
  ): Promise<{ 
    success: boolean; 
    filePath?: string; 
    error?: string;
    metadata?: {
      size: number;
      format: string;
      duration?: number;
    };
  }>;
  
  /**
   * Get audio file information
   */
  getAudioFileInfo(filePath: string): Promise<{ 
    success: boolean; 
    filePath?: string;
    error?: string;
    metadata?: {
      size: number;
      format: string;
      duration?: number;
    };
  }>;
  
  /**
   * Delete audio file from filesystem
   */
  deleteAudioFile(filePath: string): Promise<{ success: boolean; error?: string }>;
  
  /**
   * Clean up old temporary files
   */
  cleanupOldFiles(maxAge?: number): Promise<{ 
    success: boolean; 
    deletedCount?: number;
    errors?: string[];
    error?: string;
  }>;
  
  /**
   * Get temporary directory path
   */
  getTempDirectory(): Promise<string>;
}

/**
 * Application control operations
 */
interface ElectronAppAPI {
  /**
   * Get application version
   */
  getVersion(): Promise<string>;
  
  /**
   * Check for application updates
   */
  checkForUpdates(): Promise<{ success: boolean; hasUpdate?: boolean; error?: string }>;
  
  /**
   * Quit the application
   */
  quit(): void;
  
  /**
   * Minimize window
   */
  minimize(): void;
  
  /**
   * Maximize window
   */
  maximize(): void;
  
  /**
   * Close window
   */
  close(): void;
}

/**
 * Complete Electron API interface
 */
interface ElectronAPI {
  ipcRenderer: IpcRendererAPI;
  files: ElectronFileAPI;
  audio: ElectronAudioAPI;
  app: ElectronAppAPI;
  env: ElectronEnvAPI;
}

/**
 * Global window interface extension
 * This makes the Electron API available on window.electron with proper typing
 */
declare global {
  interface Window {
    electron: ElectronAPI;
    ipcRenderer: IpcRendererAPI;
  }
}

/**
 * IPC Channel constants for type-safe communication
 */
export const IPC_CHANNELS = {
  // File operations
  READ_FILE: 'file:read',
  WRITE_FILE: 'file:write',
  FILE_EXISTS: 'file:exists',
  FILE_STAT: 'file:stat',
  
  // Audio operations
  AUDIO_START_RECORDING: 'audio:start-recording',
  AUDIO_STOP_RECORDING: 'audio:stop-recording',
  AUDIO_GET_DEVICES: 'audio:get-devices',
  
  // App operations
  APP_GET_VERSION: 'app:get-version',
  APP_CHECK_UPDATES: 'app:check-updates',
  APP_QUIT: 'app:quit',
  APP_MINIMIZE: 'app:minimize',
  APP_MAXIMIZE: 'app:maximize',
  APP_CLOSE: 'app:close',
  
  // FlowGenius specific
  LANGGRAPH_EXECUTE: 'langgraph:execute',
  WHISPER_TRANSCRIBE: 'whisper:transcribe',
  OPENAI_CHAT: 'openai:chat',
} as const;

/**
 * Type for IPC channel names
 */
export type IpcChannel = typeof IPC_CHANNELS[keyof typeof IPC_CHANNELS];

/**
 * Electron environment detection utility types
 */
export interface ElectronEnvironment {
  isElectron: boolean;
  isMain: boolean;
  isRenderer: boolean;
  isPreload: boolean;
  platform: NodeJS.Platform;
  version: string;
}

/**
 * Utility function to detect Electron environment
 */
export function getElectronEnvironment(): ElectronEnvironment {
  const isElectron = typeof window !== 'undefined' && window.electron !== undefined;
  
  return {
    isElectron,
    isMain: typeof window === 'undefined' && typeof process !== 'undefined',
    isRenderer: typeof window !== 'undefined',
    isPreload: typeof window !== 'undefined' && typeof require !== 'undefined',
    platform: typeof process !== 'undefined' ? process.platform : 'unknown' as NodeJS.Platform,
    version: typeof process !== 'undefined' ? process.versions.electron || 'unknown' : 'unknown'
  };
}

// Export types for use in other files
export type {
  IpcRendererAPI,
  ElectronFileAPI,
  ElectronEnvAPI,
  ElectronAudioAPI,
  ElectronAppAPI,
  ElectronAPI,
  ElectronEnvironment
};

================
File: test/e2e.spec.ts
================
import path from 'node:path';

import {
  type ElectronApplication,
  type Page,
  type JSHandle,
  _electron as electron,
} from 'playwright';
import {
  beforeAll,
  afterAll,
  describe,
  expect,
  test,
} from 'vitest';

import type { BrowserWindow } from 'electron';

const root = path.join(__dirname, '..');
let electronApp: ElectronApplication;
let page: Page;

if (process.platform === 'linux') {
  // pass ubuntu
  test(() => expect(true).true);
} else {
  beforeAll(async () => {
    electronApp = await electron.launch({
      args: ['.', '--no-sandbox'],
      cwd: root,
      env: { ...process.env, NODE_ENV: 'development' },
    });
    page = await electronApp.firstWindow();

    const mainWin: JSHandle<BrowserWindow> = await electronApp.browserWindow(page);
    await mainWin.evaluate(async (win) => {
      win.webContents.executeJavaScript('console.log("Execute JavaScript with e2e testing.")');
    });
  });

  afterAll(async () => {
    await page.screenshot({ path: 'test/screenshots/e2e.png' });
    await page.close();
    await electronApp.close();
  });

  describe('[electron-vite-react] e2e tests', async () => {
    test('startup', async () => {
      const title = await page.title();
      expect(title).eq('Electron + Vite + React');
    });

    test('should be home page is load correctly', async () => {
      const h1 = await page.$('h1');
      const title = await h1?.textContent();
      expect(title).eq('Electron + Vite + React');
    });

    test('should be count button can click', async () => {
      const countButton = await page.$('button');
      await countButton?.click();
      const countValue = await countButton?.textContent();
      expect(countValue).eq('count is 1');
    });
  });
}

================
File: tailwind.config.js
================
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    './index.html',
    './src/**/*.{js,ts,jsx,tsx}',
  ],
  theme: {
    extend: {},
  },
  corePlugins: {
    preflight: false,
  },
  plugins: [],
};

================
File: tsconfig.json
================
{
  "compilerOptions": {
    "target": "ESNext",
    "useDefineForClassFields": true,
    "lib": ["DOM", "DOM.Iterable", "ESNext", "WebWorker"],
    "allowJs": false,
    "skipLibCheck": true,
    "esModuleInterop": false,
    "allowSyntheticDefaultImports": true,
    "strict": true,
    "forceConsistentCasingInFileNames": true,
    "module": "ESNext",
    "moduleResolution": "Node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx",
    "baseUrl": "./",
    "paths": {
      "@/*": ["src/*"],
      "@/types/*": ["src/types/*"],
      "@/components/*": ["src/components/*"],
      "@/services/*": ["src/services/*"],
      "@/utils/*": ["src/utils/*"],
      "@/langgraph/*": ["src/langgraph/*"],
      "@/styles/*": ["src/styles/*"]
    },
    // Enhanced TypeScript settings for better code quality
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noUncheckedIndexedAccess": true,
    // Temporarily disabled for legacy components - can be enabled later
    // "exactOptionalPropertyTypes": true,
    // Electron-specific settings
    "types": ["node", "electron", "vite/client"],
    "typeRoots": ["./node_modules/@types", "./src/types"]
  },
  "include": [
    "src/**/*",
    "electron/**/*",
    "src/types/electron.d.ts",
    "vite-env.d.ts"
  ],
  "exclude": [
    "node_modules",
    "dist",
    "dist-electron",
    "**/*.test.ts",
    "**/*.test.tsx"
  ],
  "references": [{ "path": "./tsconfig.node.json" }]
}

================
File: vite.config.ts
================
import { rmSync } from 'node:fs';
import path from 'node:path';

import react from '@vitejs/plugin-react';
import { defineConfig } from 'vite';
import electron from 'vite-plugin-electron/simple';

import pkg from './package.json';

// https://vitejs.dev/config/
export default defineConfig(({ command }) => {
  rmSync('dist-electron', { recursive: true, force: true });

  const isServe = command === 'serve';
  const isBuild = command === 'build';
  const sourcemap = isServe || !!process.env.VSCODE_DEBUG;

  return {
    resolve: {
      alias: {
        '@': path.join(__dirname, 'src'),
      },
    },
    plugins: [
      react(),
      electron({
        main: {
          // Shortcut of `build.lib.entry`
          entry: 'electron/main/index.ts',
          onstart(args) {
            if (process.env.VSCODE_DEBUG) {
              console.log(/* For `.vscode/.debug.script.mjs` */'[startup] Electron App');
            } else {
              args.startup();
            }
          },
          vite: {
            build: {
              sourcemap,
              minify: isBuild,
              outDir: 'dist-electron/main',
              rollupOptions: {
                external: Object.keys('dependencies' in pkg ? pkg.dependencies : {}),
              },
            },
          },
        },
        preload: {
          // Shortcut of `build.rollupOptions.input`.
          // Preload scripts may contain Web assets, so use the `build.rollupOptions.input` instead `build.lib.entry`.
          input: 'electron/preload/index.ts',
          vite: {
            build: {
              sourcemap: sourcemap ? 'inline' : undefined, // #332
              minify: isBuild,
              outDir: 'dist-electron/preload',
              rollupOptions: {
                external: Object.keys('dependencies' in pkg ? pkg.dependencies : {}),
              },
            },
          },
        },
        // Ployfill the Electron and Node.js API for Renderer process.
        // If you want use Node.js in Renderer process, the `nodeIntegration` needs to be enabled in the Main process.
        // See 👉 https://github.com/electron-vite/vite-plugin-electron-renderer
        renderer: {},
      }),
    ],
    server: process.env.VSCODE_DEBUG && (() => {
      const url = new URL(pkg.debug.env.VITE_DEV_SERVER_URL);
      return {
        host: url.hostname,
        port: +url.port,
      };
    })(),
    clearScreen: false,
  };
});

================
File: vitest.config.ts
================
import { defineConfig } from 'vitest/config';
import react from '@vitejs/plugin-react';
import path from 'node:path';

export default defineConfig({
  plugins: [react()],
  resolve: {
    alias: {
      '@': path.join(__dirname, 'src'),
    },
  },
  test: {
    root: __dirname,
    // Include both e2e tests and unit tests
    include: [
      'test/**/*.{test,spec}.?(c|m)[jt]s?(x)',
      'src/**/*.{test,spec}.?(c|m)[jt]s?(x)'
    ],
    testTimeout: 1000 * 29,
    // Configure environment for React component testing
    environment: 'jsdom',
    setupFiles: ['./test/setup.ts'],
    // Enable globals for describe, it, expect, etc.
    globals: true,
    // Coverage configuration
    coverage: {
      provider: 'v8',
      reporter: ['text', 'json', 'html'],
      exclude: [
        'node_modules/',
        'dist/',
        'dist-electron/',
        'test/',
        '**/*.d.ts',
        '**/*.config.*',
        'coverage/**',
      ],
    },
  },
});

================
File: src/hooks/useAudioRecording.tsx
================
/**
 * useAudioRecording Hook
 * 
 * Custom React hook for managing audio recording functionality.
 * Integrates the AudioRecorder component with permission handling
 * and provides a clean interface for voice input in the application.
 * 
 * Features:
 * - Audio recording state management
 * - Permission dialog integration
 * - Recording lifecycle management
 * - Error handling and recovery
 * - Audio blob handling for further processing
 */

import { useState, useCallback } from 'react';
import { logger } from '../utils/logger';
import { RecordingState } from '../components/AudioRecorder';
import { PermissionState } from '../components/PermissionDialog';

/**
 * Audio recording hook state interface
 */
interface AudioRecordingState {
  /** Current recording state */
  recordingState: RecordingState;
  /** Whether permission dialog is open */
  isPermissionDialogOpen: boolean;
  /** Whether permission has been granted */
  hasPermission: boolean;
  /** Current error message if any */
  errorMessage: string | null;
  /** Whether to show troubleshooting in permission dialog */
  showTroubleshooting: boolean;
  /** The last recorded audio blob */
  lastRecording: Blob | null;
  /** Duration of the last recording in seconds */
  lastRecordingDuration: number;
}

/**
 * Audio recording hook return interface
 */
interface UseAudioRecordingReturn extends AudioRecordingState {
  /** Start or request to start recording */
  startRecording: () => void;
  /** Handle recording completion */
  handleRecordingComplete: (audioBlob: Blob, duration: number) => void;
  /** Handle recording error */
  handleRecordingError: (error: string) => void;
  /** Handle recording state change */
  handleRecordingStateChange: (state: RecordingState) => void;
  /** Handle permission granted */
  handlePermissionGranted: () => void;
  /** Handle permission denied */
  handlePermissionDenied: (reason: string) => void;
  /** Close permission dialog */
  closePermissionDialog: () => void;
  /** Clear the last recording */
  clearRecording: () => void;
  /** Reset all state */
  resetRecording: () => void;
}

/**
 * Custom hook for audio recording functionality
 * 
 * @param onRecordingComplete - Callback when recording is successfully completed
 * @returns Audio recording state and control functions
 */
export function useAudioRecording(
  onRecordingComplete?: (audioBlob: Blob, duration: number) => void
): UseAudioRecordingReturn {
  // State management
  const [state, setState] = useState<AudioRecordingState>({
    recordingState: RecordingState.IDLE,
    isPermissionDialogOpen: false,
    hasPermission: false,
    errorMessage: null,
    showTroubleshooting: false,
    lastRecording: null,
    lastRecordingDuration: 0
  });

  /**
   * Check if microphone permission has been granted
   */
  const checkPermission = useCallback(async (): Promise<boolean> => {
    try {
      logger.debug('🔍 Checking microphone permission status');
      
      // Try to check permission status first
      if (navigator.permissions && 'microphone' in navigator.permissions) {
        const permission = await navigator.permissions.query({ name: 'microphone' as PermissionName });
        const isGranted = permission.state === 'granted';
        
        logger.info('📊 Permission check result', { state: permission.state, isGranted });
        
        setState(prev => ({ ...prev, hasPermission: isGranted }));
        return isGranted;
      }
      
      // Fallback: assume we need to request permission
      logger.warn('⚠️ Permissions API not available, will request permission');
      return false;
      
    } catch (error) {
      logger.error('❌ Error checking permission', { 
        error: error instanceof Error ? error.message : String(error) 
      });
      return false;
    }
  }, []);

  /**
   * Start recording or show permission dialog
   */
  const startRecording = useCallback(async () => {
    logger.info('🎤 Start recording requested');
    
    // Clear any previous errors
    setState(prev => ({ ...prev, errorMessage: null }));
    
    // Check if we have permission
    const hasPermission = await checkPermission();
    
    if (!hasPermission) {
      logger.info('🔐 Permission required, showing dialog');
      setState(prev => ({ 
        ...prev, 
        isPermissionDialogOpen: true,
        showTroubleshooting: false 
      }));
    } else {
      logger.info('✅ Permission already granted, triggering recording');
      setState(prev => ({ 
        ...prev, 
        hasPermission: true,
        recordingState: RecordingState.REQUESTING_PERMISSION // This will show the AudioRecorder
      }));
    }
  }, [checkPermission]);

  /**
   * Handle recording completion
   */
  const handleRecordingComplete = useCallback((audioBlob: Blob, duration: number) => {
    logger.info('✅ Recording completed', { 
      blobSize: audioBlob.size, 
      duration,
      mimeType: audioBlob.type 
    });
    
    // Create a URL for the audio blob to enable playback
    const audioUrl = URL.createObjectURL(audioBlob);
    logger.info('🔊 Audio playback URL created', { url: audioUrl });
    
    // Create an audio element to play the recording
    const audio = new Audio(audioUrl);
    audio.volume = 0.7;
    
    // Log when audio plays
    audio.onplay = () => logger.info('▶️ Playing back recorded audio');
    audio.onended = () => {
      logger.info('⏹️ Audio playback finished');
      URL.revokeObjectURL(audioUrl); // Clean up the URL
    };
    
    // Play the audio automatically for testing
    audio.play().catch(err => {
      logger.error('❌ Failed to play audio', { error: err.message });
    });
    
    setState(prev => ({
      ...prev,
      recordingState: RecordingState.IDLE,
      lastRecording: audioBlob,
      lastRecordingDuration: duration,
      errorMessage: null
    }));
    
    // Call the provided callback
    onRecordingComplete?.(audioBlob, duration);
  }, [onRecordingComplete]);

  /**
   * Handle recording error
   */
  const handleRecordingError = useCallback((error: string) => {
    logger.error('❌ Recording error', { error });
    
    setState(prev => ({
      ...prev,
      recordingState: RecordingState.ERROR,
      errorMessage: error,
      showTroubleshooting: true
    }));
    
    // Check if it's a permission error and show dialog
    if (error.toLowerCase().includes('permission') || 
        error.toLowerCase().includes('denied') ||
        error.toLowerCase().includes('microphone')) {
      setState(prev => ({
        ...prev,
        isPermissionDialogOpen: true,
        showTroubleshooting: true,
        hasPermission: false
      }));
    }
  }, []);

  /**
   * Handle recording state change
   */
  const handleRecordingStateChange = useCallback((newState: RecordingState) => {
    setState(prev => {
      logger.debug('🔄 Recording state changed', { 
        from: prev.recordingState, 
        to: newState 
      });
      
      return { ...prev, recordingState: newState };
    });
  }, []); // No dependencies to ensure callback stability

  /**
   * Handle permission granted
   */
  const handlePermissionGranted = useCallback(() => {
    logger.info('✅ Microphone permission granted');
    
    setState(prev => ({
      ...prev,
      hasPermission: true,
      isPermissionDialogOpen: false,
      errorMessage: null,
      showTroubleshooting: false,
      recordingState: RecordingState.REQUESTING_PERMISSION // This will show the AudioRecorder
    }));
  }, []);

  /**
   * Handle permission denied
   */
  const handlePermissionDenied = useCallback((reason: string) => {
    logger.error('❌ Microphone permission denied', { reason });
    
    setState(prev => ({
      ...prev,
      hasPermission: false,
      errorMessage: `Microphone access denied: ${reason}`,
      showTroubleshooting: true
    }));
  }, []);

  /**
   * Close permission dialog
   */
  const closePermissionDialog = useCallback(() => {
    logger.debug('🚪 Closing permission dialog');
    
    setState(prev => ({
      ...prev,
      isPermissionDialogOpen: false
    }));
  }, []);

  /**
   * Clear the last recording
   */
  const clearRecording = useCallback(() => {
    logger.debug('🗑️ Clearing last recording');
    
    setState(prev => ({
      ...prev,
      lastRecording: null,
      lastRecordingDuration: 0
    }));
  }, []);

  /**
   * Reset all recording state
   */
  const resetRecording = useCallback(() => {
    logger.info('🔄 Resetting all recording state');
    
    setState({
      recordingState: RecordingState.IDLE,
      isPermissionDialogOpen: false,
      hasPermission: false,
      errorMessage: null,
      showTroubleshooting: false,
      lastRecording: null,
      lastRecordingDuration: 0
    });
  }, []);

  return {
    ...state,
    startRecording,
    handleRecordingComplete,
    handleRecordingError,
    handleRecordingStateChange,
    handlePermissionGranted,
    handlePermissionDenied,
    closePermissionDialog,
    clearRecording,
    resetRecording
  };
}

================
File: src/main.tsx
================
import React from 'react';
import ReactDOM from 'react-dom/client';

import App from './App';
import { initializeApplication, setupGracefulShutdown, enableDevelopmentMode } from './utils/startup';
import { logger } from './utils/logger';

import './index.css';
import './styles/globals.css';
import './styles/components.css';
import './styles/responsive.css';

// Log successful CSS loading
console.log('🎨 FlowGenius CSS styles loaded successfully:', {
  globals: 'OpenAI-inspired design system with CSS custom properties',
  components: 'Component-specific styles with button, input, and card variants',
  responsive: 'Desktop-focused responsive design for Electron window resizing',
  timestamp: new Date().toISOString()
});

import './demos/ipc';
// If you want use Node.js, the`nodeIntegration` needs to be enabled in the Main process.
// import './demos/node'

/**
 * Application startup with environment validation
 */
async function startApplication(): Promise<void> {
  try {
    logger.info('🎯 FlowGenius application starting...');
    
    // Enable development mode if applicable
    enableDevelopmentMode();
    
    // Setup graceful shutdown handlers
    setupGracefulShutdown();
    
    // Initialize application with environment validation
    const startupResult = await initializeApplication();
    
    if (!startupResult.success || !startupResult.canContinue) {
      logger.error('❌ Application startup failed, cannot continue');
      
      // Render error state instead of main app
      ReactDOM.createRoot(document.getElementById('root') as HTMLElement).render(
        <React.StrictMode>
          <div style={{ 
            padding: '2rem', 
            fontFamily: 'system-ui, sans-serif',
            backgroundColor: '#1a1a1a',
            color: '#ffffff',
            minHeight: '100vh',
            display: 'flex',
            flexDirection: 'column',
            justifyContent: 'center',
            alignItems: 'center'
          }}>
            <h1 style={{ color: '#ef4444', marginBottom: '1rem' }}>
              ❌ FlowGenius Startup Failed
            </h1>
            <div style={{ marginBottom: '2rem', textAlign: 'center' }}>
              <p>The application could not start due to configuration issues:</p>
              <ul style={{ textAlign: 'left', marginTop: '1rem' }}>
                {startupResult.errors.map((error, index) => (
                  <li key={index} style={{ margin: '0.5rem 0' }}>• {error}</li>
                ))}
              </ul>
            </div>
            <div style={{ 
              backgroundColor: '#374151', 
              padding: '1rem', 
              borderRadius: '0.5rem',
              textAlign: 'left',
              fontSize: '0.875rem'
            }}>
              <p><strong>Next Steps:</strong></p>
              <ol style={{ marginTop: '0.5rem', paddingLeft: '1.5rem' }}>
                <li>Create a .env file in your project root</li>
                <li>Copy the contents of .env.example</li>
                <li>Fill in your actual API keys and URLs</li>
                <li>Restart the application</li>
              </ol>
            </div>
          </div>
        </React.StrictMode>
      );
      return;
    }
    
    logger.info('✅ Application startup successful, rendering main app');
    
    // Render the main application
    ReactDOM.createRoot(document.getElementById('root') as HTMLElement).render(
      <React.StrictMode>
        <App />
      </React.StrictMode>,
    );
    
  } catch (error) {
    logger.error('💥 Critical error during application startup', { error: error as Error });
    
    // Render critical error state
    ReactDOM.createRoot(document.getElementById('root') as HTMLElement).render(
      <React.StrictMode>
        <div style={{ 
          padding: '2rem', 
          fontFamily: 'system-ui, sans-serif',
          backgroundColor: '#1a1a1a',
          color: '#ffffff',
          minHeight: '100vh',
          display: 'flex',
          flexDirection: 'column',
          justifyContent: 'center',
          alignItems: 'center'
        }}>
          <h1 style={{ color: '#ef4444', marginBottom: '1rem' }}>
            💥 Critical Error
          </h1>
          <p>A critical error occurred during application startup.</p>
          <p style={{ marginTop: '1rem', fontSize: '0.875rem', color: '#9ca3af' }}>
            Check the console for detailed error information.
          </p>
        </div>
      </React.StrictMode>
    );
  } finally {
    // Remove loading indicator regardless of startup result
    postMessage({ payload: 'removeLoading' }, '*');
  }
}

// Start the application
startApplication();

================
File: electron/main/index.ts
================
import { config } from 'dotenv'
import { app, BrowserWindow, shell, ipcMain } from 'electron'
import { fileURLToPath } from 'node:url'
import path from 'node:path'
import os from 'node:os'
import { update } from './update'
import { initializeLangGraphHandlers, cleanupLangGraphHandlers } from './langgraph-handler'
import { initializeAudioSystem, cleanupAudioHandlers } from './audio-ipc-handlers'

const __dirname = path.dirname(fileURLToPath(import.meta.url))

// Load environment variables from .env file
config({ path: path.join(__dirname, '../../.env') });

// The built directory structure
//
// ├─┬ dist-electron
// │ ├─┬ main
// │ │ └── index.js    > Electron-Main
// │ └─┬ preload
// │   └── index.mjs   > Preload-Scripts
// ├─┬ dist
// │ └── index.html    > Electron-Renderer
//
process.env.APP_ROOT = path.join(__dirname, '../..')

export const MAIN_DIST = path.join(process.env.APP_ROOT, 'dist-electron')
export const RENDERER_DIST = path.join(process.env.APP_ROOT, 'dist')
export const VITE_DEV_SERVER_URL = process.env.VITE_DEV_SERVER_URL

process.env.VITE_PUBLIC = VITE_DEV_SERVER_URL
  ? path.join(process.env.APP_ROOT, 'public')
  : RENDERER_DIST

// Disable GPU Acceleration for Windows 7
if (os.release().startsWith('6.1')) app.disableHardwareAcceleration()

// Set application name for Windows 10+ notifications
if (process.platform === 'win32') app.setAppUserModelId(app.getName())

if (!app.requestSingleInstanceLock()) {
  app.quit()
  process.exit(0)
}

let win: BrowserWindow | null = null
const preload = path.join(__dirname, '../preload/index.mjs')
const indexHtml = path.join(RENDERER_DIST, 'index.html')

async function createWindow() {
  win = new BrowserWindow({
    title: 'Main window',
    icon: path.join(process.env.VITE_PUBLIC, 'favicon.ico'),
    webPreferences: {
      preload,
      // Warning: Enable nodeIntegration and disable contextIsolation is not secure in production
      // nodeIntegration: true,

      // Consider using contextBridge.exposeInMainWorld
      // Read more on https://www.electronjs.org/docs/latest/tutorial/context-isolation
      // contextIsolation: false,
    },
  })

  if (VITE_DEV_SERVER_URL) { // #298
    win.loadURL(VITE_DEV_SERVER_URL)
    // Open devTool if the app is not packaged
    win.webContents.openDevTools()
  } else {
    win.loadFile(indexHtml)
  }

  // Test actively push message to the Electron-Renderer
  win.webContents.on('did-finish-load', () => {
    win?.webContents.send('main-process-message', new Date().toLocaleString())
  })

  // Make all links open with the browser, not with the application
  win.webContents.setWindowOpenHandler(({ url }) => {
    if (url.startsWith('https:')) shell.openExternal(url)
    return { action: 'deny' }
  })

  // Auto update
  update(win)
}

app.whenReady().then(async () => {
  // Initialize environment variables IPC handler
  initializeEnvironmentHandlers()
  
  // Initialize LangGraph IPC handlers
  initializeLangGraphHandlers()
  
  // Initialize Audio system
  try {
    await initializeAudioSystem()
    console.log('✅ Audio system initialized')
  } catch (error) {
    console.error('❌ Failed to initialize audio system:', error)
  }
  
  // Create main window
  createWindow()
})

app.on('window-all-closed', () => {
  win = null
  if (process.platform !== 'darwin') {
    // Cleanup LangGraph handlers before quitting
    cleanupLangGraphHandlers()
    // Cleanup Audio handlers before quitting
    cleanupAudioHandlers()
    app.quit()
  }
})

app.on('second-instance', () => {
  if (win) {
    // Focus on the main window if the user tried to open another
    if (win.isMinimized()) win.restore()
    win.focus()
  }
})

app.on('activate', () => {
  const allWindows = BrowserWindow.getAllWindows()
  if (allWindows.length > 0) {
    allWindows[0]?.focus()
  } else {
    createWindow()
  }
})

/**
 * Initialize environment variables IPC handlers
 * Provides secure access to environment variables from renderer process
 */
function initializeEnvironmentHandlers(): void {
  console.log('🔐 Initializing environment variable IPC handlers');

  /**
   * Get environment variables needed by renderer process
   * Only exposes necessary environment variables for security
   */
  ipcMain.handle('env:get-vars', async () => {
    try {
      console.log('📨 IPC: Getting environment variables');

      // Only expose the environment variables that are actually needed
      // This is a security best practice - never expose all process.env
      const envVars = {
        OPENAI_API_KEY: process.env.OPENAI_API_KEY,
        NODE_ENV: process.env.NODE_ENV,
        // Add other necessary env vars here as needed
        SUPABASE_URL: process.env.SUPABASE_URL,
        SUPABASE_ANON_KEY: process.env.SUPABASE_ANON_KEY
      };

      console.log('✅ IPC: Environment variables retrieved', {
        hasOpenAIKey: !!envVars.OPENAI_API_KEY,
        nodeEnv: envVars.NODE_ENV,
        hasSupabaseUrl: !!envVars.SUPABASE_URL,
        hasSupabaseKey: !!envVars.SUPABASE_ANON_KEY
      });

      return {
        success: true,
        data: envVars
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      
      console.error('❌ IPC: Failed to get environment variables', {
        error: errorMessage
      });

      return {
        success: false,
        error: errorMessage
      };
    }
  });

  console.log('✅ Environment variable IPC handlers initialized');
}

// New window example arg: new windows url
ipcMain.handle('open-win', (_, arg) => {
  const childWindow = new BrowserWindow({
    webPreferences: {
      preload,
      nodeIntegration: true,
      contextIsolation: false,
    },
  })

  if (VITE_DEV_SERVER_URL) {
    childWindow.loadURL(`${VITE_DEV_SERVER_URL}#${arg}`)
  } else {
    childWindow.loadFile(indexHtml, { hash: arg })
  }
})

================
File: electron/preload/index.ts
================
import { ipcRenderer, contextBridge } from 'electron'

// --------- Expose some API to the Renderer process ---------
contextBridge.exposeInMainWorld('ipcRenderer', {
  on(...args: Parameters<typeof ipcRenderer.on>) {
    const [channel, listener] = args
    return ipcRenderer.on(channel, (event, ...args) => listener(event, ...args))
  },
  off(...args: Parameters<typeof ipcRenderer.off>) {
    const [channel, ...omit] = args
    return ipcRenderer.off(channel, ...omit)
  },
  send(...args: Parameters<typeof ipcRenderer.send>) {
    const [channel, ...omit] = args
    return ipcRenderer.send(channel, ...omit)
  },
  invoke(...args: Parameters<typeof ipcRenderer.invoke>) {
    const [channel, ...omit] = args
    return ipcRenderer.invoke(channel, ...omit)
  },

  // You can expose other APTs you need here.
  // ...
})

// --------- Expose LangGraph API ---------
contextBridge.exposeInMainWorld('langgraph', {
  execute: (state: any) => ipcRenderer.invoke('langgraph:execute', state),
  createSession: (ideaId: string, userId?: string) => 
    ipcRenderer.invoke('langgraph:createSession', ideaId, userId),
  validateState: (state: any) => ipcRenderer.invoke('langgraph:validateState', state),
  getMetrics: (ideaId: string) => ipcRenderer.invoke('langgraph:getMetrics', ideaId),
  clearSession: (ideaId: string) => ipcRenderer.invoke('langgraph:clearSession', ideaId),
})

// --------- Expose APIs ---------
contextBridge.exposeInMainWorld('electron', {
  // Audio API
  audio: {
    saveAudioFile: (audioData: Buffer, originalName?: string, mimeType?: string) => 
      ipcRenderer.invoke('audio:save-file', audioData, originalName, mimeType),
    
    convertAudioFile: (inputPath: string, options?: any) => 
      ipcRenderer.invoke('audio:convert-file', inputPath, options),
    
    getAudioFileInfo: (filePath: string) => 
      ipcRenderer.invoke('audio:get-file-info', filePath),
    
    deleteAudioFile: (filePath: string) => 
      ipcRenderer.invoke('audio:delete-file', filePath),
    
    cleanupOldFiles: (maxAge?: number) => 
      ipcRenderer.invoke('audio:cleanup-old-files', maxAge),
    
    getTempDirectory: () => 
      ipcRenderer.invoke('audio:get-temp-directory'),
    
    getActiveFiles: () => 
      ipcRenderer.invoke('audio:get-active-files')
  },

  // Environment Variables API
  env: {
    getVars: () => 
      ipcRenderer.invoke('env:get-vars')
  }
})

// --------- Preload scripts loading ---------
function domReady(condition: DocumentReadyState[] = ['complete', 'interactive']) {
  return new Promise(resolve => {
    if (condition.includes(document.readyState)) {
      resolve(true)
    } else {
      document.addEventListener('readystatechange', () => {
        if (condition.includes(document.readyState)) {
          resolve(true)
        }
      })
    }
  })
}

const safeDOM = {
  append(parent: HTMLElement, child: HTMLElement): HTMLElement | undefined {
    if (!Array.from(parent.children).find(e => e === child)) {
      return parent.appendChild(child)
    }
    return undefined
  },
  remove(parent: HTMLElement, child: HTMLElement): HTMLElement | undefined {
    if (Array.from(parent.children).find(e => e === child)) {
      return parent.removeChild(child)
    }
    return undefined
  },
}

/**
 * https://tobiasahlin.com/spinkit
 * https://connoratherton.com/loaders
 * https://projects.lukehaas.me/css-loaders
 * https://matejkustec.github.io/SpinThatShit
 */
function useLoading() {
  const className = `loaders-css__square-spin`
  const styleContent = `
@keyframes square-spin {
  25% { transform: perspective(100px) rotateX(180deg) rotateY(0); }
  50% { transform: perspective(100px) rotateX(180deg) rotateY(180deg); }
  75% { transform: perspective(100px) rotateX(0) rotateY(180deg); }
  100% { transform: perspective(100px) rotateX(0) rotateY(0); }
}
.${className} > div {
  animation-fill-mode: both;
  width: 50px;
  height: 50px;
  background: #fff;
  animation: square-spin 3s 0s cubic-bezier(0.09, 0.57, 0.49, 0.9) infinite;
}
.app-loading-wrap {
  position: fixed;
  top: 0;
  left: 0;
  width: 100vw;
  height: 100vh;
  display: flex;
  align-items: center;
  justify-content: center;
  background: #282c34;
  z-index: 9;
}
    `
  const oStyle = document.createElement('style')
  const oDiv = document.createElement('div')

  oStyle.id = 'app-loading-style'
  oStyle.innerHTML = styleContent
  oDiv.className = 'app-loading-wrap'
  oDiv.innerHTML = `<div class="${className}"><div></div></div>`

  return {
    appendLoading() {
      safeDOM.append(document.head, oStyle)
      safeDOM.append(document.body, oDiv)
    },
    removeLoading() {
      safeDOM.remove(document.head, oStyle)
      safeDOM.remove(document.body, oDiv)
    },
  }
}

// ----------------------------------------------------------------------

const { appendLoading, removeLoading } = useLoading()
domReady().then(appendLoading)

window.onmessage = (ev) => {
  if (ev.data.payload === 'removeLoading') {
    removeLoading()
  }
}

setTimeout(removeLoading, 4999)

================
File: src/components/AudioRecorder.tsx
================
/**
 * AudioRecorder Component
 * 
 * A React component for recording audio using the MediaRecorder API.
 * Provides voice recording functionality for FlowGenius with proper browser compatibility,
 * error handling, and visual feedback during recording.
 * 
 * Features:
 * - MediaRecorder API integration with fallback support
 * - Microphone permission handling
 * - Real-time recording feedback
 * - Audio format validation
 * - Comprehensive error handling
 * - Accessibility features
 */

import React, { useState, useRef, useCallback, useEffect } from 'react';
import { logger } from '../utils/logger';
import { handleAudioError } from '../utils/errorHandler';

/**
 * Global registry to track all active MediaRecorder instances
 * This helps prevent memory leaks when components remount
 */
const globalMediaRecorderRegistry = new Map<string, { mediaRecorder: MediaRecorder; instanceId: string }>();

/**
 * Global cleanup function to stop all orphaned MediaRecorder instances
 */
function cleanupAllMediaRecorders() {
  logger.info('🧹 Global cleanup: Stopping all registered MediaRecorder instances', { 
    activeCount: globalMediaRecorderRegistry.size 
  });
  
  for (const [id, { mediaRecorder, instanceId }] of globalMediaRecorderRegistry.entries()) {
    try {
      if (mediaRecorder.state === 'recording' || mediaRecorder.state === 'paused') {
        logger.warn('🛑 Force stopping orphaned MediaRecorder', { instanceId, state: mediaRecorder.state });
        mediaRecorder.stop();
      }
      
      // Clear event handlers
      mediaRecorder.ondataavailable = null;
      mediaRecorder.onstop = null;
      mediaRecorder.onstart = null;
      mediaRecorder.onerror = null;
      mediaRecorder.onpause = null;
      mediaRecorder.onresume = null;
    } catch (error) {
      logger.warn('⚠️ Error cleaning up orphaned MediaRecorder', { 
        instanceId, 
        error: error instanceof Error ? error.message : String(error) 
      });
    }
  }
  
  globalMediaRecorderRegistry.clear();
  logger.info('✅ Global cleanup completed');
}

/**
 * Recording state enumeration
 */
export enum RecordingState {
  IDLE = 'idle',
  REQUESTING_PERMISSION = 'requesting_permission',
  RECORDING = 'recording',
  STOPPING = 'stopping',
  ERROR = 'error'
}

/**
 * Audio recording configuration
 */
interface AudioConfig {
  /** Audio sample rate (default: 44100) */
  sampleRate?: number;
  /** Number of audio channels (default: 1) */
  channelCount?: number;
  /** Audio bit depth (default: 16) */
  bitsPerSample?: number;
  /** Maximum recording duration in seconds (default: 300) */
  maxDurationSeconds?: number;
  /** Preferred audio format (default: 'audio/webm') */
  mimeType?: string;
}

/**
 * Props interface for AudioRecorder component
 */
interface AudioRecorderProps {
  /** Callback when recording is completed successfully */
  onRecordingComplete: (audioBlob: Blob, duration: number) => void;
  /** Callback when recording fails */
  onRecordingError: (error: string) => void;
  /** Callback when recording state changes */
  onStateChange?: (state: RecordingState) => void;
  /** Audio recording configuration */
  config?: AudioConfig;
  /** Whether the recorder is disabled */
  disabled?: boolean;
  /** Custom CSS class name */
  className?: string;
  /** Whether to show visual feedback during recording */
  showVisualFeedback?: boolean;
  /** Whether to auto-start recording on mount */
  autoStart?: boolean;
}

/**
 * Default audio configuration optimized for speech recognition
 */
const DEFAULT_AUDIO_CONFIG: Required<AudioConfig> = {
  sampleRate: 44100,
  channelCount: 1,
  bitsPerSample: 16,
  maxDurationSeconds: 300, // 5 minutes
  mimeType: 'audio/webm'
};

/**
 * Supported audio MIME types in order of preference (prioritizing OpenAI Whisper compatibility)
 */
const SUPPORTED_MIME_TYPES = [
  'audio/mp4',
  'audio/mp4;codecs=mp4a.40.2',
  'audio/mpeg',
  'audio/webm',
  'audio/webm;codecs=opus',
  'audio/ogg;codecs=opus',
  'audio/ogg',
  'audio/wav'
];

/**
 * AudioRecorder component for capturing voice input
 */
export const AudioRecorder: React.FC<AudioRecorderProps> = ({
  onRecordingComplete,
  onRecordingError,
  onStateChange,
  config = {},
  disabled = false,
  className = '',
  showVisualFeedback = true,
  autoStart = false
}) => {
  // Merge user config with defaults
  const audioConfig = { ...DEFAULT_AUDIO_CONFIG, ...config };
  
  // Component state
  const [recordingState, setRecordingState] = useState<RecordingState>(RecordingState.IDLE);
  const [recordingDuration, setRecordingDuration] = useState<number>(0);
  const [audioLevel, setAudioLevel] = useState<number>(0);
  const [errorMessage, setErrorMessage] = useState<string>('');

  // Refs for MediaRecorder and related objects
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const recordingStartTimeRef = useRef<number>(0);
  const durationIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const audioLevelIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const lastChunkLogTimeRef = useRef<number>(0);
  const chunkCountSinceLastLogRef = useRef<number>(0);
  const instanceIdRef = useRef<string>(`recorder_${Date.now()}_${Math.random().toString(36).substring(2, 8)}`);

  /**
   * Update recording state and notify parent component
   */
  const updateRecordingState = useCallback((newState: RecordingState) => {
    logger.info('🎤 AudioRecorder: State change', { 
      from: recordingState, 
      to: newState,
      instanceId: instanceIdRef.current,
      timestamp: new Date()
    });
    
    setRecordingState(newState);
    onStateChange?.(newState);
  }, [recordingState, onStateChange]);

  /**
   * Check browser compatibility for MediaRecorder API
   */
  const checkBrowserCompatibility = useCallback((): { supported: boolean; mimeType: string } => {
    logger.debug('🔍 AudioRecorder: Checking browser compatibility');

    // Check if MediaRecorder is supported
    if (!window.MediaRecorder) {
      logger.error('❌ AudioRecorder: MediaRecorder API not supported');
      return { supported: false, mimeType: '' };
    }

    // Find the best supported MIME type
    for (const mimeType of SUPPORTED_MIME_TYPES) {
      if (MediaRecorder.isTypeSupported(mimeType)) {
        logger.info('✅ AudioRecorder: Found supported MIME type', { mimeType });
        return { supported: true, mimeType };
      }
    }

    // Fallback to basic support check
    const fallbackMimeType = 'audio/webm';
    const isSupported = MediaRecorder.isTypeSupported(fallbackMimeType);
    
    logger.warn('⚠️ AudioRecorder: Using fallback MIME type', { 
      mimeType: fallbackMimeType, 
      supported: isSupported 
    });
    
    return { supported: isSupported, mimeType: fallbackMimeType };
  }, []);

  /**
   * Request microphone permission and get media stream
   */
  const requestMicrophoneAccess = useCallback(async (): Promise<MediaStream> => {
    logger.info('🎤 AudioRecorder: Requesting microphone access');

    try {
      const constraints: MediaStreamConstraints = {
        audio: {
          sampleRate: audioConfig.sampleRate,
          channelCount: audioConfig.channelCount,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        },
        video: false
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      
      logger.info('✅ AudioRecorder: Microphone access granted', {
        tracks: stream.getAudioTracks().length,
        settings: stream.getAudioTracks()[0]?.getSettings()
      });

      return stream;
    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      logger.error('❌ AudioRecorder: Microphone access denied', { error: errorMsg });
      
      if (errorMsg.includes('Permission denied') || errorMsg.includes('NotAllowedError')) {
        throw new Error('Microphone permission denied. Please allow microphone access and try again.');
      } else if (errorMsg.includes('NotFoundError')) {
        throw new Error('No microphone found. Please connect a microphone and try again.');
      } else if (errorMsg.includes('NotReadableError')) {
        throw new Error('Microphone is being used by another application. Please close other apps and try again.');
      } else {
        throw new Error(`Microphone access failed: ${errorMsg}`);
      }
    }
  }, [audioConfig]);

  /**
   * Set up audio level monitoring for visual feedback
   */
  const setupAudioLevelMonitoring = useCallback((stream: MediaStream) => {
    if (!showVisualFeedback) return;

    try {
      logger.debug('📊 AudioRecorder: Setting up audio level monitoring');

      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const analyser = audioContext.createAnalyser();
      const microphone = audioContext.createMediaStreamSource(stream);
      
      analyser.fftSize = 256;
      analyser.smoothingTimeConstant = 0.8;
      microphone.connect(analyser);

      audioContextRef.current = audioContext;
      analyserRef.current = analyser;

      // Start monitoring audio levels
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      
      audioLevelIntervalRef.current = setInterval(() => {
        if (analyserRef.current && recordingState === RecordingState.RECORDING) {
          analyserRef.current.getByteFrequencyData(dataArray);
          
          // Calculate average audio level (0-100)
          const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
          const normalizedLevel = Math.round((average / 255) * 100);
          
          setAudioLevel(normalizedLevel);
        }
      }, 100);

      logger.info('✅ AudioRecorder: Audio level monitoring started');
    } catch (error) {
      logger.warn('⚠️ AudioRecorder: Failed to set up audio level monitoring', { 
        error: error instanceof Error ? error.message : String(error) 
      });
      // Continue without audio level monitoring
    }
  }, [showVisualFeedback, recordingState]);

  /**
   * Start recording audio
   */
  const startRecording = useCallback(async () => {
    if (disabled || recordingState !== RecordingState.IDLE) {
      logger.debug('🚫 AudioRecorder: Start recording blocked', { disabled, recordingState });
      return;
    }

    logger.info('🎤 AudioRecorder: Starting recording process');
    updateRecordingState(RecordingState.REQUESTING_PERMISSION);
    setErrorMessage('');
    setRecordingDuration(0);
    setAudioLevel(0);

    try {
      // Check browser compatibility
      const { supported, mimeType } = checkBrowserCompatibility();
      if (!supported) {
        throw new Error('Audio recording is not supported in this browser. Please use Chrome, Firefox, or Safari.');
      }

      // Request microphone access
      const stream = await requestMicrophoneAccess();
      mediaStreamRef.current = stream;

      // Set up audio level monitoring
      setupAudioLevelMonitoring(stream);

      // Clean up any existing orphaned instances before creating new one
      if (globalMediaRecorderRegistry.size > 0) {
        logger.warn('⚠️ Found orphaned MediaRecorder instances before creating new one', { 
          orphanedCount: globalMediaRecorderRegistry.size,
          instanceId: instanceIdRef.current
        });
        cleanupAllMediaRecorders();
      }

      // Create MediaRecorder
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: mimeType || audioConfig.mimeType
      });

      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      // Register MediaRecorder in global registry
      const registryKey = `${instanceIdRef.current}_${Date.now()}`;
      globalMediaRecorderRegistry.set(registryKey, { 
        mediaRecorder, 
        instanceId: instanceIdRef.current 
      });
      
      logger.info('📝 MediaRecorder registered globally', { 
        instanceId: instanceIdRef.current,
        registryKey,
        totalActive: globalMediaRecorderRegistry.size
      });

      // Set up MediaRecorder event handlers
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
          chunkCountSinceLastLogRef.current++;
          
          // Throttle logging: log every 2 seconds or every 20 chunks, whichever comes first
          const now = Date.now();
          const timeSinceLastLog = now - lastChunkLogTimeRef.current;
          const shouldLog = timeSinceLastLog >= 2000 || chunkCountSinceLastLogRef.current >= 20;
          
          if (shouldLog) {
            logger.debug('📊 AudioRecorder: Data chunks received', { 
              latestChunkSize: event.data.size,
              totalChunks: audioChunksRef.current.length,
              chunksInPeriod: chunkCountSinceLastLogRef.current,
              periodMs: timeSinceLastLog,
              instanceId: instanceIdRef.current
            });
            
            lastChunkLogTimeRef.current = now;
            chunkCountSinceLastLogRef.current = 0;
          }
        }
      };

      mediaRecorder.onstop = () => {
        logger.info('🛑 AudioRecorder: Recording stopped');
        
        const audioBlob = new Blob(audioChunksRef.current, { 
          type: mimeType || audioConfig.mimeType 
        });
        
        // Calculate actual duration from timestamps
        const actualDuration = Math.floor((Date.now() - recordingStartTimeRef.current) / 1000);
        
        logger.info('✅ AudioRecorder: Recording completed', {
          blobSize: audioBlob.size,
          duration: actualDuration,
          mimeType: audioBlob.type
        });

        // Clean up
        cleanupRecording();
        
        // Notify completion with actual duration
        onRecordingComplete(audioBlob, actualDuration);
        updateRecordingState(RecordingState.IDLE);
      };

      mediaRecorder.onerror = (event) => {
        const error = (event as any).error || new Error('Recording failed');
        logger.error('❌ AudioRecorder: MediaRecorder error', { error: error.message });
        handleRecordingError(error.message);
      };

      // Start recording
      mediaRecorder.start(100); // Collect data every 100ms
      recordingStartTimeRef.current = Date.now();
      updateRecordingState(RecordingState.RECORDING);

      // Start duration tracking
      durationIntervalRef.current = setInterval(() => {
        const elapsed = Math.floor((Date.now() - recordingStartTimeRef.current) / 1000);
        setRecordingDuration(elapsed);

        // Check max duration
        if (elapsed >= audioConfig.maxDurationSeconds) {
          logger.warn('⏰ AudioRecorder: Maximum recording duration reached');
          stopRecording();
        }
      }, 1000);

      logger.info('✅ AudioRecorder: Recording started successfully');

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      logger.error('❌ AudioRecorder: Failed to start recording', { error: errorMsg });
      handleRecordingError(errorMsg);
    }
  }, [disabled, recordingState, updateRecordingState, checkBrowserCompatibility, requestMicrophoneAccess, setupAudioLevelMonitoring, audioConfig, onRecordingComplete]);

  /**
   * Stop recording audio
   */
  const stopRecording = useCallback(() => {
    if (recordingState !== RecordingState.RECORDING) {
      logger.debug('🚫 AudioRecorder: Stop recording blocked', { recordingState });
      return;
    }

    logger.info('🛑 AudioRecorder: Stopping recording');
    updateRecordingState(RecordingState.STOPPING);

    try {
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.stop();
      }
    } catch (error) {
      logger.error('❌ AudioRecorder: Error stopping MediaRecorder', { 
        error: error instanceof Error ? error.message : String(error) 
      });
    }
  }, [recordingState, updateRecordingState]);

  /**
   * Handle recording errors
   */
  const handleRecordingError = useCallback((errorMessage: string) => {
    logger.error('❌ AudioRecorder: Recording error occurred', { errorMessage });
    
    const errorInfo = handleAudioError(new Error(errorMessage), 'recording');
    setErrorMessage(errorInfo.userMessage);
    updateRecordingState(RecordingState.ERROR);
    
    cleanupRecording();
    onRecordingError(errorInfo.userMessage);
  }, [updateRecordingState, onRecordingError]);

  /**
   * Clean up recording resources
   */
  const cleanupRecording = useCallback(() => {
    logger.debug('🧹 AudioRecorder: Cleaning up recording resources', { 
      instanceId: instanceIdRef.current 
    });

    // Clear intervals
    if (durationIntervalRef.current) {
      clearInterval(durationIntervalRef.current);
      durationIntervalRef.current = null;
    }

    if (audioLevelIntervalRef.current) {
      clearInterval(audioLevelIntervalRef.current);
      audioLevelIntervalRef.current = null;
    }

    // Clean up MediaRecorder and clear event handlers to prevent memory leaks
    if (mediaRecorderRef.current) {
      const mediaRecorder = mediaRecorderRef.current;
      
      // Stop recording if still active
      if (mediaRecorder.state === 'recording' || mediaRecorder.state === 'paused') {
        try {
          mediaRecorder.stop();
          logger.debug('🛑 AudioRecorder: Forced MediaRecorder stop during cleanup', { 
            instanceId: instanceIdRef.current 
          });
        } catch (error) {
          logger.warn('⚠️ AudioRecorder: Error stopping MediaRecorder during cleanup', { 
            instanceId: instanceIdRef.current,
            error: error instanceof Error ? error.message : String(error) 
          });
        }
      }
      
      // Clear all event handlers to prevent orphaned callbacks
      mediaRecorder.ondataavailable = null;
      mediaRecorder.onstop = null;
      mediaRecorder.onstart = null;
      mediaRecorder.onerror = null;
      mediaRecorder.onpause = null;
      mediaRecorder.onresume = null;
      
      // Remove from global registry
      for (const [key, { mediaRecorder: registeredRecorder, instanceId }] of globalMediaRecorderRegistry.entries()) {
        if (registeredRecorder === mediaRecorder || instanceId === instanceIdRef.current) {
          globalMediaRecorderRegistry.delete(key);
          logger.debug('🗑️ MediaRecorder unregistered from global registry', { 
            instanceId: instanceIdRef.current,
            registryKey: key,
            remainingActive: globalMediaRecorderRegistry.size
          });
          break;
        }
      }
      
      logger.debug('🧹 AudioRecorder: MediaRecorder event handlers cleared', { 
        instanceId: instanceIdRef.current 
      });
      mediaRecorderRef.current = null;
    }

    // Stop media stream
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => {
        track.stop();
        logger.debug('🛑 AudioRecorder: Stopped media track', { kind: track.kind });
      });
      mediaStreamRef.current = null;
    }

    // Close audio context
    if (audioContextRef.current) {
      audioContextRef.current.close().catch(error => {
        logger.warn('⚠️ AudioRecorder: Failed to close audio context', { error });
      });
      audioContextRef.current = null;
    }

    // Clear refs and reset counters
    analyserRef.current = null;
    audioChunksRef.current = [];
    lastChunkLogTimeRef.current = 0;
    chunkCountSinceLastLogRef.current = 0;
    
    setAudioLevel(0);
    
    logger.debug('✅ AudioRecorder: Cleanup completed successfully', { 
      instanceId: instanceIdRef.current 
    });
  }, []);

  /**
   * Format recording duration for display
   */
  const formatDuration = useCallback((seconds: number): string => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  }, []);

  /**
   * Initialize component and clean up any orphaned instances
   */
  useEffect(() => {
    logger.info('🎤 AudioRecorder: Component mounted', { 
      instanceId: instanceIdRef.current,
      autoStart,
      disabled 
    });
    
    // Clean up any orphaned MediaRecorder instances from previous component unmounts
    if (globalMediaRecorderRegistry.size > 0) {
      logger.warn('⚠️ Found orphaned MediaRecorder instances, cleaning up', { 
        orphanedCount: globalMediaRecorderRegistry.size,
        instanceId: instanceIdRef.current
      });
      cleanupAllMediaRecorders();
    }
  }, []); // Only run on mount

  /**
   * Auto-start recording if requested
   */
  useEffect(() => {
    if (autoStart && recordingState === RecordingState.IDLE && !disabled) {
      logger.info('🚀 AudioRecorder: Auto-starting recording', { 
        instanceId: instanceIdRef.current 
      });
      startRecording();
    }
  }, [autoStart, disabled]); // Removed recordingState and startRecording to avoid infinite loop

  /**
   * Cleanup on component unmount
   */
  useEffect(() => {
    return () => {
      logger.debug('🧹 AudioRecorder: Component unmounting, cleaning up', { 
        instanceId: instanceIdRef.current 
      });
      cleanupRecording();
    };
  }, [cleanupRecording]);

  /**
   * Get CSS classes for recording state
   */
  const getRecordingStateClasses = useCallback(() => {
    const baseClasses = 'audio-recorder';
    const stateClasses = {
      [RecordingState.IDLE]: 'idle',
      [RecordingState.REQUESTING_PERMISSION]: 'requesting-permission',
      [RecordingState.RECORDING]: 'recording',
      [RecordingState.STOPPING]: 'stopping',
      [RecordingState.ERROR]: 'error'
    };

    return `${baseClasses} ${stateClasses[recordingState]} ${className}`.trim();
  }, [recordingState, className]);

  return (
    <div className={getRecordingStateClasses()}>
      {/* Recording button */}
      <button
        type="button"
        onClick={recordingState === RecordingState.RECORDING ? stopRecording : startRecording}
        disabled={disabled || recordingState === RecordingState.REQUESTING_PERMISSION || recordingState === RecordingState.STOPPING}
        className="audio-recorder-button"
        aria-label={recordingState === RecordingState.RECORDING ? 'Stop recording' : 'Start recording'}
        title={recordingState === RecordingState.RECORDING ? 'Stop recording' : 'Start voice recording'}
      >
        {recordingState === RecordingState.RECORDING ? (
          <div className="recording-indicator">
            🛑
          </div>
        ) : recordingState === RecordingState.REQUESTING_PERMISSION ? (
          <div className="permission-indicator">
            ⏳
          </div>
        ) : (
          <div className="microphone-icon">
            🎤
          </div>
        )}
      </button>

      {/* Recording status and feedback */}
      {recordingState !== RecordingState.IDLE && (
        <div className="recording-status">
          {recordingState === RecordingState.REQUESTING_PERMISSION && (
            <div className="status-message">Requesting microphone access...</div>
          )}
          
          {recordingState === RecordingState.RECORDING && (
            <>
              <div className="recording-duration">
                {formatDuration(recordingDuration)}
              </div>
              
              {showVisualFeedback && (
                <div className="audio-level-indicator">
                  <div 
                    className="audio-level-bar"
                    style={{ 
                      width: `${audioLevel}%`,
                      backgroundColor: audioLevel > 70 ? '#ef4444' : audioLevel > 40 ? '#f59e0b' : '#10b981'
                    }}
                  />
                </div>
              )}
            </>
          )}
          
          {recordingState === RecordingState.STOPPING && (
            <div className="status-message">Processing recording...</div>
          )}
          
          {recordingState === RecordingState.ERROR && errorMessage && (
            <div className="error-message" role="alert">
              {errorMessage}
            </div>
          )}
        </div>
      )}

      {/* Recording limits info */}
      {recordingState === RecordingState.RECORDING && (
        <div className="recording-info">
          Max duration: {Math.floor(audioConfig.maxDurationSeconds / 60)} minutes
        </div>
      )}
    </div>
  );
};

================
File: src/App.css
================
/**
 * FlowGenius App Styles
 * 
 * OpenAI-inspired design system with dark theme, clean typography,
 * and responsive layout for the main application interface.
 */

/* CSS Reset and Base Styles */
* {
  box-sizing: border-box;
  margin: 0;
  padding: 0;
}

/* App Container - Full viewport layout */
.app-container {
  display: flex;
  flex-direction: column;
  height: 100vh;
  width: 100vw;
  background-color: #171717;
  color: #ececec;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen',
    'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', 'Helvetica Neue',
    sans-serif;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  overflow: hidden;
}

/* Loading Overlay */
.loading-overlay {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(23, 23, 23, 0.8);
  display: flex;
  align-items: center;
  justify-content: center;
  z-index: 1000;
  backdrop-filter: blur(4px);
}

.loading-spinner {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 1rem;
  color: #ececec;
}

.spinner {
  width: 40px;
  height: 40px;
  border: 3px solid #2d2d2d;
  border-top: 3px solid #10a37f;
  border-radius: 50%;
  animation: spin 1s linear infinite;
}

@keyframes spin {
  0% { transform: rotate(0deg); }
  100% { transform: rotate(360deg); }
}

/* Mobile Header - Hidden on desktop */
.mobile-header {
  display: none;
  padding: 1rem;
  background-color: #202123;
  border-bottom: 1px solid #2d2d2d;
  align-items: center;
  gap: 1rem;
}

.hamburger-button {
  background: none;
  border: none;
  color: #ececec;
  cursor: pointer;
  padding: 0.5rem;
  border-radius: 0.375rem;
  transition: background-color 0.2s;
  display: flex;
  flex-direction: column;
  gap: 3px;
}

.hamburger-button:hover {
  background-color: #2d2d2d;
}

.hamburger-line {
  width: 18px;
  height: 2px;
  background-color: currentColor;
  transition: all 0.2s;
}

.mobile-title {
  font-size: 1.25rem;
  font-weight: 600;
  color: #ececec;
}

/* Main Layout - Sidebar + Chat */
.main-layout {
  display: flex;
  flex: 1;
  overflow: hidden;
}

/* Sidebar styles now handled by Tailwind CSS in Sidebar component */

/* Chat Main Area */
.chat-main {
  flex: 1;
  display: flex;
  flex-direction: column;
  background-color: #171717;
  overflow: hidden;
}

/* Chat Header */
.chat-header {
  padding: 1rem 1.5rem;
  border-bottom: 1px solid #2d2d2d;
  background-color: #171717;
}

.chat-header-content {
  display: flex;
  justify-content: space-between;
  align-items: center;
  max-width: 768px;
  margin: 0 auto;
}

.chat-title {
  font-size: 1.125rem;
  font-weight: 600;
  color: #ececec;
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

.chat-status {
  display: flex;
  align-items: center;
}

.status-indicator {
  font-size: 0.75rem;
  padding: 0.25rem 0.5rem;
  border-radius: 0.25rem;
  text-transform: capitalize;
}

.status-indicator.ready {
  background-color: rgba(16, 163, 127, 0.1);
  color: #10a37f;
}

.status-indicator.processing {
  background-color: rgba(255, 193, 7, 0.1);
  color: #ffc107;
  animation: pulse 2s infinite;
}

@keyframes pulse {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.5; }
}

@keyframes spin {
  from { transform: rotate(0deg); }
  to { transform: rotate(360deg); }
}

/* Chat Content */
.chat-content {
  flex: 1;
  overflow-y: auto;
  padding: 1rem;
  display: flex;
  flex-direction: column;
}

/* Welcome Message */
.welcome-message {
  max-width: 768px;
  margin: 2rem auto;
  text-align: center;
  padding: 2rem;
}

.welcome-message h2 {
  font-size: 2rem;
  font-weight: 600;
  color: #ececec;
  margin-bottom: 1rem;
}

.welcome-message p {
  font-size: 1rem;
  color: #8e8ea0;
  margin-bottom: 2rem;
  line-height: 1.5;
}

.workflow-stages {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 1rem;
  flex-wrap: wrap;
}

.stage-item {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  padding: 0.75rem 1rem;
  background-color: #202123;
  border-radius: 0.5rem;
  border: 1px solid #2d2d2d;
}

.stage-number {
  width: 24px;
  height: 24px;
  border-radius: 50%;
  background-color: #10a37f;
  color: #ffffff;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 0.75rem;
  font-weight: 600;
}

.stage-name {
  font-size: 0.875rem;
  font-weight: 500;
  color: #ececec;
}

.stage-arrow {
  color: #8e8ea0;
  font-size: 1.25rem;
}

/* Messages Container */
.messages-container {
  max-width: 768px;
  margin: 0 auto;
  width: 100%;
  display: flex;
  flex-direction: column;
  gap: 1.5rem;
}

.message {
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
}

.message-content {
  display: flex;
  gap: 0.75rem;
  align-items: flex-start;
}

.message-avatar {
  width: 32px;
  height: 32px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 0.875rem;
  font-weight: 600;
  flex-shrink: 0;
}

.message.user .message-avatar {
  background-color: #10a37f;
  color: #ffffff;
}

.message.assistant .message-avatar {
  background-color: #8e8ea0;
  color: #171717;
}

.message-text {
  flex: 1;
  padding: 0.75rem 1rem;
  background-color: #202123;
  border-radius: 0.75rem;
  line-height: 1.5;
  color: #ececec;
  word-wrap: break-word;
}

.message.user .message-text {
  background-color: #10a37f;
  color: #ffffff;
}

.message-meta {
  display: flex;
  justify-content: space-between;
  align-items: center;
  font-size: 0.75rem;
  color: #8e8ea0;
  margin-left: 44px;
}

.message-time {
  opacity: 0.7;
}

.message-stage {
  background-color: rgba(142, 142, 160, 0.1);
  padding: 0.125rem 0.375rem;
  border-radius: 0.25rem;
  text-transform: capitalize;
}

/* Chat Input Area */
.chat-input-area {
  padding: 1rem 1.5rem;
  border-top: 1px solid #2d2d2d;
  background-color: #171717;
}

/* InputBar Component Styles */
.input-bar-container {
  max-width: 768px;
  margin: 0 auto;
  width: 100%;
}

.character-warning {
  text-align: center;
  margin-bottom: 0.5rem;
  font-size: 0.75rem;
}

.input-bar {
  display: flex;
  align-items: flex-end;
  gap: 0.5rem;
  padding: 0.75rem;
  background-color: #202123;
  border: 1px solid #2d2d2d;
  border-radius: 0.75rem;
  transition: border-color 0.2s, box-shadow 0.2s;
}

.input-bar.focused {
  border-color: #10a37f;
  box-shadow: 0 0 0 2px rgba(16, 163, 127, 0.1);
}

.input-bar.disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

.input-text-container {
  flex: 1;
  min-height: 24px;
  max-height: 120px;
  overflow: hidden;
}

.input-textarea {
  width: 100%;
  background: none;
  border: none;
  color: #ececec;
  font-size: 0.875rem;
  line-height: 1.5;
  outline: none;
  resize: none;
  font-family: inherit;
  overflow-y: auto;
  scrollbar-width: thin;
  scrollbar-color: #2d2d2d #171717;
}

.input-textarea::placeholder {
  color: #8e8ea0;
}

.input-textarea:disabled {
  cursor: not-allowed;
}

/* Webkit scrollbar styles for textarea */
.input-textarea::-webkit-scrollbar {
  width: 4px;
}

.input-textarea::-webkit-scrollbar-track {
  background: transparent;
}

.input-textarea::-webkit-scrollbar-thumb {
  background: #2d2d2d;
  border-radius: 2px;
}

.input-textarea::-webkit-scrollbar-thumb:hover {
  background: #404040;
}

.input-action-button {
  display: flex;
  align-items: center;
  justify-content: center;
  width: 32px;
  height: 32px;
  background: none;
  border: none;
  border-radius: 0.375rem;
  cursor: pointer;
  transition: all 0.2s;
  flex-shrink: 0;
}

.input-action-button:disabled {
  cursor: not-allowed;
  opacity: 0.4;
}

.upload-button {
  color: #8e8ea0;
}

.upload-button:hover:not(:disabled) {
  color: #ececec;
  background-color: rgba(255, 255, 255, 0.05);
}

.voice-button {
  color: #8e8ea0;
}

.voice-button:hover:not(:disabled) {
  color: #ececec;
  background-color: rgba(255, 255, 255, 0.05);
}

.voice-button:active:not(:disabled) {
  color: #10a37f;
  background-color: rgba(16, 163, 127, 0.1);
}

.send-button {
  color: #8e8ea0;
}

.send-button.enabled {
  color: #10a37f;
  background-color: rgba(16, 163, 127, 0.1);
}

.send-button.enabled:hover {
  background-color: rgba(16, 163, 127, 0.2);
}

.send-button.enabled:active {
  background-color: rgba(16, 163, 127, 0.3);
}

.input-help {
  text-align: center;
  margin-top: 0.5rem;
  font-size: 0.75rem;
  color: #8e8ea0;
}

.help-text {
  font-style: italic;
}

/* Legacy placeholder styles (to be removed) */
.input-placeholder {
  max-width: 768px;
  margin: 0 auto;
  display: flex;
  gap: 0.5rem;
  align-items: center;
  padding: 0.75rem;
  background-color: #202123;
  border: 1px solid #2d2d2d;
  border-radius: 0.75rem;
}

.temp-input {
  flex: 1;
  background: none;
  border: none;
  color: #ececec;
  font-size: 0.875rem;
  outline: none;
}

.temp-input::placeholder {
  color: #8e8ea0;
}

.temp-mic-button,
.temp-send-button {
  background: none;
  border: none;
  color: #8e8ea0;
  cursor: not-allowed;
  padding: 0.5rem;
  border-radius: 0.375rem;
  font-size: 0.875rem;
  opacity: 0.5;
}

.input-disclaimer {
  text-align: center;
  font-size: 0.75rem;
  color: #8e8ea0;
  margin-top: 0.5rem;
  font-style: italic;
}

/* Audio Recorder Modal */
.audio-recorder-modal {
  position: fixed;
  bottom: 8rem;
  left: 50%;
  transform: translateX(-50%);
  z-index: 100;
  background-color: #2f2f2f;
  border: 1px solid #4d4d4f;
  border-radius: 1rem;
  padding: 1.5rem;
  box-shadow: 0 10px 25px rgba(0, 0, 0, 0.3);
  animation: slideUp 0.3s ease-out;
}

@keyframes slideUp {
  from {
    transform: translateX(-50%) translateY(20px);
    opacity: 0;
  }
  to {
    transform: translateX(-50%) translateY(0);
    opacity: 1;
  }
}

/* Error Banner */
.error-banner {
  position: fixed;
  top: 1rem;
  left: 50%;
  transform: translateX(-50%);
  z-index: 1000;
  max-width: 400px;
  width: calc(100% - 2rem);
}

.error-content {
  display: flex;
  align-items: center;
  gap: 0.75rem;
  padding: 0.75rem 1rem;
  background-color: #dc2626;
  color: #ffffff;
  border-radius: 0.5rem;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
}

.error-icon {
  font-size: 1.125rem;
}

.error-message {
  flex: 1;
  font-size: 0.875rem;
  line-height: 1.4;
}

.error-dismiss {
  background: none;
  border: none;
  color: #ffffff;
  cursor: pointer;
  padding: 0.25rem;
  border-radius: 0.25rem;
  font-size: 1rem;
  line-height: 1;
  transition: background-color 0.2s;
}

.error-dismiss:hover {
  background-color: rgba(255, 255, 255, 0.1);
}

/* Responsive Design */
@media (max-width: 768px) {
  .mobile-header {
    display: flex;
  }

  .sidebar {
    position: fixed;
    top: 0;
    left: 0;
    height: 100vh;
    z-index: 200;
    box-shadow: 2px 0 8px rgba(0, 0, 0, 0.3);
  }

  .sidebar-closed {
    transform: translateX(-100%);
  }

  .chat-header-content {
    padding: 0;
  }

  .chat-title {
    font-size: 1rem;
  }

  .workflow-stages {
    flex-direction: column;
    gap: 0.5rem;
  }

  .stage-arrow {
    transform: rotate(90deg);
  }

  .messages-container {
    padding: 0 0.5rem;
  }

  .message-meta {
    margin-left: 0;
    margin-top: 0.25rem;
  }

  .chat-input-area {
    padding: 1rem;
  }
}

@media (max-width: 480px) {
  .welcome-message {
    padding: 1rem;
    margin: 1rem auto;
  }

  .welcome-message h2 {
    font-size: 1.5rem;
  }

  .stage-item {
    padding: 0.5rem 0.75rem;
    width: 100%;
    justify-content: center;
  }

  .chat-header {
    padding: 0.75rem 1rem;
  }

  .input-placeholder {
    padding: 0.5rem;
  }
}

/* Accessibility */
@media (prefers-reduced-motion: reduce) {
  *,
  *::before,
  *::after {
    animation-duration: 0.01ms !important;
    animation-iteration-count: 1 !important;
    transition-duration: 0.01ms !important;
  }
}

/* Focus styles for keyboard navigation */
button:focus-visible,
input:focus-visible {
  outline: 2px solid #10a37f;
  outline-offset: 2px;
}

/* Scrollbar styling */
.sidebar-content::-webkit-scrollbar,
.chat-content::-webkit-scrollbar {
  width: 6px;
}

.sidebar-content::-webkit-scrollbar-track,
.chat-content::-webkit-scrollbar-track {
  background: transparent;
}

.sidebar-content::-webkit-scrollbar-thumb,
.chat-content::-webkit-scrollbar-thumb {
  background: #2d2d2d;
  border-radius: 3px;
}

.sidebar-content::-webkit-scrollbar-thumb:hover,
.chat-content::-webkit-scrollbar-thumb:hover {
  background: #4d4d4f;
}

================
File: package.json
================
{
  "name": "electron-vite-react",
  "version": "2.2.0",
  "main": "dist-electron/main/index.js",
  "description": "Electron Vite React boilerplate.",
  "author": "草鞋没号 <308487730@qq.com>",
  "license": "MIT",
  "private": true,
  "debug": {
    "env": {
      "VITE_DEV_SERVER_URL": "http://127.0.0.1:7777/"
    }
  },
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc && vite build && electron-builder",
    "preview": "vite preview",
    "pretest": "vite build --mode=test",
    "test": "vitest run",
    "test:watch": "vitest",
    "test:ui": "vitest --ui",
    "test:coverage": "vitest run --coverage",
    "test:e2e": "vitest run test/e2e.spec.ts",
    "test:unit": "vitest run src/",
    "lint": "eslint .",
    "lint:fix": "eslint . --fix",
    "type-check": "tsc --noEmit",
    "type-check:watch": "tsc --noEmit --watch",
    "check": "npm run type-check && npm run lint",
    "check:fix": "npm run type-check && npm run lint:fix"
  },
  "dependencies": {
    "@langchain/community": "^0.3.1",
    "@langchain/core": "^0.3.9",
    "@langchain/langgraph": "^0.2.28",
    "@langchain/openai": "^0.2.1",
    "@supabase/ssr": "^0.1.0",
    "@supabase/supabase-js": "^2.39.3",
    "dotenv": "^16.6.1",
    "electron-updater": "^6.3.9",
    "openai": "^4.67.3",
    "uuid": "^9.0.1"
  },
  "devDependencies": {
    "@eslint/js": "^9.30.0",
    "@playwright/test": "^1.48.2",
    "@testing-library/jest-dom": "^6.6.3",
    "@testing-library/react": "^16.3.0",
    "@testing-library/user-event": "^14.6.1",
    "@types/react": "^18.3.12",
    "@types/react-dom": "^18.3.1",
    "@types/uuid": "^9.0.8",
    "@typescript-eslint/eslint-plugin": "^8.35.1",
    "@typescript-eslint/parser": "^8.35.1",
    "@vitejs/plugin-react": "^4.3.3",
    "autoprefixer": "^10.4.20",
    "electron": "^33.2.0",
    "electron-builder": "^24.13.3",
    "eslint": "^8.57.1",
    "eslint-plugin-electron": "^7.0.0",
    "eslint-plugin-react": "^7.37.5",
    "eslint-plugin-react-hooks": "^5.2.0",
    "jsdom": "^26.1.0",
    "postcss": "^8.4.49",
    "postcss-import": "^16.1.0",
    "react": "^18.3.1",
    "react-dom": "^18.3.1",
    "tailwindcss": "^3.4.15",
    "typescript": "^5.4.2",
    "typescript-eslint": "^8.35.1",
    "vite": "^5.4.11",
    "vite-plugin-electron": "^0.29.0",
    "vite-plugin-electron-renderer": "^0.14.6",
    "vitest": "^2.1.5"
  },
  "overrides": {
    "@langchain/core": "^0.3.9"
  }
}

================
File: src/App.tsx
================
/**
 * Main Application Component
 * 
 * This is the root component for FlowGenius that implements an OpenAI-style layout
 * with a left sidebar for session management and a main chat pane for conversations.
 * It now uses the LangGraph context for state management and workflow execution.
 */

import { useState, useEffect, useCallback } from 'react';
import { IdeaEntity } from './types/AppState';
import { logger } from './utils/logger';
import { LangGraphProvider, useLangGraph, useSendMessage, useSessionManagement } from './hooks/useLangGraph';
import { useAudioRecording } from './hooks/useAudioRecording';
import { createWhisperService, WhisperService } from './services/whisperService';
import Sidebar from './components/Sidebar';
import Chat from './components/Chat';
import InputBar from './components/InputBar';
import { AudioRecorder, RecordingState } from './components/AudioRecorder';
import { PermissionDialog } from './components/PermissionDialog';
import './App.css';

/**
 * Mock session data for testing the sidebar functionality
 * TODO: Replace with real database integration in task 4.0
 */
const createMockSessions = (currentSessionId: string): IdeaEntity[] => [
  {
    id: currentSessionId,
    title: 'AI-Powered Task Manager',
    current_stage: 'brainstorm',
    created_at: new Date(Date.now() - 1000 * 60 * 30), // 30 minutes ago
    user_id: 'user_123'
  },
  {
    id: 'session_1704067200000_abc123',
    title: 'E-commerce Mobile App',
    current_stage: 'summary',
    created_at: new Date(Date.now() - 1000 * 60 * 60 * 2), // 2 hours ago
    user_id: 'user_123'
  },
  {
    id: 'session_1704060000000_def456',
    title: 'Social Media Analytics Dashboard',
    current_stage: 'prd',
    created_at: new Date(Date.now() - 1000 * 60 * 60 * 24), // 1 day ago
    user_id: 'user_123'
  },
  {
    id: 'session_1703980000000_ghi789',
    title: 'Voice Assistant Integration',
    current_stage: 'brainstorm',
    created_at: new Date(Date.now() - 1000 * 60 * 60 * 48), // 2 days ago
    user_id: 'user_123'
  }
];

/**
 * Inner App component that uses LangGraph hooks
 * This component has access to the LangGraph context
 */
function AppInner() {
  // LangGraph hooks for state and actions
  const { state: langGraphState, clearError } = useLangGraph();
  const { sendMessage, isLoading: isSendingMessage, error: sendMessageError } = useSendMessage();
  const { createNewSession, currentSession, isLoading: isSessionLoading } = useSessionManagement();

  // UI state for sidebar visibility (responsive design)
  const [isSidebarOpen, setIsSidebarOpen] = useState(true);
  
  // Input state for the message input bar
  const [inputValue, setInputValue] = useState('');

  // WhisperService instance for audio transcription
  const [whisperService, setWhisperService] = useState<WhisperService | null>(null);
  const [isTranscribing, setIsTranscribing] = useState(false);

  // Mock sessions data - will be replaced with real database data
  const [sessions, setSessions] = useState<IdeaEntity[]>(() => 
    createMockSessions(langGraphState.appState.idea_id)
  );

  // Extract current app state from LangGraph context
  const appState = langGraphState.appState;
  const isProcessing = langGraphState.isExecuting || isSendingMessage || isTranscribing;
  const currentError = langGraphState.error || sendMessageError;

  // Initialize WhisperService on component mount
  useEffect(() => {
    async function initializeWhisperService() {
      logger.info('🎤 Initializing WhisperService for voice transcription');
      
      try {
        const service = await createWhisperService();
        setWhisperService(service);
        
        logger.info('✅ WhisperService initialized successfully');
        
        // Test connection to verify API key
        try {
          const result = await service.testConnection();
          if (result.success) {
            logger.info('🔗 OpenAI API connection verified');
          } else {
            logger.warn('⚠️ OpenAI API connection test failed', { error: result.error });
          }
        } catch (error) {
          logger.warn('⚠️ OpenAI API connection test error', { 
            error: error instanceof Error ? error.message : String(error) 
          });
        }
        
      } catch (error) {
        const errorMsg = error instanceof Error ? error.message : String(error);
        logger.error('❌ Failed to initialize WhisperService', { error: errorMsg });
        
        // Don't block the app, just disable voice features
        if (errorMsg.includes('OPENAI_API_KEY')) {
          logger.warn('🔑 Voice transcription disabled - OpenAI API key not configured');
          logger.info('💡 To enable voice features: Set your OpenAI API key in the .env file');
        }
      }
    }

    initializeWhisperService();
  }, []);

  // Audio recording hook with WhisperService integration
  const audioRecording = useAudioRecording(async (audioBlob, duration) => {
    logger.info('🎤 Audio recording completed, starting transcription', { 
      blobSize: audioBlob.size, 
      duration,
      mimeType: audioBlob.type 
    });
    
    // Check if WhisperService is available
    if (!whisperService) {
      logger.warn('⚠️ WhisperService not available, using placeholder message');
      const placeholderMessage = `[Voice recording: ${duration}s - WhisperService not initialized]`;
      await handleSendMessage(placeholderMessage);
      return;
    }

    setIsTranscribing(true);
    
    try {
      logger.info('🔄 Starting audio transcription with Whisper API', {
        blobSize: audioBlob.size,
        duration,
        mimeType: audioBlob.type
      });

      // Transcribe the audio using WhisperService
      const transcriptionResult = await whisperService.transcribeBlob(audioBlob, {
        responseFormat: 'text',
        language: 'en', // Auto-detect if not specified
        temperature: 0.2, // Lower temperature for more consistent transcription
        prompt: 'This is a voice message for an AI assistant conversation.'
      });

      if (transcriptionResult.success && transcriptionResult.data?.text) {
        const transcribedText = transcriptionResult.data.text.trim();
        
        logger.info('✅ Audio transcription completed successfully', {
          transcriptionLength: transcribedText.length,
          duration: transcriptionResult.duration,
          retryCount: transcriptionResult.retryCount
        });

        // Log the transcription for debugging
        logger.debug('📝 Transcribed text', { text: transcribedText });

        // Send the transcribed text as a message
        if (transcribedText) {
          await handleSendMessage(transcribedText);
        } else {
          logger.warn('⚠️ Transcription was empty, sending placeholder');
          await handleSendMessage(`[Voice recording: ${duration}s - No speech detected]`);
        }

      } else {
        // Handle transcription failure
        const errorMsg = transcriptionResult.error || 'Unknown transcription error';
        logger.error('❌ Audio transcription failed', { 
          error: errorMsg,
          duration: transcriptionResult.duration,
          retryCount: transcriptionResult.retryCount
        });

        // Send error message to chat
        const errorMessage = `[Voice recording: ${duration}s - Transcription failed: ${errorMsg}]`;
        await handleSendMessage(errorMessage);
      }

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      logger.error('❌ Unexpected error during audio transcription', { 
        error: errorMsg,
        duration 
      });

      // Send error message to chat
      const errorMessage = `[Voice recording: ${duration}s - Transcription error: ${errorMsg}]`;
      await handleSendMessage(errorMessage);

    } finally {
      setIsTranscribing(false);
    }
  });

  /**
   * Handles input value changes
   */
  const handleInputChange = useCallback((value: string) => {
    setInputValue(value);
  }, []);

  /**
   * Toggles the sidebar visibility for responsive design
   */
  const toggleSidebar = useCallback(() => {
    logger.debug('🔄 Toggling sidebar visibility', { currentState: isSidebarOpen });
    setIsSidebarOpen(prev => !prev);
  }, [isSidebarOpen]);

  /**
   * Handles sending a message through the LangGraph workflow
   */
  const handleSendMessage = useCallback(async (message: string) => {
    // Validate message
    if (!message.trim() || isProcessing) {
      logger.debug('🚫 Message send blocked', { 
        hasContent: !!message.trim(),
        isProcessing
      });
      return;
    }

    logger.info('📤 Sending user message via LangGraph', { 
      messageLength: message.length,
      currentStage: appState.current_stage,
      sessionId: appState.idea_id
    });

    try {
      // Send message through LangGraph workflow
      await sendMessage(message);
      
      // Clear input on successful send
      setInputValue('');
      
      logger.info('✅ Message sent successfully via LangGraph', { 
        messageLength: message.length,
        sessionId: appState.idea_id
      });
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error('❌ Failed to send message via LangGraph', { 
        error: errorMessage,
        sessionId: appState.idea_id
      });
    }
  }, [sendMessage, isProcessing, appState.current_stage, appState.idea_id]);

  /**
   * Handles voice recording requests from the InputBar
   */
  const handleVoiceRecord = useCallback(() => {
    logger.info('🎤 Voice recording requested');
    audioRecording.startRecording();
  }, [audioRecording]);

  /**
   * Handles file upload requests from the InputBar
   * TODO: Implement file upload functionality in future tasks
   */
  const handleFileUpload = useCallback(() => {
    logger.info('📎 File upload requested (not yet implemented)');
    // TODO: Implement file upload functionality
  }, []);

  /**
   * Creates a new session using LangGraph
   */
  const handleCreateNewSession = useCallback(async () => {
    logger.info('🆕 Creating new session via LangGraph');
    
    try {
      await createNewSession('user_123');
      
      // Add new session to mock sessions list
      const newSession: IdeaEntity = {
        id: currentSession,
        title: `New Session ${new Date().toLocaleTimeString()}`,
        current_stage: 'brainstorm',
        created_at: new Date(),
        user_id: 'user_123'
      };
      
      setSessions(prevSessions => [newSession, ...prevSessions]);
      
      logger.info('✅ New session created successfully via LangGraph', { 
        sessionId: currentSession 
      });
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger.error('❌ Failed to create new session', { error: errorMessage });
    }
  }, [createNewSession, currentSession]);

  /**
   * Switches to a different session
   * TODO: This will be fully implemented when we add session persistence in task 4.0
   */
  const handleSessionSwitch = useCallback((sessionId: string) => {
    logger.info('🔄 Session switch requested (placeholder)', { sessionId });
    // TODO: Implement actual session switching with LangGraph context
    // For now, just log the request
  }, []);

  /**
   * Deletes a session
   * TODO: Implement when we add session persistence in task 4.0
   */
  const handleDeleteSession = useCallback((sessionId: string) => {
    logger.info('🗑️ Session deletion requested (placeholder)', { sessionId });
    // TODO: Implement actual session deletion
  }, []);

  /**
   * Renames a session
   * TODO: Implement when we add session persistence in task 4.0
   */
  const handleRenameSession = useCallback((sessionId: string, newTitle: string) => {
    logger.info('✏️ Session rename requested (placeholder)', { sessionId, newTitle });
    // TODO: Implement actual session renaming
  }, []);

  /**
   * Clears the current error state
   */
  const handleClearError = useCallback(() => {
    logger.info('🧹 Clearing error state');
    clearError();
  }, [clearError]);

  // Log app initialization and state changes
  useEffect(() => {
    logger.info('🚀 FlowGenius App component mounted with LangGraph', {
      sessionId: appState.idea_id,
      currentStage: appState.current_stage,
      messageCount: appState.messages.length,
      totalSessions: sessions.length
    });

    return () => {
      logger.info('🔄 FlowGenius App component unmounting', {
        sessionId: appState.idea_id,
        finalMessageCount: appState.messages.length
      });
    };
  }, [appState.idea_id, appState.current_stage, appState.messages.length, sessions.length]);

  // Log LangGraph state changes for debugging
  useEffect(() => {
    logger.debug('📊 LangGraph state changed', {
      stage: appState.current_stage,
      messageCount: appState.messages.length,
      isExecuting: langGraphState.isExecuting,
      lastAction: appState.last_user_action,
      hasError: !!langGraphState.error
    });
  }, [
    appState.current_stage, 
    appState.messages.length, 
    langGraphState.isExecuting, 
    appState.last_user_action, 
    langGraphState.error
  ]);

  return (
    <div className="app-container">
      {/* Mobile header with hamburger menu */}
      <div className="mobile-header">
        <button 
          className="hamburger-button"
          onClick={toggleSidebar}
          aria-label="Toggle sidebar"
        >
          <span className="hamburger-line"></span>
          <span className="hamburger-line"></span>
          <span className="hamburger-line"></span>
        </button>
        <h1 className="mobile-title">FlowGenius</h1>
      </div>

      {/* Main layout container */}
      <div className="main-layout">
        {/* Sidebar Component */}
        <Sidebar
          currentAppState={appState}
          isOpen={isSidebarOpen}
          onToggle={toggleSidebar}
          onCreateNewSession={handleCreateNewSession}
          onSessionSwitch={handleSessionSwitch}
          sessions={sessions}
          isLoading={isSessionLoading}
          onDeleteSession={handleDeleteSession}
          onRenameSession={handleRenameSession}
        />

        {/* Main Chat Area */}
        <main className="chat-main">
          {/* Chat header with current session info */}
          <header className="chat-header">
            <div className="chat-header-content">
              <h1 className="chat-title">
                {appState.title || 'New Conversation'}
              </h1>
              <div className="chat-status">
                <span className={`status-indicator ${isProcessing ? 'processing' : 'ready'}`}>
                  {isProcessing ? 'Processing...' : `${appState.current_stage} stage`}
                </span>
                {langGraphState.executionHistory.length > 0 && (
                  <span className="execution-count">
                    {langGraphState.executionHistory.length} executions
                  </span>
                )}
              </div>
            </div>
          </header>

          {/* Chat messages area */}
          <div className="chat-content">
            <Chat
              messages={appState.messages}
              currentStage={appState.current_stage}
              isProcessing={isProcessing}
              autoScroll={true}
              onMessageAction={(action, messageIndex) => {
                logger.info('🎯 Chat message action triggered', { action, messageIndex });
                // TODO: Implement message actions (copy, regenerate, etc.)
              }}
            />
          </div>

          {/* Input area */}
          <div className="chat-input-area">
            <InputBar
              value={inputValue}
              onChange={handleInputChange}
              onSend={handleSendMessage}
              onVoiceRecord={handleVoiceRecord}
              onFileUpload={handleFileUpload}
              isProcessing={isProcessing}
              isVoiceEnabled={true}
              isUploadEnabled={true} // For future implementation
              placeholder="Message FlowGenius..."
              disabled={isProcessing}
            />
            
            {/* Audio Recorder Modal (shows when recording is active) */}
            {audioRecording.hasPermission && audioRecording.recordingState !== RecordingState.IDLE && (
              <div className="audio-recorder-modal">
                <AudioRecorder
                  onRecordingComplete={audioRecording.handleRecordingComplete}
                  onRecordingError={audioRecording.handleRecordingError}
                  onStateChange={audioRecording.handleRecordingStateChange}
                  disabled={isProcessing}
                  autoStart={true}
                />
              </div>
            )}
          </div>
        </main>
      </div>

      {/* Permission Dialog */}
      <PermissionDialog
        isOpen={audioRecording.isPermissionDialogOpen}
        onPermissionGranted={audioRecording.handlePermissionGranted}
        onPermissionDenied={audioRecording.handlePermissionDenied}
        onClose={audioRecording.closePermissionDialog}
        showTroubleshooting={audioRecording.showTroubleshooting}
        errorMessage={audioRecording.errorMessage || undefined}
      />

      {/* Error display */}
      {currentError && (
        <div className="error-banner">
          <div className="error-content">
            <span className="error-icon">⚠️</span>
            <span className="error-message">{currentError}</span>
            <button 
              className="error-dismiss"
              onClick={handleClearError}
            >
              ✕
            </button>
          </div>
        </div>
      )}

      {/* Debug info in development */}
      {process.env.NODE_ENV === 'development' && (
        <div className="debug-info">
          <details>
            <summary>🔍 LangGraph Debug Info</summary>
            <pre>{JSON.stringify({
              currentStage: appState.current_stage,
              lastAction: appState.last_user_action,
              messageCount: appState.messages.length,
              isExecuting: langGraphState.isExecuting,
              executionCount: langGraphState.metrics.totalExecutions,
              avgExecutionTime: Math.round(langGraphState.metrics.averageExecutionTime)
            }, null, 2)}</pre>
          </details>
        </div>
      )}
    </div>
  );
}

/**
 * Main App component with LangGraph provider
 * This wraps the inner component with the LangGraph context
 */
function App() {
  return (
    <LangGraphProvider>
      <AppInner />
    </LangGraphProvider>
  );
}

export default App;

================
File: tasks/tasks-mvp.md
================
## Relevant Files

- `src/types/AppState.ts` - Core TypeScript interface for the entire application state as defined in FlowGenius.md
- `src/types/AppState.test.ts` - Unit tests for AppState interface validation
- `src/supabaseClient.ts` - Supabase client configuration and initialization
- `src/supabaseClient.test.ts` - Unit tests for Supabase client connection and operations
- `src/components/Sidebar.tsx` - Session management sidebar component (OpenAI-style)
- `src/components/Sidebar.test.tsx` - Unit tests for Sidebar component
- `src/components/Chat.tsx` - Main chat interface component with message display
- `src/components/Chat.test.tsx` - Unit tests for Chat component
- `src/components/AudioRecorder.tsx` - Voice recording component with MediaRecorder API
- `src/components/AudioRecorder.test.tsx` - Unit tests for AudioRecorder component
- `src/components/InputBar.tsx` - Bottom input bar with text field, microphone, and upload icons
- `src/components/InputBar.test.tsx` - Unit tests for InputBar component
- `src/components/ConsoleLog.tsx` - Collapsible console log panel for debugging app errors and logs
- `src/components/ConsoleLog.test.tsx` - Unit tests for ConsoleLog component
- `src/langgraph/index.ts` - Main LangGraph workflow setup and initialization
- `src/hooks/useLangGraph.tsx` - React context and hooks for LangGraph integration
- `src/langgraph/nodes/processUserTurn.ts` - LangGraph node for handling standard chat messages
- `src/langgraph/nodes/processVoiceInput.ts` - LangGraph node for processing voice-to-text
- `src/langgraph/nodes/generateSummary.ts` - LangGraph node for generating summaries with GPT-4o
- `src/langgraph/nodes/index.ts` - Export all LangGraph nodes
- `src/langgraph/router.ts` - Conditional routing logic for LangGraph workflow
- `src/langgraph/state.ts` - LangGraph state management utilities and AppState interface
- `src/langgraph/langgraph.test.ts` - Unit tests for LangGraph workflow
- `src/services/whisperService.ts` - Service for handling Whisper API calls
- `src/services/whisperService.test.ts` - Unit tests for Whisper service
- `src/services/openaiService.ts` - Service for handling OpenAI GPT-4o API calls
- `src/services/openaiService.test.ts` - Unit tests for OpenAI service
- `src/services/supabaseService.ts` - Service for database operations (ideas, chat_messages, prompts)
- `src/services/supabaseService.test.ts` - Unit tests for Supabase service
- `src/utils/logger.ts` - Centralized logging utility for debugging and monitoring
- `src/utils/errorHandler.ts` - Global error handling utility with user-friendly error messages and recovery suggestions
- `src/utils/errorHandler.ts` - Global error handling utility
- `src/utils/audioUtils.ts` - Audio processing utilities (format conversion, validation)
- `src/utils/audioUtils.test.ts` - Unit tests for audio utilities
- `src/styles/globals.css` - Global CSS styles with OpenAI-inspired design system, CSS custom properties, typography, and comprehensive utility classes
- `src/styles/components.css` - Component-specific CSS styles with button variants, input components, cards, navigation, status indicators, and loading states
- `src/styles/responsive.css` - Desktop-focused responsive design for Electron window resizing with breakpoints for compact, standard, large, and ultra-wide desktop layouts
- `src/App.tsx` - Main application component with layout and state management
- `src/App.test.tsx` - Unit tests for main App component
- `.env.example` - Example environment variables file
- `README.md` - Updated project documentation with setup instructions
- `package.json` - Updated dependencies for LangGraph, Supabase, audio recording

### Notes

- **LangGraph First**: We build the LangGraph workflow engine early (task 3.0) because it's the orchestration layer that connects all features. This prevents having to retrofit isolated functions later.
- Unit tests should typically be placed alongside the code files they are testing (e.g., `MyComponent.tsx` and `MyComponent.test.tsx` in the same directory).
- Use `npm test` to run all tests found by the Jest configuration.
- All components must be thoroughly commented with JSDoc and include extensive console logging.
- The codebase must be modular and extensible for easy addition of future features.
- UI styling must closely match OpenAI's ChatGPT interface based on the provided screenshots.

## Tasks

- [x] 1.0 Set up project structure for modular, extensible architecture
  - [x] 1.1 Create comprehensive TypeScript interfaces for AppState matching FlowGenius.md specification
  - [x] 1.2 Set up folder structure for modular components (components/, services/, utils/, langgraph/, styles/)
  - [x] 1.3 Configure TypeScript strict mode and ESLint rules for code quality
  - [x] 1.4 Set up centralized logging utility with different log levels (debug, info, warn, error)
  - [x] 1.5 Create global error handling utility with user-friendly error messages
  - [x] 1.6 Set up testing framework (Vitest + React Testing Library) with configuration for React components and TypeScript
  - [x] 1.7 Create .env.example file with all required environment variables documented
  - [x] 1.8 Update package.json with all required dependencies (LangGraph, Supabase, audio libraries)
  - [x] 1.9 Create environment validation script to check all required API keys and connections on startup

- [ ] 2.0 Implement OpenAI-style UI with sidebar, chat, and input bar
  - [x] 2.1 Create main App.tsx layout with left sidebar and main chat pane (matching OpenAI's layout)
  - [x] 2.2 Implement Sidebar component with session list, create new session button, and OpenAI styling
  - [x] 2.3 Create Chat component with message display, scrolling, and continuous thread design
  - [x] 2.4 Build InputBar component with text field, microphone icon, and upload icon (styled like OpenAI)
  - [ ] 2.5 Create ConsoleLog component for real-time debugging (collapsible panel showing app logs/errors)
  - [x] 2.6 Implement global CSS styles matching OpenAI's color scheme, typography, and spacing
  - [x] 2.7 Add responsive design considerations for different window sizes
  - [ ] 2.8 Create component-specific CSS with proper hover states and animations
  - [ ] 2.9 Implement proper accessibility features (ARIA labels, keyboard navigation)

- [ ] 3.0 Set up LangGraph workflow engine for MVP (recording → summarization)
  - [x] 3.1 Initialize LangGraph StateGraph with AppState interface from FlowGenius.md
  - [x] 3.2 Create base node structure for processUserTurn (will handle chat messages)
  - [x] 3.3 Create placeholder nodes for V2T and summarization (to be implemented)
  - [x] 3.4 Implement conditional routing logic based on last_user_action
  - [x] 3.5 Create state management utilities for LangGraph workflow
  - [x] 3.6 Add workflow execution logging and debugging capabilities
  - [x] 3.7 Implement workflow error handling and recovery mechanisms
  - [ ] 3.8 Create workflow testing utilities with mock implementations
  - [x] 3.9 Create React hooks/context for connecting UI components to LangGraph workflow

- [ ] 4.0 Integrate Supabase for persistent chat/session data
  - [ ] 4.1 Set up Supabase client configuration with environment variables
  - [ ] 4.2 Create database schema matching FlowGenius.md (ideas, chat_messages, prompts tables)
  - [ ] 4.3 Implement SupabaseService with CRUD operations for all entities
  - [ ] 4.4 Add real-time subscriptions for chat messages and session updates
  - [ ] 4.5 Create data validation and sanitization for all database operations
  - [ ] 4.6 Implement proper error handling for network failures and database errors
  - [ ] 4.7 Add database migration scripts and setup documentation
  - [ ] 4.8 Create comprehensive logging for all database operations

- [ ] 5.0 Implement voice-to-text node with Whisper API
  - [x] 5.1 Create AudioRecorder component using MediaRecorder API with proper browser compatibility
  - [x] 5.2 Implement microphone permission handling with user-friendly prompts
  - [ ] 5.3 Add visual feedback during recording (blue ebbing microphone icon like GPT-4o)
  - [x] 5.4 Create audio format validation and conversion utilities (ensure Whisper API compatibility)
  - [x] 5.5 Build WhisperService for handling API calls with proper error handling and retries
  - [ ] 5.6 Integrate V2T functionality as a LangGraph node
  - [ ] 5.7 Add recording duration limits and progress indicators
  - [ ] 5.8 Create comprehensive error handling for audio recording failures

- [ ] 6.0 Implement summarization node using OpenAI GPT-4o
  - [ ] 6.1 Create OpenAI service with GPT-4o API integration and proper authentication
  - [ ] 6.2 Implement generateSummary as a proper LangGraph node with context management
  - [ ] 6.3 Create prompt templates for summarization (ending with "Ireland is great" as specified)
  - [ ] 6.4 Add token counting and context window management for large conversations
  - [ ] 6.5 Implement streaming responses for better user experience
  - [ ] 6.6 Add retry logic and rate limiting for API calls
  - [ ] 6.7 Create response validation and error handling for malformed AI responses
  - [ ] 6.8 Add comprehensive logging for all AI interactions and debugging

- [ ] 7.0 Implement simple session management sidebar (scaffold for future)
  - [ ] 7.1 Create session list display with idea titles and creation dates
  - [ ] 7.2 Implement "Create New Session" functionality with database persistence
  - [ ] 7.3 Add session switching with proper state management and chat history loading
  - [ ] 7.4 Create session deletion functionality (soft delete for data integrity)
  - [ ] 7.5 Implement session search and filtering capabilities (scaffold for future)
  - [ ] 7.6 Add session export functionality (copy to clipboard, JSON export)
  - [ ] 7.7 Create session metadata display (stage, message count, last updated)
  - [ ] 7.8 Implement proper loading states and error handling for session operations
  - [ ] 7.9 Ensure LangGraph state syncs properly with UI state and database on session switches

- [ ] 8.0 Add logging, error handling, and comments throughout
  - [ ] 8.1 Add JSDoc comments to all functions, classes, and interfaces
  - [ ] 8.2 Implement comprehensive console logging for all user interactions
  - [ ] 8.3 Add error boundaries in React components for graceful error handling
  - [ ] 8.4 Create user-friendly error messages and recovery suggestions
  - [ ] 8.5 Add performance monitoring and logging for API calls and database operations
  - [ ] 8.6 Implement debug mode with verbose logging for development
  - [ ] 8.7 Add input validation and sanitization with proper error messages
  - [ ] 8.8 Create comprehensive testing documentation and examples
  - [ ] 8.9 Create end-to-end tests for complete voice → summary workflow




================================================================
End of Codebase
================================================================
